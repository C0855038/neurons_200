{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pg_from_scratch (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "0l9hHvTk6ec8"
      },
      "cell_type": "markdown",
      "source": [
        "# Policy Gradient\n",
        "\n",
        "* http://karpathy.github.io/2016/05/31/rl/\n",
        "* https://gist.github.com/karpathy/a4166c7fe253700972fcbc77e4ea32c5\n",
        "* https://github.com/gameofdimension/policy-gradient-pong\n",
        "* https://www.youtube.com/watch?v=tqrcjHuNdmQ\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "mqkOdLyN9Ylm"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 1: Installation for Colab - just execute these cells and do not worry too much\n",
        "\n",
        "* http://nbviewer.jupyter.org/github/patrickmineault/xcorr-notebooks/blob/master/Render%20OpenAI%20gym%20as%20GIF.ipynb \n",
        "* https://docs.microsoft.com/en-us/message-passing-interface/microsoft-mpi\n",
        "* https://nyu-cds.github.io/python-mpi/setup/\n",
        "* https://medium.com/@kaleajit27/reinforcement-learning-on-google-colab-9cb2e1ef51e\n"
      ]
    },
    {
      "metadata": {
        "id": "uF9MAVI16huj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2ac98f2-d242-4e76-ddb4-3b3fe95d9017"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install python-opengl -y  >/dev/null\n",
        "!apt install xvfb -y >/dev/null"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "fSC11TfN6p69"
      },
      "cell_type": "code",
      "source": [
        "!pip install pyvirtualdisplay >/dev/null\n",
        "!pip install piglet >/dev/null"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "caiHE2hy6xrf"
      },
      "cell_type": "code",
      "source": [
        "# from pyvirtualdisplay import Display\n",
        "# display = Display(visible=0, size=(1400, 900))\n",
        "# display.start()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cWACPRL869I4"
      },
      "cell_type": "code",
      "source": [
        "!pip install gym >/dev/null"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Os6feRY6ec_"
      },
      "cell_type": "code",
      "source": [
        "!pip install JSAnimation >/dev/null"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wotUOa_e6edP"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from JSAnimation.IPython_display import display_animation\n",
        "from matplotlib import animation\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def display_frames_as_gif(frames):\n",
        "    \"\"\"\n",
        "    Displays a list of frames as a gif, with controls\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n",
        "    patch = plt.imshow(frames[0])\n",
        "    plt.axis('off')\n",
        "\n",
        "    def animate(i):\n",
        "        patch.set_data(frames[i])\n",
        "\n",
        "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
        "    HTML(anim.to_jshtml())"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R66_INeZ9nYX"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2: Playing Pong"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U gym>=0.21.0\n",
        "%pip install -U gym[atari,accept-rom-license]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ngMhg3fB9aA",
        "outputId": "5e8e931e-b3fe-4bd2-ba00-2243184f7f45"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.25.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.12.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.7)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n",
            "Collecting autorom[accept-rom-license]~=0.4.2\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Collecting ale-py~=0.7.5\n",
            "  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 34.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n",
            "Collecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=79c5d6023f4d683765a37acded875f9de7d27f2f7c5a299c73bf6cd2d08c14be\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: AutoROM.accept-rom-license, autorom, ale-py\n",
            "Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "MtT2GyK_6edc",
        "outputId": "6eb224e1-ce06-4486-a0a6-a3fcf815b722",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "env = gym.make('Pong-v0')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:594: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  f\"The environment {id} is out of date. You should consider \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "oRE6WmXQJ1Z0",
        "outputId": "2971a141-059f-48bc-c2a3-b3a20ab8f305",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "env.action_space"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(6)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "yl_9d4HFJ31W",
        "outputId": "7cc9b473-3a4f-46d3-a01e-4396ae401b6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "env.observation_space"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Box(0, 255, (210, 160, 3), uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "trwRXI-h6eeI",
        "outputId": "b132e236-ca88-443c-98da-6b0453af6645",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Run a demo of the environment\n",
        "observation = env.reset()\n",
        "cumulated_reward = 0\n",
        "\n",
        "frames = []\n",
        "for t in range(1000):\n",
        "#     print(observation)\n",
        "    frames.append(env.render(mode = 'rgb_array'))\n",
        "    # very stupid agent, just makes a random action within the allowd action space\n",
        "    action = env.action_space.sample()\n",
        "#     print(\"Action: {}\".format(t+1))    \n",
        "    observation, reward, done, info = env.step(action)\n",
        "#     print(reward)\n",
        "    cumulated_reward += reward\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
        "        break\n",
        "print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
        "\n",
        "env.close()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
            "  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  \"Core environment is written in old step API which returns one bool instead of two. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -20.0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "3zZTecVWLLes"
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(x): \n",
        "  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n",
        "\n",
        "def prepro(I):\n",
        "  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
        "  I = I[35:195] # crop\n",
        "  I = I[::2,::2,0] # downsample by factor of 2\n",
        "  I[I == 144] = 0 # erase background (background type 1)\n",
        "  I[I == 109] = 0 # erase background (background type 2)\n",
        "  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
        "  return I.astype(np.float).ravel()\n",
        "\n",
        "def policy_forward(x):\n",
        "  h = np.dot(model['W1'], x)\n",
        "  h[h<0] = 0 # ReLU nonlinearity\n",
        "  logp = np.dot(model['W2'], h)\n",
        "  p = sigmoid(logp)\n",
        "  return p, h # return probability of taking action 2, and hidden state\n",
        "\n",
        "def model_step(model, observation, prev_x):\n",
        "  # preprocess the observation, set input to network to be difference image\n",
        "  cur_x = prepro(observation)\n",
        "  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
        "  prev_x = cur_x\n",
        "  \n",
        "  # forward the policy network and sample an action from the returned probability\n",
        "  aprob, _ = policy_forward(x)\n",
        "  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n",
        "  \n",
        "  return action, prev_x\n",
        "\n",
        "def play_game(env, model):\n",
        "  observation = env.reset()\n",
        "\n",
        "  frames = []\n",
        "  cumulated_reward = 0\n",
        "\n",
        "  prev_x = None # used in computing the difference frame\n",
        "\n",
        "  for t in range(1000):\n",
        "      frames.append(env.render(mode = 'rgb_array'))\n",
        "      action, prev_x = model_step(model, observation, prev_x)\n",
        "      observation, reward, done, info = env.step(action)\n",
        "      cumulated_reward += reward\n",
        "      if done:\n",
        "          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
        "          break\n",
        "  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
        "  env.close()\n",
        "  display_frames_as_gif(frames)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6gWvZQ7AQLQt"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3: Policy Gradient from Scratch"
      ]
    },
    {
      "metadata": {
        "id": "eqFm7hqcItWl"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# model initialization\n",
        "H = 200 # number of hidden layer neurons\n",
        "D = 80 * 80 # input dimensionality: 80x80 grid\n",
        "model = {}\n",
        "model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n",
        "model['W2'] = np.random.randn(H) / np.sqrt(H)\n",
        "\n",
        "# import pickle\n",
        "# model = pickle.load(open('model.pkl', 'rb'))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TwjiwKisQM19"
      },
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "batch_size = 3 # every how many episodes to do a param update?\n",
        "# learning_rate = 1e-4\n",
        "learning_rate = 1e-4\n",
        " \n",
        "gamma = 0.99 # discount factor for reward\n",
        "decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n",
        "  \n",
        "grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n",
        "rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n",
        "\n",
        "def discount_rewards(r):\n",
        "  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
        "  discounted_r = np.zeros_like(r, dtype=np.float32)\n",
        "  running_add = 0\n",
        "  for t in reversed(range(0, r.size)):\n",
        "    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
        "    running_add = running_add * gamma + r[t]\n",
        "    discounted_r[t] = running_add\n",
        "  return discounted_r\n",
        "\n",
        "def policy_backward(epx, eph, epdlogp):\n",
        "  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n",
        "  dW2 = np.dot(eph.T, epdlogp).ravel()\n",
        "  dh = np.outer(epdlogp, model['W2'])\n",
        "  dh[eph <= 0] = 0 # backpro prelu\n",
        "  dW1 = np.dot(dh.T, epx)\n",
        "  return {'W1':dW1, 'W2':dW2}\n",
        "\n",
        "def train_model(env, model, total_episodes = 100):\n",
        "  hist = []\n",
        "  observation = env.reset()\n",
        "\n",
        "  prev_x = None # used in computing the difference frame\n",
        "  xs,hs,dlogps,drs = [],[],[],[]\n",
        "  running_reward = None\n",
        "  reward_sum = 0\n",
        "  episode_number = 0\n",
        "\n",
        "  while True:\n",
        "    # preprocess the observation, set input to network to be difference image\n",
        "    cur_x = prepro(observation)\n",
        "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
        "    prev_x = cur_x\n",
        "\n",
        "    # forward the policy network and sample an action from the returned probability\n",
        "    aprob, h = policy_forward(x)\n",
        "    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n",
        "\n",
        "    # record various intermediates (needed later for backprop)\n",
        "    xs.append(x) # observation\n",
        "    hs.append(h) # hidden state\n",
        "    y = 1 if action == 2 else 0 # a \"fake label\"\n",
        "    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n",
        "\n",
        "    # step the environment and get new measurements\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    reward_sum += reward\n",
        "\n",
        "    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
        "\n",
        "    if done: # an episode finished\n",
        "      episode_number += 1\n",
        "\n",
        "      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
        "      epx = np.vstack(xs)\n",
        "      eph = np.vstack(hs)\n",
        "      epdlogp = np.vstack(dlogps)\n",
        "      epr = np.vstack(drs)\n",
        "      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n",
        "\n",
        "      # compute the discounted reward backwards through time\n",
        "      discounted_epr = discount_rewards(epr)\n",
        "      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n",
        "      discounted_epr -= np.mean(discounted_epr)\n",
        "      discounted_epr /= np.std(discounted_epr)\n",
        "\n",
        "      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n",
        "      grad = policy_backward(epx, eph, epdlogp)\n",
        "      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n",
        "\n",
        "      # perform rmsprop parameter update every batch_size episodes\n",
        "      if episode_number % batch_size == 0:\n",
        "        for k,v in model.items():\n",
        "          g = grad_buffer[k] # gradient\n",
        "          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n",
        "          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
        "          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n",
        "\n",
        "      # boring book-keeping\n",
        "      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
        "      hist.append((episode_number, reward_sum, running_reward))\n",
        "      print ('resetting env. episode %f, reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n",
        "      reward_sum = 0\n",
        "      observation = env.reset() # reset env\n",
        "      prev_x = None\n",
        "      if episode_number == total_episodes: return hist\n",
        "\n",
        "      if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n",
        "        print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6Ka_5Vl9Orm",
        "outputId": "5dda046a-9b58-4684-c701-5d4e8eafbd35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "%time hist1 = train_model(env, model, total_episodes=500)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n",
            "resetting env. episode 2.000000, reward total was -21.000000. running mean: -21.000000\n",
            "resetting env. episode 3.000000, reward total was -21.000000. running mean: -21.000000\n",
            "resetting env. episode 4.000000, reward total was -19.000000. running mean: -20.980000\n",
            "resetting env. episode 5.000000, reward total was -21.000000. running mean: -20.980200\n",
            "resetting env. episode 6.000000, reward total was -19.000000. running mean: -20.960398\n",
            "resetting env. episode 7.000000, reward total was -20.000000. running mean: -20.950794\n",
            "resetting env. episode 8.000000, reward total was -18.000000. running mean: -20.921286\n",
            "resetting env. episode 9.000000, reward total was -20.000000. running mean: -20.912073\n",
            "resetting env. episode 10.000000, reward total was -17.000000. running mean: -20.872952\n",
            "resetting env. episode 11.000000, reward total was -20.000000. running mean: -20.864223\n",
            "resetting env. episode 12.000000, reward total was -20.000000. running mean: -20.855581\n",
            "resetting env. episode 13.000000, reward total was -20.000000. running mean: -20.847025\n",
            "resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.848555\n",
            "resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.850069\n",
            "resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.851568\n",
            "resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.853053\n",
            "resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.854522\n",
            "resetting env. episode 19.000000, reward total was -20.000000. running mean: -20.845977\n",
            "resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.847517\n",
            "resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.849042\n",
            "resetting env. episode 22.000000, reward total was -20.000000. running mean: -20.840552\n",
            "resetting env. episode 23.000000, reward total was -19.000000. running mean: -20.822146\n",
            "resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.823925\n",
            "resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.825685\n",
            "resetting env. episode 26.000000, reward total was -20.000000. running mean: -20.817429\n",
            "resetting env. episode 27.000000, reward total was -21.000000. running mean: -20.819254\n",
            "resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.821062\n",
            "resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.822851\n",
            "resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.824623\n",
            "resetting env. episode 31.000000, reward total was -20.000000. running mean: -20.816376\n",
            "resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.818213\n",
            "resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.820030\n",
            "resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.821830\n",
            "resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.823612\n",
            "resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.825376\n",
            "resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.827122\n",
            "resetting env. episode 38.000000, reward total was -21.000000. running mean: -20.828851\n",
            "resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.830562\n",
            "resetting env. episode 40.000000, reward total was -21.000000. running mean: -20.832257\n",
            "resetting env. episode 41.000000, reward total was -21.000000. running mean: -20.833934\n",
            "resetting env. episode 42.000000, reward total was -21.000000. running mean: -20.835595\n",
            "resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.837239\n",
            "resetting env. episode 44.000000, reward total was -21.000000. running mean: -20.838866\n",
            "resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.840478\n",
            "resetting env. episode 46.000000, reward total was -20.000000. running mean: -20.832073\n",
            "resetting env. episode 47.000000, reward total was -20.000000. running mean: -20.823752\n",
            "resetting env. episode 48.000000, reward total was -18.000000. running mean: -20.795515\n",
            "resetting env. episode 49.000000, reward total was -21.000000. running mean: -20.797560\n",
            "resetting env. episode 50.000000, reward total was -19.000000. running mean: -20.779584\n",
            "resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.781788\n",
            "resetting env. episode 52.000000, reward total was -20.000000. running mean: -20.773970\n",
            "resetting env. episode 53.000000, reward total was -20.000000. running mean: -20.766231\n",
            "resetting env. episode 54.000000, reward total was -20.000000. running mean: -20.758568\n",
            "resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.760983\n",
            "resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.763373\n",
            "resetting env. episode 57.000000, reward total was -20.000000. running mean: -20.755739\n",
            "resetting env. episode 58.000000, reward total was -18.000000. running mean: -20.728182\n",
            "resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.730900\n",
            "resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.733591\n",
            "resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.736255\n",
            "resetting env. episode 62.000000, reward total was -20.000000. running mean: -20.728892\n",
            "resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.731603\n",
            "resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.734287\n",
            "resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.736945\n",
            "resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.739575\n",
            "resetting env. episode 67.000000, reward total was -20.000000. running mean: -20.732179\n",
            "resetting env. episode 68.000000, reward total was -20.000000. running mean: -20.724858\n",
            "resetting env. episode 69.000000, reward total was -20.000000. running mean: -20.717609\n",
            "resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.720433\n",
            "resetting env. episode 71.000000, reward total was -21.000000. running mean: -20.723229\n",
            "resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.725996\n",
            "resetting env. episode 73.000000, reward total was -21.000000. running mean: -20.728736\n",
            "resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.731449\n",
            "resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.734134\n",
            "resetting env. episode 76.000000, reward total was -20.000000. running mean: -20.726793\n",
            "resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.729525\n",
            "resetting env. episode 78.000000, reward total was -19.000000. running mean: -20.712230\n",
            "resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.715108\n",
            "resetting env. episode 80.000000, reward total was -20.000000. running mean: -20.707957\n",
            "resetting env. episode 81.000000, reward total was -18.000000. running mean: -20.680877\n",
            "resetting env. episode 82.000000, reward total was -21.000000. running mean: -20.684068\n",
            "resetting env. episode 83.000000, reward total was -20.000000. running mean: -20.677228\n",
            "resetting env. episode 84.000000, reward total was -20.000000. running mean: -20.670455\n",
            "resetting env. episode 85.000000, reward total was -20.000000. running mean: -20.663751\n",
            "resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.667113\n",
            "resetting env. episode 87.000000, reward total was -18.000000. running mean: -20.640442\n",
            "resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.644038\n",
            "resetting env. episode 89.000000, reward total was -20.000000. running mean: -20.637597\n",
            "resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.641221\n",
            "resetting env. episode 91.000000, reward total was -20.000000. running mean: -20.634809\n",
            "resetting env. episode 92.000000, reward total was -20.000000. running mean: -20.628461\n",
            "resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.632176\n",
            "resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.635855\n",
            "resetting env. episode 95.000000, reward total was -21.000000. running mean: -20.639496\n",
            "resetting env. episode 96.000000, reward total was -20.000000. running mean: -20.633101\n",
            "resetting env. episode 97.000000, reward total was -19.000000. running mean: -20.616770\n",
            "resetting env. episode 98.000000, reward total was -19.000000. running mean: -20.600602\n",
            "resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.604596\n",
            "resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.608550\n",
            "resetting env. episode 101.000000, reward total was -20.000000. running mean: -20.602465\n",
            "resetting env. episode 102.000000, reward total was -20.000000. running mean: -20.596440\n",
            "resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.600476\n",
            "resetting env. episode 104.000000, reward total was -21.000000. running mean: -20.604471\n",
            "resetting env. episode 105.000000, reward total was -20.000000. running mean: -20.598426\n",
            "resetting env. episode 106.000000, reward total was -21.000000. running mean: -20.602442\n",
            "resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.606418\n",
            "resetting env. episode 108.000000, reward total was -20.000000. running mean: -20.600354\n",
            "resetting env. episode 109.000000, reward total was -21.000000. running mean: -20.604350\n",
            "resetting env. episode 110.000000, reward total was -20.000000. running mean: -20.598306\n",
            "resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.602323\n",
            "resetting env. episode 112.000000, reward total was -20.000000. running mean: -20.596300\n",
            "resetting env. episode 113.000000, reward total was -21.000000. running mean: -20.600337\n",
            "resetting env. episode 114.000000, reward total was -20.000000. running mean: -20.594334\n",
            "resetting env. episode 115.000000, reward total was -19.000000. running mean: -20.578390\n",
            "resetting env. episode 116.000000, reward total was -20.000000. running mean: -20.572607\n",
            "resetting env. episode 117.000000, reward total was -18.000000. running mean: -20.546880\n",
            "resetting env. episode 118.000000, reward total was -20.000000. running mean: -20.541412\n",
            "resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.545998\n",
            "resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.550538\n",
            "resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.555032\n",
            "resetting env. episode 122.000000, reward total was -19.000000. running mean: -20.539482\n",
            "resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.544087\n",
            "resetting env. episode 124.000000, reward total was -21.000000. running mean: -20.548646\n",
            "resetting env. episode 125.000000, reward total was -21.000000. running mean: -20.553160\n",
            "resetting env. episode 126.000000, reward total was -21.000000. running mean: -20.557628\n",
            "resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.562052\n",
            "resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.566431\n",
            "resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.570767\n",
            "resetting env. episode 130.000000, reward total was -21.000000. running mean: -20.575059\n",
            "resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.579309\n",
            "resetting env. episode 132.000000, reward total was -16.000000. running mean: -20.533516\n",
            "resetting env. episode 133.000000, reward total was -19.000000. running mean: -20.518181\n",
            "resetting env. episode 134.000000, reward total was -20.000000. running mean: -20.512999\n",
            "resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.517869\n",
            "resetting env. episode 136.000000, reward total was -20.000000. running mean: -20.512690\n",
            "resetting env. episode 137.000000, reward total was -20.000000. running mean: -20.507563\n",
            "resetting env. episode 138.000000, reward total was -19.000000. running mean: -20.492488\n",
            "resetting env. episode 139.000000, reward total was -20.000000. running mean: -20.487563\n",
            "resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.492687\n",
            "resetting env. episode 141.000000, reward total was -17.000000. running mean: -20.457760\n",
            "resetting env. episode 142.000000, reward total was -21.000000. running mean: -20.463183\n",
            "resetting env. episode 143.000000, reward total was -20.000000. running mean: -20.458551\n",
            "resetting env. episode 144.000000, reward total was -21.000000. running mean: -20.463965\n",
            "resetting env. episode 145.000000, reward total was -21.000000. running mean: -20.469326\n",
            "resetting env. episode 146.000000, reward total was -21.000000. running mean: -20.474632\n",
            "resetting env. episode 147.000000, reward total was -20.000000. running mean: -20.469886\n",
            "resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.475187\n",
            "resetting env. episode 149.000000, reward total was -17.000000. running mean: -20.440435\n",
            "resetting env. episode 150.000000, reward total was -21.000000. running mean: -20.446031\n",
            "resetting env. episode 151.000000, reward total was -19.000000. running mean: -20.431571\n",
            "resetting env. episode 152.000000, reward total was -20.000000. running mean: -20.427255\n",
            "resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.432982\n",
            "resetting env. episode 154.000000, reward total was -19.000000. running mean: -20.418653\n",
            "resetting env. episode 155.000000, reward total was -20.000000. running mean: -20.414466\n",
            "resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.420321\n",
            "resetting env. episode 157.000000, reward total was -20.000000. running mean: -20.416118\n",
            "resetting env. episode 158.000000, reward total was -21.000000. running mean: -20.421957\n",
            "resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.427737\n",
            "resetting env. episode 160.000000, reward total was -21.000000. running mean: -20.433460\n",
            "resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.439125\n",
            "resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.444734\n",
            "resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.450287\n",
            "resetting env. episode 164.000000, reward total was -18.000000. running mean: -20.425784\n",
            "resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.431526\n",
            "resetting env. episode 166.000000, reward total was -21.000000. running mean: -20.437211\n",
            "resetting env. episode 167.000000, reward total was -19.000000. running mean: -20.422839\n",
            "resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.428610\n",
            "resetting env. episode 169.000000, reward total was -21.000000. running mean: -20.434324\n",
            "resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.439981\n",
            "resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.445581\n",
            "resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.451125\n",
            "resetting env. episode 173.000000, reward total was -21.000000. running mean: -20.456614\n",
            "resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.462048\n",
            "resetting env. episode 175.000000, reward total was -19.000000. running mean: -20.447427\n",
            "resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.452953\n",
            "resetting env. episode 177.000000, reward total was -20.000000. running mean: -20.448424\n",
            "resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.453939\n",
            "resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.459400\n",
            "resetting env. episode 180.000000, reward total was -20.000000. running mean: -20.454806\n",
            "resetting env. episode 181.000000, reward total was -20.000000. running mean: -20.450258\n",
            "resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.455755\n",
            "resetting env. episode 183.000000, reward total was -20.000000. running mean: -20.451198\n",
            "resetting env. episode 184.000000, reward total was -20.000000. running mean: -20.446686\n",
            "resetting env. episode 185.000000, reward total was -20.000000. running mean: -20.442219\n",
            "resetting env. episode 186.000000, reward total was -20.000000. running mean: -20.437797\n",
            "resetting env. episode 187.000000, reward total was -21.000000. running mean: -20.443419\n",
            "resetting env. episode 188.000000, reward total was -20.000000. running mean: -20.438985\n",
            "resetting env. episode 189.000000, reward total was -20.000000. running mean: -20.434595\n",
            "resetting env. episode 190.000000, reward total was -20.000000. running mean: -20.430249\n",
            "resetting env. episode 191.000000, reward total was -20.000000. running mean: -20.425946\n",
            "resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.431687\n",
            "resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.437370\n",
            "resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.442996\n",
            "resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.448566\n",
            "resetting env. episode 196.000000, reward total was -20.000000. running mean: -20.444081\n",
            "resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.449640\n",
            "resetting env. episode 198.000000, reward total was -20.000000. running mean: -20.445144\n",
            "resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.450692\n",
            "resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.456185\n",
            "resetting env. episode 201.000000, reward total was -20.000000. running mean: -20.451623\n",
            "resetting env. episode 202.000000, reward total was -19.000000. running mean: -20.437107\n",
            "resetting env. episode 203.000000, reward total was -21.000000. running mean: -20.442736\n",
            "resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.448309\n",
            "resetting env. episode 205.000000, reward total was -21.000000. running mean: -20.453826\n",
            "resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.459287\n",
            "resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.464694\n",
            "resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.470047\n",
            "resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.475347\n",
            "resetting env. episode 210.000000, reward total was -21.000000. running mean: -20.480594\n",
            "resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.485788\n",
            "resetting env. episode 212.000000, reward total was -20.000000. running mean: -20.480930\n",
            "resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.486120\n",
            "resetting env. episode 214.000000, reward total was -20.000000. running mean: -20.481259\n",
            "resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.486447\n",
            "resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.491582\n",
            "resetting env. episode 217.000000, reward total was -21.000000. running mean: -20.496666\n",
            "resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.501700\n",
            "resetting env. episode 219.000000, reward total was -20.000000. running mean: -20.496683\n",
            "resetting env. episode 220.000000, reward total was -20.000000. running mean: -20.491716\n",
            "resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.496799\n",
            "resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.501831\n",
            "resetting env. episode 223.000000, reward total was -21.000000. running mean: -20.506812\n",
            "resetting env. episode 224.000000, reward total was -19.000000. running mean: -20.491744\n",
            "resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.496827\n",
            "resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.501859\n",
            "resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.506840\n",
            "resetting env. episode 228.000000, reward total was -21.000000. running mean: -20.511772\n",
            "resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.516654\n",
            "resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.521487\n",
            "resetting env. episode 231.000000, reward total was -20.000000. running mean: -20.516272\n",
            "resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.521110\n",
            "resetting env. episode 233.000000, reward total was -21.000000. running mean: -20.525899\n",
            "resetting env. episode 234.000000, reward total was -19.000000. running mean: -20.510640\n",
            "resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.515533\n",
            "resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.520378\n",
            "resetting env. episode 237.000000, reward total was -21.000000. running mean: -20.525174\n",
            "resetting env. episode 238.000000, reward total was -19.000000. running mean: -20.509922\n",
            "resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.514823\n",
            "resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.519675\n",
            "resetting env. episode 241.000000, reward total was -20.000000. running mean: -20.514478\n",
            "resetting env. episode 242.000000, reward total was -20.000000. running mean: -20.509333\n",
            "resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.514240\n",
            "resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.519098\n",
            "resetting env. episode 245.000000, reward total was -20.000000. running mean: -20.513907\n",
            "resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.518768\n",
            "resetting env. episode 247.000000, reward total was -20.000000. running mean: -20.513580\n",
            "resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.518444\n",
            "resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.523260\n",
            "resetting env. episode 250.000000, reward total was -20.000000. running mean: -20.518027\n",
            "resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.522847\n",
            "resetting env. episode 252.000000, reward total was -21.000000. running mean: -20.527618\n",
            "resetting env. episode 253.000000, reward total was -19.000000. running mean: -20.512342\n",
            "resetting env. episode 254.000000, reward total was -20.000000. running mean: -20.507219\n",
            "resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.512147\n",
            "resetting env. episode 256.000000, reward total was -19.000000. running mean: -20.497025\n",
            "resetting env. episode 257.000000, reward total was -20.000000. running mean: -20.492055\n",
            "resetting env. episode 258.000000, reward total was -19.000000. running mean: -20.477134\n",
            "resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.482363\n",
            "resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.487539\n",
            "resetting env. episode 261.000000, reward total was -21.000000. running mean: -20.492664\n",
            "resetting env. episode 262.000000, reward total was -20.000000. running mean: -20.487737\n",
            "resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.492860\n",
            "resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.497931\n",
            "resetting env. episode 265.000000, reward total was -20.000000. running mean: -20.492952\n",
            "resetting env. episode 266.000000, reward total was -21.000000. running mean: -20.498023\n",
            "resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.503042\n",
            "resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.508012\n",
            "resetting env. episode 269.000000, reward total was -20.000000. running mean: -20.502932\n",
            "resetting env. episode 270.000000, reward total was -21.000000. running mean: -20.507902\n",
            "resetting env. episode 271.000000, reward total was -21.000000. running mean: -20.512823\n",
            "resetting env. episode 272.000000, reward total was -20.000000. running mean: -20.507695\n",
            "resetting env. episode 273.000000, reward total was -20.000000. running mean: -20.502618\n",
            "resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.507592\n",
            "resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.512516\n",
            "resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.517391\n",
            "resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.522217\n",
            "resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.526995\n",
            "resetting env. episode 279.000000, reward total was -21.000000. running mean: -20.531725\n",
            "resetting env. episode 280.000000, reward total was -20.000000. running mean: -20.526408\n",
            "resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.531144\n",
            "resetting env. episode 282.000000, reward total was -20.000000. running mean: -20.525832\n",
            "resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.530574\n",
            "resetting env. episode 284.000000, reward total was -19.000000. running mean: -20.515268\n",
            "resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.520115\n",
            "resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.524914\n",
            "resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.529665\n",
            "resetting env. episode 288.000000, reward total was -20.000000. running mean: -20.524368\n",
            "resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.529125\n",
            "resetting env. episode 290.000000, reward total was -19.000000. running mean: -20.513834\n",
            "resetting env. episode 291.000000, reward total was -20.000000. running mean: -20.508695\n",
            "resetting env. episode 292.000000, reward total was -19.000000. running mean: -20.493608\n",
            "resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.498672\n",
            "resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.503685\n",
            "resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.508649\n",
            "resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.513562\n",
            "resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.518426\n",
            "resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.523242\n",
            "resetting env. episode 299.000000, reward total was -20.000000. running mean: -20.518010\n",
            "resetting env. episode 300.000000, reward total was -21.000000. running mean: -20.522830\n",
            "resetting env. episode 301.000000, reward total was -21.000000. running mean: -20.527601\n",
            "resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.532325\n",
            "resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.537002\n",
            "resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.541632\n",
            "resetting env. episode 305.000000, reward total was -20.000000. running mean: -20.536216\n",
            "resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.540854\n",
            "resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.545445\n",
            "resetting env. episode 308.000000, reward total was -19.000000. running mean: -20.529991\n",
            "resetting env. episode 309.000000, reward total was -21.000000. running mean: -20.534691\n",
            "resetting env. episode 310.000000, reward total was -20.000000. running mean: -20.529344\n",
            "resetting env. episode 311.000000, reward total was -19.000000. running mean: -20.514050\n",
            "resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.518910\n",
            "resetting env. episode 313.000000, reward total was -20.000000. running mean: -20.513721\n",
            "resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.518584\n",
            "resetting env. episode 315.000000, reward total was -21.000000. running mean: -20.523398\n",
            "resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.528164\n",
            "resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.532882\n",
            "resetting env. episode 318.000000, reward total was -19.000000. running mean: -20.517553\n",
            "resetting env. episode 319.000000, reward total was -20.000000. running mean: -20.512378\n",
            "resetting env. episode 320.000000, reward total was -20.000000. running mean: -20.507254\n",
            "resetting env. episode 321.000000, reward total was -20.000000. running mean: -20.502181\n",
            "resetting env. episode 322.000000, reward total was -19.000000. running mean: -20.487160\n",
            "resetting env. episode 323.000000, reward total was -20.000000. running mean: -20.482288\n",
            "resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.487465\n",
            "resetting env. episode 325.000000, reward total was -20.000000. running mean: -20.482591\n",
            "resetting env. episode 326.000000, reward total was -20.000000. running mean: -20.477765\n",
            "resetting env. episode 327.000000, reward total was -20.000000. running mean: -20.472987\n",
            "resetting env. episode 328.000000, reward total was -20.000000. running mean: -20.468257\n",
            "resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.473575\n",
            "resetting env. episode 330.000000, reward total was -21.000000. running mean: -20.478839\n",
            "resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.484050\n",
            "resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.489210\n",
            "resetting env. episode 333.000000, reward total was -21.000000. running mean: -20.494318\n",
            "resetting env. episode 334.000000, reward total was -20.000000. running mean: -20.489375\n",
            "resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.494481\n",
            "resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.499536\n",
            "resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.504541\n",
            "resetting env. episode 338.000000, reward total was -21.000000. running mean: -20.509495\n",
            "resetting env. episode 339.000000, reward total was -21.000000. running mean: -20.514400\n",
            "resetting env. episode 340.000000, reward total was -20.000000. running mean: -20.509256\n",
            "resetting env. episode 341.000000, reward total was -19.000000. running mean: -20.494164\n",
            "resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.499222\n",
            "resetting env. episode 343.000000, reward total was -20.000000. running mean: -20.494230\n",
            "resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.499288\n",
            "resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.504295\n",
            "resetting env. episode 346.000000, reward total was -21.000000. running mean: -20.509252\n",
            "resetting env. episode 347.000000, reward total was -21.000000. running mean: -20.514159\n",
            "resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.519018\n",
            "resetting env. episode 349.000000, reward total was -20.000000. running mean: -20.513828\n",
            "resetting env. episode 350.000000, reward total was -21.000000. running mean: -20.518689\n",
            "resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.523502\n",
            "resetting env. episode 352.000000, reward total was -18.000000. running mean: -20.498267\n",
            "resetting env. episode 353.000000, reward total was -19.000000. running mean: -20.483285\n",
            "resetting env. episode 354.000000, reward total was -20.000000. running mean: -20.478452\n",
            "resetting env. episode 355.000000, reward total was -20.000000. running mean: -20.473667\n",
            "resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.478931\n",
            "resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.484141\n",
            "resetting env. episode 358.000000, reward total was -20.000000. running mean: -20.479300\n",
            "resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.484507\n",
            "resetting env. episode 360.000000, reward total was -19.000000. running mean: -20.469662\n",
            "resetting env. episode 361.000000, reward total was -20.000000. running mean: -20.464965\n",
            "resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.470316\n",
            "resetting env. episode 363.000000, reward total was -20.000000. running mean: -20.465612\n",
            "resetting env. episode 364.000000, reward total was -21.000000. running mean: -20.470956\n",
            "resetting env. episode 365.000000, reward total was -19.000000. running mean: -20.456247\n",
            "resetting env. episode 366.000000, reward total was -20.000000. running mean: -20.451684\n",
            "resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.457167\n",
            "resetting env. episode 368.000000, reward total was -19.000000. running mean: -20.442596\n",
            "resetting env. episode 369.000000, reward total was -20.000000. running mean: -20.438170\n",
            "resetting env. episode 370.000000, reward total was -21.000000. running mean: -20.443788\n",
            "resetting env. episode 371.000000, reward total was -20.000000. running mean: -20.439350\n",
            "resetting env. episode 372.000000, reward total was -19.000000. running mean: -20.424957\n",
            "resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.430707\n",
            "resetting env. episode 374.000000, reward total was -21.000000. running mean: -20.436400\n",
            "resetting env. episode 375.000000, reward total was -21.000000. running mean: -20.442036\n",
            "resetting env. episode 376.000000, reward total was -20.000000. running mean: -20.437616\n",
            "resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.443240\n",
            "resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.448807\n",
            "resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.454319\n",
            "resetting env. episode 380.000000, reward total was -20.000000. running mean: -20.449776\n",
            "resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.455278\n",
            "resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.460725\n",
            "resetting env. episode 383.000000, reward total was -20.000000. running mean: -20.456118\n",
            "resetting env. episode 384.000000, reward total was -20.000000. running mean: -20.451557\n",
            "resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.457041\n",
            "resetting env. episode 386.000000, reward total was -20.000000. running mean: -20.452471\n",
            "resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.457946\n",
            "resetting env. episode 388.000000, reward total was -20.000000. running mean: -20.453367\n",
            "resetting env. episode 389.000000, reward total was -20.000000. running mean: -20.448833\n",
            "resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.454345\n",
            "resetting env. episode 391.000000, reward total was -20.000000. running mean: -20.449801\n",
            "resetting env. episode 392.000000, reward total was -21.000000. running mean: -20.455303\n",
            "resetting env. episode 393.000000, reward total was -20.000000. running mean: -20.450750\n",
            "resetting env. episode 394.000000, reward total was -21.000000. running mean: -20.456243\n",
            "resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.461680\n",
            "resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.467064\n",
            "resetting env. episode 397.000000, reward total was -21.000000. running mean: -20.472393\n",
            "resetting env. episode 398.000000, reward total was -21.000000. running mean: -20.477669\n",
            "resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.482892\n",
            "resetting env. episode 400.000000, reward total was -21.000000. running mean: -20.488063\n",
            "resetting env. episode 401.000000, reward total was -20.000000. running mean: -20.483183\n",
            "resetting env. episode 402.000000, reward total was -20.000000. running mean: -20.478351\n",
            "resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.483567\n",
            "resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.488732\n",
            "resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.493844\n",
            "resetting env. episode 406.000000, reward total was -21.000000. running mean: -20.498906\n",
            "resetting env. episode 407.000000, reward total was -20.000000. running mean: -20.493917\n",
            "resetting env. episode 408.000000, reward total was -20.000000. running mean: -20.488978\n",
            "resetting env. episode 409.000000, reward total was -20.000000. running mean: -20.484088\n",
            "resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.489247\n",
            "resetting env. episode 411.000000, reward total was -20.000000. running mean: -20.484355\n",
            "resetting env. episode 412.000000, reward total was -20.000000. running mean: -20.479511\n",
            "resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.484716\n",
            "resetting env. episode 414.000000, reward total was -21.000000. running mean: -20.489869\n",
            "resetting env. episode 415.000000, reward total was -21.000000. running mean: -20.494970\n",
            "resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.500020\n",
            "resetting env. episode 417.000000, reward total was -19.000000. running mean: -20.485020\n",
            "resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.490170\n",
            "resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.495268\n",
            "resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.500316\n",
            "resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.505312\n",
            "resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.510259\n",
            "resetting env. episode 423.000000, reward total was -21.000000. running mean: -20.515157\n",
            "resetting env. episode 424.000000, reward total was -19.000000. running mean: -20.500005\n",
            "resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.505005\n",
            "resetting env. episode 426.000000, reward total was -19.000000. running mean: -20.489955\n",
            "resetting env. episode 427.000000, reward total was -20.000000. running mean: -20.485055\n",
            "resetting env. episode 428.000000, reward total was -20.000000. running mean: -20.480205\n",
            "resetting env. episode 429.000000, reward total was -21.000000. running mean: -20.485403\n",
            "resetting env. episode 430.000000, reward total was -18.000000. running mean: -20.460549\n",
            "resetting env. episode 431.000000, reward total was -21.000000. running mean: -20.465943\n",
            "resetting env. episode 432.000000, reward total was -21.000000. running mean: -20.471284\n",
            "resetting env. episode 433.000000, reward total was -20.000000. running mean: -20.466571\n",
            "resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.471905\n",
            "resetting env. episode 435.000000, reward total was -21.000000. running mean: -20.477186\n",
            "resetting env. episode 436.000000, reward total was -19.000000. running mean: -20.462414\n",
            "resetting env. episode 437.000000, reward total was -17.000000. running mean: -20.427790\n",
            "resetting env. episode 438.000000, reward total was -19.000000. running mean: -20.413512\n",
            "resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.419377\n",
            "resetting env. episode 440.000000, reward total was -21.000000. running mean: -20.425184\n",
            "resetting env. episode 441.000000, reward total was -20.000000. running mean: -20.420932\n",
            "resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.426722\n",
            "resetting env. episode 443.000000, reward total was -20.000000. running mean: -20.422455\n",
            "resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.428231\n",
            "resetting env. episode 445.000000, reward total was -19.000000. running mean: -20.413948\n",
            "resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.419809\n",
            "resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.425611\n",
            "resetting env. episode 448.000000, reward total was -19.000000. running mean: -20.411355\n",
            "resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.417241\n",
            "resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.423069\n",
            "resetting env. episode 451.000000, reward total was -21.000000. running mean: -20.428838\n",
            "resetting env. episode 452.000000, reward total was -21.000000. running mean: -20.434550\n",
            "resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.440204\n",
            "resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.445802\n",
            "resetting env. episode 455.000000, reward total was -21.000000. running mean: -20.451344\n",
            "resetting env. episode 456.000000, reward total was -20.000000. running mean: -20.446831\n",
            "resetting env. episode 457.000000, reward total was -21.000000. running mean: -20.452362\n",
            "resetting env. episode 458.000000, reward total was -20.000000. running mean: -20.447839\n",
            "resetting env. episode 459.000000, reward total was -20.000000. running mean: -20.443360\n",
            "resetting env. episode 460.000000, reward total was -21.000000. running mean: -20.448927\n",
            "resetting env. episode 461.000000, reward total was -21.000000. running mean: -20.454437\n",
            "resetting env. episode 462.000000, reward total was -20.000000. running mean: -20.449893\n",
            "resetting env. episode 463.000000, reward total was -20.000000. running mean: -20.445394\n",
            "resetting env. episode 464.000000, reward total was -19.000000. running mean: -20.430940\n",
            "resetting env. episode 465.000000, reward total was -19.000000. running mean: -20.416631\n",
            "resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.422464\n",
            "resetting env. episode 467.000000, reward total was -21.000000. running mean: -20.428240\n",
            "resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.433957\n",
            "resetting env. episode 469.000000, reward total was -19.000000. running mean: -20.419618\n",
            "resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.425422\n",
            "resetting env. episode 471.000000, reward total was -20.000000. running mean: -20.421167\n",
            "resetting env. episode 472.000000, reward total was -20.000000. running mean: -20.416956\n",
            "resetting env. episode 473.000000, reward total was -20.000000. running mean: -20.412786\n",
            "resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.418658\n",
            "resetting env. episode 475.000000, reward total was -20.000000. running mean: -20.414472\n",
            "resetting env. episode 476.000000, reward total was -20.000000. running mean: -20.410327\n",
            "resetting env. episode 477.000000, reward total was -19.000000. running mean: -20.396224\n",
            "resetting env. episode 478.000000, reward total was -20.000000. running mean: -20.392262\n",
            "resetting env. episode 479.000000, reward total was -20.000000. running mean: -20.388339\n",
            "resetting env. episode 480.000000, reward total was -17.000000. running mean: -20.354456\n",
            "resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.360911\n",
            "resetting env. episode 482.000000, reward total was -21.000000. running mean: -20.367302\n",
            "resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.373629\n",
            "resetting env. episode 484.000000, reward total was -20.000000. running mean: -20.369893\n",
            "resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.376194\n",
            "resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.382432\n",
            "resetting env. episode 487.000000, reward total was -20.000000. running mean: -20.378607\n",
            "resetting env. episode 488.000000, reward total was -20.000000. running mean: -20.374821\n",
            "resetting env. episode 489.000000, reward total was -19.000000. running mean: -20.361073\n",
            "resetting env. episode 490.000000, reward total was -18.000000. running mean: -20.337462\n",
            "resetting env. episode 491.000000, reward total was -21.000000. running mean: -20.344088\n",
            "resetting env. episode 492.000000, reward total was -20.000000. running mean: -20.340647\n",
            "resetting env. episode 493.000000, reward total was -20.000000. running mean: -20.337240\n",
            "resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.343868\n",
            "resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.350429\n",
            "resetting env. episode 496.000000, reward total was -18.000000. running mean: -20.326925\n",
            "resetting env. episode 497.000000, reward total was -21.000000. running mean: -20.333656\n",
            "resetting env. episode 498.000000, reward total was -21.000000. running mean: -20.340319\n",
            "resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.346916\n",
            "resetting env. episode 500.000000, reward total was -21.000000. running mean: -20.353447\n",
            "CPU times: user 24min 12s, sys: 11min 20s, total: 35min 32s\n",
            "Wall time: 18min 23s\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "cHYCDYwhlVLV",
        "outputId": "f5c1c608-e7bf-48a5-c90a-0a209f3da671",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "%time hist2 = train_model(env, model, total_episodes=500)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n",
            "resetting env. episode 2.000000, reward total was -21.000000. running mean: -21.000000\n",
            "resetting env. episode 3.000000, reward total was -21.000000. running mean: -21.000000\n",
            "resetting env. episode 4.000000, reward total was -21.000000. running mean: -21.000000\n",
            "resetting env. episode 5.000000, reward total was -19.000000. running mean: -20.980000\n",
            "resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.980200\n",
            "resetting env. episode 7.000000, reward total was -19.000000. running mean: -20.960398\n",
            "resetting env. episode 8.000000, reward total was -21.000000. running mean: -20.960794\n",
            "resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.961186\n",
            "resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.961574\n",
            "resetting env. episode 11.000000, reward total was -20.000000. running mean: -20.951958\n",
            "resetting env. episode 12.000000, reward total was -20.000000. running mean: -20.942439\n",
            "resetting env. episode 13.000000, reward total was -21.000000. running mean: -20.943015\n",
            "resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.943584\n",
            "resetting env. episode 15.000000, reward total was -20.000000. running mean: -20.934149\n",
            "resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.934807\n",
            "resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.935459\n",
            "resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.936104\n",
            "resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.936743\n",
            "resetting env. episode 20.000000, reward total was -20.000000. running mean: -20.927376\n",
            "resetting env. episode 21.000000, reward total was -19.000000. running mean: -20.908102\n",
            "resetting env. episode 22.000000, reward total was -20.000000. running mean: -20.899021\n",
            "resetting env. episode 23.000000, reward total was -21.000000. running mean: -20.900031\n",
            "resetting env. episode 24.000000, reward total was -20.000000. running mean: -20.891031\n",
            "resetting env. episode 25.000000, reward total was -20.000000. running mean: -20.882120\n",
            "resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.883299\n",
            "resetting env. episode 27.000000, reward total was -19.000000. running mean: -20.864466\n",
            "resetting env. episode 28.000000, reward total was -19.000000. running mean: -20.845821\n",
            "resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.847363\n",
            "resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.848890\n",
            "resetting env. episode 31.000000, reward total was -19.000000. running mean: -20.830401\n",
            "resetting env. episode 32.000000, reward total was -20.000000. running mean: -20.822097\n",
            "resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.823876\n",
            "resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.825637\n",
            "resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.827381\n",
            "resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.829107\n",
            "resetting env. episode 37.000000, reward total was -19.000000. running mean: -20.810816\n",
            "resetting env. episode 38.000000, reward total was -19.000000. running mean: -20.792708\n",
            "resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.794780\n",
            "resetting env. episode 40.000000, reward total was -21.000000. running mean: -20.796833\n",
            "resetting env. episode 41.000000, reward total was -19.000000. running mean: -20.778864\n",
            "resetting env. episode 42.000000, reward total was -20.000000. running mean: -20.771076\n",
            "resetting env. episode 43.000000, reward total was -20.000000. running mean: -20.763365\n",
            "resetting env. episode 44.000000, reward total was -21.000000. running mean: -20.765731\n",
            "resetting env. episode 45.000000, reward total was -20.000000. running mean: -20.758074\n",
            "resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.760493\n",
            "resetting env. episode 47.000000, reward total was -18.000000. running mean: -20.732888\n",
            "resetting env. episode 48.000000, reward total was -20.000000. running mean: -20.725559\n",
            "resetting env. episode 49.000000, reward total was -21.000000. running mean: -20.728304\n",
            "resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.731021\n",
            "resetting env. episode 51.000000, reward total was -19.000000. running mean: -20.713711\n",
            "resetting env. episode 52.000000, reward total was -21.000000. running mean: -20.716573\n",
            "resetting env. episode 53.000000, reward total was -18.000000. running mean: -20.689408\n",
            "resetting env. episode 54.000000, reward total was -21.000000. running mean: -20.692514\n",
            "resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.695589\n",
            "resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.698633\n",
            "resetting env. episode 57.000000, reward total was -19.000000. running mean: -20.681646\n",
            "resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.684830\n",
            "resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.687982\n",
            "resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.691102\n",
            "resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.694191\n",
            "resetting env. episode 62.000000, reward total was -21.000000. running mean: -20.697249\n",
            "resetting env. episode 63.000000, reward total was -20.000000. running mean: -20.690276\n",
            "resetting env. episode 64.000000, reward total was -19.000000. running mean: -20.673374\n",
            "resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.676640\n",
            "resetting env. episode 66.000000, reward total was -20.000000. running mean: -20.669873\n",
            "resetting env. episode 67.000000, reward total was -20.000000. running mean: -20.663175\n",
            "resetting env. episode 68.000000, reward total was -20.000000. running mean: -20.656543\n",
            "resetting env. episode 69.000000, reward total was -20.000000. running mean: -20.649978\n",
            "resetting env. episode 70.000000, reward total was -20.000000. running mean: -20.643478\n",
            "resetting env. episode 71.000000, reward total was -21.000000. running mean: -20.647043\n",
            "resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.650573\n",
            "resetting env. episode 73.000000, reward total was -21.000000. running mean: -20.654067\n",
            "resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.657526\n",
            "resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.660951\n",
            "resetting env. episode 76.000000, reward total was -19.000000. running mean: -20.644341\n",
            "resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.647898\n",
            "resetting env. episode 78.000000, reward total was -20.000000. running mean: -20.641419\n",
            "resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.645005\n",
            "resetting env. episode 80.000000, reward total was -20.000000. running mean: -20.638555\n",
            "resetting env. episode 81.000000, reward total was -20.000000. running mean: -20.632169\n",
            "resetting env. episode 82.000000, reward total was -21.000000. running mean: -20.635848\n",
            "resetting env. episode 83.000000, reward total was -20.000000. running mean: -20.629489\n",
            "resetting env. episode 84.000000, reward total was -21.000000. running mean: -20.633194\n",
            "resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.636862\n",
            "resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.640494\n",
            "resetting env. episode 87.000000, reward total was -20.000000. running mean: -20.634089\n",
            "resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.637748\n",
            "resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.641370\n",
            "resetting env. episode 90.000000, reward total was -20.000000. running mean: -20.634957\n",
            "resetting env. episode 91.000000, reward total was -19.000000. running mean: -20.618607\n",
            "resetting env. episode 92.000000, reward total was -20.000000. running mean: -20.612421\n",
            "resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.616297\n",
            "resetting env. episode 94.000000, reward total was -19.000000. running mean: -20.600134\n",
            "resetting env. episode 95.000000, reward total was -20.000000. running mean: -20.594132\n",
            "resetting env. episode 96.000000, reward total was -21.000000. running mean: -20.598191\n",
            "resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.602209\n",
            "resetting env. episode 98.000000, reward total was -20.000000. running mean: -20.596187\n",
            "resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.600225\n",
            "resetting env. episode 100.000000, reward total was -20.000000. running mean: -20.594223\n",
            "resetting env. episode 101.000000, reward total was -21.000000. running mean: -20.598281\n",
            "resetting env. episode 102.000000, reward total was -20.000000. running mean: -20.592298\n",
            "resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.596375\n",
            "resetting env. episode 104.000000, reward total was -21.000000. running mean: -20.600411\n",
            "resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.604407\n",
            "resetting env. episode 106.000000, reward total was -19.000000. running mean: -20.588363\n",
            "resetting env. episode 107.000000, reward total was -20.000000. running mean: -20.582479\n",
            "resetting env. episode 108.000000, reward total was -21.000000. running mean: -20.586655\n",
            "resetting env. episode 109.000000, reward total was -20.000000. running mean: -20.580788\n",
            "resetting env. episode 110.000000, reward total was -20.000000. running mean: -20.574980\n",
            "resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.579230\n",
            "resetting env. episode 112.000000, reward total was -21.000000. running mean: -20.583438\n",
            "resetting env. episode 113.000000, reward total was -19.000000. running mean: -20.567604\n",
            "resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.571928\n",
            "resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.576208\n",
            "resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.580446\n",
            "resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.584642\n",
            "resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.588795\n",
            "resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.592907\n",
            "resetting env. episode 120.000000, reward total was -20.000000. running mean: -20.586978\n",
            "resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.591109\n",
            "resetting env. episode 122.000000, reward total was -20.000000. running mean: -20.585198\n",
            "resetting env. episode 123.000000, reward total was -20.000000. running mean: -20.579346\n",
            "resetting env. episode 124.000000, reward total was -20.000000. running mean: -20.573552\n",
            "resetting env. episode 125.000000, reward total was -20.000000. running mean: -20.567817\n",
            "resetting env. episode 126.000000, reward total was -20.000000. running mean: -20.562138\n",
            "resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.566517\n",
            "resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.570852\n",
            "resetting env. episode 129.000000, reward total was -20.000000. running mean: -20.565143\n",
            "resetting env. episode 130.000000, reward total was -21.000000. running mean: -20.569492\n",
            "resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.573797\n",
            "resetting env. episode 132.000000, reward total was -20.000000. running mean: -20.568059\n",
            "resetting env. episode 133.000000, reward total was -21.000000. running mean: -20.572378\n",
            "resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.576655\n",
            "resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.580888\n",
            "resetting env. episode 136.000000, reward total was -20.000000. running mean: -20.575079\n",
            "resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.579328\n",
            "resetting env. episode 138.000000, reward total was -20.000000. running mean: -20.573535\n",
            "resetting env. episode 139.000000, reward total was -19.000000. running mean: -20.557800\n",
            "resetting env. episode 140.000000, reward total was -19.000000. running mean: -20.542222\n",
            "resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.546800\n",
            "resetting env. episode 142.000000, reward total was -19.000000. running mean: -20.531332\n",
            "resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.536018\n",
            "resetting env. episode 144.000000, reward total was -21.000000. running mean: -20.540658\n",
            "resetting env. episode 145.000000, reward total was -21.000000. running mean: -20.545251\n",
            "resetting env. episode 146.000000, reward total was -19.000000. running mean: -20.529799\n",
            "resetting env. episode 147.000000, reward total was -19.000000. running mean: -20.514501\n",
            "resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.519356\n",
            "resetting env. episode 149.000000, reward total was -19.000000. running mean: -20.504162\n",
            "resetting env. episode 150.000000, reward total was -21.000000. running mean: -20.509121\n",
            "resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.514030\n",
            "resetting env. episode 152.000000, reward total was -21.000000. running mean: -20.518889\n",
            "resetting env. episode 153.000000, reward total was -20.000000. running mean: -20.513700\n",
            "resetting env. episode 154.000000, reward total was -21.000000. running mean: -20.518563\n",
            "resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.523378\n",
            "resetting env. episode 156.000000, reward total was -20.000000. running mean: -20.518144\n",
            "resetting env. episode 157.000000, reward total was -20.000000. running mean: -20.512963\n",
            "resetting env. episode 158.000000, reward total was -21.000000. running mean: -20.517833\n",
            "resetting env. episode 159.000000, reward total was -18.000000. running mean: -20.492655\n",
            "resetting env. episode 160.000000, reward total was -21.000000. running mean: -20.497728\n",
            "resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.502751\n",
            "resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.507723\n",
            "resetting env. episode 163.000000, reward total was -20.000000. running mean: -20.502646\n",
            "resetting env. episode 164.000000, reward total was -19.000000. running mean: -20.487620\n",
            "resetting env. episode 165.000000, reward total was -20.000000. running mean: -20.482743\n",
            "resetting env. episode 166.000000, reward total was -21.000000. running mean: -20.487916\n",
            "resetting env. episode 167.000000, reward total was -21.000000. running mean: -20.493037\n",
            "resetting env. episode 168.000000, reward total was -19.000000. running mean: -20.478106\n",
            "resetting env. episode 169.000000, reward total was -21.000000. running mean: -20.483325\n",
            "resetting env. episode 170.000000, reward total was -20.000000. running mean: -20.478492\n",
            "resetting env. episode 171.000000, reward total was -19.000000. running mean: -20.463707\n",
            "resetting env. episode 172.000000, reward total was -20.000000. running mean: -20.459070\n",
            "resetting env. episode 173.000000, reward total was -20.000000. running mean: -20.454479\n",
            "resetting env. episode 174.000000, reward total was -20.000000. running mean: -20.449935\n",
            "resetting env. episode 175.000000, reward total was -21.000000. running mean: -20.455435\n",
            "resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.460881\n",
            "resetting env. episode 177.000000, reward total was -19.000000. running mean: -20.446272\n",
            "resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.451809\n",
            "resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.457291\n",
            "resetting env. episode 180.000000, reward total was -20.000000. running mean: -20.452718\n",
            "resetting env. episode 181.000000, reward total was -20.000000. running mean: -20.448191\n",
            "resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.453709\n",
            "resetting env. episode 183.000000, reward total was -20.000000. running mean: -20.449172\n",
            "resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.454680\n",
            "resetting env. episode 185.000000, reward total was -19.000000. running mean: -20.440134\n",
            "resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.445732\n",
            "resetting env. episode 187.000000, reward total was -21.000000. running mean: -20.451275\n",
            "resetting env. episode 188.000000, reward total was -19.000000. running mean: -20.436762\n",
            "resetting env. episode 189.000000, reward total was -20.000000. running mean: -20.432395\n",
            "resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.438071\n",
            "resetting env. episode 191.000000, reward total was -21.000000. running mean: -20.443690\n",
            "resetting env. episode 192.000000, reward total was -20.000000. running mean: -20.439253\n",
            "resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.444861\n",
            "resetting env. episode 194.000000, reward total was -20.000000. running mean: -20.440412\n",
            "resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.446008\n",
            "resetting env. episode 196.000000, reward total was -20.000000. running mean: -20.441548\n",
            "resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.447132\n",
            "resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.452661\n",
            "resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.458134\n",
            "resetting env. episode 200.000000, reward total was -18.000000. running mean: -20.433553\n",
            "resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.439217\n",
            "resetting env. episode 202.000000, reward total was -19.000000. running mean: -20.424825\n",
            "resetting env. episode 203.000000, reward total was -20.000000. running mean: -20.420577\n",
            "resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.426371\n",
            "resetting env. episode 205.000000, reward total was -21.000000. running mean: -20.432108\n",
            "resetting env. episode 206.000000, reward total was -19.000000. running mean: -20.417786\n",
            "resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.423609\n",
            "resetting env. episode 208.000000, reward total was -20.000000. running mean: -20.419373\n",
            "resetting env. episode 209.000000, reward total was -19.000000. running mean: -20.405179\n",
            "resetting env. episode 210.000000, reward total was -21.000000. running mean: -20.411127\n",
            "resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.417016\n",
            "resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.422846\n",
            "resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.428617\n",
            "resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.434331\n",
            "resetting env. episode 215.000000, reward total was -20.000000. running mean: -20.429988\n",
            "resetting env. episode 216.000000, reward total was -20.000000. running mean: -20.425688\n",
            "resetting env. episode 217.000000, reward total was -21.000000. running mean: -20.431431\n",
            "resetting env. episode 218.000000, reward total was -20.000000. running mean: -20.427117\n",
            "resetting env. episode 219.000000, reward total was -20.000000. running mean: -20.422845\n",
            "resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.428617\n",
            "resetting env. episode 221.000000, reward total was -19.000000. running mean: -20.414331\n",
            "resetting env. episode 222.000000, reward total was -19.000000. running mean: -20.400187\n",
            "resetting env. episode 223.000000, reward total was -20.000000. running mean: -20.396186\n",
            "resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.402224\n",
            "resetting env. episode 225.000000, reward total was -20.000000. running mean: -20.398202\n",
            "resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.404219\n",
            "resetting env. episode 227.000000, reward total was -19.000000. running mean: -20.390177\n",
            "resetting env. episode 228.000000, reward total was -19.000000. running mean: -20.376276\n",
            "resetting env. episode 229.000000, reward total was -20.000000. running mean: -20.372513\n",
            "resetting env. episode 230.000000, reward total was -20.000000. running mean: -20.368788\n",
            "resetting env. episode 231.000000, reward total was -19.000000. running mean: -20.355100\n",
            "resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.361549\n",
            "resetting env. episode 233.000000, reward total was -21.000000. running mean: -20.367933\n",
            "resetting env. episode 234.000000, reward total was -19.000000. running mean: -20.354254\n",
            "resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.360711\n",
            "resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.367104\n",
            "resetting env. episode 237.000000, reward total was -20.000000. running mean: -20.363433\n",
            "resetting env. episode 238.000000, reward total was -21.000000. running mean: -20.369799\n",
            "resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.376101\n",
            "resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.382340\n",
            "resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.388517\n",
            "resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.394631\n",
            "resetting env. episode 243.000000, reward total was -17.000000. running mean: -20.360685\n",
            "resetting env. episode 244.000000, reward total was -20.000000. running mean: -20.357078\n",
            "resetting env. episode 245.000000, reward total was -19.000000. running mean: -20.343507\n",
            "resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.350072\n",
            "resetting env. episode 247.000000, reward total was -20.000000. running mean: -20.346572\n",
            "resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.353106\n",
            "resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.359575\n",
            "resetting env. episode 250.000000, reward total was -21.000000. running mean: -20.365979\n",
            "resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.372319\n",
            "resetting env. episode 252.000000, reward total was -21.000000. running mean: -20.378596\n",
            "resetting env. episode 253.000000, reward total was -20.000000. running mean: -20.374810\n",
            "resetting env. episode 254.000000, reward total was -21.000000. running mean: -20.381062\n",
            "resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.387251\n",
            "resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.393379\n",
            "resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.399445\n",
            "resetting env. episode 258.000000, reward total was -21.000000. running mean: -20.405451\n",
            "resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.411396\n",
            "resetting env. episode 260.000000, reward total was -19.000000. running mean: -20.397282\n",
            "resetting env. episode 261.000000, reward total was -21.000000. running mean: -20.403309\n",
            "resetting env. episode 262.000000, reward total was -20.000000. running mean: -20.399276\n",
            "resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.405284\n",
            "resetting env. episode 264.000000, reward total was -20.000000. running mean: -20.401231\n",
            "resetting env. episode 265.000000, reward total was -19.000000. running mean: -20.387218\n",
            "resetting env. episode 266.000000, reward total was -20.000000. running mean: -20.383346\n",
            "resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.389513\n",
            "resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.395618\n",
            "resetting env. episode 269.000000, reward total was -20.000000. running mean: -20.391661\n",
            "resetting env. episode 270.000000, reward total was -21.000000. running mean: -20.397745\n",
            "resetting env. episode 271.000000, reward total was -20.000000. running mean: -20.393767\n",
            "resetting env. episode 272.000000, reward total was -21.000000. running mean: -20.399830\n",
            "resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.405831\n",
            "resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.411773\n",
            "resetting env. episode 275.000000, reward total was -20.000000. running mean: -20.407655\n",
            "resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.413579\n",
            "resetting env. episode 277.000000, reward total was -20.000000. running mean: -20.409443\n",
            "resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.415349\n",
            "resetting env. episode 279.000000, reward total was -20.000000. running mean: -20.411195\n",
            "resetting env. episode 280.000000, reward total was -20.000000. running mean: -20.407083\n",
            "resetting env. episode 281.000000, reward total was -20.000000. running mean: -20.403012\n",
            "resetting env. episode 282.000000, reward total was -21.000000. running mean: -20.408982\n",
            "resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.414892\n",
            "resetting env. episode 284.000000, reward total was -19.000000. running mean: -20.400743\n",
            "resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.406736\n",
            "resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.412669\n",
            "resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.418542\n",
            "resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.424357\n",
            "resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.430113\n",
            "resetting env. episode 290.000000, reward total was -20.000000. running mean: -20.425812\n",
            "resetting env. episode 291.000000, reward total was -21.000000. running mean: -20.431554\n",
            "resetting env. episode 292.000000, reward total was -21.000000. running mean: -20.437238\n",
            "resetting env. episode 293.000000, reward total was -20.000000. running mean: -20.432866\n",
            "resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.438537\n",
            "resetting env. episode 295.000000, reward total was -20.000000. running mean: -20.434152\n",
            "resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.439810\n",
            "resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.445412\n",
            "resetting env. episode 298.000000, reward total was -19.000000. running mean: -20.430958\n",
            "resetting env. episode 299.000000, reward total was -21.000000. running mean: -20.436648\n",
            "resetting env. episode 300.000000, reward total was -21.000000. running mean: -20.442282\n",
            "resetting env. episode 301.000000, reward total was -20.000000. running mean: -20.437859\n",
            "resetting env. episode 302.000000, reward total was -20.000000. running mean: -20.433481\n",
            "resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.439146\n",
            "resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.444754\n",
            "resetting env. episode 305.000000, reward total was -21.000000. running mean: -20.450307\n",
            "resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.455804\n",
            "resetting env. episode 307.000000, reward total was -18.000000. running mean: -20.431246\n",
            "resetting env. episode 308.000000, reward total was -20.000000. running mean: -20.426933\n",
            "resetting env. episode 309.000000, reward total was -21.000000. running mean: -20.432664\n",
            "resetting env. episode 310.000000, reward total was -19.000000. running mean: -20.418337\n",
            "resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.424154\n",
            "resetting env. episode 312.000000, reward total was -20.000000. running mean: -20.419912\n",
            "resetting env. episode 313.000000, reward total was -21.000000. running mean: -20.425713\n",
            "resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.431456\n",
            "resetting env. episode 315.000000, reward total was -21.000000. running mean: -20.437141\n",
            "resetting env. episode 316.000000, reward total was -20.000000. running mean: -20.432770\n",
            "resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.438442\n",
            "resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.444058\n",
            "resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.449617\n",
            "resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.455121\n",
            "resetting env. episode 321.000000, reward total was -20.000000. running mean: -20.450570\n",
            "resetting env. episode 322.000000, reward total was -21.000000. running mean: -20.456064\n",
            "resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.461504\n",
            "resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.466889\n",
            "resetting env. episode 325.000000, reward total was -21.000000. running mean: -20.472220\n",
            "resetting env. episode 326.000000, reward total was -20.000000. running mean: -20.467498\n",
            "resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.472823\n",
            "resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.478094\n",
            "resetting env. episode 329.000000, reward total was -19.000000. running mean: -20.463313\n",
            "resetting env. episode 330.000000, reward total was -20.000000. running mean: -20.458680\n",
            "resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.464093\n",
            "resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.469453\n",
            "resetting env. episode 333.000000, reward total was -20.000000. running mean: -20.464758\n",
            "resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.470110\n",
            "resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.475409\n",
            "resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.480655\n",
            "resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.485849\n",
            "resetting env. episode 338.000000, reward total was -21.000000. running mean: -20.490990\n",
            "resetting env. episode 339.000000, reward total was -20.000000. running mean: -20.486080\n",
            "resetting env. episode 340.000000, reward total was -21.000000. running mean: -20.491219\n",
            "resetting env. episode 341.000000, reward total was -20.000000. running mean: -20.486307\n",
            "resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.491444\n",
            "resetting env. episode 343.000000, reward total was -21.000000. running mean: -20.496530\n",
            "resetting env. episode 344.000000, reward total was -20.000000. running mean: -20.491564\n",
            "resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.496649\n",
            "resetting env. episode 346.000000, reward total was -19.000000. running mean: -20.481682\n",
            "resetting env. episode 347.000000, reward total was -20.000000. running mean: -20.476866\n",
            "resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.482097\n",
            "resetting env. episode 349.000000, reward total was -19.000000. running mean: -20.467276\n",
            "resetting env. episode 350.000000, reward total was -20.000000. running mean: -20.462603\n",
            "resetting env. episode 351.000000, reward total was -19.000000. running mean: -20.447977\n",
            "resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.453497\n",
            "resetting env. episode 353.000000, reward total was -20.000000. running mean: -20.448962\n",
            "resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.454473\n",
            "resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.459928\n",
            "resetting env. episode 356.000000, reward total was -18.000000. running mean: -20.435329\n",
            "resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.440975\n",
            "resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.446566\n",
            "resetting env. episode 359.000000, reward total was -20.000000. running mean: -20.442100\n",
            "resetting env. episode 360.000000, reward total was -21.000000. running mean: -20.447679\n",
            "resetting env. episode 361.000000, reward total was -21.000000. running mean: -20.453202\n",
            "resetting env. episode 362.000000, reward total was -20.000000. running mean: -20.448670\n",
            "resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.454184\n",
            "resetting env. episode 364.000000, reward total was -18.000000. running mean: -20.429642\n",
            "resetting env. episode 365.000000, reward total was -21.000000. running mean: -20.435345\n",
            "resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.440992\n",
            "resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.446582\n",
            "resetting env. episode 368.000000, reward total was -20.000000. running mean: -20.442116\n",
            "resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.447695\n",
            "resetting env. episode 370.000000, reward total was -20.000000. running mean: -20.443218\n",
            "resetting env. episode 371.000000, reward total was -19.000000. running mean: -20.428786\n",
            "resetting env. episode 372.000000, reward total was -19.000000. running mean: -20.414498\n",
            "resetting env. episode 373.000000, reward total was -20.000000. running mean: -20.410353\n",
            "resetting env. episode 374.000000, reward total was -17.000000. running mean: -20.376249\n",
            "resetting env. episode 375.000000, reward total was -18.000000. running mean: -20.352487\n",
            "resetting env. episode 376.000000, reward total was -20.000000. running mean: -20.348962\n",
            "resetting env. episode 377.000000, reward total was -20.000000. running mean: -20.345472\n",
            "resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.352018\n",
            "resetting env. episode 379.000000, reward total was -20.000000. running mean: -20.348498\n",
            "resetting env. episode 380.000000, reward total was -21.000000. running mean: -20.355013\n",
            "resetting env. episode 381.000000, reward total was -20.000000. running mean: -20.351462\n",
            "resetting env. episode 382.000000, reward total was -20.000000. running mean: -20.347948\n",
            "resetting env. episode 383.000000, reward total was -21.000000. running mean: -20.354468\n",
            "resetting env. episode 384.000000, reward total was -20.000000. running mean: -20.350924\n",
            "resetting env. episode 385.000000, reward total was -18.000000. running mean: -20.327414\n",
            "resetting env. episode 386.000000, reward total was -20.000000. running mean: -20.324140\n",
            "resetting env. episode 387.000000, reward total was -20.000000. running mean: -20.320899\n",
            "resetting env. episode 388.000000, reward total was -20.000000. running mean: -20.317690\n",
            "resetting env. episode 389.000000, reward total was -20.000000. running mean: -20.314513\n",
            "resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.321368\n",
            "resetting env. episode 391.000000, reward total was -20.000000. running mean: -20.318154\n",
            "resetting env. episode 392.000000, reward total was -20.000000. running mean: -20.314973\n",
            "resetting env. episode 393.000000, reward total was -19.000000. running mean: -20.301823\n",
            "resetting env. episode 394.000000, reward total was -20.000000. running mean: -20.298805\n",
            "resetting env. episode 395.000000, reward total was -20.000000. running mean: -20.295817\n",
            "resetting env. episode 396.000000, reward total was -17.000000. running mean: -20.262858\n",
            "resetting env. episode 397.000000, reward total was -19.000000. running mean: -20.250230\n",
            "resetting env. episode 398.000000, reward total was -19.000000. running mean: -20.237728\n",
            "resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.245350\n",
            "resetting env. episode 400.000000, reward total was -21.000000. running mean: -20.252897\n",
            "resetting env. episode 401.000000, reward total was -20.000000. running mean: -20.250368\n",
            "resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.257864\n",
            "resetting env. episode 403.000000, reward total was -18.000000. running mean: -20.235285\n",
            "resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.242933\n",
            "resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.250503\n",
            "resetting env. episode 406.000000, reward total was -20.000000. running mean: -20.247998\n",
            "resetting env. episode 407.000000, reward total was -21.000000. running mean: -20.255518\n",
            "resetting env. episode 408.000000, reward total was -20.000000. running mean: -20.252963\n",
            "resetting env. episode 409.000000, reward total was -21.000000. running mean: -20.260433\n",
            "resetting env. episode 410.000000, reward total was -20.000000. running mean: -20.257829\n",
            "resetting env. episode 411.000000, reward total was -20.000000. running mean: -20.255251\n",
            "resetting env. episode 412.000000, reward total was -20.000000. running mean: -20.252698\n",
            "resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.260171\n",
            "resetting env. episode 414.000000, reward total was -21.000000. running mean: -20.267570\n",
            "resetting env. episode 415.000000, reward total was -20.000000. running mean: -20.264894\n",
            "resetting env. episode 416.000000, reward total was -20.000000. running mean: -20.262245\n",
            "resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.269623\n",
            "resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.276926\n",
            "resetting env. episode 419.000000, reward total was -20.000000. running mean: -20.274157\n",
            "resetting env. episode 420.000000, reward total was -20.000000. running mean: -20.271416\n",
            "resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.278701\n",
            "resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.285914\n",
            "resetting env. episode 423.000000, reward total was -18.000000. running mean: -20.263055\n",
            "resetting env. episode 424.000000, reward total was -20.000000. running mean: -20.260425\n",
            "resetting env. episode 425.000000, reward total was -20.000000. running mean: -20.257820\n",
            "resetting env. episode 426.000000, reward total was -21.000000. running mean: -20.265242\n",
            "resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.272590\n",
            "resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.279864\n",
            "resetting env. episode 429.000000, reward total was -21.000000. running mean: -20.287065\n",
            "resetting env. episode 430.000000, reward total was -19.000000. running mean: -20.274195\n",
            "resetting env. episode 431.000000, reward total was -19.000000. running mean: -20.261453\n",
            "resetting env. episode 432.000000, reward total was -20.000000. running mean: -20.258838\n",
            "resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.266250\n",
            "resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.273587\n",
            "resetting env. episode 435.000000, reward total was -21.000000. running mean: -20.280851\n",
            "resetting env. episode 436.000000, reward total was -20.000000. running mean: -20.278043\n",
            "resetting env. episode 437.000000, reward total was -20.000000. running mean: -20.275262\n",
            "resetting env. episode 438.000000, reward total was -20.000000. running mean: -20.272510\n",
            "resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.279785\n",
            "resetting env. episode 440.000000, reward total was -19.000000. running mean: -20.266987\n",
            "resetting env. episode 441.000000, reward total was -19.000000. running mean: -20.254317\n",
            "resetting env. episode 442.000000, reward total was -20.000000. running mean: -20.251774\n",
            "resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.259256\n",
            "resetting env. episode 444.000000, reward total was -19.000000. running mean: -20.246664\n",
            "resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.254197\n",
            "resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.261655\n",
            "resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.269038\n",
            "resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.276348\n",
            "resetting env. episode 449.000000, reward total was -20.000000. running mean: -20.273584\n",
            "resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.280849\n",
            "resetting env. episode 451.000000, reward total was -21.000000. running mean: -20.288040\n",
            "resetting env. episode 452.000000, reward total was -20.000000. running mean: -20.285160\n",
            "resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.292308\n",
            "resetting env. episode 454.000000, reward total was -20.000000. running mean: -20.289385\n",
            "resetting env. episode 455.000000, reward total was -18.000000. running mean: -20.266491\n",
            "resetting env. episode 456.000000, reward total was -20.000000. running mean: -20.263826\n",
            "resetting env. episode 457.000000, reward total was -21.000000. running mean: -20.271188\n",
            "resetting env. episode 458.000000, reward total was -20.000000. running mean: -20.268476\n",
            "resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.275791\n",
            "resetting env. episode 460.000000, reward total was -20.000000. running mean: -20.273034\n",
            "resetting env. episode 461.000000, reward total was -19.000000. running mean: -20.260303\n",
            "resetting env. episode 462.000000, reward total was -21.000000. running mean: -20.267700\n",
            "resetting env. episode 463.000000, reward total was -20.000000. running mean: -20.265023\n",
            "resetting env. episode 464.000000, reward total was -20.000000. running mean: -20.262373\n",
            "resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.269749\n",
            "resetting env. episode 466.000000, reward total was -20.000000. running mean: -20.267052\n",
            "resetting env. episode 467.000000, reward total was -21.000000. running mean: -20.274381\n",
            "resetting env. episode 468.000000, reward total was -19.000000. running mean: -20.261637\n",
            "resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.269021\n",
            "resetting env. episode 470.000000, reward total was -20.000000. running mean: -20.266331\n",
            "resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.273667\n",
            "resetting env. episode 472.000000, reward total was -19.000000. running mean: -20.260931\n",
            "resetting env. episode 473.000000, reward total was -20.000000. running mean: -20.258321\n",
            "resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.265738\n",
            "resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.273081\n",
            "resetting env. episode 476.000000, reward total was -20.000000. running mean: -20.270350\n",
            "resetting env. episode 477.000000, reward total was -20.000000. running mean: -20.267647\n",
            "resetting env. episode 478.000000, reward total was -20.000000. running mean: -20.264970\n",
            "resetting env. episode 479.000000, reward total was -19.000000. running mean: -20.252320\n",
            "resetting env. episode 480.000000, reward total was -19.000000. running mean: -20.239797\n",
            "resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.247399\n",
            "resetting env. episode 482.000000, reward total was -21.000000. running mean: -20.254925\n",
            "resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.262376\n",
            "resetting env. episode 484.000000, reward total was -21.000000. running mean: -20.269752\n",
            "resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.277055\n",
            "resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.284284\n",
            "resetting env. episode 487.000000, reward total was -20.000000. running mean: -20.281441\n",
            "resetting env. episode 488.000000, reward total was -20.000000. running mean: -20.278627\n",
            "resetting env. episode 489.000000, reward total was -20.000000. running mean: -20.275841\n",
            "resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.283082\n",
            "resetting env. episode 491.000000, reward total was -21.000000. running mean: -20.290251\n",
            "resetting env. episode 492.000000, reward total was -21.000000. running mean: -20.297349\n",
            "resetting env. episode 493.000000, reward total was -21.000000. running mean: -20.304375\n",
            "resetting env. episode 494.000000, reward total was -20.000000. running mean: -20.301332\n",
            "resetting env. episode 495.000000, reward total was -20.000000. running mean: -20.298318\n",
            "resetting env. episode 496.000000, reward total was -20.000000. running mean: -20.295335\n",
            "resetting env. episode 497.000000, reward total was -20.000000. running mean: -20.292382\n",
            "resetting env. episode 498.000000, reward total was -20.000000. running mean: -20.289458\n",
            "resetting env. episode 499.000000, reward total was -20.000000. running mean: -20.286563\n",
            "resetting env. episode 500.000000, reward total was -20.000000. running mean: -20.283698\n",
            "CPU times: user 25min 2s, sys: 11min 40s, total: 36min 42s\n",
            "Wall time: 18min 58s\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8fheN9DRlWXQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "fe066fc6-93fb-4220-f75b-1d5845665996"
      },
      "cell_type": "code",
      "source": [
        "play_game(env, model)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9AxOcQhIsKow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c29761c5-cc26-4fb6-82fb-89df9df85297"
      },
      "cell_type": "code",
      "source": [
        "%time hist3 = train_model(env, model, total_episodes=3500)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resetting env. episode 1.000000, reward total was -19.000000. running mean: -19.000000\n",
            "resetting env. episode 2.000000, reward total was -21.000000. running mean: -19.020000\n",
            "resetting env. episode 3.000000, reward total was -21.000000. running mean: -19.039800\n",
            "resetting env. episode 4.000000, reward total was -21.000000. running mean: -19.059402\n",
            "resetting env. episode 5.000000, reward total was -20.000000. running mean: -19.068808\n",
            "resetting env. episode 6.000000, reward total was -21.000000. running mean: -19.088120\n",
            "resetting env. episode 7.000000, reward total was -21.000000. running mean: -19.107239\n",
            "resetting env. episode 8.000000, reward total was -21.000000. running mean: -19.126166\n",
            "resetting env. episode 9.000000, reward total was -21.000000. running mean: -19.144905\n",
            "resetting env. episode 10.000000, reward total was -21.000000. running mean: -19.163456\n",
            "resetting env. episode 11.000000, reward total was -19.000000. running mean: -19.161821\n",
            "resetting env. episode 12.000000, reward total was -19.000000. running mean: -19.160203\n",
            "resetting env. episode 13.000000, reward total was -19.000000. running mean: -19.158601\n",
            "resetting env. episode 14.000000, reward total was -21.000000. running mean: -19.177015\n",
            "resetting env. episode 15.000000, reward total was -20.000000. running mean: -19.185245\n",
            "resetting env. episode 16.000000, reward total was -21.000000. running mean: -19.203392\n",
            "resetting env. episode 17.000000, reward total was -21.000000. running mean: -19.221358\n",
            "resetting env. episode 18.000000, reward total was -20.000000. running mean: -19.229145\n",
            "resetting env. episode 19.000000, reward total was -20.000000. running mean: -19.236853\n",
            "resetting env. episode 20.000000, reward total was -21.000000. running mean: -19.254485\n",
            "resetting env. episode 21.000000, reward total was -21.000000. running mean: -19.271940\n",
            "resetting env. episode 22.000000, reward total was -21.000000. running mean: -19.289220\n",
            "resetting env. episode 23.000000, reward total was -21.000000. running mean: -19.306328\n",
            "resetting env. episode 24.000000, reward total was -19.000000. running mean: -19.303265\n",
            "resetting env. episode 25.000000, reward total was -21.000000. running mean: -19.320232\n",
            "resetting env. episode 26.000000, reward total was -21.000000. running mean: -19.337030\n",
            "resetting env. episode 27.000000, reward total was -21.000000. running mean: -19.353660\n",
            "resetting env. episode 28.000000, reward total was -21.000000. running mean: -19.370123\n",
            "resetting env. episode 29.000000, reward total was -20.000000. running mean: -19.376422\n",
            "resetting env. episode 30.000000, reward total was -21.000000. running mean: -19.392658\n",
            "resetting env. episode 31.000000, reward total was -21.000000. running mean: -19.408731\n",
            "resetting env. episode 32.000000, reward total was -20.000000. running mean: -19.414644\n",
            "resetting env. episode 33.000000, reward total was -20.000000. running mean: -19.420497\n",
            "resetting env. episode 34.000000, reward total was -21.000000. running mean: -19.436292\n",
            "resetting env. episode 35.000000, reward total was -21.000000. running mean: -19.451929\n",
            "resetting env. episode 36.000000, reward total was -21.000000. running mean: -19.467410\n",
            "resetting env. episode 37.000000, reward total was -19.000000. running mean: -19.462736\n",
            "resetting env. episode 38.000000, reward total was -21.000000. running mean: -19.478109\n",
            "resetting env. episode 39.000000, reward total was -21.000000. running mean: -19.493328\n",
            "resetting env. episode 40.000000, reward total was -21.000000. running mean: -19.508394\n",
            "resetting env. episode 41.000000, reward total was -20.000000. running mean: -19.513310\n",
            "resetting env. episode 42.000000, reward total was -19.000000. running mean: -19.508177\n",
            "resetting env. episode 43.000000, reward total was -21.000000. running mean: -19.523096\n",
            "resetting env. episode 44.000000, reward total was -21.000000. running mean: -19.537865\n",
            "resetting env. episode 45.000000, reward total was -21.000000. running mean: -19.552486\n",
            "resetting env. episode 46.000000, reward total was -21.000000. running mean: -19.566961\n",
            "resetting env. episode 47.000000, reward total was -19.000000. running mean: -19.561291\n",
            "resetting env. episode 48.000000, reward total was -19.000000. running mean: -19.555679\n",
            "resetting env. episode 49.000000, reward total was -20.000000. running mean: -19.560122\n",
            "resetting env. episode 50.000000, reward total was -20.000000. running mean: -19.564521\n",
            "resetting env. episode 51.000000, reward total was -21.000000. running mean: -19.578875\n",
            "resetting env. episode 52.000000, reward total was -18.000000. running mean: -19.563087\n",
            "resetting env. episode 53.000000, reward total was -21.000000. running mean: -19.577456\n",
            "resetting env. episode 54.000000, reward total was -21.000000. running mean: -19.591681\n",
            "resetting env. episode 55.000000, reward total was -20.000000. running mean: -19.595764\n",
            "resetting env. episode 56.000000, reward total was -17.000000. running mean: -19.569807\n",
            "resetting env. episode 57.000000, reward total was -21.000000. running mean: -19.584109\n",
            "resetting env. episode 58.000000, reward total was -20.000000. running mean: -19.588268\n",
            "resetting env. episode 59.000000, reward total was -21.000000. running mean: -19.602385\n",
            "resetting env. episode 60.000000, reward total was -21.000000. running mean: -19.616361\n",
            "resetting env. episode 61.000000, reward total was -19.000000. running mean: -19.610197\n",
            "resetting env. episode 62.000000, reward total was -21.000000. running mean: -19.624095\n",
            "resetting env. episode 63.000000, reward total was -21.000000. running mean: -19.637854\n",
            "resetting env. episode 64.000000, reward total was -21.000000. running mean: -19.651476\n",
            "resetting env. episode 65.000000, reward total was -20.000000. running mean: -19.654961\n",
            "resetting env. episode 66.000000, reward total was -20.000000. running mean: -19.658412\n",
            "resetting env. episode 67.000000, reward total was -21.000000. running mean: -19.671827\n",
            "resetting env. episode 68.000000, reward total was -21.000000. running mean: -19.685109\n",
            "resetting env. episode 69.000000, reward total was -20.000000. running mean: -19.688258\n",
            "resetting env. episode 70.000000, reward total was -21.000000. running mean: -19.701375\n",
            "resetting env. episode 71.000000, reward total was -19.000000. running mean: -19.694362\n",
            "resetting env. episode 72.000000, reward total was -18.000000. running mean: -19.677418\n",
            "resetting env. episode 73.000000, reward total was -19.000000. running mean: -19.670644\n",
            "resetting env. episode 74.000000, reward total was -21.000000. running mean: -19.683937\n",
            "resetting env. episode 75.000000, reward total was -18.000000. running mean: -19.667098\n",
            "resetting env. episode 76.000000, reward total was -20.000000. running mean: -19.670427\n",
            "resetting env. episode 77.000000, reward total was -21.000000. running mean: -19.683723\n",
            "resetting env. episode 78.000000, reward total was -21.000000. running mean: -19.696886\n",
            "resetting env. episode 79.000000, reward total was -21.000000. running mean: -19.709917\n",
            "resetting env. episode 80.000000, reward total was -21.000000. running mean: -19.722818\n",
            "resetting env. episode 81.000000, reward total was -19.000000. running mean: -19.715589\n",
            "resetting env. episode 82.000000, reward total was -20.000000. running mean: -19.718434\n",
            "resetting env. episode 83.000000, reward total was -21.000000. running mean: -19.731249\n",
            "resetting env. episode 84.000000, reward total was -21.000000. running mean: -19.743937\n",
            "resetting env. episode 85.000000, reward total was -21.000000. running mean: -19.756497\n",
            "resetting env. episode 86.000000, reward total was -21.000000. running mean: -19.768932\n",
            "resetting env. episode 87.000000, reward total was -18.000000. running mean: -19.751243\n",
            "resetting env. episode 88.000000, reward total was -21.000000. running mean: -19.763731\n",
            "resetting env. episode 89.000000, reward total was -21.000000. running mean: -19.776093\n",
            "resetting env. episode 90.000000, reward total was -20.000000. running mean: -19.778332\n",
            "resetting env. episode 91.000000, reward total was -21.000000. running mean: -19.790549\n",
            "resetting env. episode 92.000000, reward total was -19.000000. running mean: -19.782644\n",
            "resetting env. episode 93.000000, reward total was -21.000000. running mean: -19.794817\n",
            "resetting env. episode 94.000000, reward total was -21.000000. running mean: -19.806869\n",
            "resetting env. episode 95.000000, reward total was -20.000000. running mean: -19.808800\n",
            "resetting env. episode 96.000000, reward total was -19.000000. running mean: -19.800712\n",
            "resetting env. episode 97.000000, reward total was -19.000000. running mean: -19.792705\n",
            "resetting env. episode 98.000000, reward total was -20.000000. running mean: -19.794778\n",
            "resetting env. episode 99.000000, reward total was -19.000000. running mean: -19.786830\n",
            "resetting env. episode 100.000000, reward total was -20.000000. running mean: -19.788962\n",
            "resetting env. episode 101.000000, reward total was -20.000000. running mean: -19.791072\n",
            "resetting env. episode 102.000000, reward total was -21.000000. running mean: -19.803162\n",
            "resetting env. episode 103.000000, reward total was -19.000000. running mean: -19.795130\n",
            "resetting env. episode 104.000000, reward total was -20.000000. running mean: -19.797179\n",
            "resetting env. episode 105.000000, reward total was -21.000000. running mean: -19.809207\n",
            "resetting env. episode 106.000000, reward total was -21.000000. running mean: -19.821115\n",
            "resetting env. episode 107.000000, reward total was -19.000000. running mean: -19.812904\n",
            "resetting env. episode 108.000000, reward total was -20.000000. running mean: -19.814775\n",
            "resetting env. episode 109.000000, reward total was -19.000000. running mean: -19.806627\n",
            "resetting env. episode 110.000000, reward total was -20.000000. running mean: -19.808561\n",
            "resetting env. episode 111.000000, reward total was -19.000000. running mean: -19.800475\n",
            "resetting env. episode 112.000000, reward total was -21.000000. running mean: -19.812470\n",
            "resetting env. episode 113.000000, reward total was -21.000000. running mean: -19.824346\n",
            "resetting env. episode 114.000000, reward total was -20.000000. running mean: -19.826102\n",
            "resetting env. episode 115.000000, reward total was -20.000000. running mean: -19.827841\n",
            "resetting env. episode 116.000000, reward total was -21.000000. running mean: -19.839563\n",
            "resetting env. episode 117.000000, reward total was -21.000000. running mean: -19.851167\n",
            "resetting env. episode 118.000000, reward total was -20.000000. running mean: -19.852655\n",
            "resetting env. episode 119.000000, reward total was -20.000000. running mean: -19.854129\n",
            "resetting env. episode 120.000000, reward total was -21.000000. running mean: -19.865588\n",
            "resetting env. episode 121.000000, reward total was -21.000000. running mean: -19.876932\n",
            "resetting env. episode 122.000000, reward total was -21.000000. running mean: -19.888162\n",
            "resetting env. episode 123.000000, reward total was -19.000000. running mean: -19.879281\n",
            "resetting env. episode 124.000000, reward total was -20.000000. running mean: -19.880488\n",
            "resetting env. episode 125.000000, reward total was -21.000000. running mean: -19.891683\n",
            "resetting env. episode 126.000000, reward total was -18.000000. running mean: -19.872766\n",
            "resetting env. episode 127.000000, reward total was -18.000000. running mean: -19.854039\n",
            "resetting env. episode 128.000000, reward total was -19.000000. running mean: -19.845498\n",
            "resetting env. episode 129.000000, reward total was -21.000000. running mean: -19.857043\n",
            "resetting env. episode 130.000000, reward total was -21.000000. running mean: -19.868473\n",
            "resetting env. episode 131.000000, reward total was -21.000000. running mean: -19.879788\n",
            "resetting env. episode 132.000000, reward total was -21.000000. running mean: -19.890990\n",
            "resetting env. episode 133.000000, reward total was -19.000000. running mean: -19.882080\n",
            "resetting env. episode 134.000000, reward total was -20.000000. running mean: -19.883259\n",
            "resetting env. episode 135.000000, reward total was -19.000000. running mean: -19.874427\n",
            "resetting env. episode 136.000000, reward total was -20.000000. running mean: -19.875683\n",
            "resetting env. episode 137.000000, reward total was -20.000000. running mean: -19.876926\n",
            "resetting env. episode 138.000000, reward total was -19.000000. running mean: -19.868157\n",
            "resetting env. episode 139.000000, reward total was -21.000000. running mean: -19.879475\n",
            "resetting env. episode 140.000000, reward total was -21.000000. running mean: -19.890680\n",
            "resetting env. episode 141.000000, reward total was -20.000000. running mean: -19.891773\n",
            "resetting env. episode 142.000000, reward total was -21.000000. running mean: -19.902856\n",
            "resetting env. episode 143.000000, reward total was -21.000000. running mean: -19.913827\n",
            "resetting env. episode 144.000000, reward total was -21.000000. running mean: -19.924689\n",
            "resetting env. episode 145.000000, reward total was -19.000000. running mean: -19.915442\n",
            "resetting env. episode 146.000000, reward total was -21.000000. running mean: -19.926288\n",
            "resetting env. episode 147.000000, reward total was -20.000000. running mean: -19.927025\n",
            "resetting env. episode 148.000000, reward total was -21.000000. running mean: -19.937754\n",
            "resetting env. episode 149.000000, reward total was -21.000000. running mean: -19.948377\n",
            "resetting env. episode 150.000000, reward total was -20.000000. running mean: -19.948893\n",
            "resetting env. episode 151.000000, reward total was -18.000000. running mean: -19.929404\n",
            "resetting env. episode 152.000000, reward total was -21.000000. running mean: -19.940110\n",
            "resetting env. episode 153.000000, reward total was -20.000000. running mean: -19.940709\n",
            "resetting env. episode 154.000000, reward total was -20.000000. running mean: -19.941302\n",
            "resetting env. episode 155.000000, reward total was -19.000000. running mean: -19.931889\n",
            "resetting env. episode 156.000000, reward total was -21.000000. running mean: -19.942570\n",
            "resetting env. episode 157.000000, reward total was -19.000000. running mean: -19.933144\n",
            "resetting env. episode 158.000000, reward total was -20.000000. running mean: -19.933813\n",
            "resetting env. episode 159.000000, reward total was -21.000000. running mean: -19.944475\n",
            "resetting env. episode 160.000000, reward total was -21.000000. running mean: -19.955030\n",
            "resetting env. episode 161.000000, reward total was -19.000000. running mean: -19.945480\n",
            "resetting env. episode 162.000000, reward total was -21.000000. running mean: -19.956025\n",
            "resetting env. episode 163.000000, reward total was -20.000000. running mean: -19.956465\n",
            "resetting env. episode 164.000000, reward total was -20.000000. running mean: -19.956900\n",
            "resetting env. episode 165.000000, reward total was -20.000000. running mean: -19.957331\n",
            "resetting env. episode 166.000000, reward total was -21.000000. running mean: -19.967758\n",
            "resetting env. episode 167.000000, reward total was -21.000000. running mean: -19.978080\n",
            "resetting env. episode 168.000000, reward total was -20.000000. running mean: -19.978299\n",
            "resetting env. episode 169.000000, reward total was -21.000000. running mean: -19.988516\n",
            "resetting env. episode 170.000000, reward total was -21.000000. running mean: -19.998631\n",
            "resetting env. episode 171.000000, reward total was -20.000000. running mean: -19.998645\n",
            "resetting env. episode 172.000000, reward total was -20.000000. running mean: -19.998658\n",
            "resetting env. episode 173.000000, reward total was -19.000000. running mean: -19.988672\n",
            "resetting env. episode 174.000000, reward total was -20.000000. running mean: -19.988785\n",
            "resetting env. episode 175.000000, reward total was -18.000000. running mean: -19.968897\n",
            "resetting env. episode 176.000000, reward total was -18.000000. running mean: -19.949208\n",
            "resetting env. episode 177.000000, reward total was -19.000000. running mean: -19.939716\n",
            "resetting env. episode 178.000000, reward total was -21.000000. running mean: -19.950319\n",
            "resetting env. episode 179.000000, reward total was -21.000000. running mean: -19.960816\n",
            "resetting env. episode 180.000000, reward total was -20.000000. running mean: -19.961208\n",
            "resetting env. episode 181.000000, reward total was -19.000000. running mean: -19.951596\n",
            "resetting env. episode 182.000000, reward total was -19.000000. running mean: -19.942080\n",
            "resetting env. episode 183.000000, reward total was -21.000000. running mean: -19.952659\n",
            "resetting env. episode 184.000000, reward total was -19.000000. running mean: -19.943132\n",
            "resetting env. episode 185.000000, reward total was -19.000000. running mean: -19.933701\n",
            "resetting env. episode 186.000000, reward total was -21.000000. running mean: -19.944364\n",
            "resetting env. episode 187.000000, reward total was -21.000000. running mean: -19.954920\n",
            "resetting env. episode 188.000000, reward total was -21.000000. running mean: -19.965371\n",
            "resetting env. episode 189.000000, reward total was -20.000000. running mean: -19.965717\n",
            "resetting env. episode 190.000000, reward total was -20.000000. running mean: -19.966060\n",
            "resetting env. episode 191.000000, reward total was -20.000000. running mean: -19.966400\n",
            "resetting env. episode 192.000000, reward total was -21.000000. running mean: -19.976736\n",
            "resetting env. episode 193.000000, reward total was -20.000000. running mean: -19.976968\n",
            "resetting env. episode 194.000000, reward total was -20.000000. running mean: -19.977199\n",
            "resetting env. episode 195.000000, reward total was -21.000000. running mean: -19.987427\n",
            "resetting env. episode 196.000000, reward total was -21.000000. running mean: -19.997552\n",
            "resetting env. episode 197.000000, reward total was -19.000000. running mean: -19.987577\n",
            "resetting env. episode 198.000000, reward total was -21.000000. running mean: -19.997701\n",
            "resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.007724\n",
            "resetting env. episode 200.000000, reward total was -20.000000. running mean: -20.007647\n",
            "resetting env. episode 201.000000, reward total was -20.000000. running mean: -20.007570\n",
            "resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.017495\n",
            "resetting env. episode 203.000000, reward total was -19.000000. running mean: -20.007320\n",
            "resetting env. episode 204.000000, reward total was -20.000000. running mean: -20.007246\n",
            "resetting env. episode 205.000000, reward total was -21.000000. running mean: -20.017174\n",
            "resetting env. episode 206.000000, reward total was -20.000000. running mean: -20.017002\n",
            "resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.026832\n",
            "resetting env. episode 208.000000, reward total was -17.000000. running mean: -19.996564\n",
            "resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.006598\n",
            "resetting env. episode 210.000000, reward total was -21.000000. running mean: -20.016532\n",
            "resetting env. episode 211.000000, reward total was -20.000000. running mean: -20.016367\n",
            "resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.026203\n",
            "resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.035941\n",
            "resetting env. episode 214.000000, reward total was -19.000000. running mean: -20.025582\n",
            "resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.035326\n",
            "resetting env. episode 216.000000, reward total was -20.000000. running mean: -20.034973\n",
            "resetting env. episode 217.000000, reward total was -20.000000. running mean: -20.034623\n",
            "resetting env. episode 218.000000, reward total was -20.000000. running mean: -20.034277\n",
            "resetting env. episode 219.000000, reward total was -20.000000. running mean: -20.033934\n",
            "resetting env. episode 220.000000, reward total was -20.000000. running mean: -20.033595\n",
            "resetting env. episode 221.000000, reward total was -20.000000. running mean: -20.033259\n",
            "resetting env. episode 222.000000, reward total was -20.000000. running mean: -20.032926\n",
            "resetting env. episode 223.000000, reward total was -19.000000. running mean: -20.022597\n",
            "resetting env. episode 224.000000, reward total was -20.000000. running mean: -20.022371\n",
            "resetting env. episode 225.000000, reward total was -20.000000. running mean: -20.022147\n",
            "resetting env. episode 226.000000, reward total was -19.000000. running mean: -20.011926\n",
            "resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.021807\n",
            "resetting env. episode 228.000000, reward total was -21.000000. running mean: -20.031588\n",
            "resetting env. episode 229.000000, reward total was -20.000000. running mean: -20.031273\n",
            "resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.040960\n",
            "resetting env. episode 231.000000, reward total was -20.000000. running mean: -20.040550\n",
            "resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.050145\n",
            "resetting env. episode 233.000000, reward total was -21.000000. running mean: -20.059643\n",
            "resetting env. episode 234.000000, reward total was -21.000000. running mean: -20.069047\n",
            "resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.078356\n",
            "resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.087573\n",
            "resetting env. episode 237.000000, reward total was -21.000000. running mean: -20.096697\n",
            "resetting env. episode 238.000000, reward total was -20.000000. running mean: -20.095730\n",
            "resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.104773\n",
            "resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.113725\n",
            "resetting env. episode 241.000000, reward total was -20.000000. running mean: -20.112588\n",
            "resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.121462\n",
            "resetting env. episode 243.000000, reward total was -20.000000. running mean: -20.120247\n",
            "resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.129045\n",
            "resetting env. episode 245.000000, reward total was -17.000000. running mean: -20.097754\n",
            "resetting env. episode 246.000000, reward total was -17.000000. running mean: -20.066777\n",
            "resetting env. episode 247.000000, reward total was -19.000000. running mean: -20.056109\n",
            "resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.065548\n",
            "resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.074893\n",
            "resetting env. episode 250.000000, reward total was -20.000000. running mean: -20.074144\n",
            "resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.083402\n",
            "resetting env. episode 252.000000, reward total was -21.000000. running mean: -20.092568\n",
            "resetting env. episode 253.000000, reward total was -20.000000. running mean: -20.091642\n",
            "resetting env. episode 254.000000, reward total was -21.000000. running mean: -20.100726\n",
            "resetting env. episode 255.000000, reward total was -20.000000. running mean: -20.099719\n",
            "resetting env. episode 256.000000, reward total was -20.000000. running mean: -20.098722\n",
            "resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.107734\n",
            "resetting env. episode 258.000000, reward total was -21.000000. running mean: -20.116657\n",
            "resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.125490\n",
            "resetting env. episode 260.000000, reward total was -19.000000. running mean: -20.114236\n",
            "resetting env. episode 261.000000, reward total was -20.000000. running mean: -20.113093\n",
            "resetting env. episode 262.000000, reward total was -19.000000. running mean: -20.101962\n",
            "resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.110943\n",
            "resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.119833\n",
            "resetting env. episode 265.000000, reward total was -20.000000. running mean: -20.118635\n",
            "resetting env. episode 266.000000, reward total was -21.000000. running mean: -20.127449\n",
            "resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.136174\n",
            "resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.144812\n",
            "resetting env. episode 269.000000, reward total was -18.000000. running mean: -20.123364\n",
            "resetting env. episode 270.000000, reward total was -20.000000. running mean: -20.122131\n",
            "resetting env. episode 271.000000, reward total was -21.000000. running mean: -20.130909\n",
            "resetting env. episode 272.000000, reward total was -20.000000. running mean: -20.129600\n",
            "resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.138304\n",
            "resetting env. episode 274.000000, reward total was -20.000000. running mean: -20.136921\n",
            "resetting env. episode 275.000000, reward total was -20.000000. running mean: -20.135552\n",
            "resetting env. episode 276.000000, reward total was -19.000000. running mean: -20.124196\n",
            "resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.132954\n",
            "resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.141625\n",
            "resetting env. episode 279.000000, reward total was -21.000000. running mean: -20.150209\n",
            "resetting env. episode 280.000000, reward total was -19.000000. running mean: -20.138707\n",
            "resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.147319\n",
            "resetting env. episode 282.000000, reward total was -18.000000. running mean: -20.125846\n",
            "resetting env. episode 283.000000, reward total was -20.000000. running mean: -20.124588\n",
            "resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.133342\n",
            "resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.142009\n",
            "resetting env. episode 286.000000, reward total was -20.000000. running mean: -20.140588\n",
            "resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.149183\n",
            "resetting env. episode 288.000000, reward total was -19.000000. running mean: -20.137691\n",
            "resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.146314\n",
            "resetting env. episode 290.000000, reward total was -20.000000. running mean: -20.144851\n",
            "resetting env. episode 291.000000, reward total was -20.000000. running mean: -20.143402\n",
            "resetting env. episode 292.000000, reward total was -21.000000. running mean: -20.151968\n",
            "resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.160448\n",
            "resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.168844\n",
            "resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.177156\n",
            "resetting env. episode 296.000000, reward total was -14.000000. running mean: -20.115384\n",
            "resetting env. episode 297.000000, reward total was -20.000000. running mean: -20.114230\n",
            "resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.123088\n",
            "resetting env. episode 299.000000, reward total was -21.000000. running mean: -20.131857\n",
            "resetting env. episode 300.000000, reward total was -21.000000. running mean: -20.140538\n",
            "resetting env. episode 301.000000, reward total was -21.000000. running mean: -20.149133\n",
            "resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.157642\n",
            "resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.166065\n",
            "resetting env. episode 304.000000, reward total was -20.000000. running mean: -20.164405\n",
            "resetting env. episode 305.000000, reward total was -20.000000. running mean: -20.162761\n",
            "resetting env. episode 306.000000, reward total was -20.000000. running mean: -20.161133\n",
            "resetting env. episode 307.000000, reward total was -20.000000. running mean: -20.159522\n",
            "resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.167926\n",
            "resetting env. episode 309.000000, reward total was -21.000000. running mean: -20.176247\n",
            "resetting env. episode 310.000000, reward total was -20.000000. running mean: -20.174485\n",
            "resetting env. episode 311.000000, reward total was -20.000000. running mean: -20.172740\n",
            "resetting env. episode 312.000000, reward total was -17.000000. running mean: -20.141012\n",
            "resetting env. episode 313.000000, reward total was -20.000000. running mean: -20.139602\n",
            "resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.148206\n",
            "resetting env. episode 315.000000, reward total was -20.000000. running mean: -20.146724\n",
            "resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.155257\n",
            "resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.163704\n",
            "resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.172067\n",
            "resetting env. episode 319.000000, reward total was -19.000000. running mean: -20.160347\n",
            "resetting env. episode 320.000000, reward total was -18.000000. running mean: -20.138743\n",
            "resetting env. episode 321.000000, reward total was -20.000000. running mean: -20.137356\n",
            "resetting env. episode 322.000000, reward total was -21.000000. running mean: -20.145982\n",
            "resetting env. episode 323.000000, reward total was -20.000000. running mean: -20.144522\n",
            "resetting env. episode 324.000000, reward total was -17.000000. running mean: -20.113077\n",
            "resetting env. episode 325.000000, reward total was -21.000000. running mean: -20.121946\n",
            "resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.130727\n",
            "resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.139420\n",
            "resetting env. episode 328.000000, reward total was -20.000000. running mean: -20.138025\n",
            "resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.146645\n",
            "resetting env. episode 330.000000, reward total was -21.000000. running mean: -20.155179\n",
            "resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.163627\n",
            "resetting env. episode 332.000000, reward total was -18.000000. running mean: -20.141991\n",
            "resetting env. episode 333.000000, reward total was -20.000000. running mean: -20.140571\n",
            "resetting env. episode 334.000000, reward total was -20.000000. running mean: -20.139165\n",
            "resetting env. episode 335.000000, reward total was -20.000000. running mean: -20.137773\n",
            "resetting env. episode 336.000000, reward total was -20.000000. running mean: -20.136396\n",
            "resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.145032\n",
            "resetting env. episode 338.000000, reward total was -21.000000. running mean: -20.153581\n",
            "resetting env. episode 339.000000, reward total was -21.000000. running mean: -20.162046\n",
            "resetting env. episode 340.000000, reward total was -21.000000. running mean: -20.170425\n",
            "resetting env. episode 341.000000, reward total was -20.000000. running mean: -20.168721\n",
            "resetting env. episode 342.000000, reward total was -19.000000. running mean: -20.157034\n",
            "resetting env. episode 343.000000, reward total was -21.000000. running mean: -20.165463\n",
            "resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.173809\n",
            "resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.182071\n",
            "resetting env. episode 346.000000, reward total was -20.000000. running mean: -20.180250\n",
            "resetting env. episode 347.000000, reward total was -20.000000. running mean: -20.178447\n",
            "resetting env. episode 348.000000, reward total was -20.000000. running mean: -20.176663\n",
            "resetting env. episode 349.000000, reward total was -20.000000. running mean: -20.174896\n",
            "resetting env. episode 350.000000, reward total was -20.000000. running mean: -20.173147\n",
            "resetting env. episode 351.000000, reward total was -19.000000. running mean: -20.161416\n",
            "resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.169802\n",
            "resetting env. episode 353.000000, reward total was -18.000000. running mean: -20.148104\n",
            "resetting env. episode 354.000000, reward total was -17.000000. running mean: -20.116623\n",
            "resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.125456\n",
            "resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.134202\n",
            "resetting env. episode 357.000000, reward total was -20.000000. running mean: -20.132860\n",
            "resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.141531\n",
            "resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.150116\n",
            "resetting env. episode 360.000000, reward total was -19.000000. running mean: -20.138615\n",
            "resetting env. episode 361.000000, reward total was -20.000000. running mean: -20.137229\n",
            "resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.145856\n",
            "resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.154398\n",
            "resetting env. episode 364.000000, reward total was -20.000000. running mean: -20.152854\n",
            "resetting env. episode 365.000000, reward total was -21.000000. running mean: -20.161325\n",
            "resetting env. episode 366.000000, reward total was -18.000000. running mean: -20.139712\n",
            "resetting env. episode 367.000000, reward total was -20.000000. running mean: -20.138315\n",
            "resetting env. episode 368.000000, reward total was -20.000000. running mean: -20.136932\n",
            "resetting env. episode 369.000000, reward total was -20.000000. running mean: -20.135562\n",
            "resetting env. episode 370.000000, reward total was -21.000000. running mean: -20.144207\n",
            "resetting env. episode 371.000000, reward total was -19.000000. running mean: -20.132765\n",
            "resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.141437\n",
            "resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.150023\n",
            "resetting env. episode 374.000000, reward total was -18.000000. running mean: -20.128523\n",
            "resetting env. episode 375.000000, reward total was -21.000000. running mean: -20.137237\n",
            "resetting env. episode 376.000000, reward total was -21.000000. running mean: -20.145865\n",
            "resetting env. episode 377.000000, reward total was -18.000000. running mean: -20.124406\n",
            "resetting env. episode 378.000000, reward total was -20.000000. running mean: -20.123162\n",
            "resetting env. episode 379.000000, reward total was -20.000000. running mean: -20.121931\n",
            "resetting env. episode 380.000000, reward total was -20.000000. running mean: -20.120711\n",
            "resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.129504\n",
            "resetting env. episode 382.000000, reward total was -20.000000. running mean: -20.128209\n",
            "resetting env. episode 383.000000, reward total was -21.000000. running mean: -20.136927\n",
            "resetting env. episode 384.000000, reward total was -20.000000. running mean: -20.135558\n",
            "resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.144202\n",
            "resetting env. episode 386.000000, reward total was -19.000000. running mean: -20.132760\n",
            "resetting env. episode 387.000000, reward total was -19.000000. running mean: -20.121433\n",
            "resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.130218\n",
            "resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.138916\n",
            "resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.147527\n",
            "resetting env. episode 391.000000, reward total was -18.000000. running mean: -20.126052\n",
            "resetting env. episode 392.000000, reward total was -20.000000. running mean: -20.124791\n",
            "resetting env. episode 393.000000, reward total was -20.000000. running mean: -20.123543\n",
            "resetting env. episode 394.000000, reward total was -21.000000. running mean: -20.132308\n",
            "resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.140985\n",
            "resetting env. episode 396.000000, reward total was -20.000000. running mean: -20.139575\n",
            "resetting env. episode 397.000000, reward total was -18.000000. running mean: -20.118179\n",
            "resetting env. episode 398.000000, reward total was -20.000000. running mean: -20.116997\n",
            "resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.125827\n",
            "resetting env. episode 400.000000, reward total was -20.000000. running mean: -20.124569\n",
            "resetting env. episode 401.000000, reward total was -20.000000. running mean: -20.123323\n",
            "resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.132090\n",
            "resetting env. episode 403.000000, reward total was -19.000000. running mean: -20.120769\n",
            "resetting env. episode 404.000000, reward total was -20.000000. running mean: -20.119562\n",
            "resetting env. episode 405.000000, reward total was -20.000000. running mean: -20.118366\n",
            "resetting env. episode 406.000000, reward total was -21.000000. running mean: -20.127182\n",
            "resetting env. episode 407.000000, reward total was -19.000000. running mean: -20.115910\n",
            "resetting env. episode 408.000000, reward total was -18.000000. running mean: -20.094751\n",
            "resetting env. episode 409.000000, reward total was -19.000000. running mean: -20.083804\n",
            "resetting env. episode 410.000000, reward total was -19.000000. running mean: -20.072966\n",
            "resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.082236\n",
            "resetting env. episode 412.000000, reward total was -21.000000. running mean: -20.091414\n",
            "resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.100500\n",
            "resetting env. episode 414.000000, reward total was -19.000000. running mean: -20.089495\n",
            "resetting env. episode 415.000000, reward total was -21.000000. running mean: -20.098600\n",
            "resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.107614\n",
            "resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.116538\n",
            "resetting env. episode 418.000000, reward total was -20.000000. running mean: -20.115372\n",
            "resetting env. episode 419.000000, reward total was -20.000000. running mean: -20.114218\n",
            "resetting env. episode 420.000000, reward total was -20.000000. running mean: -20.113076\n",
            "resetting env. episode 421.000000, reward total was -19.000000. running mean: -20.101946\n",
            "resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.110926\n",
            "resetting env. episode 423.000000, reward total was -21.000000. running mean: -20.119817\n",
            "resetting env. episode 424.000000, reward total was -21.000000. running mean: -20.128619\n",
            "resetting env. episode 425.000000, reward total was -20.000000. running mean: -20.127332\n",
            "resetting env. episode 426.000000, reward total was -17.000000. running mean: -20.096059\n",
            "resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.105099\n",
            "resetting env. episode 428.000000, reward total was -20.000000. running mean: -20.104048\n",
            "resetting env. episode 429.000000, reward total was -21.000000. running mean: -20.113007\n",
            "resetting env. episode 430.000000, reward total was -21.000000. running mean: -20.121877\n",
            "resetting env. episode 431.000000, reward total was -21.000000. running mean: -20.130658\n",
            "resetting env. episode 432.000000, reward total was -20.000000. running mean: -20.129352\n",
            "resetting env. episode 433.000000, reward total was -20.000000. running mean: -20.128058\n",
            "resetting env. episode 434.000000, reward total was -20.000000. running mean: -20.126778\n",
            "resetting env. episode 435.000000, reward total was -21.000000. running mean: -20.135510\n",
            "resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.144155\n",
            "resetting env. episode 437.000000, reward total was -21.000000. running mean: -20.152713\n",
            "resetting env. episode 438.000000, reward total was -20.000000. running mean: -20.151186\n",
            "resetting env. episode 439.000000, reward total was -20.000000. running mean: -20.149674\n",
            "resetting env. episode 440.000000, reward total was -18.000000. running mean: -20.128177\n",
            "resetting env. episode 441.000000, reward total was -21.000000. running mean: -20.136896\n",
            "resetting env. episode 442.000000, reward total was -20.000000. running mean: -20.135527\n",
            "resetting env. episode 443.000000, reward total was -18.000000. running mean: -20.114171\n",
            "resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.123030\n",
            "resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.131799\n",
            "resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.140481\n",
            "resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.149077\n",
            "resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.157586\n",
            "resetting env. episode 449.000000, reward total was -20.000000. running mean: -20.156010\n",
            "resetting env. episode 450.000000, reward total was -19.000000. running mean: -20.144450\n",
            "resetting env. episode 451.000000, reward total was -18.000000. running mean: -20.123005\n",
            "resetting env. episode 452.000000, reward total was -19.000000. running mean: -20.111775\n",
            "resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.120658\n",
            "resetting env. episode 454.000000, reward total was -20.000000. running mean: -20.119451\n",
            "resetting env. episode 455.000000, reward total was -21.000000. running mean: -20.128256\n",
            "resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.136974\n",
            "resetting env. episode 457.000000, reward total was -17.000000. running mean: -20.105604\n",
            "resetting env. episode 458.000000, reward total was -18.000000. running mean: -20.084548\n",
            "resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.093703\n",
            "resetting env. episode 460.000000, reward total was -21.000000. running mean: -20.102766\n",
            "resetting env. episode 461.000000, reward total was -20.000000. running mean: -20.101738\n",
            "resetting env. episode 462.000000, reward total was -20.000000. running mean: -20.100721\n",
            "resetting env. episode 463.000000, reward total was -20.000000. running mean: -20.099713\n",
            "resetting env. episode 464.000000, reward total was -21.000000. running mean: -20.108716\n",
            "resetting env. episode 465.000000, reward total was -20.000000. running mean: -20.107629\n",
            "resetting env. episode 466.000000, reward total was -20.000000. running mean: -20.106553\n",
            "resetting env. episode 467.000000, reward total was -20.000000. running mean: -20.105487\n",
            "resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.114432\n",
            "resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.123288\n",
            "resetting env. episode 470.000000, reward total was -20.000000. running mean: -20.122055\n",
            "resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.130835\n",
            "resetting env. episode 472.000000, reward total was -19.000000. running mean: -20.119526\n",
            "resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.128331\n",
            "resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.137048\n",
            "resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.145677\n",
            "resetting env. episode 476.000000, reward total was -20.000000. running mean: -20.144220\n",
            "resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.152778\n",
            "resetting env. episode 478.000000, reward total was -21.000000. running mean: -20.161250\n",
            "resetting env. episode 479.000000, reward total was -21.000000. running mean: -20.169638\n",
            "resetting env. episode 480.000000, reward total was -20.000000. running mean: -20.167942\n",
            "resetting env. episode 481.000000, reward total was -19.000000. running mean: -20.156262\n",
            "resetting env. episode 482.000000, reward total was -20.000000. running mean: -20.154700\n",
            "resetting env. episode 483.000000, reward total was -20.000000. running mean: -20.153153\n",
            "resetting env. episode 484.000000, reward total was -21.000000. running mean: -20.161621\n",
            "resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.170005\n",
            "resetting env. episode 486.000000, reward total was -20.000000. running mean: -20.168305\n",
            "resetting env. episode 487.000000, reward total was -19.000000. running mean: -20.156622\n",
            "resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.165056\n",
            "resetting env. episode 489.000000, reward total was -21.000000. running mean: -20.173405\n",
            "resetting env. episode 490.000000, reward total was -20.000000. running mean: -20.171671\n",
            "resetting env. episode 491.000000, reward total was -21.000000. running mean: -20.179954\n",
            "resetting env. episode 492.000000, reward total was -20.000000. running mean: -20.178155\n",
            "resetting env. episode 493.000000, reward total was -20.000000. running mean: -20.176373\n",
            "resetting env. episode 494.000000, reward total was -19.000000. running mean: -20.164609\n",
            "resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.172963\n",
            "resetting env. episode 496.000000, reward total was -19.000000. running mean: -20.161234\n",
            "resetting env. episode 497.000000, reward total was -19.000000. running mean: -20.149621\n",
            "resetting env. episode 498.000000, reward total was -19.000000. running mean: -20.138125\n",
            "resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.146744\n",
            "resetting env. episode 500.000000, reward total was -21.000000. running mean: -20.155276\n",
            "resetting env. episode 501.000000, reward total was -20.000000. running mean: -20.153724\n",
            "resetting env. episode 502.000000, reward total was -21.000000. running mean: -20.162186\n",
            "resetting env. episode 503.000000, reward total was -21.000000. running mean: -20.170565\n",
            "resetting env. episode 504.000000, reward total was -21.000000. running mean: -20.178859\n",
            "resetting env. episode 505.000000, reward total was -20.000000. running mean: -20.177070\n",
            "resetting env. episode 506.000000, reward total was -20.000000. running mean: -20.175300\n",
            "resetting env. episode 507.000000, reward total was -20.000000. running mean: -20.173547\n",
            "resetting env. episode 508.000000, reward total was -20.000000. running mean: -20.171811\n",
            "resetting env. episode 509.000000, reward total was -21.000000. running mean: -20.180093\n",
            "resetting env. episode 510.000000, reward total was -20.000000. running mean: -20.178292\n",
            "resetting env. episode 511.000000, reward total was -21.000000. running mean: -20.186509\n",
            "resetting env. episode 512.000000, reward total was -20.000000. running mean: -20.184644\n",
            "resetting env. episode 513.000000, reward total was -18.000000. running mean: -20.162798\n",
            "resetting env. episode 514.000000, reward total was -21.000000. running mean: -20.171170\n",
            "resetting env. episode 515.000000, reward total was -20.000000. running mean: -20.169458\n",
            "resetting env. episode 516.000000, reward total was -21.000000. running mean: -20.177763\n",
            "resetting env. episode 517.000000, reward total was -21.000000. running mean: -20.185986\n",
            "resetting env. episode 518.000000, reward total was -21.000000. running mean: -20.194126\n",
            "resetting env. episode 519.000000, reward total was -20.000000. running mean: -20.192185\n",
            "resetting env. episode 520.000000, reward total was -17.000000. running mean: -20.160263\n",
            "resetting env. episode 521.000000, reward total was -21.000000. running mean: -20.168660\n",
            "resetting env. episode 522.000000, reward total was -17.000000. running mean: -20.136974\n",
            "resetting env. episode 523.000000, reward total was -21.000000. running mean: -20.145604\n",
            "resetting env. episode 524.000000, reward total was -21.000000. running mean: -20.154148\n",
            "resetting env. episode 525.000000, reward total was -20.000000. running mean: -20.152606\n",
            "resetting env. episode 526.000000, reward total was -21.000000. running mean: -20.161080\n",
            "resetting env. episode 527.000000, reward total was -20.000000. running mean: -20.159469\n",
            "resetting env. episode 528.000000, reward total was -19.000000. running mean: -20.147875\n",
            "resetting env. episode 529.000000, reward total was -21.000000. running mean: -20.156396\n",
            "resetting env. episode 530.000000, reward total was -20.000000. running mean: -20.154832\n",
            "resetting env. episode 531.000000, reward total was -18.000000. running mean: -20.133284\n",
            "resetting env. episode 532.000000, reward total was -21.000000. running mean: -20.141951\n",
            "resetting env. episode 533.000000, reward total was -21.000000. running mean: -20.150531\n",
            "resetting env. episode 534.000000, reward total was -19.000000. running mean: -20.139026\n",
            "resetting env. episode 535.000000, reward total was -20.000000. running mean: -20.137636\n",
            "resetting env. episode 536.000000, reward total was -20.000000. running mean: -20.136259\n",
            "resetting env. episode 537.000000, reward total was -20.000000. running mean: -20.134897\n",
            "resetting env. episode 538.000000, reward total was -18.000000. running mean: -20.113548\n",
            "resetting env. episode 539.000000, reward total was -21.000000. running mean: -20.122412\n",
            "resetting env. episode 540.000000, reward total was -21.000000. running mean: -20.131188\n",
            "resetting env. episode 541.000000, reward total was -19.000000. running mean: -20.119876\n",
            "resetting env. episode 542.000000, reward total was -21.000000. running mean: -20.128678\n",
            "resetting env. episode 543.000000, reward total was -21.000000. running mean: -20.137391\n",
            "resetting env. episode 544.000000, reward total was -21.000000. running mean: -20.146017\n",
            "resetting env. episode 545.000000, reward total was -19.000000. running mean: -20.134557\n",
            "resetting env. episode 546.000000, reward total was -21.000000. running mean: -20.143211\n",
            "resetting env. episode 547.000000, reward total was -19.000000. running mean: -20.131779\n",
            "resetting env. episode 548.000000, reward total was -21.000000. running mean: -20.140461\n",
            "resetting env. episode 549.000000, reward total was -21.000000. running mean: -20.149057\n",
            "resetting env. episode 550.000000, reward total was -21.000000. running mean: -20.157566\n",
            "resetting env. episode 551.000000, reward total was -19.000000. running mean: -20.145990\n",
            "resetting env. episode 552.000000, reward total was -21.000000. running mean: -20.154531\n",
            "resetting env. episode 553.000000, reward total was -21.000000. running mean: -20.162985\n",
            "resetting env. episode 554.000000, reward total was -20.000000. running mean: -20.161355\n",
            "resetting env. episode 555.000000, reward total was -19.000000. running mean: -20.149742\n",
            "resetting env. episode 556.000000, reward total was -21.000000. running mean: -20.158244\n",
            "resetting env. episode 557.000000, reward total was -19.000000. running mean: -20.146662\n",
            "resetting env. episode 558.000000, reward total was -20.000000. running mean: -20.145195\n",
            "resetting env. episode 559.000000, reward total was -21.000000. running mean: -20.153743\n",
            "resetting env. episode 560.000000, reward total was -21.000000. running mean: -20.162206\n",
            "resetting env. episode 561.000000, reward total was -19.000000. running mean: -20.150584\n",
            "resetting env. episode 562.000000, reward total was -21.000000. running mean: -20.159078\n",
            "resetting env. episode 563.000000, reward total was -20.000000. running mean: -20.157487\n",
            "resetting env. episode 564.000000, reward total was -20.000000. running mean: -20.155912\n",
            "resetting env. episode 565.000000, reward total was -20.000000. running mean: -20.154353\n",
            "resetting env. episode 566.000000, reward total was -20.000000. running mean: -20.152810\n",
            "resetting env. episode 567.000000, reward total was -18.000000. running mean: -20.131282\n",
            "resetting env. episode 568.000000, reward total was -21.000000. running mean: -20.139969\n",
            "resetting env. episode 569.000000, reward total was -21.000000. running mean: -20.148569\n",
            "resetting env. episode 570.000000, reward total was -21.000000. running mean: -20.157083\n",
            "resetting env. episode 571.000000, reward total was -19.000000. running mean: -20.145513\n",
            "resetting env. episode 572.000000, reward total was -19.000000. running mean: -20.134058\n",
            "resetting env. episode 573.000000, reward total was -21.000000. running mean: -20.142717\n",
            "resetting env. episode 574.000000, reward total was -20.000000. running mean: -20.141290\n",
            "resetting env. episode 575.000000, reward total was -21.000000. running mean: -20.149877\n",
            "resetting env. episode 576.000000, reward total was -21.000000. running mean: -20.158378\n",
            "resetting env. episode 577.000000, reward total was -21.000000. running mean: -20.166794\n",
            "resetting env. episode 578.000000, reward total was -20.000000. running mean: -20.165126\n",
            "resetting env. episode 579.000000, reward total was -20.000000. running mean: -20.163475\n",
            "resetting env. episode 580.000000, reward total was -20.000000. running mean: -20.161840\n",
            "resetting env. episode 581.000000, reward total was -20.000000. running mean: -20.160222\n",
            "resetting env. episode 582.000000, reward total was -20.000000. running mean: -20.158620\n",
            "resetting env. episode 583.000000, reward total was -20.000000. running mean: -20.157034\n",
            "resetting env. episode 584.000000, reward total was -20.000000. running mean: -20.155463\n",
            "resetting env. episode 585.000000, reward total was -20.000000. running mean: -20.153909\n",
            "resetting env. episode 586.000000, reward total was -18.000000. running mean: -20.132369\n",
            "resetting env. episode 587.000000, reward total was -21.000000. running mean: -20.141046\n",
            "resetting env. episode 588.000000, reward total was -21.000000. running mean: -20.149635\n",
            "resetting env. episode 589.000000, reward total was -21.000000. running mean: -20.158139\n",
            "resetting env. episode 590.000000, reward total was -21.000000. running mean: -20.166558\n",
            "resetting env. episode 591.000000, reward total was -19.000000. running mean: -20.154892\n",
            "resetting env. episode 592.000000, reward total was -21.000000. running mean: -20.163343\n",
            "resetting env. episode 593.000000, reward total was -19.000000. running mean: -20.151710\n",
            "resetting env. episode 594.000000, reward total was -19.000000. running mean: -20.140193\n",
            "resetting env. episode 595.000000, reward total was -20.000000. running mean: -20.138791\n",
            "resetting env. episode 596.000000, reward total was -20.000000. running mean: -20.137403\n",
            "resetting env. episode 597.000000, reward total was -20.000000. running mean: -20.136029\n",
            "resetting env. episode 598.000000, reward total was -20.000000. running mean: -20.134668\n",
            "resetting env. episode 599.000000, reward total was -21.000000. running mean: -20.143322\n",
            "resetting env. episode 600.000000, reward total was -21.000000. running mean: -20.151889\n",
            "resetting env. episode 601.000000, reward total was -18.000000. running mean: -20.130370\n",
            "resetting env. episode 602.000000, reward total was -19.000000. running mean: -20.119066\n",
            "resetting env. episode 603.000000, reward total was -21.000000. running mean: -20.127875\n",
            "resetting env. episode 604.000000, reward total was -20.000000. running mean: -20.126597\n",
            "resetting env. episode 605.000000, reward total was -21.000000. running mean: -20.135331\n",
            "resetting env. episode 606.000000, reward total was -21.000000. running mean: -20.143977\n",
            "resetting env. episode 607.000000, reward total was -20.000000. running mean: -20.142537\n",
            "resetting env. episode 608.000000, reward total was -20.000000. running mean: -20.141112\n",
            "resetting env. episode 609.000000, reward total was -21.000000. running mean: -20.149701\n",
            "resetting env. episode 610.000000, reward total was -20.000000. running mean: -20.148204\n",
            "resetting env. episode 611.000000, reward total was -20.000000. running mean: -20.146722\n",
            "resetting env. episode 612.000000, reward total was -21.000000. running mean: -20.155255\n",
            "resetting env. episode 613.000000, reward total was -20.000000. running mean: -20.153702\n",
            "resetting env. episode 614.000000, reward total was -21.000000. running mean: -20.162165\n",
            "resetting env. episode 615.000000, reward total was -21.000000. running mean: -20.170543\n",
            "resetting env. episode 616.000000, reward total was -20.000000. running mean: -20.168838\n",
            "resetting env. episode 617.000000, reward total was -21.000000. running mean: -20.177150\n",
            "resetting env. episode 618.000000, reward total was -21.000000. running mean: -20.185378\n",
            "resetting env. episode 619.000000, reward total was -21.000000. running mean: -20.193524\n",
            "resetting env. episode 620.000000, reward total was -20.000000. running mean: -20.191589\n",
            "resetting env. episode 621.000000, reward total was -19.000000. running mean: -20.179673\n",
            "resetting env. episode 622.000000, reward total was -18.000000. running mean: -20.157877\n",
            "resetting env. episode 623.000000, reward total was -19.000000. running mean: -20.146298\n",
            "resetting env. episode 624.000000, reward total was -21.000000. running mean: -20.154835\n",
            "resetting env. episode 625.000000, reward total was -18.000000. running mean: -20.133286\n",
            "resetting env. episode 626.000000, reward total was -21.000000. running mean: -20.141954\n",
            "resetting env. episode 627.000000, reward total was -20.000000. running mean: -20.140534\n",
            "resetting env. episode 628.000000, reward total was -21.000000. running mean: -20.149129\n",
            "resetting env. episode 629.000000, reward total was -20.000000. running mean: -20.147637\n",
            "resetting env. episode 630.000000, reward total was -21.000000. running mean: -20.156161\n",
            "resetting env. episode 631.000000, reward total was -20.000000. running mean: -20.154599\n",
            "resetting env. episode 632.000000, reward total was -21.000000. running mean: -20.163053\n",
            "resetting env. episode 633.000000, reward total was -21.000000. running mean: -20.171423\n",
            "resetting env. episode 634.000000, reward total was -20.000000. running mean: -20.169709\n",
            "resetting env. episode 635.000000, reward total was -21.000000. running mean: -20.178012\n",
            "resetting env. episode 636.000000, reward total was -20.000000. running mean: -20.176231\n",
            "resetting env. episode 637.000000, reward total was -21.000000. running mean: -20.184469\n",
            "resetting env. episode 638.000000, reward total was -20.000000. running mean: -20.182624\n",
            "resetting env. episode 639.000000, reward total was -21.000000. running mean: -20.190798\n",
            "resetting env. episode 640.000000, reward total was -18.000000. running mean: -20.168890\n",
            "resetting env. episode 641.000000, reward total was -20.000000. running mean: -20.167201\n",
            "resetting env. episode 642.000000, reward total was -21.000000. running mean: -20.175529\n",
            "resetting env. episode 643.000000, reward total was -20.000000. running mean: -20.173774\n",
            "resetting env. episode 644.000000, reward total was -21.000000. running mean: -20.182036\n",
            "resetting env. episode 645.000000, reward total was -21.000000. running mean: -20.190216\n",
            "resetting env. episode 646.000000, reward total was -21.000000. running mean: -20.198314\n",
            "resetting env. episode 647.000000, reward total was -21.000000. running mean: -20.206331\n",
            "resetting env. episode 648.000000, reward total was -19.000000. running mean: -20.194267\n",
            "resetting env. episode 649.000000, reward total was -19.000000. running mean: -20.182325\n",
            "resetting env. episode 650.000000, reward total was -21.000000. running mean: -20.190501\n",
            "resetting env. episode 651.000000, reward total was -21.000000. running mean: -20.198596\n",
            "resetting env. episode 652.000000, reward total was -20.000000. running mean: -20.196610\n",
            "resetting env. episode 653.000000, reward total was -21.000000. running mean: -20.204644\n",
            "resetting env. episode 654.000000, reward total was -18.000000. running mean: -20.182598\n",
            "resetting env. episode 655.000000, reward total was -18.000000. running mean: -20.160772\n",
            "resetting env. episode 656.000000, reward total was -19.000000. running mean: -20.149164\n",
            "resetting env. episode 657.000000, reward total was -21.000000. running mean: -20.157673\n",
            "resetting env. episode 658.000000, reward total was -20.000000. running mean: -20.156096\n",
            "resetting env. episode 659.000000, reward total was -21.000000. running mean: -20.164535\n",
            "resetting env. episode 660.000000, reward total was -21.000000. running mean: -20.172890\n",
            "resetting env. episode 661.000000, reward total was -17.000000. running mean: -20.141161\n",
            "resetting env. episode 662.000000, reward total was -21.000000. running mean: -20.149749\n",
            "resetting env. episode 663.000000, reward total was -21.000000. running mean: -20.158252\n",
            "resetting env. episode 664.000000, reward total was -19.000000. running mean: -20.146669\n",
            "resetting env. episode 665.000000, reward total was -20.000000. running mean: -20.145202\n",
            "resetting env. episode 666.000000, reward total was -21.000000. running mean: -20.153750\n",
            "resetting env. episode 667.000000, reward total was -21.000000. running mean: -20.162213\n",
            "resetting env. episode 668.000000, reward total was -20.000000. running mean: -20.160591\n",
            "resetting env. episode 669.000000, reward total was -18.000000. running mean: -20.138985\n",
            "resetting env. episode 670.000000, reward total was -21.000000. running mean: -20.147595\n",
            "resetting env. episode 671.000000, reward total was -21.000000. running mean: -20.156119\n",
            "resetting env. episode 672.000000, reward total was -20.000000. running mean: -20.154558\n",
            "resetting env. episode 673.000000, reward total was -21.000000. running mean: -20.163012\n",
            "resetting env. episode 674.000000, reward total was -19.000000. running mean: -20.151382\n",
            "resetting env. episode 675.000000, reward total was -21.000000. running mean: -20.159868\n",
            "resetting env. episode 676.000000, reward total was -20.000000. running mean: -20.158270\n",
            "resetting env. episode 677.000000, reward total was -21.000000. running mean: -20.166687\n",
            "resetting env. episode 678.000000, reward total was -21.000000. running mean: -20.175020\n",
            "resetting env. episode 679.000000, reward total was -20.000000. running mean: -20.173270\n",
            "resetting env. episode 680.000000, reward total was -21.000000. running mean: -20.181537\n",
            "resetting env. episode 681.000000, reward total was -21.000000. running mean: -20.189722\n",
            "resetting env. episode 682.000000, reward total was -20.000000. running mean: -20.187825\n",
            "resetting env. episode 683.000000, reward total was -21.000000. running mean: -20.195946\n",
            "resetting env. episode 684.000000, reward total was -21.000000. running mean: -20.203987\n",
            "resetting env. episode 685.000000, reward total was -21.000000. running mean: -20.211947\n",
            "resetting env. episode 686.000000, reward total was -21.000000. running mean: -20.219827\n",
            "resetting env. episode 687.000000, reward total was -20.000000. running mean: -20.217629\n",
            "resetting env. episode 688.000000, reward total was -20.000000. running mean: -20.215453\n",
            "resetting env. episode 689.000000, reward total was -18.000000. running mean: -20.193298\n",
            "resetting env. episode 690.000000, reward total was -20.000000. running mean: -20.191365\n",
            "resetting env. episode 691.000000, reward total was -21.000000. running mean: -20.199452\n",
            "resetting env. episode 692.000000, reward total was -21.000000. running mean: -20.207457\n",
            "resetting env. episode 693.000000, reward total was -21.000000. running mean: -20.215383\n",
            "resetting env. episode 694.000000, reward total was -21.000000. running mean: -20.223229\n",
            "resetting env. episode 695.000000, reward total was -21.000000. running mean: -20.230997\n",
            "resetting env. episode 696.000000, reward total was -19.000000. running mean: -20.218687\n",
            "resetting env. episode 697.000000, reward total was -20.000000. running mean: -20.216500\n",
            "resetting env. episode 698.000000, reward total was -21.000000. running mean: -20.224335\n",
            "resetting env. episode 699.000000, reward total was -20.000000. running mean: -20.222091\n",
            "resetting env. episode 700.000000, reward total was -20.000000. running mean: -20.219870\n",
            "resetting env. episode 701.000000, reward total was -19.000000. running mean: -20.207672\n",
            "resetting env. episode 702.000000, reward total was -19.000000. running mean: -20.195595\n",
            "resetting env. episode 703.000000, reward total was -21.000000. running mean: -20.203639\n",
            "resetting env. episode 704.000000, reward total was -18.000000. running mean: -20.181603\n",
            "resetting env. episode 705.000000, reward total was -21.000000. running mean: -20.189787\n",
            "resetting env. episode 706.000000, reward total was -21.000000. running mean: -20.197889\n",
            "resetting env. episode 707.000000, reward total was -19.000000. running mean: -20.185910\n",
            "resetting env. episode 708.000000, reward total was -20.000000. running mean: -20.184051\n",
            "resetting env. episode 709.000000, reward total was -20.000000. running mean: -20.182210\n",
            "resetting env. episode 710.000000, reward total was -21.000000. running mean: -20.190388\n",
            "resetting env. episode 711.000000, reward total was -21.000000. running mean: -20.198484\n",
            "resetting env. episode 712.000000, reward total was -20.000000. running mean: -20.196499\n",
            "resetting env. episode 713.000000, reward total was -21.000000. running mean: -20.204534\n",
            "resetting env. episode 714.000000, reward total was -20.000000. running mean: -20.202489\n",
            "resetting env. episode 715.000000, reward total was -19.000000. running mean: -20.190464\n",
            "resetting env. episode 716.000000, reward total was -21.000000. running mean: -20.198560\n",
            "resetting env. episode 717.000000, reward total was -21.000000. running mean: -20.206574\n",
            "resetting env. episode 718.000000, reward total was -20.000000. running mean: -20.204508\n",
            "resetting env. episode 719.000000, reward total was -19.000000. running mean: -20.192463\n",
            "resetting env. episode 720.000000, reward total was -21.000000. running mean: -20.200539\n",
            "resetting env. episode 721.000000, reward total was -20.000000. running mean: -20.198533\n",
            "resetting env. episode 722.000000, reward total was -19.000000. running mean: -20.186548\n",
            "resetting env. episode 723.000000, reward total was -21.000000. running mean: -20.194682\n",
            "resetting env. episode 724.000000, reward total was -20.000000. running mean: -20.192736\n",
            "resetting env. episode 725.000000, reward total was -19.000000. running mean: -20.180808\n",
            "resetting env. episode 726.000000, reward total was -20.000000. running mean: -20.179000\n",
            "resetting env. episode 727.000000, reward total was -21.000000. running mean: -20.187210\n",
            "resetting env. episode 728.000000, reward total was -20.000000. running mean: -20.185338\n",
            "resetting env. episode 729.000000, reward total was -21.000000. running mean: -20.193485\n",
            "resetting env. episode 730.000000, reward total was -19.000000. running mean: -20.181550\n",
            "resetting env. episode 731.000000, reward total was -21.000000. running mean: -20.189734\n",
            "resetting env. episode 732.000000, reward total was -20.000000. running mean: -20.187837\n",
            "resetting env. episode 733.000000, reward total was -20.000000. running mean: -20.185959\n",
            "resetting env. episode 734.000000, reward total was -20.000000. running mean: -20.184099\n",
            "resetting env. episode 735.000000, reward total was -21.000000. running mean: -20.192258\n",
            "resetting env. episode 736.000000, reward total was -19.000000. running mean: -20.180335\n",
            "resetting env. episode 737.000000, reward total was -21.000000. running mean: -20.188532\n",
            "resetting env. episode 738.000000, reward total was -20.000000. running mean: -20.186647\n",
            "resetting env. episode 739.000000, reward total was -20.000000. running mean: -20.184780\n",
            "resetting env. episode 740.000000, reward total was -21.000000. running mean: -20.192932\n",
            "resetting env. episode 741.000000, reward total was -19.000000. running mean: -20.181003\n",
            "resetting env. episode 742.000000, reward total was -21.000000. running mean: -20.189193\n",
            "resetting env. episode 743.000000, reward total was -18.000000. running mean: -20.167301\n",
            "resetting env. episode 744.000000, reward total was -18.000000. running mean: -20.145628\n",
            "resetting env. episode 745.000000, reward total was -19.000000. running mean: -20.134172\n",
            "resetting env. episode 746.000000, reward total was -20.000000. running mean: -20.132830\n",
            "resetting env. episode 747.000000, reward total was -21.000000. running mean: -20.141502\n",
            "resetting env. episode 748.000000, reward total was -20.000000. running mean: -20.140087\n",
            "resetting env. episode 749.000000, reward total was -21.000000. running mean: -20.148686\n",
            "resetting env. episode 750.000000, reward total was -20.000000. running mean: -20.147199\n",
            "resetting env. episode 751.000000, reward total was -19.000000. running mean: -20.135727\n",
            "resetting env. episode 752.000000, reward total was -20.000000. running mean: -20.134370\n",
            "resetting env. episode 753.000000, reward total was -19.000000. running mean: -20.123026\n",
            "resetting env. episode 754.000000, reward total was -21.000000. running mean: -20.131796\n",
            "resetting env. episode 755.000000, reward total was -20.000000. running mean: -20.130478\n",
            "resetting env. episode 756.000000, reward total was -20.000000. running mean: -20.129173\n",
            "resetting env. episode 757.000000, reward total was -19.000000. running mean: -20.117881\n",
            "resetting env. episode 758.000000, reward total was -21.000000. running mean: -20.126703\n",
            "resetting env. episode 759.000000, reward total was -21.000000. running mean: -20.135436\n",
            "resetting env. episode 760.000000, reward total was -18.000000. running mean: -20.114081\n",
            "resetting env. episode 761.000000, reward total was -20.000000. running mean: -20.112940\n",
            "resetting env. episode 762.000000, reward total was -20.000000. running mean: -20.111811\n",
            "resetting env. episode 763.000000, reward total was -20.000000. running mean: -20.110693\n",
            "resetting env. episode 764.000000, reward total was -21.000000. running mean: -20.119586\n",
            "resetting env. episode 765.000000, reward total was -20.000000. running mean: -20.118390\n",
            "resetting env. episode 766.000000, reward total was -20.000000. running mean: -20.117206\n",
            "resetting env. episode 767.000000, reward total was -20.000000. running mean: -20.116034\n",
            "resetting env. episode 768.000000, reward total was -21.000000. running mean: -20.124874\n",
            "resetting env. episode 769.000000, reward total was -19.000000. running mean: -20.113625\n",
            "resetting env. episode 770.000000, reward total was -21.000000. running mean: -20.122489\n",
            "resetting env. episode 771.000000, reward total was -21.000000. running mean: -20.131264\n",
            "resetting env. episode 772.000000, reward total was -20.000000. running mean: -20.129951\n",
            "resetting env. episode 773.000000, reward total was -21.000000. running mean: -20.138652\n",
            "resetting env. episode 774.000000, reward total was -21.000000. running mean: -20.147265\n",
            "resetting env. episode 775.000000, reward total was -21.000000. running mean: -20.155793\n",
            "resetting env. episode 776.000000, reward total was -21.000000. running mean: -20.164235\n",
            "resetting env. episode 777.000000, reward total was -20.000000. running mean: -20.162592\n",
            "resetting env. episode 778.000000, reward total was -20.000000. running mean: -20.160966\n",
            "resetting env. episode 779.000000, reward total was -21.000000. running mean: -20.169357\n",
            "resetting env. episode 780.000000, reward total was -21.000000. running mean: -20.177663\n",
            "resetting env. episode 781.000000, reward total was -21.000000. running mean: -20.185887\n",
            "resetting env. episode 782.000000, reward total was -20.000000. running mean: -20.184028\n",
            "resetting env. episode 783.000000, reward total was -21.000000. running mean: -20.192187\n",
            "resetting env. episode 784.000000, reward total was -20.000000. running mean: -20.190266\n",
            "resetting env. episode 785.000000, reward total was -18.000000. running mean: -20.168363\n",
            "resetting env. episode 786.000000, reward total was -21.000000. running mean: -20.176679\n",
            "resetting env. episode 787.000000, reward total was -20.000000. running mean: -20.174912\n",
            "resetting env. episode 788.000000, reward total was -20.000000. running mean: -20.173163\n",
            "resetting env. episode 789.000000, reward total was -18.000000. running mean: -20.151432\n",
            "resetting env. episode 790.000000, reward total was -19.000000. running mean: -20.139917\n",
            "resetting env. episode 791.000000, reward total was -21.000000. running mean: -20.148518\n",
            "resetting env. episode 792.000000, reward total was -21.000000. running mean: -20.157033\n",
            "resetting env. episode 793.000000, reward total was -20.000000. running mean: -20.155463\n",
            "resetting env. episode 794.000000, reward total was -21.000000. running mean: -20.163908\n",
            "resetting env. episode 795.000000, reward total was -21.000000. running mean: -20.172269\n",
            "resetting env. episode 796.000000, reward total was -21.000000. running mean: -20.180546\n",
            "resetting env. episode 797.000000, reward total was -20.000000. running mean: -20.178741\n",
            "resetting env. episode 798.000000, reward total was -19.000000. running mean: -20.166953\n",
            "resetting env. episode 799.000000, reward total was -21.000000. running mean: -20.175284\n",
            "resetting env. episode 800.000000, reward total was -20.000000. running mean: -20.173531\n",
            "resetting env. episode 801.000000, reward total was -18.000000. running mean: -20.151796\n",
            "resetting env. episode 802.000000, reward total was -19.000000. running mean: -20.140278\n",
            "resetting env. episode 803.000000, reward total was -20.000000. running mean: -20.138875\n",
            "resetting env. episode 804.000000, reward total was -21.000000. running mean: -20.147486\n",
            "resetting env. episode 805.000000, reward total was -18.000000. running mean: -20.126011\n",
            "resetting env. episode 806.000000, reward total was -20.000000. running mean: -20.124751\n",
            "resetting env. episode 807.000000, reward total was -20.000000. running mean: -20.123504\n",
            "resetting env. episode 808.000000, reward total was -20.000000. running mean: -20.122269\n",
            "resetting env. episode 809.000000, reward total was -18.000000. running mean: -20.101046\n",
            "resetting env. episode 810.000000, reward total was -21.000000. running mean: -20.110036\n",
            "resetting env. episode 811.000000, reward total was -20.000000. running mean: -20.108935\n",
            "resetting env. episode 812.000000, reward total was -20.000000. running mean: -20.107846\n",
            "resetting env. episode 813.000000, reward total was -21.000000. running mean: -20.116767\n",
            "resetting env. episode 814.000000, reward total was -21.000000. running mean: -20.125600\n",
            "resetting env. episode 815.000000, reward total was -21.000000. running mean: -20.134344\n",
            "resetting env. episode 816.000000, reward total was -20.000000. running mean: -20.133000\n",
            "resetting env. episode 817.000000, reward total was -20.000000. running mean: -20.131670\n",
            "resetting env. episode 818.000000, reward total was -21.000000. running mean: -20.140354\n",
            "resetting env. episode 819.000000, reward total was -21.000000. running mean: -20.148950\n",
            "resetting env. episode 820.000000, reward total was -20.000000. running mean: -20.147461\n",
            "resetting env. episode 821.000000, reward total was -18.000000. running mean: -20.125986\n",
            "resetting env. episode 822.000000, reward total was -21.000000. running mean: -20.134726\n",
            "resetting env. episode 823.000000, reward total was -21.000000. running mean: -20.143379\n",
            "resetting env. episode 824.000000, reward total was -19.000000. running mean: -20.131945\n",
            "resetting env. episode 825.000000, reward total was -18.000000. running mean: -20.110626\n",
            "resetting env. episode 826.000000, reward total was -19.000000. running mean: -20.099519\n",
            "resetting env. episode 827.000000, reward total was -21.000000. running mean: -20.108524\n",
            "resetting env. episode 828.000000, reward total was -20.000000. running mean: -20.107439\n",
            "resetting env. episode 829.000000, reward total was -20.000000. running mean: -20.106365\n",
            "resetting env. episode 830.000000, reward total was -21.000000. running mean: -20.115301\n",
            "resetting env. episode 831.000000, reward total was -21.000000. running mean: -20.124148\n",
            "resetting env. episode 832.000000, reward total was -21.000000. running mean: -20.132906\n",
            "resetting env. episode 833.000000, reward total was -20.000000. running mean: -20.131577\n",
            "resetting env. episode 834.000000, reward total was -21.000000. running mean: -20.140262\n",
            "resetting env. episode 835.000000, reward total was -20.000000. running mean: -20.138859\n",
            "resetting env. episode 836.000000, reward total was -20.000000. running mean: -20.137470\n",
            "resetting env. episode 837.000000, reward total was -20.000000. running mean: -20.136096\n",
            "resetting env. episode 838.000000, reward total was -21.000000. running mean: -20.144735\n",
            "resetting env. episode 839.000000, reward total was -21.000000. running mean: -20.153287\n",
            "resetting env. episode 840.000000, reward total was -20.000000. running mean: -20.151754\n",
            "resetting env. episode 841.000000, reward total was -20.000000. running mean: -20.150237\n",
            "resetting env. episode 842.000000, reward total was -21.000000. running mean: -20.158735\n",
            "resetting env. episode 843.000000, reward total was -19.000000. running mean: -20.147147\n",
            "resetting env. episode 844.000000, reward total was -21.000000. running mean: -20.155676\n",
            "resetting env. episode 845.000000, reward total was -21.000000. running mean: -20.164119\n",
            "resetting env. episode 846.000000, reward total was -20.000000. running mean: -20.162478\n",
            "resetting env. episode 847.000000, reward total was -21.000000. running mean: -20.170853\n",
            "resetting env. episode 848.000000, reward total was -21.000000. running mean: -20.179144\n",
            "resetting env. episode 849.000000, reward total was -19.000000. running mean: -20.167353\n",
            "resetting env. episode 850.000000, reward total was -21.000000. running mean: -20.175679\n",
            "resetting env. episode 851.000000, reward total was -20.000000. running mean: -20.173923\n",
            "resetting env. episode 852.000000, reward total was -18.000000. running mean: -20.152183\n",
            "resetting env. episode 853.000000, reward total was -21.000000. running mean: -20.160662\n",
            "resetting env. episode 854.000000, reward total was -19.000000. running mean: -20.149055\n",
            "resetting env. episode 855.000000, reward total was -21.000000. running mean: -20.157564\n",
            "resetting env. episode 856.000000, reward total was -18.000000. running mean: -20.135989\n",
            "resetting env. episode 857.000000, reward total was -20.000000. running mean: -20.134629\n",
            "resetting env. episode 858.000000, reward total was -20.000000. running mean: -20.133283\n",
            "resetting env. episode 859.000000, reward total was -21.000000. running mean: -20.141950\n",
            "resetting env. episode 860.000000, reward total was -21.000000. running mean: -20.150530\n",
            "resetting env. episode 861.000000, reward total was -20.000000. running mean: -20.149025\n",
            "resetting env. episode 862.000000, reward total was -20.000000. running mean: -20.147535\n",
            "resetting env. episode 863.000000, reward total was -18.000000. running mean: -20.126059\n",
            "resetting env. episode 864.000000, reward total was -20.000000. running mean: -20.124799\n",
            "resetting env. episode 865.000000, reward total was -21.000000. running mean: -20.133551\n",
            "resetting env. episode 866.000000, reward total was -20.000000. running mean: -20.132215\n",
            "resetting env. episode 867.000000, reward total was -18.000000. running mean: -20.110893\n",
            "resetting env. episode 868.000000, reward total was -21.000000. running mean: -20.119784\n",
            "resetting env. episode 869.000000, reward total was -19.000000. running mean: -20.108586\n",
            "resetting env. episode 870.000000, reward total was -18.000000. running mean: -20.087501\n",
            "resetting env. episode 871.000000, reward total was -21.000000. running mean: -20.096626\n",
            "resetting env. episode 872.000000, reward total was -21.000000. running mean: -20.105659\n",
            "resetting env. episode 873.000000, reward total was -21.000000. running mean: -20.114603\n",
            "resetting env. episode 874.000000, reward total was -19.000000. running mean: -20.103457\n",
            "resetting env. episode 875.000000, reward total was -20.000000. running mean: -20.102422\n",
            "resetting env. episode 876.000000, reward total was -18.000000. running mean: -20.081398\n",
            "resetting env. episode 877.000000, reward total was -20.000000. running mean: -20.080584\n",
            "resetting env. episode 878.000000, reward total was -20.000000. running mean: -20.079778\n",
            "resetting env. episode 879.000000, reward total was -18.000000. running mean: -20.058980\n",
            "resetting env. episode 880.000000, reward total was -21.000000. running mean: -20.068390\n",
            "resetting env. episode 881.000000, reward total was -20.000000. running mean: -20.067707\n",
            "resetting env. episode 882.000000, reward total was -20.000000. running mean: -20.067030\n",
            "resetting env. episode 883.000000, reward total was -20.000000. running mean: -20.066359\n",
            "resetting env. episode 884.000000, reward total was -20.000000. running mean: -20.065696\n",
            "resetting env. episode 885.000000, reward total was -20.000000. running mean: -20.065039\n",
            "resetting env. episode 886.000000, reward total was -21.000000. running mean: -20.074388\n",
            "resetting env. episode 887.000000, reward total was -20.000000. running mean: -20.073644\n",
            "resetting env. episode 888.000000, reward total was -19.000000. running mean: -20.062908\n",
            "resetting env. episode 889.000000, reward total was -21.000000. running mean: -20.072279\n",
            "resetting env. episode 890.000000, reward total was -20.000000. running mean: -20.071556\n",
            "resetting env. episode 891.000000, reward total was -20.000000. running mean: -20.070841\n",
            "resetting env. episode 892.000000, reward total was -19.000000. running mean: -20.060132\n",
            "resetting env. episode 893.000000, reward total was -17.000000. running mean: -20.029531\n",
            "resetting env. episode 894.000000, reward total was -18.000000. running mean: -20.009235\n",
            "resetting env. episode 895.000000, reward total was -20.000000. running mean: -20.009143\n",
            "resetting env. episode 896.000000, reward total was -21.000000. running mean: -20.019052\n",
            "resetting env. episode 897.000000, reward total was -20.000000. running mean: -20.018861\n",
            "resetting env. episode 898.000000, reward total was -20.000000. running mean: -20.018673\n",
            "resetting env. episode 899.000000, reward total was -21.000000. running mean: -20.028486\n",
            "resetting env. episode 900.000000, reward total was -20.000000. running mean: -20.028201\n",
            "resetting env. episode 901.000000, reward total was -21.000000. running mean: -20.037919\n",
            "resetting env. episode 902.000000, reward total was -21.000000. running mean: -20.047540\n",
            "resetting env. episode 903.000000, reward total was -19.000000. running mean: -20.037064\n",
            "resetting env. episode 904.000000, reward total was -20.000000. running mean: -20.036694\n",
            "resetting env. episode 905.000000, reward total was -19.000000. running mean: -20.026327\n",
            "resetting env. episode 906.000000, reward total was -21.000000. running mean: -20.036064\n",
            "resetting env. episode 907.000000, reward total was -20.000000. running mean: -20.035703\n",
            "resetting env. episode 908.000000, reward total was -21.000000. running mean: -20.045346\n",
            "resetting env. episode 909.000000, reward total was -21.000000. running mean: -20.054892\n",
            "resetting env. episode 910.000000, reward total was -21.000000. running mean: -20.064343\n",
            "resetting env. episode 911.000000, reward total was -20.000000. running mean: -20.063700\n",
            "resetting env. episode 912.000000, reward total was -19.000000. running mean: -20.053063\n",
            "resetting env. episode 913.000000, reward total was -20.000000. running mean: -20.052532\n",
            "resetting env. episode 914.000000, reward total was -19.000000. running mean: -20.042007\n",
            "resetting env. episode 915.000000, reward total was -21.000000. running mean: -20.051587\n",
            "resetting env. episode 916.000000, reward total was -20.000000. running mean: -20.051071\n",
            "resetting env. episode 917.000000, reward total was -21.000000. running mean: -20.060560\n",
            "resetting env. episode 918.000000, reward total was -21.000000. running mean: -20.069955\n",
            "resetting env. episode 919.000000, reward total was -21.000000. running mean: -20.079255\n",
            "resetting env. episode 920.000000, reward total was -19.000000. running mean: -20.068463\n",
            "resetting env. episode 921.000000, reward total was -21.000000. running mean: -20.077778\n",
            "resetting env. episode 922.000000, reward total was -20.000000. running mean: -20.077000\n",
            "resetting env. episode 923.000000, reward total was -19.000000. running mean: -20.066230\n",
            "resetting env. episode 924.000000, reward total was -19.000000. running mean: -20.055568\n",
            "resetting env. episode 925.000000, reward total was -21.000000. running mean: -20.065012\n",
            "resetting env. episode 926.000000, reward total was -21.000000. running mean: -20.074362\n",
            "resetting env. episode 927.000000, reward total was -21.000000. running mean: -20.083619\n",
            "resetting env. episode 928.000000, reward total was -19.000000. running mean: -20.072782\n",
            "resetting env. episode 929.000000, reward total was -20.000000. running mean: -20.072055\n",
            "resetting env. episode 930.000000, reward total was -20.000000. running mean: -20.071334\n",
            "resetting env. episode 931.000000, reward total was -18.000000. running mean: -20.050621\n",
            "resetting env. episode 932.000000, reward total was -20.000000. running mean: -20.050114\n",
            "resetting env. episode 933.000000, reward total was -20.000000. running mean: -20.049613\n",
            "resetting env. episode 934.000000, reward total was -21.000000. running mean: -20.059117\n",
            "resetting env. episode 935.000000, reward total was -20.000000. running mean: -20.058526\n",
            "resetting env. episode 936.000000, reward total was -21.000000. running mean: -20.067941\n",
            "resetting env. episode 937.000000, reward total was -20.000000. running mean: -20.067261\n",
            "resetting env. episode 938.000000, reward total was -20.000000. running mean: -20.066589\n",
            "resetting env. episode 939.000000, reward total was -21.000000. running mean: -20.075923\n",
            "resetting env. episode 940.000000, reward total was -17.000000. running mean: -20.045164\n",
            "resetting env. episode 941.000000, reward total was -18.000000. running mean: -20.024712\n",
            "resetting env. episode 942.000000, reward total was -20.000000. running mean: -20.024465\n",
            "resetting env. episode 943.000000, reward total was -19.000000. running mean: -20.014220\n",
            "resetting env. episode 944.000000, reward total was -19.000000. running mean: -20.004078\n",
            "resetting env. episode 945.000000, reward total was -20.000000. running mean: -20.004037\n",
            "resetting env. episode 946.000000, reward total was -21.000000. running mean: -20.013997\n",
            "resetting env. episode 947.000000, reward total was -20.000000. running mean: -20.013857\n",
            "resetting env. episode 948.000000, reward total was -21.000000. running mean: -20.023718\n",
            "resetting env. episode 949.000000, reward total was -19.000000. running mean: -20.013481\n",
            "resetting env. episode 950.000000, reward total was -21.000000. running mean: -20.023346\n",
            "resetting env. episode 951.000000, reward total was -21.000000. running mean: -20.033113\n",
            "resetting env. episode 952.000000, reward total was -21.000000. running mean: -20.042782\n",
            "resetting env. episode 953.000000, reward total was -21.000000. running mean: -20.052354\n",
            "resetting env. episode 954.000000, reward total was -17.000000. running mean: -20.021830\n",
            "resetting env. episode 955.000000, reward total was -21.000000. running mean: -20.031612\n",
            "resetting env. episode 956.000000, reward total was -19.000000. running mean: -20.021296\n",
            "resetting env. episode 957.000000, reward total was -17.000000. running mean: -19.991083\n",
            "resetting env. episode 958.000000, reward total was -18.000000. running mean: -19.971172\n",
            "resetting env. episode 959.000000, reward total was -18.000000. running mean: -19.951460\n",
            "resetting env. episode 960.000000, reward total was -21.000000. running mean: -19.961946\n",
            "resetting env. episode 961.000000, reward total was -20.000000. running mean: -19.962326\n",
            "resetting env. episode 962.000000, reward total was -19.000000. running mean: -19.952703\n",
            "resetting env. episode 963.000000, reward total was -19.000000. running mean: -19.943176\n",
            "resetting env. episode 964.000000, reward total was -15.000000. running mean: -19.893744\n",
            "resetting env. episode 965.000000, reward total was -19.000000. running mean: -19.884807\n",
            "resetting env. episode 966.000000, reward total was -18.000000. running mean: -19.865959\n",
            "resetting env. episode 967.000000, reward total was -21.000000. running mean: -19.877299\n",
            "resetting env. episode 968.000000, reward total was -20.000000. running mean: -19.878526\n",
            "resetting env. episode 969.000000, reward total was -20.000000. running mean: -19.879741\n",
            "resetting env. episode 970.000000, reward total was -20.000000. running mean: -19.880944\n",
            "resetting env. episode 971.000000, reward total was -20.000000. running mean: -19.882134\n",
            "resetting env. episode 972.000000, reward total was -20.000000. running mean: -19.883313\n",
            "resetting env. episode 973.000000, reward total was -20.000000. running mean: -19.884480\n",
            "resetting env. episode 974.000000, reward total was -20.000000. running mean: -19.885635\n",
            "resetting env. episode 975.000000, reward total was -21.000000. running mean: -19.896779\n",
            "resetting env. episode 976.000000, reward total was -21.000000. running mean: -19.907811\n",
            "resetting env. episode 977.000000, reward total was -21.000000. running mean: -19.918733\n",
            "resetting env. episode 978.000000, reward total was -20.000000. running mean: -19.919545\n",
            "resetting env. episode 979.000000, reward total was -20.000000. running mean: -19.920350\n",
            "resetting env. episode 980.000000, reward total was -21.000000. running mean: -19.931146\n",
            "resetting env. episode 981.000000, reward total was -19.000000. running mean: -19.921835\n",
            "resetting env. episode 982.000000, reward total was -21.000000. running mean: -19.932617\n",
            "resetting env. episode 983.000000, reward total was -20.000000. running mean: -19.933290\n",
            "resetting env. episode 984.000000, reward total was -21.000000. running mean: -19.943957\n",
            "resetting env. episode 985.000000, reward total was -21.000000. running mean: -19.954518\n",
            "resetting env. episode 986.000000, reward total was -19.000000. running mean: -19.944973\n",
            "resetting env. episode 987.000000, reward total was -21.000000. running mean: -19.955523\n",
            "resetting env. episode 988.000000, reward total was -21.000000. running mean: -19.965968\n",
            "resetting env. episode 989.000000, reward total was -21.000000. running mean: -19.976308\n",
            "resetting env. episode 990.000000, reward total was -21.000000. running mean: -19.986545\n",
            "resetting env. episode 991.000000, reward total was -20.000000. running mean: -19.986680\n",
            "resetting env. episode 992.000000, reward total was -19.000000. running mean: -19.976813\n",
            "resetting env. episode 993.000000, reward total was -21.000000. running mean: -19.987045\n",
            "resetting env. episode 994.000000, reward total was -21.000000. running mean: -19.997174\n",
            "resetting env. episode 995.000000, reward total was -20.000000. running mean: -19.997202\n",
            "resetting env. episode 996.000000, reward total was -21.000000. running mean: -20.007230\n",
            "resetting env. episode 997.000000, reward total was -18.000000. running mean: -19.987158\n",
            "resetting env. episode 998.000000, reward total was -21.000000. running mean: -19.997287\n",
            "resetting env. episode 999.000000, reward total was -21.000000. running mean: -20.007314\n",
            "resetting env. episode 1000.000000, reward total was -20.000000. running mean: -20.007241\n",
            "resetting env. episode 1001.000000, reward total was -21.000000. running mean: -20.017168\n",
            "resetting env. episode 1002.000000, reward total was -21.000000. running mean: -20.026996\n",
            "resetting env. episode 1003.000000, reward total was -19.000000. running mean: -20.016726\n",
            "resetting env. episode 1004.000000, reward total was -21.000000. running mean: -20.026559\n",
            "resetting env. episode 1005.000000, reward total was -20.000000. running mean: -20.026294\n",
            "resetting env. episode 1006.000000, reward total was -21.000000. running mean: -20.036031\n",
            "resetting env. episode 1007.000000, reward total was -17.000000. running mean: -20.005670\n",
            "resetting env. episode 1008.000000, reward total was -20.000000. running mean: -20.005614\n",
            "resetting env. episode 1009.000000, reward total was -19.000000. running mean: -19.995558\n",
            "resetting env. episode 1010.000000, reward total was -20.000000. running mean: -19.995602\n",
            "resetting env. episode 1011.000000, reward total was -21.000000. running mean: -20.005646\n",
            "resetting env. episode 1012.000000, reward total was -21.000000. running mean: -20.015589\n",
            "resetting env. episode 1013.000000, reward total was -18.000000. running mean: -19.995434\n",
            "resetting env. episode 1014.000000, reward total was -19.000000. running mean: -19.985479\n",
            "resetting env. episode 1015.000000, reward total was -19.000000. running mean: -19.975624\n",
            "resetting env. episode 1016.000000, reward total was -20.000000. running mean: -19.975868\n",
            "resetting env. episode 1017.000000, reward total was -20.000000. running mean: -19.976110\n",
            "resetting env. episode 1018.000000, reward total was -20.000000. running mean: -19.976348\n",
            "resetting env. episode 1019.000000, reward total was -20.000000. running mean: -19.976585\n",
            "resetting env. episode 1020.000000, reward total was -20.000000. running mean: -19.976819\n",
            "resetting env. episode 1021.000000, reward total was -21.000000. running mean: -19.987051\n",
            "resetting env. episode 1022.000000, reward total was -20.000000. running mean: -19.987180\n",
            "resetting env. episode 1023.000000, reward total was -21.000000. running mean: -19.997309\n",
            "resetting env. episode 1024.000000, reward total was -20.000000. running mean: -19.997336\n",
            "resetting env. episode 1025.000000, reward total was -19.000000. running mean: -19.987362\n",
            "resetting env. episode 1026.000000, reward total was -21.000000. running mean: -19.997489\n",
            "resetting env. episode 1027.000000, reward total was -20.000000. running mean: -19.997514\n",
            "resetting env. episode 1028.000000, reward total was -20.000000. running mean: -19.997539\n",
            "resetting env. episode 1029.000000, reward total was -20.000000. running mean: -19.997563\n",
            "resetting env. episode 1030.000000, reward total was -21.000000. running mean: -20.007588\n",
            "resetting env. episode 1031.000000, reward total was -21.000000. running mean: -20.017512\n",
            "resetting env. episode 1032.000000, reward total was -21.000000. running mean: -20.027337\n",
            "resetting env. episode 1033.000000, reward total was -21.000000. running mean: -20.037063\n",
            "resetting env. episode 1034.000000, reward total was -20.000000. running mean: -20.036693\n",
            "resetting env. episode 1035.000000, reward total was -18.000000. running mean: -20.016326\n",
            "resetting env. episode 1036.000000, reward total was -20.000000. running mean: -20.016162\n",
            "resetting env. episode 1037.000000, reward total was -21.000000. running mean: -20.026001\n",
            "resetting env. episode 1038.000000, reward total was -20.000000. running mean: -20.025741\n",
            "resetting env. episode 1039.000000, reward total was -21.000000. running mean: -20.035483\n",
            "resetting env. episode 1040.000000, reward total was -20.000000. running mean: -20.035128\n",
            "resetting env. episode 1041.000000, reward total was -21.000000. running mean: -20.044777\n",
            "resetting env. episode 1042.000000, reward total was -21.000000. running mean: -20.054329\n",
            "resetting env. episode 1043.000000, reward total was -20.000000. running mean: -20.053786\n",
            "resetting env. episode 1044.000000, reward total was -21.000000. running mean: -20.063248\n",
            "resetting env. episode 1045.000000, reward total was -20.000000. running mean: -20.062616\n",
            "resetting env. episode 1046.000000, reward total was -21.000000. running mean: -20.071990\n",
            "resetting env. episode 1047.000000, reward total was -19.000000. running mean: -20.061270\n",
            "resetting env. episode 1048.000000, reward total was -19.000000. running mean: -20.050657\n",
            "resetting env. episode 1049.000000, reward total was -21.000000. running mean: -20.060150\n",
            "resetting env. episode 1050.000000, reward total was -16.000000. running mean: -20.019549\n",
            "resetting env. episode 1051.000000, reward total was -19.000000. running mean: -20.009353\n",
            "resetting env. episode 1052.000000, reward total was -21.000000. running mean: -20.019260\n",
            "resetting env. episode 1053.000000, reward total was -21.000000. running mean: -20.029067\n",
            "resetting env. episode 1054.000000, reward total was -21.000000. running mean: -20.038777\n",
            "resetting env. episode 1055.000000, reward total was -17.000000. running mean: -20.008389\n",
            "resetting env. episode 1056.000000, reward total was -19.000000. running mean: -19.998305\n",
            "resetting env. episode 1057.000000, reward total was -20.000000. running mean: -19.998322\n",
            "resetting env. episode 1058.000000, reward total was -21.000000. running mean: -20.008339\n",
            "resetting env. episode 1059.000000, reward total was -19.000000. running mean: -19.998255\n",
            "resetting env. episode 1060.000000, reward total was -21.000000. running mean: -20.008273\n",
            "resetting env. episode 1061.000000, reward total was -20.000000. running mean: -20.008190\n",
            "resetting env. episode 1062.000000, reward total was -18.000000. running mean: -19.988108\n",
            "resetting env. episode 1063.000000, reward total was -21.000000. running mean: -19.998227\n",
            "resetting env. episode 1064.000000, reward total was -19.000000. running mean: -19.988245\n",
            "resetting env. episode 1065.000000, reward total was -20.000000. running mean: -19.988362\n",
            "resetting env. episode 1066.000000, reward total was -21.000000. running mean: -19.998479\n",
            "resetting env. episode 1067.000000, reward total was -21.000000. running mean: -20.008494\n",
            "resetting env. episode 1068.000000, reward total was -21.000000. running mean: -20.018409\n",
            "resetting env. episode 1069.000000, reward total was -19.000000. running mean: -20.008225\n",
            "resetting env. episode 1070.000000, reward total was -18.000000. running mean: -19.988143\n",
            "resetting env. episode 1071.000000, reward total was -20.000000. running mean: -19.988261\n",
            "resetting env. episode 1072.000000, reward total was -21.000000. running mean: -19.998379\n",
            "resetting env. episode 1073.000000, reward total was -20.000000. running mean: -19.998395\n",
            "resetting env. episode 1074.000000, reward total was -20.000000. running mean: -19.998411\n",
            "resetting env. episode 1075.000000, reward total was -20.000000. running mean: -19.998427\n",
            "resetting env. episode 1076.000000, reward total was -21.000000. running mean: -20.008443\n",
            "resetting env. episode 1077.000000, reward total was -20.000000. running mean: -20.008358\n",
            "resetting env. episode 1078.000000, reward total was -21.000000. running mean: -20.018275\n",
            "resetting env. episode 1079.000000, reward total was -19.000000. running mean: -20.008092\n",
            "resetting env. episode 1080.000000, reward total was -21.000000. running mean: -20.018011\n",
            "resetting env. episode 1081.000000, reward total was -20.000000. running mean: -20.017831\n",
            "resetting env. episode 1082.000000, reward total was -19.000000. running mean: -20.007652\n",
            "resetting env. episode 1083.000000, reward total was -19.000000. running mean: -19.997576\n",
            "resetting env. episode 1084.000000, reward total was -21.000000. running mean: -20.007600\n",
            "resetting env. episode 1085.000000, reward total was -19.000000. running mean: -19.997524\n",
            "resetting env. episode 1086.000000, reward total was -21.000000. running mean: -20.007549\n",
            "resetting env. episode 1087.000000, reward total was -19.000000. running mean: -19.997473\n",
            "resetting env. episode 1088.000000, reward total was -20.000000. running mean: -19.997499\n",
            "resetting env. episode 1089.000000, reward total was -21.000000. running mean: -20.007524\n",
            "resetting env. episode 1090.000000, reward total was -20.000000. running mean: -20.007448\n",
            "resetting env. episode 1091.000000, reward total was -19.000000. running mean: -19.997374\n",
            "resetting env. episode 1092.000000, reward total was -20.000000. running mean: -19.997400\n",
            "resetting env. episode 1093.000000, reward total was -19.000000. running mean: -19.987426\n",
            "resetting env. episode 1094.000000, reward total was -19.000000. running mean: -19.977552\n",
            "resetting env. episode 1095.000000, reward total was -19.000000. running mean: -19.967776\n",
            "resetting env. episode 1096.000000, reward total was -20.000000. running mean: -19.968099\n",
            "resetting env. episode 1097.000000, reward total was -18.000000. running mean: -19.948418\n",
            "resetting env. episode 1098.000000, reward total was -16.000000. running mean: -19.908934\n",
            "resetting env. episode 1099.000000, reward total was -20.000000. running mean: -19.909844\n",
            "resetting env. episode 1100.000000, reward total was -19.000000. running mean: -19.900746\n",
            "resetting env. episode 1101.000000, reward total was -19.000000. running mean: -19.891738\n",
            "resetting env. episode 1102.000000, reward total was -21.000000. running mean: -19.902821\n",
            "resetting env. episode 1103.000000, reward total was -21.000000. running mean: -19.913793\n",
            "resetting env. episode 1104.000000, reward total was -21.000000. running mean: -19.924655\n",
            "resetting env. episode 1105.000000, reward total was -20.000000. running mean: -19.925408\n",
            "resetting env. episode 1106.000000, reward total was -20.000000. running mean: -19.926154\n",
            "resetting env. episode 1107.000000, reward total was -21.000000. running mean: -19.936893\n",
            "resetting env. episode 1108.000000, reward total was -20.000000. running mean: -19.937524\n",
            "resetting env. episode 1109.000000, reward total was -21.000000. running mean: -19.948148\n",
            "resetting env. episode 1110.000000, reward total was -19.000000. running mean: -19.938667\n",
            "resetting env. episode 1111.000000, reward total was -21.000000. running mean: -19.949280\n",
            "resetting env. episode 1112.000000, reward total was -21.000000. running mean: -19.959787\n",
            "resetting env. episode 1113.000000, reward total was -21.000000. running mean: -19.970190\n",
            "resetting env. episode 1114.000000, reward total was -19.000000. running mean: -19.960488\n",
            "resetting env. episode 1115.000000, reward total was -20.000000. running mean: -19.960883\n",
            "resetting env. episode 1116.000000, reward total was -18.000000. running mean: -19.941274\n",
            "resetting env. episode 1117.000000, reward total was -21.000000. running mean: -19.951861\n",
            "resetting env. episode 1118.000000, reward total was -19.000000. running mean: -19.942343\n",
            "resetting env. episode 1119.000000, reward total was -21.000000. running mean: -19.952919\n",
            "resetting env. episode 1120.000000, reward total was -21.000000. running mean: -19.963390\n",
            "resetting env. episode 1121.000000, reward total was -20.000000. running mean: -19.963756\n",
            "resetting env. episode 1122.000000, reward total was -19.000000. running mean: -19.954119\n",
            "resetting env. episode 1123.000000, reward total was -20.000000. running mean: -19.954577\n",
            "resetting env. episode 1124.000000, reward total was -21.000000. running mean: -19.965032\n",
            "resetting env. episode 1125.000000, reward total was -20.000000. running mean: -19.965381\n",
            "resetting env. episode 1126.000000, reward total was -21.000000. running mean: -19.975727\n",
            "resetting env. episode 1127.000000, reward total was -21.000000. running mean: -19.985970\n",
            "resetting env. episode 1128.000000, reward total was -20.000000. running mean: -19.986111\n",
            "resetting env. episode 1129.000000, reward total was -18.000000. running mean: -19.966249\n",
            "resetting env. episode 1130.000000, reward total was -20.000000. running mean: -19.966587\n",
            "resetting env. episode 1131.000000, reward total was -21.000000. running mean: -19.976921\n",
            "resetting env. episode 1132.000000, reward total was -21.000000. running mean: -19.987152\n",
            "resetting env. episode 1133.000000, reward total was -21.000000. running mean: -19.997280\n",
            "resetting env. episode 1134.000000, reward total was -21.000000. running mean: -20.007308\n",
            "resetting env. episode 1135.000000, reward total was -21.000000. running mean: -20.017234\n",
            "resetting env. episode 1136.000000, reward total was -18.000000. running mean: -19.997062\n",
            "resetting env. episode 1137.000000, reward total was -18.000000. running mean: -19.977091\n",
            "resetting env. episode 1138.000000, reward total was -21.000000. running mean: -19.987321\n",
            "resetting env. episode 1139.000000, reward total was -21.000000. running mean: -19.997447\n",
            "resetting env. episode 1140.000000, reward total was -21.000000. running mean: -20.007473\n",
            "resetting env. episode 1141.000000, reward total was -21.000000. running mean: -20.017398\n",
            "resetting env. episode 1142.000000, reward total was -21.000000. running mean: -20.027224\n",
            "resetting env. episode 1143.000000, reward total was -20.000000. running mean: -20.026952\n",
            "resetting env. episode 1144.000000, reward total was -19.000000. running mean: -20.016682\n",
            "resetting env. episode 1145.000000, reward total was -21.000000. running mean: -20.026516\n",
            "resetting env. episode 1146.000000, reward total was -20.000000. running mean: -20.026250\n",
            "resetting env. episode 1147.000000, reward total was -18.000000. running mean: -20.005988\n",
            "resetting env. episode 1148.000000, reward total was -20.000000. running mean: -20.005928\n",
            "resetting env. episode 1149.000000, reward total was -20.000000. running mean: -20.005869\n",
            "resetting env. episode 1150.000000, reward total was -20.000000. running mean: -20.005810\n",
            "resetting env. episode 1151.000000, reward total was -21.000000. running mean: -20.015752\n",
            "resetting env. episode 1152.000000, reward total was -21.000000. running mean: -20.025594\n",
            "resetting env. episode 1153.000000, reward total was -21.000000. running mean: -20.035339\n",
            "resetting env. episode 1154.000000, reward total was -21.000000. running mean: -20.044985\n",
            "resetting env. episode 1155.000000, reward total was -21.000000. running mean: -20.054535\n",
            "resetting env. episode 1156.000000, reward total was -19.000000. running mean: -20.043990\n",
            "resetting env. episode 1157.000000, reward total was -20.000000. running mean: -20.043550\n",
            "resetting env. episode 1158.000000, reward total was -21.000000. running mean: -20.053115\n",
            "resetting env. episode 1159.000000, reward total was -21.000000. running mean: -20.062583\n",
            "resetting env. episode 1160.000000, reward total was -20.000000. running mean: -20.061958\n",
            "resetting env. episode 1161.000000, reward total was -21.000000. running mean: -20.071338\n",
            "resetting env. episode 1162.000000, reward total was -21.000000. running mean: -20.080625\n",
            "resetting env. episode 1163.000000, reward total was -18.000000. running mean: -20.059818\n",
            "resetting env. episode 1164.000000, reward total was -21.000000. running mean: -20.069220\n",
            "resetting env. episode 1165.000000, reward total was -20.000000. running mean: -20.068528\n",
            "resetting env. episode 1166.000000, reward total was -21.000000. running mean: -20.077843\n",
            "resetting env. episode 1167.000000, reward total was -21.000000. running mean: -20.087064\n",
            "resetting env. episode 1168.000000, reward total was -19.000000. running mean: -20.076194\n",
            "resetting env. episode 1169.000000, reward total was -21.000000. running mean: -20.085432\n",
            "resetting env. episode 1170.000000, reward total was -20.000000. running mean: -20.084577\n",
            "resetting env. episode 1171.000000, reward total was -20.000000. running mean: -20.083732\n",
            "resetting env. episode 1172.000000, reward total was -21.000000. running mean: -20.092894\n",
            "resetting env. episode 1173.000000, reward total was -19.000000. running mean: -20.081965\n",
            "resetting env. episode 1174.000000, reward total was -20.000000. running mean: -20.081146\n",
            "resetting env. episode 1175.000000, reward total was -20.000000. running mean: -20.080334\n",
            "resetting env. episode 1176.000000, reward total was -20.000000. running mean: -20.079531\n",
            "resetting env. episode 1177.000000, reward total was -21.000000. running mean: -20.088736\n",
            "resetting env. episode 1178.000000, reward total was -16.000000. running mean: -20.047848\n",
            "resetting env. episode 1179.000000, reward total was -21.000000. running mean: -20.057370\n",
            "resetting env. episode 1180.000000, reward total was -20.000000. running mean: -20.056796\n",
            "resetting env. episode 1181.000000, reward total was -20.000000. running mean: -20.056228\n",
            "resetting env. episode 1182.000000, reward total was -21.000000. running mean: -20.065666\n",
            "resetting env. episode 1183.000000, reward total was -19.000000. running mean: -20.055009\n",
            "resetting env. episode 1184.000000, reward total was -19.000000. running mean: -20.044459\n",
            "resetting env. episode 1185.000000, reward total was -15.000000. running mean: -19.994014\n",
            "resetting env. episode 1186.000000, reward total was -19.000000. running mean: -19.984074\n",
            "resetting env. episode 1187.000000, reward total was -21.000000. running mean: -19.994234\n",
            "resetting env. episode 1188.000000, reward total was -20.000000. running mean: -19.994291\n",
            "resetting env. episode 1189.000000, reward total was -21.000000. running mean: -20.004348\n",
            "resetting env. episode 1190.000000, reward total was -21.000000. running mean: -20.014305\n",
            "resetting env. episode 1191.000000, reward total was -21.000000. running mean: -20.024162\n",
            "resetting env. episode 1192.000000, reward total was -20.000000. running mean: -20.023920\n",
            "resetting env. episode 1193.000000, reward total was -20.000000. running mean: -20.023681\n",
            "resetting env. episode 1194.000000, reward total was -20.000000. running mean: -20.023444\n",
            "resetting env. episode 1195.000000, reward total was -21.000000. running mean: -20.033210\n",
            "resetting env. episode 1196.000000, reward total was -21.000000. running mean: -20.042878\n",
            "resetting env. episode 1197.000000, reward total was -19.000000. running mean: -20.032449\n",
            "resetting env. episode 1198.000000, reward total was -21.000000. running mean: -20.042124\n",
            "resetting env. episode 1199.000000, reward total was -20.000000. running mean: -20.041703\n",
            "resetting env. episode 1200.000000, reward total was -19.000000. running mean: -20.031286\n",
            "resetting env. episode 1201.000000, reward total was -19.000000. running mean: -20.020973\n",
            "resetting env. episode 1202.000000, reward total was -20.000000. running mean: -20.020763\n",
            "resetting env. episode 1203.000000, reward total was -21.000000. running mean: -20.030556\n",
            "resetting env. episode 1204.000000, reward total was -18.000000. running mean: -20.010250\n",
            "resetting env. episode 1205.000000, reward total was -19.000000. running mean: -20.000148\n",
            "resetting env. episode 1206.000000, reward total was -21.000000. running mean: -20.010146\n",
            "resetting env. episode 1207.000000, reward total was -18.000000. running mean: -19.990045\n",
            "resetting env. episode 1208.000000, reward total was -21.000000. running mean: -20.000144\n",
            "resetting env. episode 1209.000000, reward total was -21.000000. running mean: -20.010143\n",
            "resetting env. episode 1210.000000, reward total was -21.000000. running mean: -20.020042\n",
            "resetting env. episode 1211.000000, reward total was -18.000000. running mean: -19.999841\n",
            "resetting env. episode 1212.000000, reward total was -20.000000. running mean: -19.999843\n",
            "resetting env. episode 1213.000000, reward total was -17.000000. running mean: -19.969844\n",
            "resetting env. episode 1214.000000, reward total was -21.000000. running mean: -19.980146\n",
            "resetting env. episode 1215.000000, reward total was -21.000000. running mean: -19.990344\n",
            "resetting env. episode 1216.000000, reward total was -21.000000. running mean: -20.000441\n",
            "resetting env. episode 1217.000000, reward total was -20.000000. running mean: -20.000437\n",
            "resetting env. episode 1218.000000, reward total was -21.000000. running mean: -20.010432\n",
            "resetting env. episode 1219.000000, reward total was -20.000000. running mean: -20.010328\n",
            "resetting env. episode 1220.000000, reward total was -21.000000. running mean: -20.020225\n",
            "resetting env. episode 1221.000000, reward total was -19.000000. running mean: -20.010022\n",
            "resetting env. episode 1222.000000, reward total was -21.000000. running mean: -20.019922\n",
            "resetting env. episode 1223.000000, reward total was -21.000000. running mean: -20.029723\n",
            "resetting env. episode 1224.000000, reward total was -18.000000. running mean: -20.009426\n",
            "resetting env. episode 1225.000000, reward total was -21.000000. running mean: -20.019331\n",
            "resetting env. episode 1226.000000, reward total was -19.000000. running mean: -20.009138\n",
            "resetting env. episode 1227.000000, reward total was -20.000000. running mean: -20.009047\n",
            "resetting env. episode 1228.000000, reward total was -19.000000. running mean: -19.998956\n",
            "resetting env. episode 1229.000000, reward total was -20.000000. running mean: -19.998967\n",
            "resetting env. episode 1230.000000, reward total was -19.000000. running mean: -19.988977\n",
            "resetting env. episode 1231.000000, reward total was -21.000000. running mean: -19.999087\n",
            "resetting env. episode 1232.000000, reward total was -20.000000. running mean: -19.999096\n",
            "resetting env. episode 1233.000000, reward total was -21.000000. running mean: -20.009105\n",
            "resetting env. episode 1234.000000, reward total was -17.000000. running mean: -19.979014\n",
            "resetting env. episode 1235.000000, reward total was -16.000000. running mean: -19.939224\n",
            "resetting env. episode 1236.000000, reward total was -19.000000. running mean: -19.929832\n",
            "resetting env. episode 1237.000000, reward total was -19.000000. running mean: -19.920534\n",
            "resetting env. episode 1238.000000, reward total was -20.000000. running mean: -19.921328\n",
            "resetting env. episode 1239.000000, reward total was -21.000000. running mean: -19.932115\n",
            "resetting env. episode 1240.000000, reward total was -20.000000. running mean: -19.932794\n",
            "resetting env. episode 1241.000000, reward total was -19.000000. running mean: -19.923466\n",
            "resetting env. episode 1242.000000, reward total was -21.000000. running mean: -19.934231\n",
            "resetting env. episode 1243.000000, reward total was -21.000000. running mean: -19.944889\n",
            "resetting env. episode 1244.000000, reward total was -20.000000. running mean: -19.945440\n",
            "resetting env. episode 1245.000000, reward total was -19.000000. running mean: -19.935986\n",
            "resetting env. episode 1246.000000, reward total was -20.000000. running mean: -19.936626\n",
            "resetting env. episode 1247.000000, reward total was -20.000000. running mean: -19.937260\n",
            "resetting env. episode 1248.000000, reward total was -21.000000. running mean: -19.947887\n",
            "resetting env. episode 1249.000000, reward total was -19.000000. running mean: -19.938408\n",
            "resetting env. episode 1250.000000, reward total was -20.000000. running mean: -19.939024\n",
            "resetting env. episode 1251.000000, reward total was -20.000000. running mean: -19.939634\n",
            "resetting env. episode 1252.000000, reward total was -20.000000. running mean: -19.940237\n",
            "resetting env. episode 1253.000000, reward total was -18.000000. running mean: -19.920835\n",
            "resetting env. episode 1254.000000, reward total was -20.000000. running mean: -19.921627\n",
            "resetting env. episode 1255.000000, reward total was -21.000000. running mean: -19.932410\n",
            "resetting env. episode 1256.000000, reward total was -21.000000. running mean: -19.943086\n",
            "resetting env. episode 1257.000000, reward total was -20.000000. running mean: -19.943655\n",
            "resetting env. episode 1258.000000, reward total was -21.000000. running mean: -19.954219\n",
            "resetting env. episode 1259.000000, reward total was -20.000000. running mean: -19.954677\n",
            "resetting env. episode 1260.000000, reward total was -18.000000. running mean: -19.935130\n",
            "resetting env. episode 1261.000000, reward total was -21.000000. running mean: -19.945779\n",
            "resetting env. episode 1262.000000, reward total was -20.000000. running mean: -19.946321\n",
            "resetting env. episode 1263.000000, reward total was -20.000000. running mean: -19.946858\n",
            "resetting env. episode 1264.000000, reward total was -19.000000. running mean: -19.937389\n",
            "resetting env. episode 1265.000000, reward total was -19.000000. running mean: -19.928015\n",
            "resetting env. episode 1266.000000, reward total was -21.000000. running mean: -19.938735\n",
            "resetting env. episode 1267.000000, reward total was -21.000000. running mean: -19.949348\n",
            "resetting env. episode 1268.000000, reward total was -20.000000. running mean: -19.949854\n",
            "resetting env. episode 1269.000000, reward total was -21.000000. running mean: -19.960356\n",
            "resetting env. episode 1270.000000, reward total was -21.000000. running mean: -19.970752\n",
            "resetting env. episode 1271.000000, reward total was -21.000000. running mean: -19.981045\n",
            "resetting env. episode 1272.000000, reward total was -19.000000. running mean: -19.971234\n",
            "resetting env. episode 1273.000000, reward total was -20.000000. running mean: -19.971522\n",
            "resetting env. episode 1274.000000, reward total was -21.000000. running mean: -19.981807\n",
            "resetting env. episode 1275.000000, reward total was -20.000000. running mean: -19.981989\n",
            "resetting env. episode 1276.000000, reward total was -19.000000. running mean: -19.972169\n",
            "resetting env. episode 1277.000000, reward total was -19.000000. running mean: -19.962447\n",
            "resetting env. episode 1278.000000, reward total was -20.000000. running mean: -19.962822\n",
            "resetting env. episode 1279.000000, reward total was -18.000000. running mean: -19.943194\n",
            "resetting env. episode 1280.000000, reward total was -21.000000. running mean: -19.953762\n",
            "resetting env. episode 1281.000000, reward total was -21.000000. running mean: -19.964225\n",
            "resetting env. episode 1282.000000, reward total was -21.000000. running mean: -19.974582\n",
            "resetting env. episode 1283.000000, reward total was -21.000000. running mean: -19.984837\n",
            "resetting env. episode 1284.000000, reward total was -21.000000. running mean: -19.994988\n",
            "resetting env. episode 1285.000000, reward total was -21.000000. running mean: -20.005038\n",
            "resetting env. episode 1286.000000, reward total was -21.000000. running mean: -20.014988\n",
            "resetting env. episode 1287.000000, reward total was -21.000000. running mean: -20.024838\n",
            "resetting env. episode 1288.000000, reward total was -20.000000. running mean: -20.024590\n",
            "resetting env. episode 1289.000000, reward total was -20.000000. running mean: -20.024344\n",
            "resetting env. episode 1290.000000, reward total was -21.000000. running mean: -20.034100\n",
            "resetting env. episode 1291.000000, reward total was -18.000000. running mean: -20.013759\n",
            "resetting env. episode 1292.000000, reward total was -19.000000. running mean: -20.003622\n",
            "resetting env. episode 1293.000000, reward total was -20.000000. running mean: -20.003586\n",
            "resetting env. episode 1294.000000, reward total was -20.000000. running mean: -20.003550\n",
            "resetting env. episode 1295.000000, reward total was -19.000000. running mean: -19.993514\n",
            "resetting env. episode 1296.000000, reward total was -21.000000. running mean: -20.003579\n",
            "resetting env. episode 1297.000000, reward total was -20.000000. running mean: -20.003543\n",
            "resetting env. episode 1298.000000, reward total was -20.000000. running mean: -20.003508\n",
            "resetting env. episode 1299.000000, reward total was -20.000000. running mean: -20.003473\n",
            "resetting env. episode 1300.000000, reward total was -21.000000. running mean: -20.013438\n",
            "resetting env. episode 1301.000000, reward total was -19.000000. running mean: -20.003304\n",
            "resetting env. episode 1302.000000, reward total was -20.000000. running mean: -20.003271\n",
            "resetting env. episode 1303.000000, reward total was -18.000000. running mean: -19.983238\n",
            "resetting env. episode 1304.000000, reward total was -21.000000. running mean: -19.993406\n",
            "resetting env. episode 1305.000000, reward total was -21.000000. running mean: -20.003471\n",
            "resetting env. episode 1306.000000, reward total was -20.000000. running mean: -20.003437\n",
            "resetting env. episode 1307.000000, reward total was -21.000000. running mean: -20.013402\n",
            "resetting env. episode 1308.000000, reward total was -21.000000. running mean: -20.023268\n",
            "resetting env. episode 1309.000000, reward total was -20.000000. running mean: -20.023036\n",
            "resetting env. episode 1310.000000, reward total was -19.000000. running mean: -20.012805\n",
            "resetting env. episode 1311.000000, reward total was -20.000000. running mean: -20.012677\n",
            "resetting env. episode 1312.000000, reward total was -21.000000. running mean: -20.022551\n",
            "resetting env. episode 1313.000000, reward total was -20.000000. running mean: -20.022325\n",
            "resetting env. episode 1314.000000, reward total was -20.000000. running mean: -20.022102\n",
            "resetting env. episode 1315.000000, reward total was -19.000000. running mean: -20.011881\n",
            "resetting env. episode 1316.000000, reward total was -17.000000. running mean: -19.981762\n",
            "resetting env. episode 1317.000000, reward total was -21.000000. running mean: -19.991944\n",
            "resetting env. episode 1318.000000, reward total was -21.000000. running mean: -20.002025\n",
            "resetting env. episode 1319.000000, reward total was -20.000000. running mean: -20.002005\n",
            "resetting env. episode 1320.000000, reward total was -20.000000. running mean: -20.001985\n",
            "resetting env. episode 1321.000000, reward total was -21.000000. running mean: -20.011965\n",
            "resetting env. episode 1322.000000, reward total was -21.000000. running mean: -20.021845\n",
            "resetting env. episode 1323.000000, reward total was -19.000000. running mean: -20.011627\n",
            "resetting env. episode 1324.000000, reward total was -21.000000. running mean: -20.021510\n",
            "resetting env. episode 1325.000000, reward total was -20.000000. running mean: -20.021295\n",
            "resetting env. episode 1326.000000, reward total was -20.000000. running mean: -20.021082\n",
            "resetting env. episode 1327.000000, reward total was -20.000000. running mean: -20.020871\n",
            "resetting env. episode 1328.000000, reward total was -17.000000. running mean: -19.990663\n",
            "resetting env. episode 1329.000000, reward total was -20.000000. running mean: -19.990756\n",
            "resetting env. episode 1330.000000, reward total was -19.000000. running mean: -19.980849\n",
            "resetting env. episode 1331.000000, reward total was -21.000000. running mean: -19.991040\n",
            "resetting env. episode 1332.000000, reward total was -21.000000. running mean: -20.001130\n",
            "resetting env. episode 1333.000000, reward total was -21.000000. running mean: -20.011118\n",
            "resetting env. episode 1334.000000, reward total was -21.000000. running mean: -20.021007\n",
            "resetting env. episode 1335.000000, reward total was -21.000000. running mean: -20.030797\n",
            "resetting env. episode 1336.000000, reward total was -20.000000. running mean: -20.030489\n",
            "resetting env. episode 1337.000000, reward total was -21.000000. running mean: -20.040184\n",
            "resetting env. episode 1338.000000, reward total was -20.000000. running mean: -20.039782\n",
            "resetting env. episode 1339.000000, reward total was -19.000000. running mean: -20.029385\n",
            "resetting env. episode 1340.000000, reward total was -20.000000. running mean: -20.029091\n",
            "resetting env. episode 1341.000000, reward total was -20.000000. running mean: -20.028800\n",
            "resetting env. episode 1342.000000, reward total was -21.000000. running mean: -20.038512\n",
            "resetting env. episode 1343.000000, reward total was -19.000000. running mean: -20.028127\n",
            "resetting env. episode 1344.000000, reward total was -20.000000. running mean: -20.027845\n",
            "resetting env. episode 1345.000000, reward total was -18.000000. running mean: -20.007567\n",
            "resetting env. episode 1346.000000, reward total was -17.000000. running mean: -19.977491\n",
            "resetting env. episode 1347.000000, reward total was -20.000000. running mean: -19.977716\n",
            "resetting env. episode 1348.000000, reward total was -19.000000. running mean: -19.967939\n",
            "resetting env. episode 1349.000000, reward total was -20.000000. running mean: -19.968260\n",
            "resetting env. episode 1350.000000, reward total was -21.000000. running mean: -19.978577\n",
            "resetting env. episode 1351.000000, reward total was -20.000000. running mean: -19.978792\n",
            "resetting env. episode 1352.000000, reward total was -21.000000. running mean: -19.989004\n",
            "resetting env. episode 1353.000000, reward total was -21.000000. running mean: -19.999114\n",
            "resetting env. episode 1354.000000, reward total was -19.000000. running mean: -19.989122\n",
            "resetting env. episode 1355.000000, reward total was -21.000000. running mean: -19.999231\n",
            "resetting env. episode 1356.000000, reward total was -20.000000. running mean: -19.999239\n",
            "resetting env. episode 1357.000000, reward total was -19.000000. running mean: -19.989246\n",
            "resetting env. episode 1358.000000, reward total was -21.000000. running mean: -19.999354\n",
            "resetting env. episode 1359.000000, reward total was -21.000000. running mean: -20.009360\n",
            "resetting env. episode 1360.000000, reward total was -18.000000. running mean: -19.989267\n",
            "resetting env. episode 1361.000000, reward total was -20.000000. running mean: -19.989374\n",
            "resetting env. episode 1362.000000, reward total was -21.000000. running mean: -19.999480\n",
            "resetting env. episode 1363.000000, reward total was -21.000000. running mean: -20.009486\n",
            "resetting env. episode 1364.000000, reward total was -20.000000. running mean: -20.009391\n",
            "resetting env. episode 1365.000000, reward total was -19.000000. running mean: -19.999297\n",
            "resetting env. episode 1366.000000, reward total was -20.000000. running mean: -19.999304\n",
            "resetting env. episode 1367.000000, reward total was -21.000000. running mean: -20.009311\n",
            "resetting env. episode 1368.000000, reward total was -19.000000. running mean: -19.999218\n",
            "resetting env. episode 1369.000000, reward total was -21.000000. running mean: -20.009226\n",
            "resetting env. episode 1370.000000, reward total was -21.000000. running mean: -20.019133\n",
            "resetting env. episode 1371.000000, reward total was -19.000000. running mean: -20.008942\n",
            "resetting env. episode 1372.000000, reward total was -19.000000. running mean: -19.998853\n",
            "resetting env. episode 1373.000000, reward total was -21.000000. running mean: -20.008864\n",
            "resetting env. episode 1374.000000, reward total was -21.000000. running mean: -20.018775\n",
            "resetting env. episode 1375.000000, reward total was -21.000000. running mean: -20.028588\n",
            "resetting env. episode 1376.000000, reward total was -21.000000. running mean: -20.038302\n",
            "resetting env. episode 1377.000000, reward total was -21.000000. running mean: -20.047919\n",
            "resetting env. episode 1378.000000, reward total was -21.000000. running mean: -20.057440\n",
            "resetting env. episode 1379.000000, reward total was -20.000000. running mean: -20.056865\n",
            "resetting env. episode 1380.000000, reward total was -20.000000. running mean: -20.056297\n",
            "resetting env. episode 1381.000000, reward total was -19.000000. running mean: -20.045734\n",
            "resetting env. episode 1382.000000, reward total was -20.000000. running mean: -20.045276\n",
            "resetting env. episode 1383.000000, reward total was -21.000000. running mean: -20.054823\n",
            "resetting env. episode 1384.000000, reward total was -21.000000. running mean: -20.064275\n",
            "resetting env. episode 1385.000000, reward total was -20.000000. running mean: -20.063632\n",
            "resetting env. episode 1386.000000, reward total was -19.000000. running mean: -20.052996\n",
            "resetting env. episode 1387.000000, reward total was -20.000000. running mean: -20.052466\n",
            "resetting env. episode 1388.000000, reward total was -19.000000. running mean: -20.041942\n",
            "resetting env. episode 1389.000000, reward total was -21.000000. running mean: -20.051522\n",
            "resetting env. episode 1390.000000, reward total was -21.000000. running mean: -20.061007\n",
            "resetting env. episode 1391.000000, reward total was -20.000000. running mean: -20.060397\n",
            "resetting env. episode 1392.000000, reward total was -19.000000. running mean: -20.049793\n",
            "resetting env. episode 1393.000000, reward total was -21.000000. running mean: -20.059295\n",
            "resetting env. episode 1394.000000, reward total was -17.000000. running mean: -20.028702\n",
            "resetting env. episode 1395.000000, reward total was -19.000000. running mean: -20.018415\n",
            "resetting env. episode 1396.000000, reward total was -20.000000. running mean: -20.018231\n",
            "resetting env. episode 1397.000000, reward total was -18.000000. running mean: -19.998049\n",
            "resetting env. episode 1398.000000, reward total was -21.000000. running mean: -20.008068\n",
            "resetting env. episode 1399.000000, reward total was -20.000000. running mean: -20.007987\n",
            "resetting env. episode 1400.000000, reward total was -21.000000. running mean: -20.017907\n",
            "resetting env. episode 1401.000000, reward total was -21.000000. running mean: -20.027728\n",
            "resetting env. episode 1402.000000, reward total was -19.000000. running mean: -20.017451\n",
            "resetting env. episode 1403.000000, reward total was -21.000000. running mean: -20.027277\n",
            "resetting env. episode 1404.000000, reward total was -21.000000. running mean: -20.037004\n",
            "resetting env. episode 1405.000000, reward total was -19.000000. running mean: -20.026634\n",
            "resetting env. episode 1406.000000, reward total was -21.000000. running mean: -20.036367\n",
            "resetting env. episode 1407.000000, reward total was -18.000000. running mean: -20.016004\n",
            "resetting env. episode 1408.000000, reward total was -21.000000. running mean: -20.025844\n",
            "resetting env. episode 1409.000000, reward total was -21.000000. running mean: -20.035585\n",
            "resetting env. episode 1410.000000, reward total was -21.000000. running mean: -20.045229\n",
            "resetting env. episode 1411.000000, reward total was -21.000000. running mean: -20.054777\n",
            "resetting env. episode 1412.000000, reward total was -20.000000. running mean: -20.054229\n",
            "resetting env. episode 1413.000000, reward total was -20.000000. running mean: -20.053687\n",
            "resetting env. episode 1414.000000, reward total was -21.000000. running mean: -20.063150\n",
            "resetting env. episode 1415.000000, reward total was -21.000000. running mean: -20.072519\n",
            "resetting env. episode 1416.000000, reward total was -20.000000. running mean: -20.071794\n",
            "resetting env. episode 1417.000000, reward total was -20.000000. running mean: -20.071076\n",
            "resetting env. episode 1418.000000, reward total was -21.000000. running mean: -20.080365\n",
            "resetting env. episode 1419.000000, reward total was -18.000000. running mean: -20.059561\n",
            "resetting env. episode 1420.000000, reward total was -20.000000. running mean: -20.058966\n",
            "resetting env. episode 1421.000000, reward total was -20.000000. running mean: -20.058376\n",
            "resetting env. episode 1422.000000, reward total was -20.000000. running mean: -20.057792\n",
            "resetting env. episode 1423.000000, reward total was -19.000000. running mean: -20.047214\n",
            "resetting env. episode 1424.000000, reward total was -20.000000. running mean: -20.046742\n",
            "resetting env. episode 1425.000000, reward total was -20.000000. running mean: -20.046275\n",
            "resetting env. episode 1426.000000, reward total was -20.000000. running mean: -20.045812\n",
            "resetting env. episode 1427.000000, reward total was -21.000000. running mean: -20.055354\n",
            "resetting env. episode 1428.000000, reward total was -17.000000. running mean: -20.024800\n",
            "resetting env. episode 1429.000000, reward total was -20.000000. running mean: -20.024552\n",
            "resetting env. episode 1430.000000, reward total was -19.000000. running mean: -20.014307\n",
            "resetting env. episode 1431.000000, reward total was -19.000000. running mean: -20.004164\n",
            "resetting env. episode 1432.000000, reward total was -21.000000. running mean: -20.014122\n",
            "resetting env. episode 1433.000000, reward total was -21.000000. running mean: -20.023981\n",
            "resetting env. episode 1434.000000, reward total was -18.000000. running mean: -20.003741\n",
            "resetting env. episode 1435.000000, reward total was -21.000000. running mean: -20.013704\n",
            "resetting env. episode 1436.000000, reward total was -20.000000. running mean: -20.013567\n",
            "resetting env. episode 1437.000000, reward total was -19.000000. running mean: -20.003431\n",
            "resetting env. episode 1438.000000, reward total was -21.000000. running mean: -20.013397\n",
            "resetting env. episode 1439.000000, reward total was -20.000000. running mean: -20.013263\n",
            "resetting env. episode 1440.000000, reward total was -19.000000. running mean: -20.003130\n",
            "resetting env. episode 1441.000000, reward total was -18.000000. running mean: -19.983099\n",
            "resetting env. episode 1442.000000, reward total was -18.000000. running mean: -19.963268\n",
            "resetting env. episode 1443.000000, reward total was -21.000000. running mean: -19.973635\n",
            "resetting env. episode 1444.000000, reward total was -20.000000. running mean: -19.973899\n",
            "resetting env. episode 1445.000000, reward total was -21.000000. running mean: -19.984160\n",
            "resetting env. episode 1446.000000, reward total was -18.000000. running mean: -19.964318\n",
            "resetting env. episode 1447.000000, reward total was -20.000000. running mean: -19.964675\n",
            "resetting env. episode 1448.000000, reward total was -21.000000. running mean: -19.975028\n",
            "resetting env. episode 1449.000000, reward total was -19.000000. running mean: -19.965278\n",
            "resetting env. episode 1450.000000, reward total was -20.000000. running mean: -19.965625\n",
            "resetting env. episode 1451.000000, reward total was -20.000000. running mean: -19.965969\n",
            "resetting env. episode 1452.000000, reward total was -21.000000. running mean: -19.976309\n",
            "resetting env. episode 1453.000000, reward total was -19.000000. running mean: -19.966546\n",
            "resetting env. episode 1454.000000, reward total was -21.000000. running mean: -19.976881\n",
            "resetting env. episode 1455.000000, reward total was -20.000000. running mean: -19.977112\n",
            "resetting env. episode 1456.000000, reward total was -21.000000. running mean: -19.987341\n",
            "resetting env. episode 1457.000000, reward total was -20.000000. running mean: -19.987467\n",
            "resetting env. episode 1458.000000, reward total was -20.000000. running mean: -19.987593\n",
            "resetting env. episode 1459.000000, reward total was -21.000000. running mean: -19.997717\n",
            "resetting env. episode 1460.000000, reward total was -19.000000. running mean: -19.987740\n",
            "resetting env. episode 1461.000000, reward total was -19.000000. running mean: -19.977862\n",
            "resetting env. episode 1462.000000, reward total was -19.000000. running mean: -19.968084\n",
            "resetting env. episode 1463.000000, reward total was -20.000000. running mean: -19.968403\n",
            "resetting env. episode 1464.000000, reward total was -19.000000. running mean: -19.958719\n",
            "resetting env. episode 1465.000000, reward total was -20.000000. running mean: -19.959131\n",
            "resetting env. episode 1466.000000, reward total was -21.000000. running mean: -19.969540\n",
            "resetting env. episode 1467.000000, reward total was -20.000000. running mean: -19.969845\n",
            "resetting env. episode 1468.000000, reward total was -21.000000. running mean: -19.980146\n",
            "resetting env. episode 1469.000000, reward total was -20.000000. running mean: -19.980345\n",
            "resetting env. episode 1470.000000, reward total was -21.000000. running mean: -19.990541\n",
            "resetting env. episode 1471.000000, reward total was -19.000000. running mean: -19.980636\n",
            "resetting env. episode 1472.000000, reward total was -18.000000. running mean: -19.960830\n",
            "resetting env. episode 1473.000000, reward total was -21.000000. running mean: -19.971221\n",
            "resetting env. episode 1474.000000, reward total was -21.000000. running mean: -19.981509\n",
            "resetting env. episode 1475.000000, reward total was -20.000000. running mean: -19.981694\n",
            "resetting env. episode 1476.000000, reward total was -20.000000. running mean: -19.981877\n",
            "resetting env. episode 1477.000000, reward total was -19.000000. running mean: -19.972058\n",
            "resetting env. episode 1478.000000, reward total was -21.000000. running mean: -19.982338\n",
            "resetting env. episode 1479.000000, reward total was -19.000000. running mean: -19.972514\n",
            "resetting env. episode 1480.000000, reward total was -21.000000. running mean: -19.982789\n",
            "resetting env. episode 1481.000000, reward total was -20.000000. running mean: -19.982961\n",
            "resetting env. episode 1482.000000, reward total was -19.000000. running mean: -19.973132\n",
            "resetting env. episode 1483.000000, reward total was -20.000000. running mean: -19.973400\n",
            "resetting env. episode 1484.000000, reward total was -21.000000. running mean: -19.983666\n",
            "resetting env. episode 1485.000000, reward total was -19.000000. running mean: -19.973830\n",
            "resetting env. episode 1486.000000, reward total was -20.000000. running mean: -19.974091\n",
            "resetting env. episode 1487.000000, reward total was -19.000000. running mean: -19.964351\n",
            "resetting env. episode 1488.000000, reward total was -19.000000. running mean: -19.954707\n",
            "resetting env. episode 1489.000000, reward total was -21.000000. running mean: -19.965160\n",
            "resetting env. episode 1490.000000, reward total was -19.000000. running mean: -19.955508\n",
            "resetting env. episode 1491.000000, reward total was -21.000000. running mean: -19.965953\n",
            "resetting env. episode 1492.000000, reward total was -19.000000. running mean: -19.956294\n",
            "resetting env. episode 1493.000000, reward total was -21.000000. running mean: -19.966731\n",
            "resetting env. episode 1494.000000, reward total was -20.000000. running mean: -19.967063\n",
            "resetting env. episode 1495.000000, reward total was -20.000000. running mean: -19.967393\n",
            "resetting env. episode 1496.000000, reward total was -19.000000. running mean: -19.957719\n",
            "resetting env. episode 1497.000000, reward total was -19.000000. running mean: -19.948142\n",
            "resetting env. episode 1498.000000, reward total was -21.000000. running mean: -19.958660\n",
            "resetting env. episode 1499.000000, reward total was -21.000000. running mean: -19.969074\n",
            "resetting env. episode 1500.000000, reward total was -20.000000. running mean: -19.969383\n",
            "resetting env. episode 1501.000000, reward total was -18.000000. running mean: -19.949689\n",
            "resetting env. episode 1502.000000, reward total was -20.000000. running mean: -19.950192\n",
            "resetting env. episode 1503.000000, reward total was -20.000000. running mean: -19.950690\n",
            "resetting env. episode 1504.000000, reward total was -21.000000. running mean: -19.961183\n",
            "resetting env. episode 1505.000000, reward total was -21.000000. running mean: -19.971572\n",
            "resetting env. episode 1506.000000, reward total was -21.000000. running mean: -19.981856\n",
            "resetting env. episode 1507.000000, reward total was -21.000000. running mean: -19.992037\n",
            "resetting env. episode 1508.000000, reward total was -19.000000. running mean: -19.982117\n",
            "resetting env. episode 1509.000000, reward total was -19.000000. running mean: -19.972296\n",
            "resetting env. episode 1510.000000, reward total was -20.000000. running mean: -19.972573\n",
            "resetting env. episode 1511.000000, reward total was -20.000000. running mean: -19.972847\n",
            "resetting env. episode 1512.000000, reward total was -19.000000. running mean: -19.963119\n",
            "resetting env. episode 1513.000000, reward total was -19.000000. running mean: -19.953487\n",
            "resetting env. episode 1514.000000, reward total was -16.000000. running mean: -19.913953\n",
            "resetting env. episode 1515.000000, reward total was -16.000000. running mean: -19.874813\n",
            "resetting env. episode 1516.000000, reward total was -20.000000. running mean: -19.876065\n",
            "resetting env. episode 1517.000000, reward total was -19.000000. running mean: -19.867304\n",
            "resetting env. episode 1518.000000, reward total was -20.000000. running mean: -19.868631\n",
            "resetting env. episode 1519.000000, reward total was -19.000000. running mean: -19.859945\n",
            "resetting env. episode 1520.000000, reward total was -20.000000. running mean: -19.861345\n",
            "resetting env. episode 1521.000000, reward total was -20.000000. running mean: -19.862732\n",
            "resetting env. episode 1522.000000, reward total was -21.000000. running mean: -19.874105\n",
            "resetting env. episode 1523.000000, reward total was -16.000000. running mean: -19.835364\n",
            "resetting env. episode 1524.000000, reward total was -20.000000. running mean: -19.837010\n",
            "resetting env. episode 1525.000000, reward total was -20.000000. running mean: -19.838640\n",
            "resetting env. episode 1526.000000, reward total was -20.000000. running mean: -19.840253\n",
            "resetting env. episode 1527.000000, reward total was -17.000000. running mean: -19.811851\n",
            "resetting env. episode 1528.000000, reward total was -21.000000. running mean: -19.823732\n",
            "resetting env. episode 1529.000000, reward total was -19.000000. running mean: -19.815495\n",
            "resetting env. episode 1530.000000, reward total was -18.000000. running mean: -19.797340\n",
            "resetting env. episode 1531.000000, reward total was -21.000000. running mean: -19.809367\n",
            "resetting env. episode 1532.000000, reward total was -19.000000. running mean: -19.801273\n",
            "resetting env. episode 1533.000000, reward total was -21.000000. running mean: -19.813260\n",
            "resetting env. episode 1534.000000, reward total was -21.000000. running mean: -19.825128\n",
            "resetting env. episode 1535.000000, reward total was -21.000000. running mean: -19.836876\n",
            "resetting env. episode 1536.000000, reward total was -18.000000. running mean: -19.818508\n",
            "resetting env. episode 1537.000000, reward total was -20.000000. running mean: -19.820323\n",
            "resetting env. episode 1538.000000, reward total was -21.000000. running mean: -19.832119\n",
            "resetting env. episode 1539.000000, reward total was -20.000000. running mean: -19.833798\n",
            "resetting env. episode 1540.000000, reward total was -19.000000. running mean: -19.825460\n",
            "resetting env. episode 1541.000000, reward total was -20.000000. running mean: -19.827206\n",
            "resetting env. episode 1542.000000, reward total was -21.000000. running mean: -19.838934\n",
            "resetting env. episode 1543.000000, reward total was -21.000000. running mean: -19.850544\n",
            "resetting env. episode 1544.000000, reward total was -21.000000. running mean: -19.862039\n",
            "resetting env. episode 1545.000000, reward total was -20.000000. running mean: -19.863418\n",
            "resetting env. episode 1546.000000, reward total was -20.000000. running mean: -19.864784\n",
            "resetting env. episode 1547.000000, reward total was -20.000000. running mean: -19.866136\n",
            "resetting env. episode 1548.000000, reward total was -17.000000. running mean: -19.837475\n",
            "resetting env. episode 1549.000000, reward total was -18.000000. running mean: -19.819100\n",
            "resetting env. episode 1550.000000, reward total was -19.000000. running mean: -19.810909\n",
            "resetting env. episode 1551.000000, reward total was -20.000000. running mean: -19.812800\n",
            "resetting env. episode 1552.000000, reward total was -20.000000. running mean: -19.814672\n",
            "resetting env. episode 1553.000000, reward total was -21.000000. running mean: -19.826525\n",
            "resetting env. episode 1554.000000, reward total was -21.000000. running mean: -19.838260\n",
            "resetting env. episode 1555.000000, reward total was -20.000000. running mean: -19.839878\n",
            "resetting env. episode 1556.000000, reward total was -19.000000. running mean: -19.831479\n",
            "resetting env. episode 1557.000000, reward total was -20.000000. running mean: -19.833164\n",
            "resetting env. episode 1558.000000, reward total was -20.000000. running mean: -19.834832\n",
            "resetting env. episode 1559.000000, reward total was -19.000000. running mean: -19.826484\n",
            "resetting env. episode 1560.000000, reward total was -19.000000. running mean: -19.818219\n",
            "resetting env. episode 1561.000000, reward total was -20.000000. running mean: -19.820037\n",
            "resetting env. episode 1562.000000, reward total was -21.000000. running mean: -19.831837\n",
            "resetting env. episode 1563.000000, reward total was -18.000000. running mean: -19.813518\n",
            "resetting env. episode 1564.000000, reward total was -20.000000. running mean: -19.815383\n",
            "resetting env. episode 1565.000000, reward total was -15.000000. running mean: -19.767229\n",
            "resetting env. episode 1566.000000, reward total was -20.000000. running mean: -19.769557\n",
            "resetting env. episode 1567.000000, reward total was -20.000000. running mean: -19.771861\n",
            "resetting env. episode 1568.000000, reward total was -21.000000. running mean: -19.784143\n",
            "resetting env. episode 1569.000000, reward total was -20.000000. running mean: -19.786301\n",
            "resetting env. episode 1570.000000, reward total was -21.000000. running mean: -19.798438\n",
            "resetting env. episode 1571.000000, reward total was -20.000000. running mean: -19.800454\n",
            "resetting env. episode 1572.000000, reward total was -21.000000. running mean: -19.812449\n",
            "resetting env. episode 1573.000000, reward total was -21.000000. running mean: -19.824325\n",
            "resetting env. episode 1574.000000, reward total was -21.000000. running mean: -19.836082\n",
            "resetting env. episode 1575.000000, reward total was -21.000000. running mean: -19.847721\n",
            "resetting env. episode 1576.000000, reward total was -19.000000. running mean: -19.839244\n",
            "resetting env. episode 1577.000000, reward total was -19.000000. running mean: -19.830851\n",
            "resetting env. episode 1578.000000, reward total was -19.000000. running mean: -19.822543\n",
            "resetting env. episode 1579.000000, reward total was -18.000000. running mean: -19.804317\n",
            "resetting env. episode 1580.000000, reward total was -18.000000. running mean: -19.786274\n",
            "resetting env. episode 1581.000000, reward total was -19.000000. running mean: -19.778411\n",
            "resetting env. episode 1582.000000, reward total was -20.000000. running mean: -19.780627\n",
            "resetting env. episode 1583.000000, reward total was -18.000000. running mean: -19.762821\n",
            "resetting env. episode 1584.000000, reward total was -21.000000. running mean: -19.775193\n",
            "resetting env. episode 1585.000000, reward total was -19.000000. running mean: -19.767441\n",
            "resetting env. episode 1586.000000, reward total was -20.000000. running mean: -19.769766\n",
            "resetting env. episode 1587.000000, reward total was -19.000000. running mean: -19.762069\n",
            "resetting env. episode 1588.000000, reward total was -20.000000. running mean: -19.764448\n",
            "resetting env. episode 1589.000000, reward total was -20.000000. running mean: -19.766804\n",
            "resetting env. episode 1590.000000, reward total was -20.000000. running mean: -19.769136\n",
            "resetting env. episode 1591.000000, reward total was -20.000000. running mean: -19.771444\n",
            "resetting env. episode 1592.000000, reward total was -21.000000. running mean: -19.783730\n",
            "resetting env. episode 1593.000000, reward total was -20.000000. running mean: -19.785892\n",
            "resetting env. episode 1594.000000, reward total was -19.000000. running mean: -19.778034\n",
            "resetting env. episode 1595.000000, reward total was -21.000000. running mean: -19.790253\n",
            "resetting env. episode 1596.000000, reward total was -21.000000. running mean: -19.802351\n",
            "resetting env. episode 1597.000000, reward total was -19.000000. running mean: -19.794327\n",
            "resetting env. episode 1598.000000, reward total was -19.000000. running mean: -19.786384\n",
            "resetting env. episode 1599.000000, reward total was -21.000000. running mean: -19.798520\n",
            "resetting env. episode 1600.000000, reward total was -21.000000. running mean: -19.810535\n",
            "resetting env. episode 1601.000000, reward total was -20.000000. running mean: -19.812430\n",
            "resetting env. episode 1602.000000, reward total was -21.000000. running mean: -19.824305\n",
            "resetting env. episode 1603.000000, reward total was -19.000000. running mean: -19.816062\n",
            "resetting env. episode 1604.000000, reward total was -20.000000. running mean: -19.817902\n",
            "resetting env. episode 1605.000000, reward total was -20.000000. running mean: -19.819723\n",
            "resetting env. episode 1606.000000, reward total was -20.000000. running mean: -19.821525\n",
            "resetting env. episode 1607.000000, reward total was -20.000000. running mean: -19.823310\n",
            "resetting env. episode 1608.000000, reward total was -20.000000. running mean: -19.825077\n",
            "resetting env. episode 1609.000000, reward total was -19.000000. running mean: -19.816826\n",
            "resetting env. episode 1610.000000, reward total was -18.000000. running mean: -19.798658\n",
            "resetting env. episode 1611.000000, reward total was -20.000000. running mean: -19.800671\n",
            "resetting env. episode 1612.000000, reward total was -21.000000. running mean: -19.812665\n",
            "resetting env. episode 1613.000000, reward total was -19.000000. running mean: -19.804538\n",
            "resetting env. episode 1614.000000, reward total was -21.000000. running mean: -19.816493\n",
            "resetting env. episode 1615.000000, reward total was -17.000000. running mean: -19.788328\n",
            "resetting env. episode 1616.000000, reward total was -20.000000. running mean: -19.790444\n",
            "resetting env. episode 1617.000000, reward total was -20.000000. running mean: -19.792540\n",
            "resetting env. episode 1618.000000, reward total was -21.000000. running mean: -19.804615\n",
            "resetting env. episode 1619.000000, reward total was -17.000000. running mean: -19.776568\n",
            "resetting env. episode 1620.000000, reward total was -20.000000. running mean: -19.778803\n",
            "resetting env. episode 1621.000000, reward total was -21.000000. running mean: -19.791015\n",
            "resetting env. episode 1622.000000, reward total was -21.000000. running mean: -19.803105\n",
            "resetting env. episode 1623.000000, reward total was -20.000000. running mean: -19.805074\n",
            "resetting env. episode 1624.000000, reward total was -21.000000. running mean: -19.817023\n",
            "resetting env. episode 1625.000000, reward total was -21.000000. running mean: -19.828853\n",
            "resetting env. episode 1626.000000, reward total was -19.000000. running mean: -19.820564\n",
            "resetting env. episode 1627.000000, reward total was -18.000000. running mean: -19.802358\n",
            "resetting env. episode 1628.000000, reward total was -20.000000. running mean: -19.804335\n",
            "resetting env. episode 1629.000000, reward total was -19.000000. running mean: -19.796291\n",
            "resetting env. episode 1630.000000, reward total was -20.000000. running mean: -19.798329\n",
            "resetting env. episode 1631.000000, reward total was -21.000000. running mean: -19.810345\n",
            "resetting env. episode 1632.000000, reward total was -21.000000. running mean: -19.822242\n",
            "resetting env. episode 1633.000000, reward total was -18.000000. running mean: -19.804019\n",
            "resetting env. episode 1634.000000, reward total was -20.000000. running mean: -19.805979\n",
            "resetting env. episode 1635.000000, reward total was -18.000000. running mean: -19.787919\n",
            "resetting env. episode 1636.000000, reward total was -21.000000. running mean: -19.800040\n",
            "resetting env. episode 1637.000000, reward total was -21.000000. running mean: -19.812040\n",
            "resetting env. episode 1638.000000, reward total was -18.000000. running mean: -19.793919\n",
            "resetting env. episode 1639.000000, reward total was -19.000000. running mean: -19.785980\n",
            "resetting env. episode 1640.000000, reward total was -19.000000. running mean: -19.778120\n",
            "resetting env. episode 1641.000000, reward total was -21.000000. running mean: -19.790339\n",
            "resetting env. episode 1642.000000, reward total was -21.000000. running mean: -19.802436\n",
            "resetting env. episode 1643.000000, reward total was -20.000000. running mean: -19.804411\n",
            "resetting env. episode 1644.000000, reward total was -20.000000. running mean: -19.806367\n",
            "resetting env. episode 1645.000000, reward total was -21.000000. running mean: -19.818304\n",
            "resetting env. episode 1646.000000, reward total was -19.000000. running mean: -19.810121\n",
            "resetting env. episode 1647.000000, reward total was -21.000000. running mean: -19.822019\n",
            "resetting env. episode 1648.000000, reward total was -20.000000. running mean: -19.823799\n",
            "resetting env. episode 1649.000000, reward total was -21.000000. running mean: -19.835561\n",
            "resetting env. episode 1650.000000, reward total was -19.000000. running mean: -19.827206\n",
            "resetting env. episode 1651.000000, reward total was -21.000000. running mean: -19.838934\n",
            "resetting env. episode 1652.000000, reward total was -21.000000. running mean: -19.850544\n",
            "resetting env. episode 1653.000000, reward total was -19.000000. running mean: -19.842039\n",
            "resetting env. episode 1654.000000, reward total was -21.000000. running mean: -19.853618\n",
            "resetting env. episode 1655.000000, reward total was -21.000000. running mean: -19.865082\n",
            "resetting env. episode 1656.000000, reward total was -21.000000. running mean: -19.876431\n",
            "resetting env. episode 1657.000000, reward total was -20.000000. running mean: -19.877667\n",
            "resetting env. episode 1658.000000, reward total was -20.000000. running mean: -19.878890\n",
            "resetting env. episode 1659.000000, reward total was -20.000000. running mean: -19.880102\n",
            "resetting env. episode 1660.000000, reward total was -17.000000. running mean: -19.851300\n",
            "resetting env. episode 1661.000000, reward total was -21.000000. running mean: -19.862787\n",
            "resetting env. episode 1662.000000, reward total was -21.000000. running mean: -19.874160\n",
            "resetting env. episode 1663.000000, reward total was -21.000000. running mean: -19.885418\n",
            "resetting env. episode 1664.000000, reward total was -18.000000. running mean: -19.866564\n",
            "resetting env. episode 1665.000000, reward total was -21.000000. running mean: -19.877898\n",
            "resetting env. episode 1666.000000, reward total was -21.000000. running mean: -19.889119\n",
            "resetting env. episode 1667.000000, reward total was -20.000000. running mean: -19.890228\n",
            "resetting env. episode 1668.000000, reward total was -20.000000. running mean: -19.891326\n",
            "resetting env. episode 1669.000000, reward total was -19.000000. running mean: -19.882412\n",
            "resetting env. episode 1670.000000, reward total was -19.000000. running mean: -19.873588\n",
            "resetting env. episode 1671.000000, reward total was -19.000000. running mean: -19.864852\n",
            "resetting env. episode 1672.000000, reward total was -21.000000. running mean: -19.876204\n",
            "resetting env. episode 1673.000000, reward total was -21.000000. running mean: -19.887442\n",
            "resetting env. episode 1674.000000, reward total was -20.000000. running mean: -19.888567\n",
            "resetting env. episode 1675.000000, reward total was -20.000000. running mean: -19.889682\n",
            "resetting env. episode 1676.000000, reward total was -21.000000. running mean: -19.900785\n",
            "resetting env. episode 1677.000000, reward total was -21.000000. running mean: -19.911777\n",
            "resetting env. episode 1678.000000, reward total was -21.000000. running mean: -19.922659\n",
            "resetting env. episode 1679.000000, reward total was -19.000000. running mean: -19.913433\n",
            "resetting env. episode 1680.000000, reward total was -21.000000. running mean: -19.924298\n",
            "resetting env. episode 1681.000000, reward total was -20.000000. running mean: -19.925055\n",
            "resetting env. episode 1682.000000, reward total was -19.000000. running mean: -19.915805\n",
            "resetting env. episode 1683.000000, reward total was -20.000000. running mean: -19.916647\n",
            "resetting env. episode 1684.000000, reward total was -20.000000. running mean: -19.917480\n",
            "resetting env. episode 1685.000000, reward total was -19.000000. running mean: -19.908306\n",
            "resetting env. episode 1686.000000, reward total was -21.000000. running mean: -19.919223\n",
            "resetting env. episode 1687.000000, reward total was -18.000000. running mean: -19.900030\n",
            "resetting env. episode 1688.000000, reward total was -20.000000. running mean: -19.901030\n",
            "resetting env. episode 1689.000000, reward total was -19.000000. running mean: -19.892020\n",
            "resetting env. episode 1690.000000, reward total was -19.000000. running mean: -19.883100\n",
            "resetting env. episode 1691.000000, reward total was -18.000000. running mean: -19.864269\n",
            "resetting env. episode 1692.000000, reward total was -19.000000. running mean: -19.855626\n",
            "resetting env. episode 1693.000000, reward total was -20.000000. running mean: -19.857070\n",
            "resetting env. episode 1694.000000, reward total was -21.000000. running mean: -19.868499\n",
            "resetting env. episode 1695.000000, reward total was -20.000000. running mean: -19.869814\n",
            "resetting env. episode 1696.000000, reward total was -20.000000. running mean: -19.871116\n",
            "resetting env. episode 1697.000000, reward total was -20.000000. running mean: -19.872405\n",
            "resetting env. episode 1698.000000, reward total was -19.000000. running mean: -19.863681\n",
            "resetting env. episode 1699.000000, reward total was -21.000000. running mean: -19.875044\n",
            "resetting env. episode 1700.000000, reward total was -19.000000. running mean: -19.866293\n",
            "resetting env. episode 1701.000000, reward total was -19.000000. running mean: -19.857630\n",
            "resetting env. episode 1702.000000, reward total was -20.000000. running mean: -19.859054\n",
            "resetting env. episode 1703.000000, reward total was -17.000000. running mean: -19.830464\n",
            "resetting env. episode 1704.000000, reward total was -18.000000. running mean: -19.812159\n",
            "resetting env. episode 1705.000000, reward total was -20.000000. running mean: -19.814037\n",
            "resetting env. episode 1706.000000, reward total was -20.000000. running mean: -19.815897\n",
            "resetting env. episode 1707.000000, reward total was -21.000000. running mean: -19.827738\n",
            "resetting env. episode 1708.000000, reward total was -20.000000. running mean: -19.829461\n",
            "resetting env. episode 1709.000000, reward total was -18.000000. running mean: -19.811166\n",
            "resetting env. episode 1710.000000, reward total was -19.000000. running mean: -19.803054\n",
            "resetting env. episode 1711.000000, reward total was -20.000000. running mean: -19.805024\n",
            "resetting env. episode 1712.000000, reward total was -21.000000. running mean: -19.816974\n",
            "resetting env. episode 1713.000000, reward total was -19.000000. running mean: -19.808804\n",
            "resetting env. episode 1714.000000, reward total was -19.000000. running mean: -19.800716\n",
            "resetting env. episode 1715.000000, reward total was -19.000000. running mean: -19.792709\n",
            "resetting env. episode 1716.000000, reward total was -18.000000. running mean: -19.774782\n",
            "resetting env. episode 1717.000000, reward total was -19.000000. running mean: -19.767034\n",
            "resetting env. episode 1718.000000, reward total was -20.000000. running mean: -19.769363\n",
            "resetting env. episode 1719.000000, reward total was -19.000000. running mean: -19.761670\n",
            "resetting env. episode 1720.000000, reward total was -21.000000. running mean: -19.774053\n",
            "resetting env. episode 1721.000000, reward total was -18.000000. running mean: -19.756313\n",
            "resetting env. episode 1722.000000, reward total was -21.000000. running mean: -19.768749\n",
            "resetting env. episode 1723.000000, reward total was -17.000000. running mean: -19.741062\n",
            "resetting env. episode 1724.000000, reward total was -20.000000. running mean: -19.743651\n",
            "resetting env. episode 1725.000000, reward total was -19.000000. running mean: -19.736215\n",
            "resetting env. episode 1726.000000, reward total was -21.000000. running mean: -19.748853\n",
            "resetting env. episode 1727.000000, reward total was -21.000000. running mean: -19.761364\n",
            "resetting env. episode 1728.000000, reward total was -18.000000. running mean: -19.743750\n",
            "resetting env. episode 1729.000000, reward total was -18.000000. running mean: -19.726313\n",
            "resetting env. episode 1730.000000, reward total was -20.000000. running mean: -19.729050\n",
            "resetting env. episode 1731.000000, reward total was -20.000000. running mean: -19.731759\n",
            "resetting env. episode 1732.000000, reward total was -21.000000. running mean: -19.744442\n",
            "resetting env. episode 1733.000000, reward total was -21.000000. running mean: -19.756997\n",
            "resetting env. episode 1734.000000, reward total was -21.000000. running mean: -19.769427\n",
            "resetting env. episode 1735.000000, reward total was -20.000000. running mean: -19.771733\n",
            "resetting env. episode 1736.000000, reward total was -21.000000. running mean: -19.784016\n",
            "resetting env. episode 1737.000000, reward total was -21.000000. running mean: -19.796176\n",
            "resetting env. episode 1738.000000, reward total was -18.000000. running mean: -19.778214\n",
            "resetting env. episode 1739.000000, reward total was -18.000000. running mean: -19.760432\n",
            "resetting env. episode 1740.000000, reward total was -17.000000. running mean: -19.732827\n",
            "resetting env. episode 1741.000000, reward total was -21.000000. running mean: -19.745499\n",
            "resetting env. episode 1742.000000, reward total was -21.000000. running mean: -19.758044\n",
            "resetting env. episode 1743.000000, reward total was -19.000000. running mean: -19.750464\n",
            "resetting env. episode 1744.000000, reward total was -21.000000. running mean: -19.762959\n",
            "resetting env. episode 1745.000000, reward total was -21.000000. running mean: -19.775329\n",
            "resetting env. episode 1746.000000, reward total was -20.000000. running mean: -19.777576\n",
            "resetting env. episode 1747.000000, reward total was -21.000000. running mean: -19.789800\n",
            "resetting env. episode 1748.000000, reward total was -19.000000. running mean: -19.781902\n",
            "resetting env. episode 1749.000000, reward total was -21.000000. running mean: -19.794083\n",
            "resetting env. episode 1750.000000, reward total was -20.000000. running mean: -19.796143\n",
            "resetting env. episode 1751.000000, reward total was -19.000000. running mean: -19.788181\n",
            "resetting env. episode 1752.000000, reward total was -18.000000. running mean: -19.770299\n",
            "resetting env. episode 1753.000000, reward total was -21.000000. running mean: -19.782596\n",
            "resetting env. episode 1754.000000, reward total was -18.000000. running mean: -19.764770\n",
            "resetting env. episode 1755.000000, reward total was -19.000000. running mean: -19.757123\n",
            "resetting env. episode 1756.000000, reward total was -21.000000. running mean: -19.769551\n",
            "resetting env. episode 1757.000000, reward total was -21.000000. running mean: -19.781856\n",
            "resetting env. episode 1758.000000, reward total was -20.000000. running mean: -19.784037\n",
            "resetting env. episode 1759.000000, reward total was -21.000000. running mean: -19.796197\n",
            "resetting env. episode 1760.000000, reward total was -20.000000. running mean: -19.798235\n",
            "resetting env. episode 1761.000000, reward total was -20.000000. running mean: -19.800253\n",
            "resetting env. episode 1762.000000, reward total was -21.000000. running mean: -19.812250\n",
            "resetting env. episode 1763.000000, reward total was -19.000000. running mean: -19.804128\n",
            "resetting env. episode 1764.000000, reward total was -20.000000. running mean: -19.806086\n",
            "resetting env. episode 1765.000000, reward total was -19.000000. running mean: -19.798025\n",
            "resetting env. episode 1766.000000, reward total was -20.000000. running mean: -19.800045\n",
            "resetting env. episode 1767.000000, reward total was -21.000000. running mean: -19.812045\n",
            "resetting env. episode 1768.000000, reward total was -21.000000. running mean: -19.823924\n",
            "resetting env. episode 1769.000000, reward total was -21.000000. running mean: -19.835685\n",
            "resetting env. episode 1770.000000, reward total was -18.000000. running mean: -19.817328\n",
            "resetting env. episode 1771.000000, reward total was -21.000000. running mean: -19.829155\n",
            "resetting env. episode 1772.000000, reward total was -20.000000. running mean: -19.830863\n",
            "resetting env. episode 1773.000000, reward total was -20.000000. running mean: -19.832555\n",
            "resetting env. episode 1774.000000, reward total was -21.000000. running mean: -19.844229\n",
            "resetting env. episode 1775.000000, reward total was -20.000000. running mean: -19.845787\n",
            "resetting env. episode 1776.000000, reward total was -19.000000. running mean: -19.837329\n",
            "resetting env. episode 1777.000000, reward total was -20.000000. running mean: -19.838956\n",
            "resetting env. episode 1778.000000, reward total was -20.000000. running mean: -19.840566\n",
            "resetting env. episode 1779.000000, reward total was -20.000000. running mean: -19.842161\n",
            "resetting env. episode 1780.000000, reward total was -21.000000. running mean: -19.853739\n",
            "resetting env. episode 1781.000000, reward total was -17.000000. running mean: -19.825202\n",
            "resetting env. episode 1782.000000, reward total was -20.000000. running mean: -19.826950\n",
            "resetting env. episode 1783.000000, reward total was -21.000000. running mean: -19.838680\n",
            "resetting env. episode 1784.000000, reward total was -21.000000. running mean: -19.850293\n",
            "resetting env. episode 1785.000000, reward total was -20.000000. running mean: -19.851790\n",
            "resetting env. episode 1786.000000, reward total was -21.000000. running mean: -19.863272\n",
            "resetting env. episode 1787.000000, reward total was -18.000000. running mean: -19.844640\n",
            "resetting env. episode 1788.000000, reward total was -21.000000. running mean: -19.856193\n",
            "resetting env. episode 1789.000000, reward total was -21.000000. running mean: -19.867631\n",
            "resetting env. episode 1790.000000, reward total was -21.000000. running mean: -19.878955\n",
            "resetting env. episode 1791.000000, reward total was -18.000000. running mean: -19.860165\n",
            "resetting env. episode 1792.000000, reward total was -21.000000. running mean: -19.871564\n",
            "resetting env. episode 1793.000000, reward total was -18.000000. running mean: -19.852848\n",
            "resetting env. episode 1794.000000, reward total was -19.000000. running mean: -19.844320\n",
            "resetting env. episode 1795.000000, reward total was -21.000000. running mean: -19.855876\n",
            "resetting env. episode 1796.000000, reward total was -20.000000. running mean: -19.857318\n",
            "resetting env. episode 1797.000000, reward total was -19.000000. running mean: -19.848745\n",
            "resetting env. episode 1798.000000, reward total was -21.000000. running mean: -19.860257\n",
            "resetting env. episode 1799.000000, reward total was -19.000000. running mean: -19.851655\n",
            "resetting env. episode 1800.000000, reward total was -20.000000. running mean: -19.853138\n",
            "resetting env. episode 1801.000000, reward total was -18.000000. running mean: -19.834607\n",
            "resetting env. episode 1802.000000, reward total was -20.000000. running mean: -19.836261\n",
            "resetting env. episode 1803.000000, reward total was -19.000000. running mean: -19.827898\n",
            "resetting env. episode 1804.000000, reward total was -20.000000. running mean: -19.829619\n",
            "resetting env. episode 1805.000000, reward total was -20.000000. running mean: -19.831323\n",
            "resetting env. episode 1806.000000, reward total was -19.000000. running mean: -19.823010\n",
            "resetting env. episode 1807.000000, reward total was -20.000000. running mean: -19.824779\n",
            "resetting env. episode 1808.000000, reward total was -21.000000. running mean: -19.836532\n",
            "resetting env. episode 1809.000000, reward total was -20.000000. running mean: -19.838166\n",
            "resetting env. episode 1810.000000, reward total was -20.000000. running mean: -19.839785\n",
            "resetting env. episode 1811.000000, reward total was -21.000000. running mean: -19.851387\n",
            "resetting env. episode 1812.000000, reward total was -17.000000. running mean: -19.822873\n",
            "resetting env. episode 1813.000000, reward total was -21.000000. running mean: -19.834644\n",
            "resetting env. episode 1814.000000, reward total was -21.000000. running mean: -19.846298\n",
            "resetting env. episode 1815.000000, reward total was -20.000000. running mean: -19.847835\n",
            "resetting env. episode 1816.000000, reward total was -21.000000. running mean: -19.859356\n",
            "resetting env. episode 1817.000000, reward total was -21.000000. running mean: -19.870763\n",
            "resetting env. episode 1818.000000, reward total was -21.000000. running mean: -19.882055\n",
            "resetting env. episode 1819.000000, reward total was -21.000000. running mean: -19.893235\n",
            "resetting env. episode 1820.000000, reward total was -19.000000. running mean: -19.884302\n",
            "resetting env. episode 1821.000000, reward total was -21.000000. running mean: -19.895459\n",
            "resetting env. episode 1822.000000, reward total was -19.000000. running mean: -19.886505\n",
            "resetting env. episode 1823.000000, reward total was -17.000000. running mean: -19.857640\n",
            "resetting env. episode 1824.000000, reward total was -20.000000. running mean: -19.859063\n",
            "resetting env. episode 1825.000000, reward total was -21.000000. running mean: -19.870473\n",
            "resetting env. episode 1826.000000, reward total was -18.000000. running mean: -19.851768\n",
            "resetting env. episode 1827.000000, reward total was -20.000000. running mean: -19.853250\n",
            "resetting env. episode 1828.000000, reward total was -20.000000. running mean: -19.854718\n",
            "resetting env. episode 1829.000000, reward total was -19.000000. running mean: -19.846171\n",
            "resetting env. episode 1830.000000, reward total was -20.000000. running mean: -19.847709\n",
            "resetting env. episode 1831.000000, reward total was -21.000000. running mean: -19.859232\n",
            "resetting env. episode 1832.000000, reward total was -21.000000. running mean: -19.870639\n",
            "resetting env. episode 1833.000000, reward total was -21.000000. running mean: -19.881933\n",
            "resetting env. episode 1834.000000, reward total was -21.000000. running mean: -19.893114\n",
            "resetting env. episode 1835.000000, reward total was -20.000000. running mean: -19.894183\n",
            "resetting env. episode 1836.000000, reward total was -21.000000. running mean: -19.905241\n",
            "resetting env. episode 1837.000000, reward total was -21.000000. running mean: -19.916188\n",
            "resetting env. episode 1838.000000, reward total was -21.000000. running mean: -19.927026\n",
            "resetting env. episode 1839.000000, reward total was -20.000000. running mean: -19.927756\n",
            "resetting env. episode 1840.000000, reward total was -19.000000. running mean: -19.918479\n",
            "resetting env. episode 1841.000000, reward total was -20.000000. running mean: -19.919294\n",
            "resetting env. episode 1842.000000, reward total was -18.000000. running mean: -19.900101\n",
            "resetting env. episode 1843.000000, reward total was -19.000000. running mean: -19.891100\n",
            "resetting env. episode 1844.000000, reward total was -19.000000. running mean: -19.882189\n",
            "resetting env. episode 1845.000000, reward total was -21.000000. running mean: -19.893367\n",
            "resetting env. episode 1846.000000, reward total was -21.000000. running mean: -19.904433\n",
            "resetting env. episode 1847.000000, reward total was -19.000000. running mean: -19.895389\n",
            "resetting env. episode 1848.000000, reward total was -17.000000. running mean: -19.866435\n",
            "resetting env. episode 1849.000000, reward total was -17.000000. running mean: -19.837771\n",
            "resetting env. episode 1850.000000, reward total was -17.000000. running mean: -19.809393\n",
            "resetting env. episode 1851.000000, reward total was -21.000000. running mean: -19.821299\n",
            "resetting env. episode 1852.000000, reward total was -20.000000. running mean: -19.823086\n",
            "resetting env. episode 1853.000000, reward total was -21.000000. running mean: -19.834855\n",
            "resetting env. episode 1854.000000, reward total was -21.000000. running mean: -19.846507\n",
            "resetting env. episode 1855.000000, reward total was -19.000000. running mean: -19.838042\n",
            "resetting env. episode 1856.000000, reward total was -20.000000. running mean: -19.839661\n",
            "resetting env. episode 1857.000000, reward total was -19.000000. running mean: -19.831265\n",
            "resetting env. episode 1858.000000, reward total was -21.000000. running mean: -19.842952\n",
            "resetting env. episode 1859.000000, reward total was -20.000000. running mean: -19.844522\n",
            "resetting env. episode 1860.000000, reward total was -21.000000. running mean: -19.856077\n",
            "resetting env. episode 1861.000000, reward total was -20.000000. running mean: -19.857516\n",
            "resetting env. episode 1862.000000, reward total was -18.000000. running mean: -19.838941\n",
            "resetting env. episode 1863.000000, reward total was -20.000000. running mean: -19.840552\n",
            "resetting env. episode 1864.000000, reward total was -19.000000. running mean: -19.832146\n",
            "resetting env. episode 1865.000000, reward total was -17.000000. running mean: -19.803825\n",
            "resetting env. episode 1866.000000, reward total was -19.000000. running mean: -19.795787\n",
            "resetting env. episode 1867.000000, reward total was -15.000000. running mean: -19.747829\n",
            "resetting env. episode 1868.000000, reward total was -21.000000. running mean: -19.760351\n",
            "resetting env. episode 1869.000000, reward total was -20.000000. running mean: -19.762747\n",
            "resetting env. episode 1870.000000, reward total was -19.000000. running mean: -19.755120\n",
            "resetting env. episode 1871.000000, reward total was -17.000000. running mean: -19.727568\n",
            "resetting env. episode 1872.000000, reward total was -20.000000. running mean: -19.730293\n",
            "resetting env. episode 1873.000000, reward total was -21.000000. running mean: -19.742990\n",
            "resetting env. episode 1874.000000, reward total was -21.000000. running mean: -19.755560\n",
            "resetting env. episode 1875.000000, reward total was -19.000000. running mean: -19.748004\n",
            "resetting env. episode 1876.000000, reward total was -20.000000. running mean: -19.750524\n",
            "resetting env. episode 1877.000000, reward total was -20.000000. running mean: -19.753019\n",
            "resetting env. episode 1878.000000, reward total was -20.000000. running mean: -19.755489\n",
            "resetting env. episode 1879.000000, reward total was -19.000000. running mean: -19.747934\n",
            "resetting env. episode 1880.000000, reward total was -21.000000. running mean: -19.760455\n",
            "resetting env. episode 1881.000000, reward total was -20.000000. running mean: -19.762850\n",
            "resetting env. episode 1882.000000, reward total was -20.000000. running mean: -19.765222\n",
            "resetting env. episode 1883.000000, reward total was -20.000000. running mean: -19.767569\n",
            "resetting env. episode 1884.000000, reward total was -17.000000. running mean: -19.739894\n",
            "resetting env. episode 1885.000000, reward total was -19.000000. running mean: -19.732495\n",
            "resetting env. episode 1886.000000, reward total was -21.000000. running mean: -19.745170\n",
            "resetting env. episode 1887.000000, reward total was -19.000000. running mean: -19.737718\n",
            "resetting env. episode 1888.000000, reward total was -21.000000. running mean: -19.750341\n",
            "resetting env. episode 1889.000000, reward total was -20.000000. running mean: -19.752837\n",
            "resetting env. episode 1890.000000, reward total was -21.000000. running mean: -19.765309\n",
            "resetting env. episode 1891.000000, reward total was -18.000000. running mean: -19.747656\n",
            "resetting env. episode 1892.000000, reward total was -20.000000. running mean: -19.750179\n",
            "resetting env. episode 1893.000000, reward total was -20.000000. running mean: -19.752678\n",
            "resetting env. episode 1894.000000, reward total was -21.000000. running mean: -19.765151\n",
            "resetting env. episode 1895.000000, reward total was -21.000000. running mean: -19.777499\n",
            "resetting env. episode 1896.000000, reward total was -21.000000. running mean: -19.789724\n",
            "resetting env. episode 1897.000000, reward total was -21.000000. running mean: -19.801827\n",
            "resetting env. episode 1898.000000, reward total was -19.000000. running mean: -19.793809\n",
            "resetting env. episode 1899.000000, reward total was -19.000000. running mean: -19.785871\n",
            "resetting env. episode 1900.000000, reward total was -21.000000. running mean: -19.798012\n",
            "resetting env. episode 1901.000000, reward total was -21.000000. running mean: -19.810032\n",
            "resetting env. episode 1902.000000, reward total was -19.000000. running mean: -19.801932\n",
            "resetting env. episode 1903.000000, reward total was -19.000000. running mean: -19.793912\n",
            "resetting env. episode 1904.000000, reward total was -19.000000. running mean: -19.785973\n",
            "resetting env. episode 1905.000000, reward total was -20.000000. running mean: -19.788113\n",
            "resetting env. episode 1906.000000, reward total was -20.000000. running mean: -19.790232\n",
            "resetting env. episode 1907.000000, reward total was -20.000000. running mean: -19.792330\n",
            "resetting env. episode 1908.000000, reward total was -18.000000. running mean: -19.774407\n",
            "resetting env. episode 1909.000000, reward total was -21.000000. running mean: -19.786663\n",
            "resetting env. episode 1910.000000, reward total was -20.000000. running mean: -19.788796\n",
            "resetting env. episode 1911.000000, reward total was -21.000000. running mean: -19.800908\n",
            "resetting env. episode 1912.000000, reward total was -20.000000. running mean: -19.802899\n",
            "resetting env. episode 1913.000000, reward total was -19.000000. running mean: -19.794870\n",
            "resetting env. episode 1914.000000, reward total was -21.000000. running mean: -19.806921\n",
            "resetting env. episode 1915.000000, reward total was -20.000000. running mean: -19.808852\n",
            "resetting env. episode 1916.000000, reward total was -21.000000. running mean: -19.820764\n",
            "resetting env. episode 1917.000000, reward total was -19.000000. running mean: -19.812556\n",
            "resetting env. episode 1918.000000, reward total was -20.000000. running mean: -19.814430\n",
            "resetting env. episode 1919.000000, reward total was -16.000000. running mean: -19.776286\n",
            "resetting env. episode 1920.000000, reward total was -19.000000. running mean: -19.768523\n",
            "resetting env. episode 1921.000000, reward total was -20.000000. running mean: -19.770838\n",
            "resetting env. episode 1922.000000, reward total was -21.000000. running mean: -19.783130\n",
            "resetting env. episode 1923.000000, reward total was -18.000000. running mean: -19.765298\n",
            "resetting env. episode 1924.000000, reward total was -21.000000. running mean: -19.777645\n",
            "resetting env. episode 1925.000000, reward total was -21.000000. running mean: -19.789869\n",
            "resetting env. episode 1926.000000, reward total was -20.000000. running mean: -19.791970\n",
            "resetting env. episode 1927.000000, reward total was -21.000000. running mean: -19.804050\n",
            "resetting env. episode 1928.000000, reward total was -20.000000. running mean: -19.806010\n",
            "resetting env. episode 1929.000000, reward total was -20.000000. running mean: -19.807950\n",
            "resetting env. episode 1930.000000, reward total was -19.000000. running mean: -19.799870\n",
            "resetting env. episode 1931.000000, reward total was -20.000000. running mean: -19.801872\n",
            "resetting env. episode 1932.000000, reward total was -20.000000. running mean: -19.803853\n",
            "resetting env. episode 1933.000000, reward total was -20.000000. running mean: -19.805814\n",
            "resetting env. episode 1934.000000, reward total was -20.000000. running mean: -19.807756\n",
            "resetting env. episode 1935.000000, reward total was -20.000000. running mean: -19.809679\n",
            "resetting env. episode 1936.000000, reward total was -18.000000. running mean: -19.791582\n",
            "resetting env. episode 1937.000000, reward total was -21.000000. running mean: -19.803666\n",
            "resetting env. episode 1938.000000, reward total was -20.000000. running mean: -19.805629\n",
            "resetting env. episode 1939.000000, reward total was -18.000000. running mean: -19.787573\n",
            "resetting env. episode 1940.000000, reward total was -19.000000. running mean: -19.779697\n",
            "resetting env. episode 1941.000000, reward total was -21.000000. running mean: -19.791900\n",
            "resetting env. episode 1942.000000, reward total was -21.000000. running mean: -19.803981\n",
            "resetting env. episode 1943.000000, reward total was -19.000000. running mean: -19.795942\n",
            "resetting env. episode 1944.000000, reward total was -21.000000. running mean: -19.807982\n",
            "resetting env. episode 1945.000000, reward total was -20.000000. running mean: -19.809902\n",
            "resetting env. episode 1946.000000, reward total was -20.000000. running mean: -19.811803\n",
            "resetting env. episode 1947.000000, reward total was -21.000000. running mean: -19.823685\n",
            "resetting env. episode 1948.000000, reward total was -20.000000. running mean: -19.825448\n",
            "resetting env. episode 1949.000000, reward total was -19.000000. running mean: -19.817194\n",
            "resetting env. episode 1950.000000, reward total was -20.000000. running mean: -19.819022\n",
            "resetting env. episode 1951.000000, reward total was -21.000000. running mean: -19.830832\n",
            "resetting env. episode 1952.000000, reward total was -21.000000. running mean: -19.842523\n",
            "resetting env. episode 1953.000000, reward total was -19.000000. running mean: -19.834098\n",
            "resetting env. episode 1954.000000, reward total was -19.000000. running mean: -19.825757\n",
            "resetting env. episode 1955.000000, reward total was -20.000000. running mean: -19.827500\n",
            "resetting env. episode 1956.000000, reward total was -20.000000. running mean: -19.829225\n",
            "resetting env. episode 1957.000000, reward total was -20.000000. running mean: -19.830932\n",
            "resetting env. episode 1958.000000, reward total was -19.000000. running mean: -19.822623\n",
            "resetting env. episode 1959.000000, reward total was -21.000000. running mean: -19.834397\n",
            "resetting env. episode 1960.000000, reward total was -20.000000. running mean: -19.836053\n",
            "resetting env. episode 1961.000000, reward total was -15.000000. running mean: -19.787692\n",
            "resetting env. episode 1962.000000, reward total was -20.000000. running mean: -19.789815\n",
            "resetting env. episode 1963.000000, reward total was -20.000000. running mean: -19.791917\n",
            "resetting env. episode 1964.000000, reward total was -19.000000. running mean: -19.783998\n",
            "resetting env. episode 1965.000000, reward total was -21.000000. running mean: -19.796158\n",
            "resetting env. episode 1966.000000, reward total was -18.000000. running mean: -19.778197\n",
            "resetting env. episode 1967.000000, reward total was -20.000000. running mean: -19.780415\n",
            "resetting env. episode 1968.000000, reward total was -19.000000. running mean: -19.772610\n",
            "resetting env. episode 1969.000000, reward total was -17.000000. running mean: -19.744884\n",
            "resetting env. episode 1970.000000, reward total was -15.000000. running mean: -19.697436\n",
            "resetting env. episode 1971.000000, reward total was -21.000000. running mean: -19.710461\n",
            "resetting env. episode 1972.000000, reward total was -20.000000. running mean: -19.713357\n",
            "resetting env. episode 1973.000000, reward total was -19.000000. running mean: -19.706223\n",
            "resetting env. episode 1974.000000, reward total was -19.000000. running mean: -19.699161\n",
            "resetting env. episode 1975.000000, reward total was -20.000000. running mean: -19.702169\n",
            "resetting env. episode 1976.000000, reward total was -19.000000. running mean: -19.695147\n",
            "resetting env. episode 1977.000000, reward total was -21.000000. running mean: -19.708196\n",
            "resetting env. episode 1978.000000, reward total was -19.000000. running mean: -19.701114\n",
            "resetting env. episode 1979.000000, reward total was -19.000000. running mean: -19.694103\n",
            "resetting env. episode 1980.000000, reward total was -19.000000. running mean: -19.687162\n",
            "resetting env. episode 1981.000000, reward total was -20.000000. running mean: -19.690290\n",
            "resetting env. episode 1982.000000, reward total was -19.000000. running mean: -19.683387\n",
            "resetting env. episode 1983.000000, reward total was -18.000000. running mean: -19.666553\n",
            "resetting env. episode 1984.000000, reward total was -17.000000. running mean: -19.639888\n",
            "resetting env. episode 1985.000000, reward total was -20.000000. running mean: -19.643489\n",
            "resetting env. episode 1986.000000, reward total was -19.000000. running mean: -19.637054\n",
            "resetting env. episode 1987.000000, reward total was -21.000000. running mean: -19.650684\n",
            "resetting env. episode 1988.000000, reward total was -20.000000. running mean: -19.654177\n",
            "resetting env. episode 1989.000000, reward total was -18.000000. running mean: -19.637635\n",
            "resetting env. episode 1990.000000, reward total was -20.000000. running mean: -19.641259\n",
            "resetting env. episode 1991.000000, reward total was -21.000000. running mean: -19.654846\n",
            "resetting env. episode 1992.000000, reward total was -19.000000. running mean: -19.648298\n",
            "resetting env. episode 1993.000000, reward total was -20.000000. running mean: -19.651815\n",
            "resetting env. episode 1994.000000, reward total was -21.000000. running mean: -19.665296\n",
            "resetting env. episode 1995.000000, reward total was -21.000000. running mean: -19.678644\n",
            "resetting env. episode 1996.000000, reward total was -20.000000. running mean: -19.681857\n",
            "resetting env. episode 1997.000000, reward total was -19.000000. running mean: -19.675039\n",
            "resetting env. episode 1998.000000, reward total was -21.000000. running mean: -19.688288\n",
            "resetting env. episode 1999.000000, reward total was -21.000000. running mean: -19.701405\n",
            "resetting env. episode 2000.000000, reward total was -18.000000. running mean: -19.684391\n",
            "resetting env. episode 2001.000000, reward total was -20.000000. running mean: -19.687547\n",
            "resetting env. episode 2002.000000, reward total was -21.000000. running mean: -19.700672\n",
            "resetting env. episode 2003.000000, reward total was -19.000000. running mean: -19.693665\n",
            "resetting env. episode 2004.000000, reward total was -21.000000. running mean: -19.706728\n",
            "resetting env. episode 2005.000000, reward total was -16.000000. running mean: -19.669661\n",
            "resetting env. episode 2006.000000, reward total was -19.000000. running mean: -19.662965\n",
            "resetting env. episode 2007.000000, reward total was -18.000000. running mean: -19.646335\n",
            "resetting env. episode 2008.000000, reward total was -19.000000. running mean: -19.639872\n",
            "resetting env. episode 2009.000000, reward total was -17.000000. running mean: -19.613473\n",
            "resetting env. episode 2010.000000, reward total was -19.000000. running mean: -19.607338\n",
            "resetting env. episode 2011.000000, reward total was -16.000000. running mean: -19.571265\n",
            "resetting env. episode 2012.000000, reward total was -19.000000. running mean: -19.565552\n",
            "resetting env. episode 2013.000000, reward total was -18.000000. running mean: -19.549897\n",
            "resetting env. episode 2014.000000, reward total was -20.000000. running mean: -19.554398\n",
            "resetting env. episode 2015.000000, reward total was -18.000000. running mean: -19.538854\n",
            "resetting env. episode 2016.000000, reward total was -20.000000. running mean: -19.543465\n",
            "resetting env. episode 2017.000000, reward total was -18.000000. running mean: -19.528030\n",
            "resetting env. episode 2018.000000, reward total was -20.000000. running mean: -19.532750\n",
            "resetting env. episode 2019.000000, reward total was -20.000000. running mean: -19.537423\n",
            "resetting env. episode 2020.000000, reward total was -20.000000. running mean: -19.542048\n",
            "resetting env. episode 2021.000000, reward total was -21.000000. running mean: -19.556628\n",
            "resetting env. episode 2022.000000, reward total was -20.000000. running mean: -19.561062\n",
            "resetting env. episode 2023.000000, reward total was -21.000000. running mean: -19.575451\n",
            "resetting env. episode 2024.000000, reward total was -18.000000. running mean: -19.559697\n",
            "resetting env. episode 2025.000000, reward total was -21.000000. running mean: -19.574100\n",
            "resetting env. episode 2026.000000, reward total was -19.000000. running mean: -19.568359\n",
            "resetting env. episode 2027.000000, reward total was -20.000000. running mean: -19.572675\n",
            "resetting env. episode 2028.000000, reward total was -21.000000. running mean: -19.586948\n",
            "resetting env. episode 2029.000000, reward total was -18.000000. running mean: -19.571079\n",
            "resetting env. episode 2030.000000, reward total was -19.000000. running mean: -19.565368\n",
            "resetting env. episode 2031.000000, reward total was -17.000000. running mean: -19.539714\n",
            "resetting env. episode 2032.000000, reward total was -20.000000. running mean: -19.544317\n",
            "resetting env. episode 2033.000000, reward total was -21.000000. running mean: -19.558874\n",
            "resetting env. episode 2034.000000, reward total was -19.000000. running mean: -19.553285\n",
            "resetting env. episode 2035.000000, reward total was -21.000000. running mean: -19.567752\n",
            "resetting env. episode 2036.000000, reward total was -17.000000. running mean: -19.542075\n",
            "resetting env. episode 2037.000000, reward total was -20.000000. running mean: -19.546654\n",
            "resetting env. episode 2038.000000, reward total was -21.000000. running mean: -19.561188\n",
            "resetting env. episode 2039.000000, reward total was -19.000000. running mean: -19.555576\n",
            "resetting env. episode 2040.000000, reward total was -16.000000. running mean: -19.520020\n",
            "resetting env. episode 2041.000000, reward total was -17.000000. running mean: -19.494820\n",
            "resetting env. episode 2042.000000, reward total was -20.000000. running mean: -19.499872\n",
            "resetting env. episode 2043.000000, reward total was -21.000000. running mean: -19.514873\n",
            "resetting env. episode 2044.000000, reward total was -21.000000. running mean: -19.529724\n",
            "resetting env. episode 2045.000000, reward total was -19.000000. running mean: -19.524427\n",
            "resetting env. episode 2046.000000, reward total was -21.000000. running mean: -19.539183\n",
            "resetting env. episode 2047.000000, reward total was -19.000000. running mean: -19.533791\n",
            "resetting env. episode 2048.000000, reward total was -20.000000. running mean: -19.538453\n",
            "resetting env. episode 2049.000000, reward total was -20.000000. running mean: -19.543068\n",
            "resetting env. episode 2050.000000, reward total was -19.000000. running mean: -19.537638\n",
            "resetting env. episode 2051.000000, reward total was -18.000000. running mean: -19.522261\n",
            "resetting env. episode 2052.000000, reward total was -21.000000. running mean: -19.537039\n",
            "resetting env. episode 2053.000000, reward total was -21.000000. running mean: -19.551668\n",
            "resetting env. episode 2054.000000, reward total was -21.000000. running mean: -19.566152\n",
            "resetting env. episode 2055.000000, reward total was -20.000000. running mean: -19.570490\n",
            "resetting env. episode 2056.000000, reward total was -17.000000. running mean: -19.544785\n",
            "resetting env. episode 2057.000000, reward total was -21.000000. running mean: -19.559337\n",
            "resetting env. episode 2058.000000, reward total was -21.000000. running mean: -19.573744\n",
            "resetting env. episode 2059.000000, reward total was -20.000000. running mean: -19.578006\n",
            "resetting env. episode 2060.000000, reward total was -20.000000. running mean: -19.582226\n",
            "resetting env. episode 2061.000000, reward total was -20.000000. running mean: -19.586404\n",
            "resetting env. episode 2062.000000, reward total was -20.000000. running mean: -19.590540\n",
            "resetting env. episode 2063.000000, reward total was -17.000000. running mean: -19.564635\n",
            "resetting env. episode 2064.000000, reward total was -21.000000. running mean: -19.578988\n",
            "resetting env. episode 2065.000000, reward total was -20.000000. running mean: -19.583198\n",
            "resetting env. episode 2066.000000, reward total was -19.000000. running mean: -19.577366\n",
            "resetting env. episode 2067.000000, reward total was -19.000000. running mean: -19.571593\n",
            "resetting env. episode 2068.000000, reward total was -20.000000. running mean: -19.575877\n",
            "resetting env. episode 2069.000000, reward total was -21.000000. running mean: -19.590118\n",
            "resetting env. episode 2070.000000, reward total was -21.000000. running mean: -19.604217\n",
            "resetting env. episode 2071.000000, reward total was -18.000000. running mean: -19.588175\n",
            "resetting env. episode 2072.000000, reward total was -21.000000. running mean: -19.602293\n",
            "resetting env. episode 2073.000000, reward total was -18.000000. running mean: -19.586270\n",
            "resetting env. episode 2074.000000, reward total was -21.000000. running mean: -19.600407\n",
            "resetting env. episode 2075.000000, reward total was -15.000000. running mean: -19.554403\n",
            "resetting env. episode 2076.000000, reward total was -19.000000. running mean: -19.548859\n",
            "resetting env. episode 2077.000000, reward total was -20.000000. running mean: -19.553371\n",
            "resetting env. episode 2078.000000, reward total was -21.000000. running mean: -19.567837\n",
            "resetting env. episode 2079.000000, reward total was -20.000000. running mean: -19.572159\n",
            "resetting env. episode 2080.000000, reward total was -19.000000. running mean: -19.566437\n",
            "resetting env. episode 2081.000000, reward total was -18.000000. running mean: -19.550773\n",
            "resetting env. episode 2082.000000, reward total was -21.000000. running mean: -19.565265\n",
            "resetting env. episode 2083.000000, reward total was -21.000000. running mean: -19.579612\n",
            "resetting env. episode 2084.000000, reward total was -20.000000. running mean: -19.583816\n",
            "resetting env. episode 2085.000000, reward total was -19.000000. running mean: -19.577978\n",
            "resetting env. episode 2086.000000, reward total was -21.000000. running mean: -19.592198\n",
            "resetting env. episode 2087.000000, reward total was -20.000000. running mean: -19.596276\n",
            "resetting env. episode 2088.000000, reward total was -19.000000. running mean: -19.590313\n",
            "resetting env. episode 2089.000000, reward total was -18.000000. running mean: -19.574410\n",
            "resetting env. episode 2090.000000, reward total was -19.000000. running mean: -19.568666\n",
            "resetting env. episode 2091.000000, reward total was -20.000000. running mean: -19.572980\n",
            "resetting env. episode 2092.000000, reward total was -17.000000. running mean: -19.547250\n",
            "resetting env. episode 2093.000000, reward total was -17.000000. running mean: -19.521777\n",
            "resetting env. episode 2094.000000, reward total was -21.000000. running mean: -19.536560\n",
            "resetting env. episode 2095.000000, reward total was -18.000000. running mean: -19.521194\n",
            "resetting env. episode 2096.000000, reward total was -20.000000. running mean: -19.525982\n",
            "resetting env. episode 2097.000000, reward total was -21.000000. running mean: -19.540722\n",
            "resetting env. episode 2098.000000, reward total was -21.000000. running mean: -19.555315\n",
            "resetting env. episode 2099.000000, reward total was -20.000000. running mean: -19.559762\n",
            "resetting env. episode 2100.000000, reward total was -21.000000. running mean: -19.574164\n",
            "resetting env. episode 2101.000000, reward total was -18.000000. running mean: -19.558423\n",
            "resetting env. episode 2102.000000, reward total was -20.000000. running mean: -19.562838\n",
            "resetting env. episode 2103.000000, reward total was -20.000000. running mean: -19.567210\n",
            "resetting env. episode 2104.000000, reward total was -16.000000. running mean: -19.531538\n",
            "resetting env. episode 2105.000000, reward total was -21.000000. running mean: -19.546222\n",
            "resetting env. episode 2106.000000, reward total was -20.000000. running mean: -19.550760\n",
            "resetting env. episode 2107.000000, reward total was -21.000000. running mean: -19.565253\n",
            "resetting env. episode 2108.000000, reward total was -21.000000. running mean: -19.579600\n",
            "resetting env. episode 2109.000000, reward total was -18.000000. running mean: -19.563804\n",
            "resetting env. episode 2110.000000, reward total was -21.000000. running mean: -19.578166\n",
            "resetting env. episode 2111.000000, reward total was -19.000000. running mean: -19.572384\n",
            "resetting env. episode 2112.000000, reward total was -19.000000. running mean: -19.566661\n",
            "resetting env. episode 2113.000000, reward total was -21.000000. running mean: -19.580994\n",
            "resetting env. episode 2114.000000, reward total was -17.000000. running mean: -19.555184\n",
            "resetting env. episode 2115.000000, reward total was -20.000000. running mean: -19.559632\n",
            "resetting env. episode 2116.000000, reward total was -20.000000. running mean: -19.564036\n",
            "resetting env. episode 2117.000000, reward total was -19.000000. running mean: -19.558395\n",
            "resetting env. episode 2118.000000, reward total was -14.000000. running mean: -19.502812\n",
            "resetting env. episode 2119.000000, reward total was -20.000000. running mean: -19.507783\n",
            "resetting env. episode 2120.000000, reward total was -16.000000. running mean: -19.472706\n",
            "resetting env. episode 2121.000000, reward total was -21.000000. running mean: -19.487979\n",
            "resetting env. episode 2122.000000, reward total was -20.000000. running mean: -19.493099\n",
            "resetting env. episode 2123.000000, reward total was -21.000000. running mean: -19.508168\n",
            "resetting env. episode 2124.000000, reward total was -17.000000. running mean: -19.483086\n",
            "resetting env. episode 2125.000000, reward total was -19.000000. running mean: -19.478255\n",
            "resetting env. episode 2126.000000, reward total was -21.000000. running mean: -19.493473\n",
            "resetting env. episode 2127.000000, reward total was -20.000000. running mean: -19.498538\n",
            "resetting env. episode 2128.000000, reward total was -19.000000. running mean: -19.493553\n",
            "resetting env. episode 2129.000000, reward total was -20.000000. running mean: -19.498617\n",
            "resetting env. episode 2130.000000, reward total was -21.000000. running mean: -19.513631\n",
            "resetting env. episode 2131.000000, reward total was -21.000000. running mean: -19.528495\n",
            "resetting env. episode 2132.000000, reward total was -20.000000. running mean: -19.533210\n",
            "resetting env. episode 2133.000000, reward total was -20.000000. running mean: -19.537878\n",
            "resetting env. episode 2134.000000, reward total was -20.000000. running mean: -19.542499\n",
            "resetting env. episode 2135.000000, reward total was -21.000000. running mean: -19.557074\n",
            "resetting env. episode 2136.000000, reward total was -19.000000. running mean: -19.551503\n",
            "resetting env. episode 2137.000000, reward total was -17.000000. running mean: -19.525988\n",
            "resetting env. episode 2138.000000, reward total was -20.000000. running mean: -19.530728\n",
            "resetting env. episode 2139.000000, reward total was -21.000000. running mean: -19.545421\n",
            "resetting env. episode 2140.000000, reward total was -17.000000. running mean: -19.519967\n",
            "resetting env. episode 2141.000000, reward total was -19.000000. running mean: -19.514767\n",
            "resetting env. episode 2142.000000, reward total was -20.000000. running mean: -19.519619\n",
            "resetting env. episode 2143.000000, reward total was -20.000000. running mean: -19.524423\n",
            "resetting env. episode 2144.000000, reward total was -21.000000. running mean: -19.539179\n",
            "resetting env. episode 2145.000000, reward total was -19.000000. running mean: -19.533787\n",
            "resetting env. episode 2146.000000, reward total was -20.000000. running mean: -19.538449\n",
            "resetting env. episode 2147.000000, reward total was -21.000000. running mean: -19.553065\n",
            "resetting env. episode 2148.000000, reward total was -21.000000. running mean: -19.567534\n",
            "resetting env. episode 2149.000000, reward total was -20.000000. running mean: -19.571859\n",
            "resetting env. episode 2150.000000, reward total was -21.000000. running mean: -19.586140\n",
            "resetting env. episode 2151.000000, reward total was -21.000000. running mean: -19.600279\n",
            "resetting env. episode 2152.000000, reward total was -20.000000. running mean: -19.604276\n",
            "resetting env. episode 2153.000000, reward total was -20.000000. running mean: -19.608233\n",
            "resetting env. episode 2154.000000, reward total was -18.000000. running mean: -19.592151\n",
            "resetting env. episode 2155.000000, reward total was -20.000000. running mean: -19.596229\n",
            "resetting env. episode 2156.000000, reward total was -18.000000. running mean: -19.580267\n",
            "resetting env. episode 2157.000000, reward total was -21.000000. running mean: -19.594464\n",
            "resetting env. episode 2158.000000, reward total was -19.000000. running mean: -19.588520\n",
            "resetting env. episode 2159.000000, reward total was -20.000000. running mean: -19.592635\n",
            "resetting env. episode 2160.000000, reward total was -20.000000. running mean: -19.596708\n",
            "resetting env. episode 2161.000000, reward total was -20.000000. running mean: -19.600741\n",
            "resetting env. episode 2162.000000, reward total was -21.000000. running mean: -19.614734\n",
            "resetting env. episode 2163.000000, reward total was -19.000000. running mean: -19.608586\n",
            "resetting env. episode 2164.000000, reward total was -21.000000. running mean: -19.622500\n",
            "resetting env. episode 2165.000000, reward total was -19.000000. running mean: -19.616275\n",
            "resetting env. episode 2166.000000, reward total was -20.000000. running mean: -19.620113\n",
            "resetting env. episode 2167.000000, reward total was -20.000000. running mean: -19.623912\n",
            "resetting env. episode 2168.000000, reward total was -19.000000. running mean: -19.617672\n",
            "resetting env. episode 2169.000000, reward total was -20.000000. running mean: -19.621496\n",
            "resetting env. episode 2170.000000, reward total was -20.000000. running mean: -19.625281\n",
            "resetting env. episode 2171.000000, reward total was -21.000000. running mean: -19.639028\n",
            "resetting env. episode 2172.000000, reward total was -18.000000. running mean: -19.622638\n",
            "resetting env. episode 2173.000000, reward total was -20.000000. running mean: -19.626411\n",
            "resetting env. episode 2174.000000, reward total was -20.000000. running mean: -19.630147\n",
            "resetting env. episode 2175.000000, reward total was -20.000000. running mean: -19.633846\n",
            "resetting env. episode 2176.000000, reward total was -20.000000. running mean: -19.637507\n",
            "resetting env. episode 2177.000000, reward total was -20.000000. running mean: -19.641132\n",
            "resetting env. episode 2178.000000, reward total was -17.000000. running mean: -19.614721\n",
            "resetting env. episode 2179.000000, reward total was -21.000000. running mean: -19.628574\n",
            "resetting env. episode 2180.000000, reward total was -21.000000. running mean: -19.642288\n",
            "resetting env. episode 2181.000000, reward total was -20.000000. running mean: -19.645865\n",
            "resetting env. episode 2182.000000, reward total was -21.000000. running mean: -19.659406\n",
            "resetting env. episode 2183.000000, reward total was -20.000000. running mean: -19.662812\n",
            "resetting env. episode 2184.000000, reward total was -19.000000. running mean: -19.656184\n",
            "resetting env. episode 2185.000000, reward total was -20.000000. running mean: -19.659622\n",
            "resetting env. episode 2186.000000, reward total was -19.000000. running mean: -19.653026\n",
            "resetting env. episode 2187.000000, reward total was -21.000000. running mean: -19.666496\n",
            "resetting env. episode 2188.000000, reward total was -21.000000. running mean: -19.679831\n",
            "resetting env. episode 2189.000000, reward total was -18.000000. running mean: -19.663033\n",
            "resetting env. episode 2190.000000, reward total was -20.000000. running mean: -19.666402\n",
            "resetting env. episode 2191.000000, reward total was -19.000000. running mean: -19.659738\n",
            "resetting env. episode 2192.000000, reward total was -17.000000. running mean: -19.633141\n",
            "resetting env. episode 2193.000000, reward total was -20.000000. running mean: -19.636809\n",
            "resetting env. episode 2194.000000, reward total was -20.000000. running mean: -19.640441\n",
            "resetting env. episode 2195.000000, reward total was -19.000000. running mean: -19.634037\n",
            "resetting env. episode 2196.000000, reward total was -19.000000. running mean: -19.627697\n",
            "resetting env. episode 2197.000000, reward total was -19.000000. running mean: -19.621420\n",
            "resetting env. episode 2198.000000, reward total was -18.000000. running mean: -19.605205\n",
            "resetting env. episode 2199.000000, reward total was -20.000000. running mean: -19.609153\n",
            "resetting env. episode 2200.000000, reward total was -20.000000. running mean: -19.613062\n",
            "resetting env. episode 2201.000000, reward total was -16.000000. running mean: -19.576931\n",
            "resetting env. episode 2202.000000, reward total was -21.000000. running mean: -19.591162\n",
            "resetting env. episode 2203.000000, reward total was -18.000000. running mean: -19.575250\n",
            "resetting env. episode 2204.000000, reward total was -21.000000. running mean: -19.589498\n",
            "resetting env. episode 2205.000000, reward total was -21.000000. running mean: -19.603603\n",
            "resetting env. episode 2206.000000, reward total was -19.000000. running mean: -19.597567\n",
            "resetting env. episode 2207.000000, reward total was -20.000000. running mean: -19.601591\n",
            "resetting env. episode 2208.000000, reward total was -15.000000. running mean: -19.555575\n",
            "resetting env. episode 2209.000000, reward total was -21.000000. running mean: -19.570019\n",
            "resetting env. episode 2210.000000, reward total was -21.000000. running mean: -19.584319\n",
            "resetting env. episode 2211.000000, reward total was -20.000000. running mean: -19.588476\n",
            "resetting env. episode 2212.000000, reward total was -21.000000. running mean: -19.602591\n",
            "resetting env. episode 2213.000000, reward total was -19.000000. running mean: -19.596565\n",
            "resetting env. episode 2214.000000, reward total was -20.000000. running mean: -19.600600\n",
            "resetting env. episode 2215.000000, reward total was -21.000000. running mean: -19.614594\n",
            "resetting env. episode 2216.000000, reward total was -20.000000. running mean: -19.618448\n",
            "resetting env. episode 2217.000000, reward total was -20.000000. running mean: -19.622263\n",
            "resetting env. episode 2218.000000, reward total was -17.000000. running mean: -19.596041\n",
            "resetting env. episode 2219.000000, reward total was -19.000000. running mean: -19.590080\n",
            "resetting env. episode 2220.000000, reward total was -20.000000. running mean: -19.594180\n",
            "resetting env. episode 2221.000000, reward total was -19.000000. running mean: -19.588238\n",
            "resetting env. episode 2222.000000, reward total was -21.000000. running mean: -19.602355\n",
            "resetting env. episode 2223.000000, reward total was -19.000000. running mean: -19.596332\n",
            "resetting env. episode 2224.000000, reward total was -19.000000. running mean: -19.590368\n",
            "resetting env. episode 2225.000000, reward total was -21.000000. running mean: -19.604465\n",
            "resetting env. episode 2226.000000, reward total was -18.000000. running mean: -19.588420\n",
            "resetting env. episode 2227.000000, reward total was -21.000000. running mean: -19.602536\n",
            "resetting env. episode 2228.000000, reward total was -17.000000. running mean: -19.576511\n",
            "resetting env. episode 2229.000000, reward total was -18.000000. running mean: -19.560745\n",
            "resetting env. episode 2230.000000, reward total was -17.000000. running mean: -19.535138\n",
            "resetting env. episode 2231.000000, reward total was -20.000000. running mean: -19.539787\n",
            "resetting env. episode 2232.000000, reward total was -21.000000. running mean: -19.554389\n",
            "resetting env. episode 2233.000000, reward total was -19.000000. running mean: -19.548845\n",
            "resetting env. episode 2234.000000, reward total was -21.000000. running mean: -19.563356\n",
            "resetting env. episode 2235.000000, reward total was -20.000000. running mean: -19.567723\n",
            "resetting env. episode 2236.000000, reward total was -19.000000. running mean: -19.562046\n",
            "resetting env. episode 2237.000000, reward total was -20.000000. running mean: -19.566425\n",
            "resetting env. episode 2238.000000, reward total was -19.000000. running mean: -19.560761\n",
            "resetting env. episode 2239.000000, reward total was -21.000000. running mean: -19.575153\n",
            "resetting env. episode 2240.000000, reward total was -15.000000. running mean: -19.529402\n",
            "resetting env. episode 2241.000000, reward total was -21.000000. running mean: -19.544108\n",
            "resetting env. episode 2242.000000, reward total was -21.000000. running mean: -19.558667\n",
            "resetting env. episode 2243.000000, reward total was -21.000000. running mean: -19.573080\n",
            "resetting env. episode 2244.000000, reward total was -17.000000. running mean: -19.547349\n",
            "resetting env. episode 2245.000000, reward total was -19.000000. running mean: -19.541876\n",
            "resetting env. episode 2246.000000, reward total was -20.000000. running mean: -19.546457\n",
            "resetting env. episode 2247.000000, reward total was -21.000000. running mean: -19.560992\n",
            "resetting env. episode 2248.000000, reward total was -21.000000. running mean: -19.575382\n",
            "resetting env. episode 2249.000000, reward total was -20.000000. running mean: -19.579629\n",
            "resetting env. episode 2250.000000, reward total was -21.000000. running mean: -19.593832\n",
            "resetting env. episode 2251.000000, reward total was -20.000000. running mean: -19.597894\n",
            "resetting env. episode 2252.000000, reward total was -21.000000. running mean: -19.611915\n",
            "resetting env. episode 2253.000000, reward total was -19.000000. running mean: -19.605796\n",
            "resetting env. episode 2254.000000, reward total was -18.000000. running mean: -19.589738\n",
            "resetting env. episode 2255.000000, reward total was -20.000000. running mean: -19.593841\n",
            "resetting env. episode 2256.000000, reward total was -20.000000. running mean: -19.597902\n",
            "resetting env. episode 2257.000000, reward total was -20.000000. running mean: -19.601923\n",
            "resetting env. episode 2258.000000, reward total was -21.000000. running mean: -19.615904\n",
            "resetting env. episode 2259.000000, reward total was -18.000000. running mean: -19.599745\n",
            "resetting env. episode 2260.000000, reward total was -21.000000. running mean: -19.613747\n",
            "resetting env. episode 2261.000000, reward total was -17.000000. running mean: -19.587610\n",
            "resetting env. episode 2262.000000, reward total was -20.000000. running mean: -19.591734\n",
            "resetting env. episode 2263.000000, reward total was -19.000000. running mean: -19.585817\n",
            "resetting env. episode 2264.000000, reward total was -20.000000. running mean: -19.589958\n",
            "resetting env. episode 2265.000000, reward total was -20.000000. running mean: -19.594059\n",
            "resetting env. episode 2266.000000, reward total was -18.000000. running mean: -19.578118\n",
            "resetting env. episode 2267.000000, reward total was -20.000000. running mean: -19.582337\n",
            "resetting env. episode 2268.000000, reward total was -20.000000. running mean: -19.586514\n",
            "resetting env. episode 2269.000000, reward total was -17.000000. running mean: -19.560649\n",
            "resetting env. episode 2270.000000, reward total was -19.000000. running mean: -19.555042\n",
            "resetting env. episode 2271.000000, reward total was -19.000000. running mean: -19.549492\n",
            "resetting env. episode 2272.000000, reward total was -20.000000. running mean: -19.553997\n",
            "resetting env. episode 2273.000000, reward total was -21.000000. running mean: -19.568457\n",
            "resetting env. episode 2274.000000, reward total was -18.000000. running mean: -19.552772\n",
            "resetting env. episode 2275.000000, reward total was -19.000000. running mean: -19.547244\n",
            "resetting env. episode 2276.000000, reward total was -21.000000. running mean: -19.561772\n",
            "resetting env. episode 2277.000000, reward total was -18.000000. running mean: -19.546154\n",
            "resetting env. episode 2278.000000, reward total was -19.000000. running mean: -19.540693\n",
            "resetting env. episode 2279.000000, reward total was -20.000000. running mean: -19.545286\n",
            "resetting env. episode 2280.000000, reward total was -20.000000. running mean: -19.549833\n",
            "resetting env. episode 2281.000000, reward total was -20.000000. running mean: -19.554335\n",
            "resetting env. episode 2282.000000, reward total was -18.000000. running mean: -19.538791\n",
            "resetting env. episode 2283.000000, reward total was -18.000000. running mean: -19.523403\n",
            "resetting env. episode 2284.000000, reward total was -18.000000. running mean: -19.508169\n",
            "resetting env. episode 2285.000000, reward total was -20.000000. running mean: -19.513088\n",
            "resetting env. episode 2286.000000, reward total was -19.000000. running mean: -19.507957\n",
            "resetting env. episode 2287.000000, reward total was -20.000000. running mean: -19.512877\n",
            "resetting env. episode 2288.000000, reward total was -20.000000. running mean: -19.517748\n",
            "resetting env. episode 2289.000000, reward total was -20.000000. running mean: -19.522571\n",
            "resetting env. episode 2290.000000, reward total was -19.000000. running mean: -19.517345\n",
            "resetting env. episode 2291.000000, reward total was -17.000000. running mean: -19.492172\n",
            "resetting env. episode 2292.000000, reward total was -20.000000. running mean: -19.497250\n",
            "resetting env. episode 2293.000000, reward total was -18.000000. running mean: -19.482278\n",
            "resetting env. episode 2294.000000, reward total was -21.000000. running mean: -19.497455\n",
            "resetting env. episode 2295.000000, reward total was -21.000000. running mean: -19.512480\n",
            "resetting env. episode 2296.000000, reward total was -18.000000. running mean: -19.497355\n",
            "resetting env. episode 2297.000000, reward total was -21.000000. running mean: -19.512382\n",
            "resetting env. episode 2298.000000, reward total was -19.000000. running mean: -19.507258\n",
            "resetting env. episode 2299.000000, reward total was -20.000000. running mean: -19.512185\n",
            "resetting env. episode 2300.000000, reward total was -21.000000. running mean: -19.527064\n",
            "resetting env. episode 2301.000000, reward total was -21.000000. running mean: -19.541793\n",
            "resetting env. episode 2302.000000, reward total was -21.000000. running mean: -19.556375\n",
            "resetting env. episode 2303.000000, reward total was -20.000000. running mean: -19.560811\n",
            "resetting env. episode 2304.000000, reward total was -20.000000. running mean: -19.565203\n",
            "resetting env. episode 2305.000000, reward total was -18.000000. running mean: -19.549551\n",
            "resetting env. episode 2306.000000, reward total was -19.000000. running mean: -19.544056\n",
            "resetting env. episode 2307.000000, reward total was -19.000000. running mean: -19.538615\n",
            "resetting env. episode 2308.000000, reward total was -19.000000. running mean: -19.533229\n",
            "resetting env. episode 2309.000000, reward total was -20.000000. running mean: -19.537897\n",
            "resetting env. episode 2310.000000, reward total was -18.000000. running mean: -19.522518\n",
            "resetting env. episode 2311.000000, reward total was -21.000000. running mean: -19.537293\n",
            "resetting env. episode 2312.000000, reward total was -17.000000. running mean: -19.511920\n",
            "resetting env. episode 2313.000000, reward total was -19.000000. running mean: -19.506800\n",
            "resetting env. episode 2314.000000, reward total was -20.000000. running mean: -19.511732\n",
            "resetting env. episode 2315.000000, reward total was -20.000000. running mean: -19.516615\n",
            "resetting env. episode 2316.000000, reward total was -19.000000. running mean: -19.511449\n",
            "resetting env. episode 2317.000000, reward total was -21.000000. running mean: -19.526334\n",
            "resetting env. episode 2318.000000, reward total was -19.000000. running mean: -19.521071\n",
            "resetting env. episode 2319.000000, reward total was -19.000000. running mean: -19.515860\n",
            "resetting env. episode 2320.000000, reward total was -20.000000. running mean: -19.520702\n",
            "resetting env. episode 2321.000000, reward total was -21.000000. running mean: -19.535495\n",
            "resetting env. episode 2322.000000, reward total was -19.000000. running mean: -19.530140\n",
            "resetting env. episode 2323.000000, reward total was -17.000000. running mean: -19.504838\n",
            "resetting env. episode 2324.000000, reward total was -21.000000. running mean: -19.519790\n",
            "resetting env. episode 2325.000000, reward total was -21.000000. running mean: -19.534592\n",
            "resetting env. episode 2326.000000, reward total was -21.000000. running mean: -19.549246\n",
            "resetting env. episode 2327.000000, reward total was -19.000000. running mean: -19.543754\n",
            "resetting env. episode 2328.000000, reward total was -21.000000. running mean: -19.558316\n",
            "resetting env. episode 2329.000000, reward total was -20.000000. running mean: -19.562733\n",
            "resetting env. episode 2330.000000, reward total was -20.000000. running mean: -19.567106\n",
            "resetting env. episode 2331.000000, reward total was -20.000000. running mean: -19.571435\n",
            "resetting env. episode 2332.000000, reward total was -21.000000. running mean: -19.585720\n",
            "resetting env. episode 2333.000000, reward total was -19.000000. running mean: -19.579863\n",
            "resetting env. episode 2334.000000, reward total was -18.000000. running mean: -19.564064\n",
            "resetting env. episode 2335.000000, reward total was -20.000000. running mean: -19.568424\n",
            "resetting env. episode 2336.000000, reward total was -21.000000. running mean: -19.582740\n",
            "resetting env. episode 2337.000000, reward total was -19.000000. running mean: -19.576912\n",
            "resetting env. episode 2338.000000, reward total was -21.000000. running mean: -19.591143\n",
            "resetting env. episode 2339.000000, reward total was -20.000000. running mean: -19.595232\n",
            "resetting env. episode 2340.000000, reward total was -20.000000. running mean: -19.599279\n",
            "resetting env. episode 2341.000000, reward total was -20.000000. running mean: -19.603287\n",
            "resetting env. episode 2342.000000, reward total was -19.000000. running mean: -19.597254\n",
            "resetting env. episode 2343.000000, reward total was -17.000000. running mean: -19.571281\n",
            "resetting env. episode 2344.000000, reward total was -19.000000. running mean: -19.565568\n",
            "resetting env. episode 2345.000000, reward total was -18.000000. running mean: -19.549913\n",
            "resetting env. episode 2346.000000, reward total was -20.000000. running mean: -19.554414\n",
            "resetting env. episode 2347.000000, reward total was -19.000000. running mean: -19.548869\n",
            "resetting env. episode 2348.000000, reward total was -20.000000. running mean: -19.553381\n",
            "resetting env. episode 2349.000000, reward total was -21.000000. running mean: -19.567847\n",
            "resetting env. episode 2350.000000, reward total was -21.000000. running mean: -19.582168\n",
            "resetting env. episode 2351.000000, reward total was -19.000000. running mean: -19.576347\n",
            "resetting env. episode 2352.000000, reward total was -19.000000. running mean: -19.570583\n",
            "resetting env. episode 2353.000000, reward total was -17.000000. running mean: -19.544877\n",
            "resetting env. episode 2354.000000, reward total was -18.000000. running mean: -19.529429\n",
            "resetting env. episode 2355.000000, reward total was -19.000000. running mean: -19.524134\n",
            "resetting env. episode 2356.000000, reward total was -19.000000. running mean: -19.518893\n",
            "resetting env. episode 2357.000000, reward total was -18.000000. running mean: -19.503704\n",
            "resetting env. episode 2358.000000, reward total was -21.000000. running mean: -19.518667\n",
            "resetting env. episode 2359.000000, reward total was -21.000000. running mean: -19.533480\n",
            "resetting env. episode 2360.000000, reward total was -21.000000. running mean: -19.548146\n",
            "resetting env. episode 2361.000000, reward total was -19.000000. running mean: -19.542664\n",
            "resetting env. episode 2362.000000, reward total was -19.000000. running mean: -19.537237\n",
            "resetting env. episode 2363.000000, reward total was -19.000000. running mean: -19.531865\n",
            "resetting env. episode 2364.000000, reward total was -19.000000. running mean: -19.526546\n",
            "resetting env. episode 2365.000000, reward total was -20.000000. running mean: -19.531281\n",
            "resetting env. episode 2366.000000, reward total was -20.000000. running mean: -19.535968\n",
            "resetting env. episode 2367.000000, reward total was -20.000000. running mean: -19.540608\n",
            "resetting env. episode 2368.000000, reward total was -19.000000. running mean: -19.535202\n",
            "resetting env. episode 2369.000000, reward total was -19.000000. running mean: -19.529850\n",
            "resetting env. episode 2370.000000, reward total was -19.000000. running mean: -19.524552\n",
            "resetting env. episode 2371.000000, reward total was -20.000000. running mean: -19.529306\n",
            "resetting env. episode 2372.000000, reward total was -18.000000. running mean: -19.514013\n",
            "resetting env. episode 2373.000000, reward total was -20.000000. running mean: -19.518873\n",
            "resetting env. episode 2374.000000, reward total was -17.000000. running mean: -19.493684\n",
            "resetting env. episode 2375.000000, reward total was -19.000000. running mean: -19.488748\n",
            "resetting env. episode 2376.000000, reward total was -20.000000. running mean: -19.493860\n",
            "resetting env. episode 2377.000000, reward total was -20.000000. running mean: -19.498922\n",
            "resetting env. episode 2378.000000, reward total was -19.000000. running mean: -19.493932\n",
            "resetting env. episode 2379.000000, reward total was -19.000000. running mean: -19.488993\n",
            "resetting env. episode 2380.000000, reward total was -20.000000. running mean: -19.494103\n",
            "resetting env. episode 2381.000000, reward total was -18.000000. running mean: -19.479162\n",
            "resetting env. episode 2382.000000, reward total was -19.000000. running mean: -19.474370\n",
            "resetting env. episode 2383.000000, reward total was -20.000000. running mean: -19.479627\n",
            "resetting env. episode 2384.000000, reward total was -21.000000. running mean: -19.494830\n",
            "resetting env. episode 2385.000000, reward total was -19.000000. running mean: -19.489882\n",
            "resetting env. episode 2386.000000, reward total was -19.000000. running mean: -19.484983\n",
            "resetting env. episode 2387.000000, reward total was -20.000000. running mean: -19.490133\n",
            "resetting env. episode 2388.000000, reward total was -20.000000. running mean: -19.495232\n",
            "resetting env. episode 2389.000000, reward total was -19.000000. running mean: -19.490280\n",
            "resetting env. episode 2390.000000, reward total was -19.000000. running mean: -19.485377\n",
            "resetting env. episode 2391.000000, reward total was -21.000000. running mean: -19.500523\n",
            "resetting env. episode 2392.000000, reward total was -18.000000. running mean: -19.485518\n",
            "resetting env. episode 2393.000000, reward total was -20.000000. running mean: -19.490663\n",
            "resetting env. episode 2394.000000, reward total was -19.000000. running mean: -19.485756\n",
            "resetting env. episode 2395.000000, reward total was -20.000000. running mean: -19.490899\n",
            "resetting env. episode 2396.000000, reward total was -20.000000. running mean: -19.495990\n",
            "resetting env. episode 2397.000000, reward total was -19.000000. running mean: -19.491030\n",
            "resetting env. episode 2398.000000, reward total was -17.000000. running mean: -19.466119\n",
            "resetting env. episode 2399.000000, reward total was -19.000000. running mean: -19.461458\n",
            "resetting env. episode 2400.000000, reward total was -19.000000. running mean: -19.456844\n",
            "resetting env. episode 2401.000000, reward total was -19.000000. running mean: -19.452275\n",
            "resetting env. episode 2402.000000, reward total was -19.000000. running mean: -19.447752\n",
            "resetting env. episode 2403.000000, reward total was -19.000000. running mean: -19.443275\n",
            "resetting env. episode 2404.000000, reward total was -20.000000. running mean: -19.448842\n",
            "resetting env. episode 2405.000000, reward total was -20.000000. running mean: -19.454354\n",
            "resetting env. episode 2406.000000, reward total was -20.000000. running mean: -19.459810\n",
            "resetting env. episode 2407.000000, reward total was -21.000000. running mean: -19.475212\n",
            "resetting env. episode 2408.000000, reward total was -18.000000. running mean: -19.460460\n",
            "resetting env. episode 2409.000000, reward total was -18.000000. running mean: -19.445855\n",
            "resetting env. episode 2410.000000, reward total was -19.000000. running mean: -19.441397\n",
            "resetting env. episode 2411.000000, reward total was -18.000000. running mean: -19.426983\n",
            "resetting env. episode 2412.000000, reward total was -20.000000. running mean: -19.432713\n",
            "resetting env. episode 2413.000000, reward total was -18.000000. running mean: -19.418386\n",
            "resetting env. episode 2414.000000, reward total was -18.000000. running mean: -19.404202\n",
            "resetting env. episode 2415.000000, reward total was -18.000000. running mean: -19.390160\n",
            "resetting env. episode 2416.000000, reward total was -19.000000. running mean: -19.386258\n",
            "resetting env. episode 2417.000000, reward total was -20.000000. running mean: -19.392396\n",
            "resetting env. episode 2418.000000, reward total was -18.000000. running mean: -19.378472\n",
            "resetting env. episode 2419.000000, reward total was -19.000000. running mean: -19.374687\n",
            "resetting env. episode 2420.000000, reward total was -20.000000. running mean: -19.380940\n",
            "resetting env. episode 2421.000000, reward total was -19.000000. running mean: -19.377131\n",
            "resetting env. episode 2422.000000, reward total was -14.000000. running mean: -19.323360\n",
            "resetting env. episode 2423.000000, reward total was -20.000000. running mean: -19.330126\n",
            "resetting env. episode 2424.000000, reward total was -19.000000. running mean: -19.326825\n",
            "resetting env. episode 2425.000000, reward total was -21.000000. running mean: -19.343557\n",
            "resetting env. episode 2426.000000, reward total was -20.000000. running mean: -19.350121\n",
            "resetting env. episode 2427.000000, reward total was -21.000000. running mean: -19.366620\n",
            "resetting env. episode 2428.000000, reward total was -20.000000. running mean: -19.372954\n",
            "resetting env. episode 2429.000000, reward total was -20.000000. running mean: -19.379224\n",
            "resetting env. episode 2430.000000, reward total was -21.000000. running mean: -19.395432\n",
            "resetting env. episode 2431.000000, reward total was -20.000000. running mean: -19.401477\n",
            "resetting env. episode 2432.000000, reward total was -19.000000. running mean: -19.397463\n",
            "resetting env. episode 2433.000000, reward total was -20.000000. running mean: -19.403488\n",
            "resetting env. episode 2434.000000, reward total was -18.000000. running mean: -19.389453\n",
            "resetting env. episode 2435.000000, reward total was -21.000000. running mean: -19.405559\n",
            "resetting env. episode 2436.000000, reward total was -17.000000. running mean: -19.381503\n",
            "resetting env. episode 2437.000000, reward total was -20.000000. running mean: -19.387688\n",
            "resetting env. episode 2438.000000, reward total was -19.000000. running mean: -19.383811\n",
            "resetting env. episode 2439.000000, reward total was -19.000000. running mean: -19.379973\n",
            "resetting env. episode 2440.000000, reward total was -20.000000. running mean: -19.386173\n",
            "resetting env. episode 2441.000000, reward total was -20.000000. running mean: -19.392312\n",
            "resetting env. episode 2442.000000, reward total was -19.000000. running mean: -19.388388\n",
            "resetting env. episode 2443.000000, reward total was -19.000000. running mean: -19.384505\n",
            "resetting env. episode 2444.000000, reward total was -21.000000. running mean: -19.400660\n",
            "resetting env. episode 2445.000000, reward total was -21.000000. running mean: -19.416653\n",
            "resetting env. episode 2446.000000, reward total was -20.000000. running mean: -19.422486\n",
            "resetting env. episode 2447.000000, reward total was -20.000000. running mean: -19.428262\n",
            "resetting env. episode 2448.000000, reward total was -21.000000. running mean: -19.443979\n",
            "resetting env. episode 2449.000000, reward total was -21.000000. running mean: -19.459539\n",
            "resetting env. episode 2450.000000, reward total was -19.000000. running mean: -19.454944\n",
            "resetting env. episode 2451.000000, reward total was -19.000000. running mean: -19.450394\n",
            "resetting env. episode 2452.000000, reward total was -21.000000. running mean: -19.465890\n",
            "resetting env. episode 2453.000000, reward total was -18.000000. running mean: -19.451231\n",
            "resetting env. episode 2454.000000, reward total was -19.000000. running mean: -19.446719\n",
            "resetting env. episode 2455.000000, reward total was -20.000000. running mean: -19.452252\n",
            "resetting env. episode 2456.000000, reward total was -21.000000. running mean: -19.467729\n",
            "resetting env. episode 2457.000000, reward total was -19.000000. running mean: -19.463052\n",
            "resetting env. episode 2458.000000, reward total was -20.000000. running mean: -19.468422\n",
            "resetting env. episode 2459.000000, reward total was -14.000000. running mean: -19.413737\n",
            "resetting env. episode 2460.000000, reward total was -21.000000. running mean: -19.429600\n",
            "resetting env. episode 2461.000000, reward total was -19.000000. running mean: -19.425304\n",
            "resetting env. episode 2462.000000, reward total was -20.000000. running mean: -19.431051\n",
            "resetting env. episode 2463.000000, reward total was -20.000000. running mean: -19.436740\n",
            "resetting env. episode 2464.000000, reward total was -19.000000. running mean: -19.432373\n",
            "resetting env. episode 2465.000000, reward total was -21.000000. running mean: -19.448049\n",
            "resetting env. episode 2466.000000, reward total was -20.000000. running mean: -19.453569\n",
            "resetting env. episode 2467.000000, reward total was -20.000000. running mean: -19.459033\n",
            "resetting env. episode 2468.000000, reward total was -20.000000. running mean: -19.464443\n",
            "resetting env. episode 2469.000000, reward total was -21.000000. running mean: -19.479798\n",
            "resetting env. episode 2470.000000, reward total was -21.000000. running mean: -19.495000\n",
            "resetting env. episode 2471.000000, reward total was -19.000000. running mean: -19.490050\n",
            "resetting env. episode 2472.000000, reward total was -20.000000. running mean: -19.495150\n",
            "resetting env. episode 2473.000000, reward total was -20.000000. running mean: -19.500198\n",
            "resetting env. episode 2474.000000, reward total was -21.000000. running mean: -19.515196\n",
            "resetting env. episode 2475.000000, reward total was -21.000000. running mean: -19.530044\n",
            "resetting env. episode 2476.000000, reward total was -21.000000. running mean: -19.544744\n",
            "resetting env. episode 2477.000000, reward total was -19.000000. running mean: -19.539297\n",
            "resetting env. episode 2478.000000, reward total was -19.000000. running mean: -19.533904\n",
            "resetting env. episode 2479.000000, reward total was -19.000000. running mean: -19.528565\n",
            "resetting env. episode 2480.000000, reward total was -19.000000. running mean: -19.523279\n",
            "resetting env. episode 2481.000000, reward total was -18.000000. running mean: -19.508046\n",
            "resetting env. episode 2482.000000, reward total was -19.000000. running mean: -19.502966\n",
            "resetting env. episode 2483.000000, reward total was -19.000000. running mean: -19.497936\n",
            "resetting env. episode 2484.000000, reward total was -19.000000. running mean: -19.492957\n",
            "resetting env. episode 2485.000000, reward total was -20.000000. running mean: -19.498027\n",
            "resetting env. episode 2486.000000, reward total was -17.000000. running mean: -19.473047\n",
            "resetting env. episode 2487.000000, reward total was -19.000000. running mean: -19.468316\n",
            "resetting env. episode 2488.000000, reward total was -20.000000. running mean: -19.473633\n",
            "resetting env. episode 2489.000000, reward total was -20.000000. running mean: -19.478897\n",
            "resetting env. episode 2490.000000, reward total was -19.000000. running mean: -19.474108\n",
            "resetting env. episode 2491.000000, reward total was -20.000000. running mean: -19.479367\n",
            "resetting env. episode 2492.000000, reward total was -19.000000. running mean: -19.474573\n",
            "resetting env. episode 2493.000000, reward total was -21.000000. running mean: -19.489827\n",
            "resetting env. episode 2494.000000, reward total was -20.000000. running mean: -19.494929\n",
            "resetting env. episode 2495.000000, reward total was -18.000000. running mean: -19.479980\n",
            "resetting env. episode 2496.000000, reward total was -20.000000. running mean: -19.485180\n",
            "resetting env. episode 2497.000000, reward total was -21.000000. running mean: -19.500328\n",
            "resetting env. episode 2498.000000, reward total was -18.000000. running mean: -19.485325\n",
            "resetting env. episode 2499.000000, reward total was -19.000000. running mean: -19.480472\n",
            "resetting env. episode 2500.000000, reward total was -20.000000. running mean: -19.485667\n",
            "resetting env. episode 2501.000000, reward total was -17.000000. running mean: -19.460810\n",
            "resetting env. episode 2502.000000, reward total was -19.000000. running mean: -19.456202\n",
            "resetting env. episode 2503.000000, reward total was -20.000000. running mean: -19.461640\n",
            "resetting env. episode 2504.000000, reward total was -21.000000. running mean: -19.477024\n",
            "resetting env. episode 2505.000000, reward total was -18.000000. running mean: -19.462254\n",
            "resetting env. episode 2506.000000, reward total was -21.000000. running mean: -19.477631\n",
            "resetting env. episode 2507.000000, reward total was -20.000000. running mean: -19.482855\n",
            "resetting env. episode 2508.000000, reward total was -17.000000. running mean: -19.458026\n",
            "resetting env. episode 2509.000000, reward total was -18.000000. running mean: -19.443446\n",
            "resetting env. episode 2510.000000, reward total was -20.000000. running mean: -19.449011\n",
            "resetting env. episode 2511.000000, reward total was -19.000000. running mean: -19.444521\n",
            "resetting env. episode 2512.000000, reward total was -20.000000. running mean: -19.450076\n",
            "resetting env. episode 2513.000000, reward total was -19.000000. running mean: -19.445575\n",
            "resetting env. episode 2514.000000, reward total was -21.000000. running mean: -19.461120\n",
            "resetting env. episode 2515.000000, reward total was -18.000000. running mean: -19.446508\n",
            "resetting env. episode 2516.000000, reward total was -19.000000. running mean: -19.442043\n",
            "resetting env. episode 2517.000000, reward total was -20.000000. running mean: -19.447623\n",
            "resetting env. episode 2518.000000, reward total was -18.000000. running mean: -19.433147\n",
            "resetting env. episode 2519.000000, reward total was -19.000000. running mean: -19.428815\n",
            "resetting env. episode 2520.000000, reward total was -18.000000. running mean: -19.414527\n",
            "resetting env. episode 2521.000000, reward total was -19.000000. running mean: -19.410382\n",
            "resetting env. episode 2522.000000, reward total was -18.000000. running mean: -19.396278\n",
            "resetting env. episode 2523.000000, reward total was -21.000000. running mean: -19.412315\n",
            "resetting env. episode 2524.000000, reward total was -20.000000. running mean: -19.418192\n",
            "resetting env. episode 2525.000000, reward total was -18.000000. running mean: -19.404010\n",
            "resetting env. episode 2526.000000, reward total was -19.000000. running mean: -19.399970\n",
            "resetting env. episode 2527.000000, reward total was -19.000000. running mean: -19.395970\n",
            "resetting env. episode 2528.000000, reward total was -19.000000. running mean: -19.392011\n",
            "resetting env. episode 2529.000000, reward total was -17.000000. running mean: -19.368090\n",
            "resetting env. episode 2530.000000, reward total was -21.000000. running mean: -19.384410\n",
            "resetting env. episode 2531.000000, reward total was -19.000000. running mean: -19.380565\n",
            "resetting env. episode 2532.000000, reward total was -20.000000. running mean: -19.386760\n",
            "resetting env. episode 2533.000000, reward total was -18.000000. running mean: -19.372892\n",
            "resetting env. episode 2534.000000, reward total was -19.000000. running mean: -19.369163\n",
            "resetting env. episode 2535.000000, reward total was -21.000000. running mean: -19.385472\n",
            "resetting env. episode 2536.000000, reward total was -21.000000. running mean: -19.401617\n",
            "resetting env. episode 2537.000000, reward total was -19.000000. running mean: -19.397601\n",
            "resetting env. episode 2538.000000, reward total was -21.000000. running mean: -19.413625\n",
            "resetting env. episode 2539.000000, reward total was -19.000000. running mean: -19.409489\n",
            "resetting env. episode 2540.000000, reward total was -21.000000. running mean: -19.425394\n",
            "resetting env. episode 2541.000000, reward total was -20.000000. running mean: -19.431140\n",
            "resetting env. episode 2542.000000, reward total was -19.000000. running mean: -19.426828\n",
            "resetting env. episode 2543.000000, reward total was -21.000000. running mean: -19.442560\n",
            "resetting env. episode 2544.000000, reward total was -21.000000. running mean: -19.458134\n",
            "resetting env. episode 2545.000000, reward total was -20.000000. running mean: -19.463553\n",
            "resetting env. episode 2546.000000, reward total was -19.000000. running mean: -19.458918\n",
            "resetting env. episode 2547.000000, reward total was -20.000000. running mean: -19.464328\n",
            "resetting env. episode 2548.000000, reward total was -20.000000. running mean: -19.469685\n",
            "resetting env. episode 2549.000000, reward total was -21.000000. running mean: -19.484988\n",
            "resetting env. episode 2550.000000, reward total was -20.000000. running mean: -19.490138\n",
            "resetting env. episode 2551.000000, reward total was -21.000000. running mean: -19.505237\n",
            "resetting env. episode 2552.000000, reward total was -21.000000. running mean: -19.520185\n",
            "resetting env. episode 2553.000000, reward total was -21.000000. running mean: -19.534983\n",
            "resetting env. episode 2554.000000, reward total was -20.000000. running mean: -19.539633\n",
            "resetting env. episode 2555.000000, reward total was -19.000000. running mean: -19.534237\n",
            "resetting env. episode 2556.000000, reward total was -20.000000. running mean: -19.538894\n",
            "resetting env. episode 2557.000000, reward total was -21.000000. running mean: -19.553505\n",
            "resetting env. episode 2558.000000, reward total was -21.000000. running mean: -19.567970\n",
            "resetting env. episode 2559.000000, reward total was -19.000000. running mean: -19.562291\n",
            "resetting env. episode 2560.000000, reward total was -19.000000. running mean: -19.556668\n",
            "resetting env. episode 2561.000000, reward total was -20.000000. running mean: -19.561101\n",
            "resetting env. episode 2562.000000, reward total was -20.000000. running mean: -19.565490\n",
            "resetting env. episode 2563.000000, reward total was -21.000000. running mean: -19.579835\n",
            "resetting env. episode 2564.000000, reward total was -20.000000. running mean: -19.584037\n",
            "resetting env. episode 2565.000000, reward total was -21.000000. running mean: -19.598196\n",
            "resetting env. episode 2566.000000, reward total was -20.000000. running mean: -19.602214\n",
            "resetting env. episode 2567.000000, reward total was -20.000000. running mean: -19.606192\n",
            "resetting env. episode 2568.000000, reward total was -19.000000. running mean: -19.600130\n",
            "resetting env. episode 2569.000000, reward total was -18.000000. running mean: -19.584129\n",
            "resetting env. episode 2570.000000, reward total was -21.000000. running mean: -19.598288\n",
            "resetting env. episode 2571.000000, reward total was -20.000000. running mean: -19.602305\n",
            "resetting env. episode 2572.000000, reward total was -17.000000. running mean: -19.576282\n",
            "resetting env. episode 2573.000000, reward total was -20.000000. running mean: -19.580519\n",
            "resetting env. episode 2574.000000, reward total was -17.000000. running mean: -19.554714\n",
            "resetting env. episode 2575.000000, reward total was -21.000000. running mean: -19.569167\n",
            "resetting env. episode 2576.000000, reward total was -21.000000. running mean: -19.583475\n",
            "resetting env. episode 2577.000000, reward total was -21.000000. running mean: -19.597640\n",
            "resetting env. episode 2578.000000, reward total was -19.000000. running mean: -19.591664\n",
            "resetting env. episode 2579.000000, reward total was -17.000000. running mean: -19.565747\n",
            "resetting env. episode 2580.000000, reward total was -19.000000. running mean: -19.560090\n",
            "resetting env. episode 2581.000000, reward total was -21.000000. running mean: -19.574489\n",
            "resetting env. episode 2582.000000, reward total was -19.000000. running mean: -19.568744\n",
            "resetting env. episode 2583.000000, reward total was -18.000000. running mean: -19.553056\n",
            "resetting env. episode 2584.000000, reward total was -19.000000. running mean: -19.547526\n",
            "resetting env. episode 2585.000000, reward total was -19.000000. running mean: -19.542051\n",
            "resetting env. episode 2586.000000, reward total was -21.000000. running mean: -19.556630\n",
            "resetting env. episode 2587.000000, reward total was -19.000000. running mean: -19.551064\n",
            "resetting env. episode 2588.000000, reward total was -20.000000. running mean: -19.555553\n",
            "resetting env. episode 2589.000000, reward total was -21.000000. running mean: -19.569998\n",
            "resetting env. episode 2590.000000, reward total was -17.000000. running mean: -19.544298\n",
            "resetting env. episode 2591.000000, reward total was -21.000000. running mean: -19.558855\n",
            "resetting env. episode 2592.000000, reward total was -19.000000. running mean: -19.553266\n",
            "resetting env. episode 2593.000000, reward total was -21.000000. running mean: -19.567734\n",
            "resetting env. episode 2594.000000, reward total was -19.000000. running mean: -19.562056\n",
            "resetting env. episode 2595.000000, reward total was -20.000000. running mean: -19.566436\n",
            "resetting env. episode 2596.000000, reward total was -19.000000. running mean: -19.560771\n",
            "resetting env. episode 2597.000000, reward total was -20.000000. running mean: -19.565164\n",
            "resetting env. episode 2598.000000, reward total was -19.000000. running mean: -19.559512\n",
            "resetting env. episode 2599.000000, reward total was -20.000000. running mean: -19.563917\n",
            "resetting env. episode 2600.000000, reward total was -21.000000. running mean: -19.578278\n",
            "resetting env. episode 2601.000000, reward total was -20.000000. running mean: -19.582495\n",
            "resetting env. episode 2602.000000, reward total was -18.000000. running mean: -19.566670\n",
            "resetting env. episode 2603.000000, reward total was -18.000000. running mean: -19.551003\n",
            "resetting env. episode 2604.000000, reward total was -18.000000. running mean: -19.535493\n",
            "resetting env. episode 2605.000000, reward total was -21.000000. running mean: -19.550138\n",
            "resetting env. episode 2606.000000, reward total was -21.000000. running mean: -19.564637\n",
            "resetting env. episode 2607.000000, reward total was -21.000000. running mean: -19.578990\n",
            "resetting env. episode 2608.000000, reward total was -21.000000. running mean: -19.593201\n",
            "resetting env. episode 2609.000000, reward total was -19.000000. running mean: -19.587269\n",
            "resetting env. episode 2610.000000, reward total was -19.000000. running mean: -19.581396\n",
            "resetting env. episode 2611.000000, reward total was -20.000000. running mean: -19.585582\n",
            "resetting env. episode 2612.000000, reward total was -21.000000. running mean: -19.599726\n",
            "resetting env. episode 2613.000000, reward total was -20.000000. running mean: -19.603729\n",
            "resetting env. episode 2614.000000, reward total was -20.000000. running mean: -19.607692\n",
            "resetting env. episode 2615.000000, reward total was -19.000000. running mean: -19.601615\n",
            "resetting env. episode 2616.000000, reward total was -20.000000. running mean: -19.605599\n",
            "resetting env. episode 2617.000000, reward total was -20.000000. running mean: -19.609543\n",
            "resetting env. episode 2618.000000, reward total was -19.000000. running mean: -19.603447\n",
            "resetting env. episode 2619.000000, reward total was -20.000000. running mean: -19.607413\n",
            "resetting env. episode 2620.000000, reward total was -20.000000. running mean: -19.611339\n",
            "resetting env. episode 2621.000000, reward total was -19.000000. running mean: -19.605225\n",
            "resetting env. episode 2622.000000, reward total was -20.000000. running mean: -19.609173\n",
            "resetting env. episode 2623.000000, reward total was -19.000000. running mean: -19.603081\n",
            "resetting env. episode 2624.000000, reward total was -19.000000. running mean: -19.597050\n",
            "resetting env. episode 2625.000000, reward total was -17.000000. running mean: -19.571080\n",
            "resetting env. episode 2626.000000, reward total was -16.000000. running mean: -19.535369\n",
            "resetting env. episode 2627.000000, reward total was -17.000000. running mean: -19.510015\n",
            "resetting env. episode 2628.000000, reward total was -18.000000. running mean: -19.494915\n",
            "resetting env. episode 2629.000000, reward total was -18.000000. running mean: -19.479966\n",
            "resetting env. episode 2630.000000, reward total was -17.000000. running mean: -19.455166\n",
            "resetting env. episode 2631.000000, reward total was -19.000000. running mean: -19.450615\n",
            "resetting env. episode 2632.000000, reward total was -21.000000. running mean: -19.466109\n",
            "resetting env. episode 2633.000000, reward total was -21.000000. running mean: -19.481447\n",
            "resetting env. episode 2634.000000, reward total was -20.000000. running mean: -19.486633\n",
            "resetting env. episode 2635.000000, reward total was -18.000000. running mean: -19.471767\n",
            "resetting env. episode 2636.000000, reward total was -19.000000. running mean: -19.467049\n",
            "resetting env. episode 2637.000000, reward total was -19.000000. running mean: -19.462379\n",
            "resetting env. episode 2638.000000, reward total was -20.000000. running mean: -19.467755\n",
            "resetting env. episode 2639.000000, reward total was -20.000000. running mean: -19.473077\n",
            "resetting env. episode 2640.000000, reward total was -21.000000. running mean: -19.488346\n",
            "resetting env. episode 2641.000000, reward total was -19.000000. running mean: -19.483463\n",
            "resetting env. episode 2642.000000, reward total was -17.000000. running mean: -19.458628\n",
            "resetting env. episode 2643.000000, reward total was -19.000000. running mean: -19.454042\n",
            "resetting env. episode 2644.000000, reward total was -16.000000. running mean: -19.419502\n",
            "resetting env. episode 2645.000000, reward total was -21.000000. running mean: -19.435307\n",
            "resetting env. episode 2646.000000, reward total was -20.000000. running mean: -19.440954\n",
            "resetting env. episode 2647.000000, reward total was -19.000000. running mean: -19.436544\n",
            "resetting env. episode 2648.000000, reward total was -19.000000. running mean: -19.432179\n",
            "resetting env. episode 2649.000000, reward total was -13.000000. running mean: -19.367857\n",
            "resetting env. episode 2650.000000, reward total was -20.000000. running mean: -19.374178\n",
            "resetting env. episode 2651.000000, reward total was -19.000000. running mean: -19.370436\n",
            "resetting env. episode 2652.000000, reward total was -17.000000. running mean: -19.346732\n",
            "resetting env. episode 2653.000000, reward total was -18.000000. running mean: -19.333265\n",
            "resetting env. episode 2654.000000, reward total was -18.000000. running mean: -19.319932\n",
            "resetting env. episode 2655.000000, reward total was -20.000000. running mean: -19.326733\n",
            "resetting env. episode 2656.000000, reward total was -18.000000. running mean: -19.313465\n",
            "resetting env. episode 2657.000000, reward total was -21.000000. running mean: -19.330331\n",
            "resetting env. episode 2658.000000, reward total was -19.000000. running mean: -19.327027\n",
            "resetting env. episode 2659.000000, reward total was -20.000000. running mean: -19.333757\n",
            "resetting env. episode 2660.000000, reward total was -16.000000. running mean: -19.300420\n",
            "resetting env. episode 2661.000000, reward total was -21.000000. running mean: -19.317415\n",
            "resetting env. episode 2662.000000, reward total was -19.000000. running mean: -19.314241\n",
            "resetting env. episode 2663.000000, reward total was -21.000000. running mean: -19.331099\n",
            "resetting env. episode 2664.000000, reward total was -20.000000. running mean: -19.337788\n",
            "resetting env. episode 2665.000000, reward total was -20.000000. running mean: -19.344410\n",
            "resetting env. episode 2666.000000, reward total was -20.000000. running mean: -19.350966\n",
            "resetting env. episode 2667.000000, reward total was -17.000000. running mean: -19.327456\n",
            "resetting env. episode 2668.000000, reward total was -20.000000. running mean: -19.334182\n",
            "resetting env. episode 2669.000000, reward total was -20.000000. running mean: -19.340840\n",
            "resetting env. episode 2670.000000, reward total was -16.000000. running mean: -19.307431\n",
            "resetting env. episode 2671.000000, reward total was -20.000000. running mean: -19.314357\n",
            "resetting env. episode 2672.000000, reward total was -21.000000. running mean: -19.331214\n",
            "resetting env. episode 2673.000000, reward total was -18.000000. running mean: -19.317901\n",
            "resetting env. episode 2674.000000, reward total was -19.000000. running mean: -19.314722\n",
            "resetting env. episode 2675.000000, reward total was -20.000000. running mean: -19.321575\n",
            "resetting env. episode 2676.000000, reward total was -16.000000. running mean: -19.288359\n",
            "resetting env. episode 2677.000000, reward total was -20.000000. running mean: -19.295476\n",
            "resetting env. episode 2678.000000, reward total was -21.000000. running mean: -19.312521\n",
            "resetting env. episode 2679.000000, reward total was -20.000000. running mean: -19.319396\n",
            "resetting env. episode 2680.000000, reward total was -20.000000. running mean: -19.326202\n",
            "resetting env. episode 2681.000000, reward total was -18.000000. running mean: -19.312940\n",
            "resetting env. episode 2682.000000, reward total was -19.000000. running mean: -19.309811\n",
            "resetting env. episode 2683.000000, reward total was -18.000000. running mean: -19.296712\n",
            "resetting env. episode 2684.000000, reward total was -18.000000. running mean: -19.283745\n",
            "resetting env. episode 2685.000000, reward total was -19.000000. running mean: -19.280908\n",
            "resetting env. episode 2686.000000, reward total was -15.000000. running mean: -19.238099\n",
            "resetting env. episode 2687.000000, reward total was -19.000000. running mean: -19.235718\n",
            "resetting env. episode 2688.000000, reward total was -19.000000. running mean: -19.233361\n",
            "resetting env. episode 2689.000000, reward total was -16.000000. running mean: -19.201027\n",
            "resetting env. episode 2690.000000, reward total was -18.000000. running mean: -19.189017\n",
            "resetting env. episode 2691.000000, reward total was -19.000000. running mean: -19.187127\n",
            "resetting env. episode 2692.000000, reward total was -15.000000. running mean: -19.145255\n",
            "resetting env. episode 2693.000000, reward total was -19.000000. running mean: -19.143803\n",
            "resetting env. episode 2694.000000, reward total was -18.000000. running mean: -19.132365\n",
            "resetting env. episode 2695.000000, reward total was -19.000000. running mean: -19.131041\n",
            "resetting env. episode 2696.000000, reward total was -19.000000. running mean: -19.129731\n",
            "resetting env. episode 2697.000000, reward total was -21.000000. running mean: -19.148433\n",
            "resetting env. episode 2698.000000, reward total was -21.000000. running mean: -19.166949\n",
            "resetting env. episode 2699.000000, reward total was -19.000000. running mean: -19.165280\n",
            "resetting env. episode 2700.000000, reward total was -20.000000. running mean: -19.173627\n",
            "resetting env. episode 2701.000000, reward total was -20.000000. running mean: -19.181890\n",
            "resetting env. episode 2702.000000, reward total was -19.000000. running mean: -19.180072\n",
            "resetting env. episode 2703.000000, reward total was -19.000000. running mean: -19.178271\n",
            "resetting env. episode 2704.000000, reward total was -19.000000. running mean: -19.176488\n",
            "resetting env. episode 2705.000000, reward total was -19.000000. running mean: -19.174723\n",
            "resetting env. episode 2706.000000, reward total was -19.000000. running mean: -19.172976\n",
            "resetting env. episode 2707.000000, reward total was -16.000000. running mean: -19.141246\n",
            "resetting env. episode 2708.000000, reward total was -21.000000. running mean: -19.159834\n",
            "resetting env. episode 2709.000000, reward total was -21.000000. running mean: -19.178235\n",
            "resetting env. episode 2710.000000, reward total was -19.000000. running mean: -19.176453\n",
            "resetting env. episode 2711.000000, reward total was -17.000000. running mean: -19.154689\n",
            "resetting env. episode 2712.000000, reward total was -20.000000. running mean: -19.163142\n",
            "resetting env. episode 2713.000000, reward total was -17.000000. running mean: -19.141510\n",
            "resetting env. episode 2714.000000, reward total was -18.000000. running mean: -19.130095\n",
            "resetting env. episode 2715.000000, reward total was -17.000000. running mean: -19.108794\n",
            "resetting env. episode 2716.000000, reward total was -21.000000. running mean: -19.127706\n",
            "resetting env. episode 2717.000000, reward total was -19.000000. running mean: -19.126429\n",
            "resetting env. episode 2718.000000, reward total was -19.000000. running mean: -19.125165\n",
            "resetting env. episode 2719.000000, reward total was -19.000000. running mean: -19.123913\n",
            "resetting env. episode 2720.000000, reward total was -19.000000. running mean: -19.122674\n",
            "resetting env. episode 2721.000000, reward total was -20.000000. running mean: -19.131447\n",
            "resetting env. episode 2722.000000, reward total was -19.000000. running mean: -19.130133\n",
            "resetting env. episode 2723.000000, reward total was -20.000000. running mean: -19.138832\n",
            "resetting env. episode 2724.000000, reward total was -19.000000. running mean: -19.137443\n",
            "resetting env. episode 2725.000000, reward total was -19.000000. running mean: -19.136069\n",
            "resetting env. episode 2726.000000, reward total was -20.000000. running mean: -19.144708\n",
            "resetting env. episode 2727.000000, reward total was -19.000000. running mean: -19.143261\n",
            "resetting env. episode 2728.000000, reward total was -21.000000. running mean: -19.161828\n",
            "resetting env. episode 2729.000000, reward total was -19.000000. running mean: -19.160210\n",
            "resetting env. episode 2730.000000, reward total was -18.000000. running mean: -19.148608\n",
            "resetting env. episode 2731.000000, reward total was -18.000000. running mean: -19.137122\n",
            "resetting env. episode 2732.000000, reward total was -18.000000. running mean: -19.125751\n",
            "resetting env. episode 2733.000000, reward total was -21.000000. running mean: -19.144493\n",
            "resetting env. episode 2734.000000, reward total was -20.000000. running mean: -19.153048\n",
            "resetting env. episode 2735.000000, reward total was -19.000000. running mean: -19.151518\n",
            "resetting env. episode 2736.000000, reward total was -20.000000. running mean: -19.160003\n",
            "resetting env. episode 2737.000000, reward total was -17.000000. running mean: -19.138403\n",
            "resetting env. episode 2738.000000, reward total was -20.000000. running mean: -19.147019\n",
            "resetting env. episode 2739.000000, reward total was -21.000000. running mean: -19.165548\n",
            "resetting env. episode 2740.000000, reward total was -20.000000. running mean: -19.173893\n",
            "resetting env. episode 2741.000000, reward total was -21.000000. running mean: -19.192154\n",
            "resetting env. episode 2742.000000, reward total was -18.000000. running mean: -19.180232\n",
            "resetting env. episode 2743.000000, reward total was -16.000000. running mean: -19.148430\n",
            "resetting env. episode 2744.000000, reward total was -19.000000. running mean: -19.146946\n",
            "resetting env. episode 2745.000000, reward total was -19.000000. running mean: -19.145476\n",
            "resetting env. episode 2746.000000, reward total was -20.000000. running mean: -19.154022\n",
            "resetting env. episode 2747.000000, reward total was -20.000000. running mean: -19.162481\n",
            "resetting env. episode 2748.000000, reward total was -16.000000. running mean: -19.130857\n",
            "resetting env. episode 2749.000000, reward total was -19.000000. running mean: -19.129548\n",
            "resetting env. episode 2750.000000, reward total was -20.000000. running mean: -19.138253\n",
            "resetting env. episode 2751.000000, reward total was -20.000000. running mean: -19.146870\n",
            "resetting env. episode 2752.000000, reward total was -18.000000. running mean: -19.135401\n",
            "resetting env. episode 2753.000000, reward total was -19.000000. running mean: -19.134047\n",
            "resetting env. episode 2754.000000, reward total was -20.000000. running mean: -19.142707\n",
            "resetting env. episode 2755.000000, reward total was -20.000000. running mean: -19.151280\n",
            "resetting env. episode 2756.000000, reward total was -16.000000. running mean: -19.119767\n",
            "resetting env. episode 2757.000000, reward total was -18.000000. running mean: -19.108569\n",
            "resetting env. episode 2758.000000, reward total was -17.000000. running mean: -19.087484\n",
            "resetting env. episode 2759.000000, reward total was -19.000000. running mean: -19.086609\n",
            "resetting env. episode 2760.000000, reward total was -19.000000. running mean: -19.085743\n",
            "resetting env. episode 2761.000000, reward total was -20.000000. running mean: -19.094885\n",
            "resetting env. episode 2762.000000, reward total was -19.000000. running mean: -19.093936\n",
            "resetting env. episode 2763.000000, reward total was -19.000000. running mean: -19.092997\n",
            "resetting env. episode 2764.000000, reward total was -19.000000. running mean: -19.092067\n",
            "resetting env. episode 2765.000000, reward total was -19.000000. running mean: -19.091146\n",
            "resetting env. episode 2766.000000, reward total was -21.000000. running mean: -19.110235\n",
            "resetting env. episode 2767.000000, reward total was -18.000000. running mean: -19.099133\n",
            "resetting env. episode 2768.000000, reward total was -20.000000. running mean: -19.108141\n",
            "resetting env. episode 2769.000000, reward total was -18.000000. running mean: -19.097060\n",
            "resetting env. episode 2770.000000, reward total was -21.000000. running mean: -19.116089\n",
            "resetting env. episode 2771.000000, reward total was -20.000000. running mean: -19.124928\n",
            "resetting env. episode 2772.000000, reward total was -19.000000. running mean: -19.123679\n",
            "resetting env. episode 2773.000000, reward total was -18.000000. running mean: -19.112442\n",
            "resetting env. episode 2774.000000, reward total was -20.000000. running mean: -19.121318\n",
            "resetting env. episode 2775.000000, reward total was -21.000000. running mean: -19.140105\n",
            "resetting env. episode 2776.000000, reward total was -20.000000. running mean: -19.148704\n",
            "resetting env. episode 2777.000000, reward total was -20.000000. running mean: -19.157217\n",
            "resetting env. episode 2778.000000, reward total was -21.000000. running mean: -19.175644\n",
            "resetting env. episode 2779.000000, reward total was -21.000000. running mean: -19.193888\n",
            "resetting env. episode 2780.000000, reward total was -21.000000. running mean: -19.211949\n",
            "resetting env. episode 2781.000000, reward total was -19.000000. running mean: -19.209830\n",
            "resetting env. episode 2782.000000, reward total was -20.000000. running mean: -19.217731\n",
            "resetting env. episode 2783.000000, reward total was -16.000000. running mean: -19.185554\n",
            "resetting env. episode 2784.000000, reward total was -20.000000. running mean: -19.193698\n",
            "resetting env. episode 2785.000000, reward total was -15.000000. running mean: -19.151761\n",
            "resetting env. episode 2786.000000, reward total was -21.000000. running mean: -19.170244\n",
            "resetting env. episode 2787.000000, reward total was -19.000000. running mean: -19.168541\n",
            "resetting env. episode 2788.000000, reward total was -20.000000. running mean: -19.176856\n",
            "resetting env. episode 2789.000000, reward total was -19.000000. running mean: -19.175087\n",
            "resetting env. episode 2790.000000, reward total was -21.000000. running mean: -19.193337\n",
            "resetting env. episode 2791.000000, reward total was -20.000000. running mean: -19.201403\n",
            "resetting env. episode 2792.000000, reward total was -20.000000. running mean: -19.209389\n",
            "resetting env. episode 2793.000000, reward total was -20.000000. running mean: -19.217295\n",
            "resetting env. episode 2794.000000, reward total was -19.000000. running mean: -19.215122\n",
            "resetting env. episode 2795.000000, reward total was -21.000000. running mean: -19.232971\n",
            "resetting env. episode 2796.000000, reward total was -21.000000. running mean: -19.250641\n",
            "resetting env. episode 2797.000000, reward total was -18.000000. running mean: -19.238135\n",
            "resetting env. episode 2798.000000, reward total was -20.000000. running mean: -19.245754\n",
            "resetting env. episode 2799.000000, reward total was -19.000000. running mean: -19.243296\n",
            "resetting env. episode 2800.000000, reward total was -17.000000. running mean: -19.220863\n",
            "resetting env. episode 2801.000000, reward total was -18.000000. running mean: -19.208655\n",
            "resetting env. episode 2802.000000, reward total was -20.000000. running mean: -19.216568\n",
            "resetting env. episode 2803.000000, reward total was -18.000000. running mean: -19.204402\n",
            "resetting env. episode 2804.000000, reward total was -21.000000. running mean: -19.222358\n",
            "resetting env. episode 2805.000000, reward total was -20.000000. running mean: -19.230135\n",
            "resetting env. episode 2806.000000, reward total was -19.000000. running mean: -19.227833\n",
            "resetting env. episode 2807.000000, reward total was -18.000000. running mean: -19.215555\n",
            "resetting env. episode 2808.000000, reward total was -18.000000. running mean: -19.203399\n",
            "resetting env. episode 2809.000000, reward total was -19.000000. running mean: -19.201365\n",
            "resetting env. episode 2810.000000, reward total was -21.000000. running mean: -19.219352\n",
            "resetting env. episode 2811.000000, reward total was -21.000000. running mean: -19.237158\n",
            "resetting env. episode 2812.000000, reward total was -20.000000. running mean: -19.244787\n",
            "resetting env. episode 2813.000000, reward total was -19.000000. running mean: -19.242339\n",
            "resetting env. episode 2814.000000, reward total was -20.000000. running mean: -19.249915\n",
            "resetting env. episode 2815.000000, reward total was -20.000000. running mean: -19.257416\n",
            "resetting env. episode 2816.000000, reward total was -19.000000. running mean: -19.254842\n",
            "resetting env. episode 2817.000000, reward total was -19.000000. running mean: -19.252294\n",
            "resetting env. episode 2818.000000, reward total was -17.000000. running mean: -19.229771\n",
            "resetting env. episode 2819.000000, reward total was -20.000000. running mean: -19.237473\n",
            "resetting env. episode 2820.000000, reward total was -17.000000. running mean: -19.215098\n",
            "resetting env. episode 2821.000000, reward total was -17.000000. running mean: -19.192947\n",
            "resetting env. episode 2822.000000, reward total was -20.000000. running mean: -19.201018\n",
            "resetting env. episode 2823.000000, reward total was -20.000000. running mean: -19.209008\n",
            "resetting env. episode 2824.000000, reward total was -19.000000. running mean: -19.206918\n",
            "resetting env. episode 2825.000000, reward total was -18.000000. running mean: -19.194848\n",
            "resetting env. episode 2826.000000, reward total was -19.000000. running mean: -19.192900\n",
            "resetting env. episode 2827.000000, reward total was -16.000000. running mean: -19.160971\n",
            "resetting env. episode 2828.000000, reward total was -17.000000. running mean: -19.139361\n",
            "resetting env. episode 2829.000000, reward total was -21.000000. running mean: -19.157968\n",
            "resetting env. episode 2830.000000, reward total was -20.000000. running mean: -19.166388\n",
            "resetting env. episode 2831.000000, reward total was -21.000000. running mean: -19.184724\n",
            "resetting env. episode 2832.000000, reward total was -19.000000. running mean: -19.182877\n",
            "resetting env. episode 2833.000000, reward total was -21.000000. running mean: -19.201048\n",
            "resetting env. episode 2834.000000, reward total was -21.000000. running mean: -19.219038\n",
            "resetting env. episode 2835.000000, reward total was -18.000000. running mean: -19.206847\n",
            "resetting env. episode 2836.000000, reward total was -19.000000. running mean: -19.204779\n",
            "resetting env. episode 2837.000000, reward total was -19.000000. running mean: -19.202731\n",
            "resetting env. episode 2838.000000, reward total was -19.000000. running mean: -19.200704\n",
            "resetting env. episode 2839.000000, reward total was -18.000000. running mean: -19.188697\n",
            "resetting env. episode 2840.000000, reward total was -19.000000. running mean: -19.186810\n",
            "resetting env. episode 2841.000000, reward total was -19.000000. running mean: -19.184942\n",
            "resetting env. episode 2842.000000, reward total was -17.000000. running mean: -19.163092\n",
            "resetting env. episode 2843.000000, reward total was -21.000000. running mean: -19.181461\n",
            "resetting env. episode 2844.000000, reward total was -19.000000. running mean: -19.179647\n",
            "resetting env. episode 2845.000000, reward total was -19.000000. running mean: -19.177850\n",
            "resetting env. episode 2846.000000, reward total was -16.000000. running mean: -19.146072\n",
            "resetting env. episode 2847.000000, reward total was -18.000000. running mean: -19.134611\n",
            "resetting env. episode 2848.000000, reward total was -19.000000. running mean: -19.133265\n",
            "resetting env. episode 2849.000000, reward total was -20.000000. running mean: -19.141932\n",
            "resetting env. episode 2850.000000, reward total was -21.000000. running mean: -19.160513\n",
            "resetting env. episode 2851.000000, reward total was -15.000000. running mean: -19.118908\n",
            "resetting env. episode 2852.000000, reward total was -20.000000. running mean: -19.127719\n",
            "resetting env. episode 2853.000000, reward total was -21.000000. running mean: -19.146441\n",
            "resetting env. episode 2854.000000, reward total was -19.000000. running mean: -19.144977\n",
            "resetting env. episode 2855.000000, reward total was -21.000000. running mean: -19.163527\n",
            "resetting env. episode 2856.000000, reward total was -19.000000. running mean: -19.161892\n",
            "resetting env. episode 2857.000000, reward total was -19.000000. running mean: -19.160273\n",
            "resetting env. episode 2858.000000, reward total was -21.000000. running mean: -19.178670\n",
            "resetting env. episode 2859.000000, reward total was -20.000000. running mean: -19.186884\n",
            "resetting env. episode 2860.000000, reward total was -20.000000. running mean: -19.195015\n",
            "resetting env. episode 2861.000000, reward total was -17.000000. running mean: -19.173065\n",
            "resetting env. episode 2862.000000, reward total was -19.000000. running mean: -19.171334\n",
            "resetting env. episode 2863.000000, reward total was -18.000000. running mean: -19.159621\n",
            "resetting env. episode 2864.000000, reward total was -20.000000. running mean: -19.168024\n",
            "resetting env. episode 2865.000000, reward total was -21.000000. running mean: -19.186344\n",
            "resetting env. episode 2866.000000, reward total was -17.000000. running mean: -19.164481\n",
            "resetting env. episode 2867.000000, reward total was -18.000000. running mean: -19.152836\n",
            "resetting env. episode 2868.000000, reward total was -20.000000. running mean: -19.161308\n",
            "resetting env. episode 2869.000000, reward total was -19.000000. running mean: -19.159695\n",
            "resetting env. episode 2870.000000, reward total was -21.000000. running mean: -19.178098\n",
            "resetting env. episode 2871.000000, reward total was -21.000000. running mean: -19.196317\n",
            "resetting env. episode 2872.000000, reward total was -19.000000. running mean: -19.194353\n",
            "resetting env. episode 2873.000000, reward total was -19.000000. running mean: -19.192410\n",
            "resetting env. episode 2874.000000, reward total was -14.000000. running mean: -19.140486\n",
            "resetting env. episode 2875.000000, reward total was -19.000000. running mean: -19.139081\n",
            "resetting env. episode 2876.000000, reward total was -21.000000. running mean: -19.157690\n",
            "resetting env. episode 2877.000000, reward total was -20.000000. running mean: -19.166113\n",
            "resetting env. episode 2878.000000, reward total was -16.000000. running mean: -19.134452\n",
            "resetting env. episode 2879.000000, reward total was -15.000000. running mean: -19.093108\n",
            "resetting env. episode 2880.000000, reward total was -18.000000. running mean: -19.082177\n",
            "resetting env. episode 2881.000000, reward total was -21.000000. running mean: -19.101355\n",
            "resetting env. episode 2882.000000, reward total was -18.000000. running mean: -19.090341\n",
            "resetting env. episode 2883.000000, reward total was -19.000000. running mean: -19.089438\n",
            "resetting env. episode 2884.000000, reward total was -19.000000. running mean: -19.088543\n",
            "resetting env. episode 2885.000000, reward total was -19.000000. running mean: -19.087658\n",
            "resetting env. episode 2886.000000, reward total was -20.000000. running mean: -19.096781\n",
            "resetting env. episode 2887.000000, reward total was -20.000000. running mean: -19.105814\n",
            "resetting env. episode 2888.000000, reward total was -19.000000. running mean: -19.104755\n",
            "resetting env. episode 2889.000000, reward total was -19.000000. running mean: -19.103708\n",
            "resetting env. episode 2890.000000, reward total was -19.000000. running mean: -19.102671\n",
            "resetting env. episode 2891.000000, reward total was -18.000000. running mean: -19.091644\n",
            "resetting env. episode 2892.000000, reward total was -20.000000. running mean: -19.100728\n",
            "resetting env. episode 2893.000000, reward total was -19.000000. running mean: -19.099720\n",
            "resetting env. episode 2894.000000, reward total was -21.000000. running mean: -19.118723\n",
            "resetting env. episode 2895.000000, reward total was -17.000000. running mean: -19.097536\n",
            "resetting env. episode 2896.000000, reward total was -18.000000. running mean: -19.086561\n",
            "resetting env. episode 2897.000000, reward total was -19.000000. running mean: -19.085695\n",
            "resetting env. episode 2898.000000, reward total was -20.000000. running mean: -19.094838\n",
            "resetting env. episode 2899.000000, reward total was -19.000000. running mean: -19.093890\n",
            "resetting env. episode 2900.000000, reward total was -21.000000. running mean: -19.112951\n",
            "resetting env. episode 2901.000000, reward total was -20.000000. running mean: -19.121821\n",
            "resetting env. episode 2902.000000, reward total was -21.000000. running mean: -19.140603\n",
            "resetting env. episode 2903.000000, reward total was -21.000000. running mean: -19.159197\n",
            "resetting env. episode 2904.000000, reward total was -21.000000. running mean: -19.177605\n",
            "resetting env. episode 2905.000000, reward total was -18.000000. running mean: -19.165829\n",
            "resetting env. episode 2906.000000, reward total was -13.000000. running mean: -19.104171\n",
            "resetting env. episode 2907.000000, reward total was -18.000000. running mean: -19.093129\n",
            "resetting env. episode 2908.000000, reward total was -17.000000. running mean: -19.072198\n",
            "resetting env. episode 2909.000000, reward total was -18.000000. running mean: -19.061476\n",
            "resetting env. episode 2910.000000, reward total was -20.000000. running mean: -19.070861\n",
            "resetting env. episode 2911.000000, reward total was -18.000000. running mean: -19.060152\n",
            "resetting env. episode 2912.000000, reward total was -17.000000. running mean: -19.039551\n",
            "resetting env. episode 2913.000000, reward total was -21.000000. running mean: -19.059155\n",
            "resetting env. episode 2914.000000, reward total was -19.000000. running mean: -19.058564\n",
            "resetting env. episode 2915.000000, reward total was -21.000000. running mean: -19.077978\n",
            "resetting env. episode 2916.000000, reward total was -17.000000. running mean: -19.057198\n",
            "resetting env. episode 2917.000000, reward total was -16.000000. running mean: -19.026626\n",
            "resetting env. episode 2918.000000, reward total was -19.000000. running mean: -19.026360\n",
            "resetting env. episode 2919.000000, reward total was -21.000000. running mean: -19.046096\n",
            "resetting env. episode 2920.000000, reward total was -18.000000. running mean: -19.035636\n",
            "resetting env. episode 2921.000000, reward total was -18.000000. running mean: -19.025279\n",
            "resetting env. episode 2922.000000, reward total was -21.000000. running mean: -19.045026\n",
            "resetting env. episode 2923.000000, reward total was -15.000000. running mean: -19.004576\n",
            "resetting env. episode 2924.000000, reward total was -21.000000. running mean: -19.024530\n",
            "resetting env. episode 2925.000000, reward total was -19.000000. running mean: -19.024285\n",
            "resetting env. episode 2926.000000, reward total was -18.000000. running mean: -19.014042\n",
            "resetting env. episode 2927.000000, reward total was -18.000000. running mean: -19.003902\n",
            "resetting env. episode 2928.000000, reward total was -19.000000. running mean: -19.003863\n",
            "resetting env. episode 2929.000000, reward total was -20.000000. running mean: -19.013824\n",
            "resetting env. episode 2930.000000, reward total was -15.000000. running mean: -18.973686\n",
            "resetting env. episode 2931.000000, reward total was -21.000000. running mean: -18.993949\n",
            "resetting env. episode 2932.000000, reward total was -18.000000. running mean: -18.984010\n",
            "resetting env. episode 2933.000000, reward total was -20.000000. running mean: -18.994169\n",
            "resetting env. episode 2934.000000, reward total was -18.000000. running mean: -18.984228\n",
            "resetting env. episode 2935.000000, reward total was -21.000000. running mean: -19.004385\n",
            "resetting env. episode 2936.000000, reward total was -19.000000. running mean: -19.004342\n",
            "resetting env. episode 2937.000000, reward total was -19.000000. running mean: -19.004298\n",
            "resetting env. episode 2938.000000, reward total was -19.000000. running mean: -19.004255\n",
            "resetting env. episode 2939.000000, reward total was -19.000000. running mean: -19.004213\n",
            "resetting env. episode 2940.000000, reward total was -20.000000. running mean: -19.014171\n",
            "resetting env. episode 2941.000000, reward total was -20.000000. running mean: -19.024029\n",
            "resetting env. episode 2942.000000, reward total was -20.000000. running mean: -19.033789\n",
            "resetting env. episode 2943.000000, reward total was -19.000000. running mean: -19.033451\n",
            "resetting env. episode 2944.000000, reward total was -20.000000. running mean: -19.043116\n",
            "resetting env. episode 2945.000000, reward total was -21.000000. running mean: -19.062685\n",
            "resetting env. episode 2946.000000, reward total was -20.000000. running mean: -19.072058\n",
            "resetting env. episode 2947.000000, reward total was -20.000000. running mean: -19.081338\n",
            "resetting env. episode 2948.000000, reward total was -18.000000. running mean: -19.070524\n",
            "resetting env. episode 2949.000000, reward total was -21.000000. running mean: -19.089819\n",
            "resetting env. episode 2950.000000, reward total was -21.000000. running mean: -19.108921\n",
            "resetting env. episode 2951.000000, reward total was -21.000000. running mean: -19.127832\n",
            "resetting env. episode 2952.000000, reward total was -19.000000. running mean: -19.126553\n",
            "resetting env. episode 2953.000000, reward total was -20.000000. running mean: -19.135288\n",
            "resetting env. episode 2954.000000, reward total was -19.000000. running mean: -19.133935\n",
            "resetting env. episode 2955.000000, reward total was -21.000000. running mean: -19.152595\n",
            "resetting env. episode 2956.000000, reward total was -15.000000. running mean: -19.111070\n",
            "resetting env. episode 2957.000000, reward total was -21.000000. running mean: -19.129959\n",
            "resetting env. episode 2958.000000, reward total was -21.000000. running mean: -19.148659\n",
            "resetting env. episode 2959.000000, reward total was -20.000000. running mean: -19.157173\n",
            "resetting env. episode 2960.000000, reward total was -19.000000. running mean: -19.155601\n",
            "resetting env. episode 2961.000000, reward total was -20.000000. running mean: -19.164045\n",
            "resetting env. episode 2962.000000, reward total was -19.000000. running mean: -19.162404\n",
            "resetting env. episode 2963.000000, reward total was -21.000000. running mean: -19.180780\n",
            "resetting env. episode 2964.000000, reward total was -19.000000. running mean: -19.178973\n",
            "resetting env. episode 2965.000000, reward total was -21.000000. running mean: -19.197183\n",
            "resetting env. episode 2966.000000, reward total was -20.000000. running mean: -19.205211\n",
            "resetting env. episode 2967.000000, reward total was -20.000000. running mean: -19.213159\n",
            "resetting env. episode 2968.000000, reward total was -20.000000. running mean: -19.221027\n",
            "resetting env. episode 2969.000000, reward total was -18.000000. running mean: -19.208817\n",
            "resetting env. episode 2970.000000, reward total was -21.000000. running mean: -19.226729\n",
            "resetting env. episode 2971.000000, reward total was -16.000000. running mean: -19.194462\n",
            "resetting env. episode 2972.000000, reward total was -17.000000. running mean: -19.172517\n",
            "resetting env. episode 2973.000000, reward total was -21.000000. running mean: -19.190792\n",
            "resetting env. episode 2974.000000, reward total was -19.000000. running mean: -19.188884\n",
            "resetting env. episode 2975.000000, reward total was -21.000000. running mean: -19.206995\n",
            "resetting env. episode 2976.000000, reward total was -20.000000. running mean: -19.214925\n",
            "resetting env. episode 2977.000000, reward total was -19.000000. running mean: -19.212776\n",
            "resetting env. episode 2978.000000, reward total was -21.000000. running mean: -19.230648\n",
            "resetting env. episode 2979.000000, reward total was -21.000000. running mean: -19.248342\n",
            "resetting env. episode 2980.000000, reward total was -16.000000. running mean: -19.215858\n",
            "resetting env. episode 2981.000000, reward total was -21.000000. running mean: -19.233700\n",
            "resetting env. episode 2982.000000, reward total was -21.000000. running mean: -19.251363\n",
            "resetting env. episode 2983.000000, reward total was -20.000000. running mean: -19.258849\n",
            "resetting env. episode 2984.000000, reward total was -18.000000. running mean: -19.246261\n",
            "resetting env. episode 2985.000000, reward total was -21.000000. running mean: -19.263798\n",
            "resetting env. episode 2986.000000, reward total was -19.000000. running mean: -19.261160\n",
            "resetting env. episode 2987.000000, reward total was -20.000000. running mean: -19.268548\n",
            "resetting env. episode 2988.000000, reward total was -19.000000. running mean: -19.265863\n",
            "resetting env. episode 2989.000000, reward total was -17.000000. running mean: -19.243204\n",
            "resetting env. episode 2990.000000, reward total was -17.000000. running mean: -19.220772\n",
            "resetting env. episode 2991.000000, reward total was -19.000000. running mean: -19.218564\n",
            "resetting env. episode 2992.000000, reward total was -20.000000. running mean: -19.226379\n",
            "resetting env. episode 2993.000000, reward total was -19.000000. running mean: -19.224115\n",
            "resetting env. episode 2994.000000, reward total was -20.000000. running mean: -19.231874\n",
            "resetting env. episode 2995.000000, reward total was -20.000000. running mean: -19.239555\n",
            "resetting env. episode 2996.000000, reward total was -17.000000. running mean: -19.217160\n",
            "resetting env. episode 2997.000000, reward total was -18.000000. running mean: -19.204988\n",
            "resetting env. episode 2998.000000, reward total was -20.000000. running mean: -19.212938\n",
            "resetting env. episode 2999.000000, reward total was -16.000000. running mean: -19.180809\n",
            "resetting env. episode 3000.000000, reward total was -19.000000. running mean: -19.179001\n",
            "resetting env. episode 3001.000000, reward total was -19.000000. running mean: -19.177211\n",
            "resetting env. episode 3002.000000, reward total was -21.000000. running mean: -19.195439\n",
            "resetting env. episode 3003.000000, reward total was -18.000000. running mean: -19.183484\n",
            "resetting env. episode 3004.000000, reward total was -19.000000. running mean: -19.181649\n",
            "resetting env. episode 3005.000000, reward total was -19.000000. running mean: -19.179833\n",
            "resetting env. episode 3006.000000, reward total was -18.000000. running mean: -19.168034\n",
            "resetting env. episode 3007.000000, reward total was -20.000000. running mean: -19.176354\n",
            "resetting env. episode 3008.000000, reward total was -18.000000. running mean: -19.164591\n",
            "resetting env. episode 3009.000000, reward total was -21.000000. running mean: -19.182945\n",
            "resetting env. episode 3010.000000, reward total was -19.000000. running mean: -19.181115\n",
            "resetting env. episode 3011.000000, reward total was -16.000000. running mean: -19.149304\n",
            "resetting env. episode 3012.000000, reward total was -20.000000. running mean: -19.157811\n",
            "resetting env. episode 3013.000000, reward total was -21.000000. running mean: -19.176233\n",
            "resetting env. episode 3014.000000, reward total was -19.000000. running mean: -19.174471\n",
            "resetting env. episode 3015.000000, reward total was -20.000000. running mean: -19.182726\n",
            "resetting env. episode 3016.000000, reward total was -17.000000. running mean: -19.160899\n",
            "resetting env. episode 3017.000000, reward total was -21.000000. running mean: -19.179290\n",
            "resetting env. episode 3018.000000, reward total was -18.000000. running mean: -19.167497\n",
            "resetting env. episode 3019.000000, reward total was -20.000000. running mean: -19.175822\n",
            "resetting env. episode 3020.000000, reward total was -20.000000. running mean: -19.184064\n",
            "resetting env. episode 3021.000000, reward total was -20.000000. running mean: -19.192223\n",
            "resetting env. episode 3022.000000, reward total was -21.000000. running mean: -19.210301\n",
            "resetting env. episode 3023.000000, reward total was -21.000000. running mean: -19.228198\n",
            "resetting env. episode 3024.000000, reward total was -17.000000. running mean: -19.205916\n",
            "resetting env. episode 3025.000000, reward total was -18.000000. running mean: -19.193857\n",
            "resetting env. episode 3026.000000, reward total was -20.000000. running mean: -19.201918\n",
            "resetting env. episode 3027.000000, reward total was -18.000000. running mean: -19.189899\n",
            "resetting env. episode 3028.000000, reward total was -20.000000. running mean: -19.198000\n",
            "resetting env. episode 3029.000000, reward total was -19.000000. running mean: -19.196020\n",
            "resetting env. episode 3030.000000, reward total was -17.000000. running mean: -19.174060\n",
            "resetting env. episode 3031.000000, reward total was -18.000000. running mean: -19.162319\n",
            "resetting env. episode 3032.000000, reward total was -18.000000. running mean: -19.150696\n",
            "resetting env. episode 3033.000000, reward total was -21.000000. running mean: -19.169189\n",
            "resetting env. episode 3034.000000, reward total was -19.000000. running mean: -19.167497\n",
            "resetting env. episode 3035.000000, reward total was -19.000000. running mean: -19.165822\n",
            "resetting env. episode 3036.000000, reward total was -21.000000. running mean: -19.184164\n",
            "resetting env. episode 3037.000000, reward total was -21.000000. running mean: -19.202322\n",
            "resetting env. episode 3038.000000, reward total was -21.000000. running mean: -19.220299\n",
            "resetting env. episode 3039.000000, reward total was -18.000000. running mean: -19.208096\n",
            "resetting env. episode 3040.000000, reward total was -18.000000. running mean: -19.196015\n",
            "resetting env. episode 3041.000000, reward total was -21.000000. running mean: -19.214055\n",
            "resetting env. episode 3042.000000, reward total was -20.000000. running mean: -19.221914\n",
            "resetting env. episode 3043.000000, reward total was -21.000000. running mean: -19.239695\n",
            "resetting env. episode 3044.000000, reward total was -19.000000. running mean: -19.237298\n",
            "resetting env. episode 3045.000000, reward total was -16.000000. running mean: -19.204925\n",
            "resetting env. episode 3046.000000, reward total was -18.000000. running mean: -19.192876\n",
            "resetting env. episode 3047.000000, reward total was -20.000000. running mean: -19.200947\n",
            "resetting env. episode 3048.000000, reward total was -20.000000. running mean: -19.208938\n",
            "resetting env. episode 3049.000000, reward total was -17.000000. running mean: -19.186848\n",
            "resetting env. episode 3050.000000, reward total was -17.000000. running mean: -19.164980\n",
            "resetting env. episode 3051.000000, reward total was -17.000000. running mean: -19.143330\n",
            "resetting env. episode 3052.000000, reward total was -19.000000. running mean: -19.141897\n",
            "resetting env. episode 3053.000000, reward total was -21.000000. running mean: -19.160478\n",
            "resetting env. episode 3054.000000, reward total was -21.000000. running mean: -19.178873\n",
            "resetting env. episode 3055.000000, reward total was -20.000000. running mean: -19.187084\n",
            "resetting env. episode 3056.000000, reward total was -20.000000. running mean: -19.195213\n",
            "resetting env. episode 3057.000000, reward total was -19.000000. running mean: -19.193261\n",
            "resetting env. episode 3058.000000, reward total was -20.000000. running mean: -19.201329\n",
            "resetting env. episode 3059.000000, reward total was -21.000000. running mean: -19.219315\n",
            "resetting env. episode 3060.000000, reward total was -21.000000. running mean: -19.237122\n",
            "resetting env. episode 3061.000000, reward total was -21.000000. running mean: -19.254751\n",
            "resetting env. episode 3062.000000, reward total was -19.000000. running mean: -19.252204\n",
            "resetting env. episode 3063.000000, reward total was -18.000000. running mean: -19.239682\n",
            "resetting env. episode 3064.000000, reward total was -19.000000. running mean: -19.237285\n",
            "resetting env. episode 3065.000000, reward total was -20.000000. running mean: -19.244912\n",
            "resetting env. episode 3066.000000, reward total was -19.000000. running mean: -19.242463\n",
            "resetting env. episode 3067.000000, reward total was -18.000000. running mean: -19.230038\n",
            "resetting env. episode 3068.000000, reward total was -20.000000. running mean: -19.237738\n",
            "resetting env. episode 3069.000000, reward total was -20.000000. running mean: -19.245360\n",
            "resetting env. episode 3070.000000, reward total was -17.000000. running mean: -19.222907\n",
            "resetting env. episode 3071.000000, reward total was -21.000000. running mean: -19.240678\n",
            "resetting env. episode 3072.000000, reward total was -20.000000. running mean: -19.248271\n",
            "resetting env. episode 3073.000000, reward total was -18.000000. running mean: -19.235788\n",
            "resetting env. episode 3074.000000, reward total was -20.000000. running mean: -19.243430\n",
            "resetting env. episode 3075.000000, reward total was -20.000000. running mean: -19.250996\n",
            "resetting env. episode 3076.000000, reward total was -17.000000. running mean: -19.228486\n",
            "resetting env. episode 3077.000000, reward total was -20.000000. running mean: -19.236201\n",
            "resetting env. episode 3078.000000, reward total was -21.000000. running mean: -19.253839\n",
            "resetting env. episode 3079.000000, reward total was -20.000000. running mean: -19.261301\n",
            "resetting env. episode 3080.000000, reward total was -12.000000. running mean: -19.188688\n",
            "resetting env. episode 3081.000000, reward total was -18.000000. running mean: -19.176801\n",
            "resetting env. episode 3082.000000, reward total was -19.000000. running mean: -19.175033\n",
            "resetting env. episode 3083.000000, reward total was -20.000000. running mean: -19.183283\n",
            "resetting env. episode 3084.000000, reward total was -19.000000. running mean: -19.181450\n",
            "resetting env. episode 3085.000000, reward total was -19.000000. running mean: -19.179635\n",
            "resetting env. episode 3086.000000, reward total was -16.000000. running mean: -19.147839\n",
            "resetting env. episode 3087.000000, reward total was -17.000000. running mean: -19.126360\n",
            "resetting env. episode 3088.000000, reward total was -21.000000. running mean: -19.145097\n",
            "resetting env. episode 3089.000000, reward total was -20.000000. running mean: -19.153646\n",
            "resetting env. episode 3090.000000, reward total was -19.000000. running mean: -19.152109\n",
            "resetting env. episode 3091.000000, reward total was -19.000000. running mean: -19.150588\n",
            "resetting env. episode 3092.000000, reward total was -21.000000. running mean: -19.169082\n",
            "resetting env. episode 3093.000000, reward total was -16.000000. running mean: -19.137392\n",
            "resetting env. episode 3094.000000, reward total was -21.000000. running mean: -19.156018\n",
            "resetting env. episode 3095.000000, reward total was -19.000000. running mean: -19.154458\n",
            "resetting env. episode 3096.000000, reward total was -20.000000. running mean: -19.162913\n",
            "resetting env. episode 3097.000000, reward total was -19.000000. running mean: -19.161284\n",
            "resetting env. episode 3098.000000, reward total was -21.000000. running mean: -19.179671\n",
            "resetting env. episode 3099.000000, reward total was -17.000000. running mean: -19.157874\n",
            "resetting env. episode 3100.000000, reward total was -21.000000. running mean: -19.176296\n",
            "resetting env. episode 3101.000000, reward total was -20.000000. running mean: -19.184533\n",
            "resetting env. episode 3102.000000, reward total was -20.000000. running mean: -19.192687\n",
            "resetting env. episode 3103.000000, reward total was -20.000000. running mean: -19.200760\n",
            "resetting env. episode 3104.000000, reward total was -18.000000. running mean: -19.188753\n",
            "resetting env. episode 3105.000000, reward total was -17.000000. running mean: -19.166865\n",
            "resetting env. episode 3106.000000, reward total was -18.000000. running mean: -19.155197\n",
            "resetting env. episode 3107.000000, reward total was -16.000000. running mean: -19.123645\n",
            "resetting env. episode 3108.000000, reward total was -19.000000. running mean: -19.122408\n",
            "resetting env. episode 3109.000000, reward total was -20.000000. running mean: -19.131184\n",
            "resetting env. episode 3110.000000, reward total was -19.000000. running mean: -19.129872\n",
            "resetting env. episode 3111.000000, reward total was -19.000000. running mean: -19.128574\n",
            "resetting env. episode 3112.000000, reward total was -21.000000. running mean: -19.147288\n",
            "resetting env. episode 3113.000000, reward total was -17.000000. running mean: -19.125815\n",
            "resetting env. episode 3114.000000, reward total was -19.000000. running mean: -19.124557\n",
            "resetting env. episode 3115.000000, reward total was -18.000000. running mean: -19.113311\n",
            "resetting env. episode 3116.000000, reward total was -18.000000. running mean: -19.102178\n",
            "resetting env. episode 3117.000000, reward total was -18.000000. running mean: -19.091156\n",
            "resetting env. episode 3118.000000, reward total was -17.000000. running mean: -19.070245\n",
            "resetting env. episode 3119.000000, reward total was -20.000000. running mean: -19.079542\n",
            "resetting env. episode 3120.000000, reward total was -19.000000. running mean: -19.078747\n",
            "resetting env. episode 3121.000000, reward total was -13.000000. running mean: -19.017959\n",
            "resetting env. episode 3122.000000, reward total was -19.000000. running mean: -19.017780\n",
            "resetting env. episode 3123.000000, reward total was -17.000000. running mean: -18.997602\n",
            "resetting env. episode 3124.000000, reward total was -20.000000. running mean: -19.007626\n",
            "resetting env. episode 3125.000000, reward total was -21.000000. running mean: -19.027550\n",
            "resetting env. episode 3126.000000, reward total was -21.000000. running mean: -19.047274\n",
            "resetting env. episode 3127.000000, reward total was -19.000000. running mean: -19.046802\n",
            "resetting env. episode 3128.000000, reward total was -20.000000. running mean: -19.056334\n",
            "resetting env. episode 3129.000000, reward total was -20.000000. running mean: -19.065770\n",
            "resetting env. episode 3130.000000, reward total was -21.000000. running mean: -19.085112\n",
            "resetting env. episode 3131.000000, reward total was -19.000000. running mean: -19.084261\n",
            "resetting env. episode 3132.000000, reward total was -20.000000. running mean: -19.093419\n",
            "resetting env. episode 3133.000000, reward total was -21.000000. running mean: -19.112485\n",
            "resetting env. episode 3134.000000, reward total was -17.000000. running mean: -19.091360\n",
            "resetting env. episode 3135.000000, reward total was -17.000000. running mean: -19.070446\n",
            "resetting env. episode 3136.000000, reward total was -19.000000. running mean: -19.069742\n",
            "resetting env. episode 3137.000000, reward total was -19.000000. running mean: -19.069044\n",
            "resetting env. episode 3138.000000, reward total was -18.000000. running mean: -19.058354\n",
            "resetting env. episode 3139.000000, reward total was -19.000000. running mean: -19.057770\n",
            "resetting env. episode 3140.000000, reward total was -17.000000. running mean: -19.037193\n",
            "resetting env. episode 3141.000000, reward total was -21.000000. running mean: -19.056821\n",
            "resetting env. episode 3142.000000, reward total was -19.000000. running mean: -19.056252\n",
            "resetting env. episode 3143.000000, reward total was -19.000000. running mean: -19.055690\n",
            "resetting env. episode 3144.000000, reward total was -20.000000. running mean: -19.065133\n",
            "resetting env. episode 3145.000000, reward total was -18.000000. running mean: -19.054482\n",
            "resetting env. episode 3146.000000, reward total was -20.000000. running mean: -19.063937\n",
            "resetting env. episode 3147.000000, reward total was -18.000000. running mean: -19.053297\n",
            "resetting env. episode 3148.000000, reward total was -21.000000. running mean: -19.072764\n",
            "resetting env. episode 3149.000000, reward total was -16.000000. running mean: -19.042037\n",
            "resetting env. episode 3150.000000, reward total was -19.000000. running mean: -19.041616\n",
            "resetting env. episode 3151.000000, reward total was -21.000000. running mean: -19.061200\n",
            "resetting env. episode 3152.000000, reward total was -17.000000. running mean: -19.040588\n",
            "resetting env. episode 3153.000000, reward total was -19.000000. running mean: -19.040182\n",
            "resetting env. episode 3154.000000, reward total was -18.000000. running mean: -19.029781\n",
            "resetting env. episode 3155.000000, reward total was -21.000000. running mean: -19.049483\n",
            "resetting env. episode 3156.000000, reward total was -20.000000. running mean: -19.058988\n",
            "resetting env. episode 3157.000000, reward total was -21.000000. running mean: -19.078398\n",
            "resetting env. episode 3158.000000, reward total was -17.000000. running mean: -19.057614\n",
            "resetting env. episode 3159.000000, reward total was -17.000000. running mean: -19.037038\n",
            "resetting env. episode 3160.000000, reward total was -17.000000. running mean: -19.016668\n",
            "resetting env. episode 3161.000000, reward total was -20.000000. running mean: -19.026501\n",
            "resetting env. episode 3162.000000, reward total was -19.000000. running mean: -19.026236\n",
            "resetting env. episode 3163.000000, reward total was -18.000000. running mean: -19.015974\n",
            "resetting env. episode 3164.000000, reward total was -21.000000. running mean: -19.035814\n",
            "resetting env. episode 3165.000000, reward total was -21.000000. running mean: -19.055456\n",
            "resetting env. episode 3166.000000, reward total was -21.000000. running mean: -19.074901\n",
            "resetting env. episode 3167.000000, reward total was -21.000000. running mean: -19.094152\n",
            "resetting env. episode 3168.000000, reward total was -21.000000. running mean: -19.113211\n",
            "resetting env. episode 3169.000000, reward total was -20.000000. running mean: -19.122078\n",
            "resetting env. episode 3170.000000, reward total was -21.000000. running mean: -19.140858\n",
            "resetting env. episode 3171.000000, reward total was -17.000000. running mean: -19.119449\n",
            "resetting env. episode 3172.000000, reward total was -19.000000. running mean: -19.118255\n",
            "resetting env. episode 3173.000000, reward total was -20.000000. running mean: -19.127072\n",
            "resetting env. episode 3174.000000, reward total was -20.000000. running mean: -19.135801\n",
            "resetting env. episode 3175.000000, reward total was -19.000000. running mean: -19.134443\n",
            "resetting env. episode 3176.000000, reward total was -21.000000. running mean: -19.153099\n",
            "resetting env. episode 3177.000000, reward total was -19.000000. running mean: -19.151568\n",
            "resetting env. episode 3178.000000, reward total was -21.000000. running mean: -19.170052\n",
            "resetting env. episode 3179.000000, reward total was -20.000000. running mean: -19.178352\n",
            "resetting env. episode 3180.000000, reward total was -21.000000. running mean: -19.196568\n",
            "resetting env. episode 3181.000000, reward total was -20.000000. running mean: -19.204603\n",
            "resetting env. episode 3182.000000, reward total was -18.000000. running mean: -19.192556\n",
            "resetting env. episode 3183.000000, reward total was -20.000000. running mean: -19.200631\n",
            "resetting env. episode 3184.000000, reward total was -21.000000. running mean: -19.218625\n",
            "resetting env. episode 3185.000000, reward total was -21.000000. running mean: -19.236438\n",
            "resetting env. episode 3186.000000, reward total was -20.000000. running mean: -19.244074\n",
            "resetting env. episode 3187.000000, reward total was -21.000000. running mean: -19.261633\n",
            "resetting env. episode 3188.000000, reward total was -16.000000. running mean: -19.229017\n",
            "resetting env. episode 3189.000000, reward total was -14.000000. running mean: -19.176727\n",
            "resetting env. episode 3190.000000, reward total was -17.000000. running mean: -19.154959\n",
            "resetting env. episode 3191.000000, reward total was -20.000000. running mean: -19.163410\n",
            "resetting env. episode 3192.000000, reward total was -19.000000. running mean: -19.161776\n",
            "resetting env. episode 3193.000000, reward total was -20.000000. running mean: -19.170158\n",
            "resetting env. episode 3194.000000, reward total was -18.000000. running mean: -19.158456\n",
            "resetting env. episode 3195.000000, reward total was -21.000000. running mean: -19.176872\n",
            "resetting env. episode 3196.000000, reward total was -19.000000. running mean: -19.175103\n",
            "resetting env. episode 3197.000000, reward total was -21.000000. running mean: -19.193352\n",
            "resetting env. episode 3198.000000, reward total was -19.000000. running mean: -19.191419\n",
            "resetting env. episode 3199.000000, reward total was -20.000000. running mean: -19.199504\n",
            "resetting env. episode 3200.000000, reward total was -21.000000. running mean: -19.217509\n",
            "resetting env. episode 3201.000000, reward total was -21.000000. running mean: -19.235334\n",
            "resetting env. episode 3202.000000, reward total was -18.000000. running mean: -19.222981\n",
            "resetting env. episode 3203.000000, reward total was -18.000000. running mean: -19.210751\n",
            "resetting env. episode 3204.000000, reward total was -17.000000. running mean: -19.188644\n",
            "resetting env. episode 3205.000000, reward total was -19.000000. running mean: -19.186757\n",
            "resetting env. episode 3206.000000, reward total was -18.000000. running mean: -19.174890\n",
            "resetting env. episode 3207.000000, reward total was -20.000000. running mean: -19.183141\n",
            "resetting env. episode 3208.000000, reward total was -20.000000. running mean: -19.191309\n",
            "resetting env. episode 3209.000000, reward total was -18.000000. running mean: -19.179396\n",
            "resetting env. episode 3210.000000, reward total was -19.000000. running mean: -19.177602\n",
            "resetting env. episode 3211.000000, reward total was -20.000000. running mean: -19.185826\n",
            "resetting env. episode 3212.000000, reward total was -18.000000. running mean: -19.173968\n",
            "resetting env. episode 3213.000000, reward total was -17.000000. running mean: -19.152228\n",
            "resetting env. episode 3214.000000, reward total was -20.000000. running mean: -19.160706\n",
            "resetting env. episode 3215.000000, reward total was -19.000000. running mean: -19.159099\n",
            "resetting env. episode 3216.000000, reward total was -19.000000. running mean: -19.157508\n",
            "resetting env. episode 3217.000000, reward total was -21.000000. running mean: -19.175933\n",
            "resetting env. episode 3218.000000, reward total was -21.000000. running mean: -19.194174\n",
            "resetting env. episode 3219.000000, reward total was -18.000000. running mean: -19.182232\n",
            "resetting env. episode 3220.000000, reward total was -20.000000. running mean: -19.190410\n",
            "resetting env. episode 3221.000000, reward total was -16.000000. running mean: -19.158505\n",
            "resetting env. episode 3222.000000, reward total was -17.000000. running mean: -19.136920\n",
            "resetting env. episode 3223.000000, reward total was -21.000000. running mean: -19.155551\n",
            "resetting env. episode 3224.000000, reward total was -16.000000. running mean: -19.123996\n",
            "resetting env. episode 3225.000000, reward total was -21.000000. running mean: -19.142756\n",
            "resetting env. episode 3226.000000, reward total was -20.000000. running mean: -19.151328\n",
            "resetting env. episode 3227.000000, reward total was -21.000000. running mean: -19.169815\n",
            "resetting env. episode 3228.000000, reward total was -18.000000. running mean: -19.158117\n",
            "resetting env. episode 3229.000000, reward total was -20.000000. running mean: -19.166536\n",
            "resetting env. episode 3230.000000, reward total was -20.000000. running mean: -19.174870\n",
            "resetting env. episode 3231.000000, reward total was -19.000000. running mean: -19.173121\n",
            "resetting env. episode 3232.000000, reward total was -17.000000. running mean: -19.151390\n",
            "resetting env. episode 3233.000000, reward total was -20.000000. running mean: -19.159876\n",
            "resetting env. episode 3234.000000, reward total was -19.000000. running mean: -19.158278\n",
            "resetting env. episode 3235.000000, reward total was -18.000000. running mean: -19.146695\n",
            "resetting env. episode 3236.000000, reward total was -18.000000. running mean: -19.135228\n",
            "resetting env. episode 3237.000000, reward total was -18.000000. running mean: -19.123876\n",
            "resetting env. episode 3238.000000, reward total was -20.000000. running mean: -19.132637\n",
            "resetting env. episode 3239.000000, reward total was -17.000000. running mean: -19.111310\n",
            "resetting env. episode 3240.000000, reward total was -21.000000. running mean: -19.130197\n",
            "resetting env. episode 3241.000000, reward total was -19.000000. running mean: -19.128895\n",
            "resetting env. episode 3242.000000, reward total was -18.000000. running mean: -19.117606\n",
            "resetting env. episode 3243.000000, reward total was -19.000000. running mean: -19.116430\n",
            "resetting env. episode 3244.000000, reward total was -17.000000. running mean: -19.095266\n",
            "resetting env. episode 3245.000000, reward total was -17.000000. running mean: -19.074313\n",
            "resetting env. episode 3246.000000, reward total was -19.000000. running mean: -19.073570\n",
            "resetting env. episode 3247.000000, reward total was -21.000000. running mean: -19.092835\n",
            "resetting env. episode 3248.000000, reward total was -20.000000. running mean: -19.101906\n",
            "resetting env. episode 3249.000000, reward total was -19.000000. running mean: -19.100887\n",
            "resetting env. episode 3250.000000, reward total was -19.000000. running mean: -19.099878\n",
            "resetting env. episode 3251.000000, reward total was -21.000000. running mean: -19.118880\n",
            "resetting env. episode 3252.000000, reward total was -21.000000. running mean: -19.137691\n",
            "resetting env. episode 3253.000000, reward total was -17.000000. running mean: -19.116314\n",
            "resetting env. episode 3254.000000, reward total was -19.000000. running mean: -19.115151\n",
            "resetting env. episode 3255.000000, reward total was -21.000000. running mean: -19.133999\n",
            "resetting env. episode 3256.000000, reward total was -20.000000. running mean: -19.142659\n",
            "resetting env. episode 3257.000000, reward total was -17.000000. running mean: -19.121233\n",
            "resetting env. episode 3258.000000, reward total was -20.000000. running mean: -19.130020\n",
            "resetting env. episode 3259.000000, reward total was -18.000000. running mean: -19.118720\n",
            "resetting env. episode 3260.000000, reward total was -20.000000. running mean: -19.127533\n",
            "resetting env. episode 3261.000000, reward total was -18.000000. running mean: -19.116258\n",
            "resetting env. episode 3262.000000, reward total was -20.000000. running mean: -19.125095\n",
            "resetting env. episode 3263.000000, reward total was -17.000000. running mean: -19.103844\n",
            "resetting env. episode 3264.000000, reward total was -20.000000. running mean: -19.112806\n",
            "resetting env. episode 3265.000000, reward total was -21.000000. running mean: -19.131677\n",
            "resetting env. episode 3266.000000, reward total was -17.000000. running mean: -19.110361\n",
            "resetting env. episode 3267.000000, reward total was -19.000000. running mean: -19.109257\n",
            "resetting env. episode 3268.000000, reward total was -16.000000. running mean: -19.078165\n",
            "resetting env. episode 3269.000000, reward total was -16.000000. running mean: -19.047383\n",
            "resetting env. episode 3270.000000, reward total was -17.000000. running mean: -19.026909\n",
            "resetting env. episode 3271.000000, reward total was -18.000000. running mean: -19.016640\n",
            "resetting env. episode 3272.000000, reward total was -19.000000. running mean: -19.016474\n",
            "resetting env. episode 3273.000000, reward total was -20.000000. running mean: -19.026309\n",
            "resetting env. episode 3274.000000, reward total was -19.000000. running mean: -19.026046\n",
            "resetting env. episode 3275.000000, reward total was -20.000000. running mean: -19.035785\n",
            "resetting env. episode 3276.000000, reward total was -19.000000. running mean: -19.035427\n",
            "resetting env. episode 3277.000000, reward total was -18.000000. running mean: -19.025073\n",
            "resetting env. episode 3278.000000, reward total was -20.000000. running mean: -19.034822\n",
            "resetting env. episode 3279.000000, reward total was -19.000000. running mean: -19.034474\n",
            "resetting env. episode 3280.000000, reward total was -21.000000. running mean: -19.054129\n",
            "resetting env. episode 3281.000000, reward total was -19.000000. running mean: -19.053588\n",
            "resetting env. episode 3282.000000, reward total was -19.000000. running mean: -19.053052\n",
            "resetting env. episode 3283.000000, reward total was -18.000000. running mean: -19.042522\n",
            "resetting env. episode 3284.000000, reward total was -19.000000. running mean: -19.042097\n",
            "resetting env. episode 3285.000000, reward total was -15.000000. running mean: -19.001676\n",
            "resetting env. episode 3286.000000, reward total was -18.000000. running mean: -18.991659\n",
            "resetting env. episode 3287.000000, reward total was -20.000000. running mean: -19.001742\n",
            "resetting env. episode 3288.000000, reward total was -19.000000. running mean: -19.001725\n",
            "resetting env. episode 3289.000000, reward total was -17.000000. running mean: -18.981708\n",
            "resetting env. episode 3290.000000, reward total was -21.000000. running mean: -19.001890\n",
            "resetting env. episode 3291.000000, reward total was -17.000000. running mean: -18.981872\n",
            "resetting env. episode 3292.000000, reward total was -20.000000. running mean: -18.992053\n",
            "resetting env. episode 3293.000000, reward total was -20.000000. running mean: -19.002132\n",
            "resetting env. episode 3294.000000, reward total was -17.000000. running mean: -18.982111\n",
            "resetting env. episode 3295.000000, reward total was -21.000000. running mean: -19.002290\n",
            "resetting env. episode 3296.000000, reward total was -21.000000. running mean: -19.022267\n",
            "resetting env. episode 3297.000000, reward total was -20.000000. running mean: -19.032044\n",
            "resetting env. episode 3298.000000, reward total was -20.000000. running mean: -19.041724\n",
            "resetting env. episode 3299.000000, reward total was -19.000000. running mean: -19.041307\n",
            "resetting env. episode 3300.000000, reward total was -18.000000. running mean: -19.030894\n",
            "resetting env. episode 3301.000000, reward total was -21.000000. running mean: -19.050585\n",
            "resetting env. episode 3302.000000, reward total was -20.000000. running mean: -19.060079\n",
            "resetting env. episode 3303.000000, reward total was -19.000000. running mean: -19.059478\n",
            "resetting env. episode 3304.000000, reward total was -20.000000. running mean: -19.068883\n",
            "resetting env. episode 3305.000000, reward total was -16.000000. running mean: -19.038194\n",
            "resetting env. episode 3306.000000, reward total was -21.000000. running mean: -19.057812\n",
            "resetting env. episode 3307.000000, reward total was -20.000000. running mean: -19.067234\n",
            "resetting env. episode 3308.000000, reward total was -20.000000. running mean: -19.076562\n",
            "resetting env. episode 3309.000000, reward total was -18.000000. running mean: -19.065796\n",
            "resetting env. episode 3310.000000, reward total was -21.000000. running mean: -19.085138\n",
            "resetting env. episode 3311.000000, reward total was -19.000000. running mean: -19.084287\n",
            "resetting env. episode 3312.000000, reward total was -21.000000. running mean: -19.103444\n",
            "resetting env. episode 3313.000000, reward total was -21.000000. running mean: -19.122410\n",
            "resetting env. episode 3314.000000, reward total was -21.000000. running mean: -19.141186\n",
            "resetting env. episode 3315.000000, reward total was -17.000000. running mean: -19.119774\n",
            "resetting env. episode 3316.000000, reward total was -18.000000. running mean: -19.108576\n",
            "resetting env. episode 3317.000000, reward total was -21.000000. running mean: -19.127490\n",
            "resetting env. episode 3318.000000, reward total was -21.000000. running mean: -19.146215\n",
            "resetting env. episode 3319.000000, reward total was -18.000000. running mean: -19.134753\n",
            "resetting env. episode 3320.000000, reward total was -20.000000. running mean: -19.143406\n",
            "resetting env. episode 3321.000000, reward total was -20.000000. running mean: -19.151972\n",
            "resetting env. episode 3322.000000, reward total was -19.000000. running mean: -19.150452\n",
            "resetting env. episode 3323.000000, reward total was -19.000000. running mean: -19.148947\n",
            "resetting env. episode 3324.000000, reward total was -19.000000. running mean: -19.147458\n",
            "resetting env. episode 3325.000000, reward total was -18.000000. running mean: -19.135983\n",
            "resetting env. episode 3326.000000, reward total was -19.000000. running mean: -19.134624\n",
            "resetting env. episode 3327.000000, reward total was -20.000000. running mean: -19.143277\n",
            "resetting env. episode 3328.000000, reward total was -21.000000. running mean: -19.161844\n",
            "resetting env. episode 3329.000000, reward total was -19.000000. running mean: -19.160226\n",
            "resetting env. episode 3330.000000, reward total was -17.000000. running mean: -19.138624\n",
            "resetting env. episode 3331.000000, reward total was -18.000000. running mean: -19.127238\n",
            "resetting env. episode 3332.000000, reward total was -18.000000. running mean: -19.115965\n",
            "resetting env. episode 3333.000000, reward total was -18.000000. running mean: -19.104806\n",
            "resetting env. episode 3334.000000, reward total was -20.000000. running mean: -19.113757\n",
            "resetting env. episode 3335.000000, reward total was -16.000000. running mean: -19.082620\n",
            "resetting env. episode 3336.000000, reward total was -20.000000. running mean: -19.091794\n",
            "resetting env. episode 3337.000000, reward total was -19.000000. running mean: -19.090876\n",
            "resetting env. episode 3338.000000, reward total was -18.000000. running mean: -19.079967\n",
            "resetting env. episode 3339.000000, reward total was -19.000000. running mean: -19.079167\n",
            "resetting env. episode 3340.000000, reward total was -17.000000. running mean: -19.058376\n",
            "resetting env. episode 3341.000000, reward total was -17.000000. running mean: -19.037792\n",
            "resetting env. episode 3342.000000, reward total was -21.000000. running mean: -19.057414\n",
            "resetting env. episode 3343.000000, reward total was -19.000000. running mean: -19.056840\n",
            "resetting env. episode 3344.000000, reward total was -21.000000. running mean: -19.076271\n",
            "resetting env. episode 3345.000000, reward total was -21.000000. running mean: -19.095509\n",
            "resetting env. episode 3346.000000, reward total was -17.000000. running mean: -19.074554\n",
            "resetting env. episode 3347.000000, reward total was -19.000000. running mean: -19.073808\n",
            "resetting env. episode 3348.000000, reward total was -17.000000. running mean: -19.053070\n",
            "resetting env. episode 3349.000000, reward total was -20.000000. running mean: -19.062539\n",
            "resetting env. episode 3350.000000, reward total was -21.000000. running mean: -19.081914\n",
            "resetting env. episode 3351.000000, reward total was -19.000000. running mean: -19.081095\n",
            "resetting env. episode 3352.000000, reward total was -16.000000. running mean: -19.050284\n",
            "resetting env. episode 3353.000000, reward total was -19.000000. running mean: -19.049781\n",
            "resetting env. episode 3354.000000, reward total was -16.000000. running mean: -19.019283\n",
            "resetting env. episode 3355.000000, reward total was -18.000000. running mean: -19.009090\n",
            "resetting env. episode 3356.000000, reward total was -19.000000. running mean: -19.008999\n",
            "resetting env. episode 3357.000000, reward total was -20.000000. running mean: -19.018909\n",
            "resetting env. episode 3358.000000, reward total was -18.000000. running mean: -19.008720\n",
            "resetting env. episode 3359.000000, reward total was -17.000000. running mean: -18.988633\n",
            "resetting env. episode 3360.000000, reward total was -16.000000. running mean: -18.958747\n",
            "resetting env. episode 3361.000000, reward total was -20.000000. running mean: -18.969159\n",
            "resetting env. episode 3362.000000, reward total was -20.000000. running mean: -18.979468\n",
            "resetting env. episode 3363.000000, reward total was -19.000000. running mean: -18.979673\n",
            "resetting env. episode 3364.000000, reward total was -19.000000. running mean: -18.979876\n",
            "resetting env. episode 3365.000000, reward total was -18.000000. running mean: -18.970078\n",
            "resetting env. episode 3366.000000, reward total was -21.000000. running mean: -18.990377\n",
            "resetting env. episode 3367.000000, reward total was -19.000000. running mean: -18.990473\n",
            "resetting env. episode 3368.000000, reward total was -19.000000. running mean: -18.990568\n",
            "resetting env. episode 3369.000000, reward total was -19.000000. running mean: -18.990663\n",
            "resetting env. episode 3370.000000, reward total was -19.000000. running mean: -18.990756\n",
            "resetting env. episode 3371.000000, reward total was -20.000000. running mean: -19.000848\n",
            "resetting env. episode 3372.000000, reward total was -18.000000. running mean: -18.990840\n",
            "resetting env. episode 3373.000000, reward total was -16.000000. running mean: -18.960932\n",
            "resetting env. episode 3374.000000, reward total was -21.000000. running mean: -18.981322\n",
            "resetting env. episode 3375.000000, reward total was -16.000000. running mean: -18.951509\n",
            "resetting env. episode 3376.000000, reward total was -20.000000. running mean: -18.961994\n",
            "resetting env. episode 3377.000000, reward total was -18.000000. running mean: -18.952374\n",
            "resetting env. episode 3378.000000, reward total was -20.000000. running mean: -18.962850\n",
            "resetting env. episode 3379.000000, reward total was -17.000000. running mean: -18.943222\n",
            "resetting env. episode 3380.000000, reward total was -20.000000. running mean: -18.953790\n",
            "resetting env. episode 3381.000000, reward total was -18.000000. running mean: -18.944252\n",
            "resetting env. episode 3382.000000, reward total was -20.000000. running mean: -18.954809\n",
            "resetting env. episode 3383.000000, reward total was -17.000000. running mean: -18.935261\n",
            "resetting env. episode 3384.000000, reward total was -19.000000. running mean: -18.935908\n",
            "resetting env. episode 3385.000000, reward total was -20.000000. running mean: -18.946549\n",
            "resetting env. episode 3386.000000, reward total was -20.000000. running mean: -18.957084\n",
            "resetting env. episode 3387.000000, reward total was -19.000000. running mean: -18.957513\n",
            "resetting env. episode 3388.000000, reward total was -16.000000. running mean: -18.927938\n",
            "resetting env. episode 3389.000000, reward total was -17.000000. running mean: -18.908659\n",
            "resetting env. episode 3390.000000, reward total was -19.000000. running mean: -18.909572\n",
            "resetting env. episode 3391.000000, reward total was -19.000000. running mean: -18.910476\n",
            "resetting env. episode 3392.000000, reward total was -21.000000. running mean: -18.931371\n",
            "resetting env. episode 3393.000000, reward total was -21.000000. running mean: -18.952058\n",
            "resetting env. episode 3394.000000, reward total was -16.000000. running mean: -18.922537\n",
            "resetting env. episode 3395.000000, reward total was -20.000000. running mean: -18.933312\n",
            "resetting env. episode 3396.000000, reward total was -20.000000. running mean: -18.943979\n",
            "resetting env. episode 3397.000000, reward total was -16.000000. running mean: -18.914539\n",
            "resetting env. episode 3398.000000, reward total was -21.000000. running mean: -18.935393\n",
            "resetting env. episode 3399.000000, reward total was -21.000000. running mean: -18.956040\n",
            "resetting env. episode 3400.000000, reward total was -20.000000. running mean: -18.966479\n",
            "resetting env. episode 3401.000000, reward total was -19.000000. running mean: -18.966814\n",
            "resetting env. episode 3402.000000, reward total was -18.000000. running mean: -18.957146\n",
            "resetting env. episode 3403.000000, reward total was -21.000000. running mean: -18.977575\n",
            "resetting env. episode 3404.000000, reward total was -19.000000. running mean: -18.977799\n",
            "resetting env. episode 3405.000000, reward total was -20.000000. running mean: -18.988021\n",
            "resetting env. episode 3406.000000, reward total was -19.000000. running mean: -18.988141\n",
            "resetting env. episode 3407.000000, reward total was -19.000000. running mean: -18.988259\n",
            "resetting env. episode 3408.000000, reward total was -19.000000. running mean: -18.988377\n",
            "resetting env. episode 3409.000000, reward total was -17.000000. running mean: -18.968493\n",
            "resetting env. episode 3410.000000, reward total was -19.000000. running mean: -18.968808\n",
            "resetting env. episode 3411.000000, reward total was -18.000000. running mean: -18.959120\n",
            "resetting env. episode 3412.000000, reward total was -20.000000. running mean: -18.969529\n",
            "resetting env. episode 3413.000000, reward total was -19.000000. running mean: -18.969834\n",
            "resetting env. episode 3414.000000, reward total was -18.000000. running mean: -18.960135\n",
            "resetting env. episode 3415.000000, reward total was -21.000000. running mean: -18.980534\n",
            "resetting env. episode 3416.000000, reward total was -21.000000. running mean: -19.000729\n",
            "resetting env. episode 3417.000000, reward total was -17.000000. running mean: -18.980721\n",
            "resetting env. episode 3418.000000, reward total was -20.000000. running mean: -18.990914\n",
            "resetting env. episode 3419.000000, reward total was -20.000000. running mean: -19.001005\n",
            "resetting env. episode 3420.000000, reward total was -19.000000. running mean: -19.000995\n",
            "resetting env. episode 3421.000000, reward total was -21.000000. running mean: -19.020985\n",
            "resetting env. episode 3422.000000, reward total was -21.000000. running mean: -19.040775\n",
            "resetting env. episode 3423.000000, reward total was -18.000000. running mean: -19.030367\n",
            "resetting env. episode 3424.000000, reward total was -20.000000. running mean: -19.040064\n",
            "resetting env. episode 3425.000000, reward total was -18.000000. running mean: -19.029663\n",
            "resetting env. episode 3426.000000, reward total was -19.000000. running mean: -19.029366\n",
            "resetting env. episode 3427.000000, reward total was -19.000000. running mean: -19.029073\n",
            "resetting env. episode 3428.000000, reward total was -21.000000. running mean: -19.048782\n",
            "resetting env. episode 3429.000000, reward total was -19.000000. running mean: -19.048294\n",
            "resetting env. episode 3430.000000, reward total was -19.000000. running mean: -19.047811\n",
            "resetting env. episode 3431.000000, reward total was -19.000000. running mean: -19.047333\n",
            "resetting env. episode 3432.000000, reward total was -13.000000. running mean: -18.986860\n",
            "resetting env. episode 3433.000000, reward total was -19.000000. running mean: -18.986991\n",
            "resetting env. episode 3434.000000, reward total was -18.000000. running mean: -18.977121\n",
            "resetting env. episode 3435.000000, reward total was -19.000000. running mean: -18.977350\n",
            "resetting env. episode 3436.000000, reward total was -20.000000. running mean: -18.987577\n",
            "resetting env. episode 3437.000000, reward total was -17.000000. running mean: -18.967701\n",
            "resetting env. episode 3438.000000, reward total was -19.000000. running mean: -18.968024\n",
            "resetting env. episode 3439.000000, reward total was -21.000000. running mean: -18.988344\n",
            "resetting env. episode 3440.000000, reward total was -20.000000. running mean: -18.998460\n",
            "resetting env. episode 3441.000000, reward total was -17.000000. running mean: -18.978475\n",
            "resetting env. episode 3442.000000, reward total was -14.000000. running mean: -18.928691\n",
            "resetting env. episode 3443.000000, reward total was -17.000000. running mean: -18.909404\n",
            "resetting env. episode 3444.000000, reward total was -18.000000. running mean: -18.900310\n",
            "resetting env. episode 3445.000000, reward total was -17.000000. running mean: -18.881307\n",
            "resetting env. episode 3446.000000, reward total was -21.000000. running mean: -18.902494\n",
            "resetting env. episode 3447.000000, reward total was -19.000000. running mean: -18.903469\n",
            "resetting env. episode 3448.000000, reward total was -20.000000. running mean: -18.914434\n",
            "resetting env. episode 3449.000000, reward total was -17.000000. running mean: -18.895290\n",
            "resetting env. episode 3450.000000, reward total was -20.000000. running mean: -18.906337\n",
            "resetting env. episode 3451.000000, reward total was -18.000000. running mean: -18.897273\n",
            "resetting env. episode 3452.000000, reward total was -19.000000. running mean: -18.898301\n",
            "resetting env. episode 3453.000000, reward total was -19.000000. running mean: -18.899318\n",
            "resetting env. episode 3454.000000, reward total was -19.000000. running mean: -18.900324\n",
            "resetting env. episode 3455.000000, reward total was -19.000000. running mean: -18.901321\n",
            "resetting env. episode 3456.000000, reward total was -20.000000. running mean: -18.912308\n",
            "resetting env. episode 3457.000000, reward total was -20.000000. running mean: -18.923185\n",
            "resetting env. episode 3458.000000, reward total was -19.000000. running mean: -18.923953\n",
            "resetting env. episode 3459.000000, reward total was -18.000000. running mean: -18.914714\n",
            "resetting env. episode 3460.000000, reward total was -19.000000. running mean: -18.915566\n",
            "resetting env. episode 3461.000000, reward total was -19.000000. running mean: -18.916411\n",
            "resetting env. episode 3462.000000, reward total was -19.000000. running mean: -18.917247\n",
            "resetting env. episode 3463.000000, reward total was -19.000000. running mean: -18.918074\n",
            "resetting env. episode 3464.000000, reward total was -16.000000. running mean: -18.888893\n",
            "resetting env. episode 3465.000000, reward total was -20.000000. running mean: -18.900005\n",
            "resetting env. episode 3466.000000, reward total was -18.000000. running mean: -18.891004\n",
            "resetting env. episode 3467.000000, reward total was -19.000000. running mean: -18.892094\n",
            "resetting env. episode 3468.000000, reward total was -19.000000. running mean: -18.893173\n",
            "resetting env. episode 3469.000000, reward total was -17.000000. running mean: -18.874242\n",
            "resetting env. episode 3470.000000, reward total was -21.000000. running mean: -18.895499\n",
            "resetting env. episode 3471.000000, reward total was -21.000000. running mean: -18.916544\n",
            "resetting env. episode 3472.000000, reward total was -19.000000. running mean: -18.917379\n",
            "resetting env. episode 3473.000000, reward total was -19.000000. running mean: -18.918205\n",
            "resetting env. episode 3474.000000, reward total was -20.000000. running mean: -18.929023\n",
            "resetting env. episode 3475.000000, reward total was -20.000000. running mean: -18.939733\n",
            "resetting env. episode 3476.000000, reward total was -19.000000. running mean: -18.940335\n",
            "resetting env. episode 3477.000000, reward total was -17.000000. running mean: -18.920932\n",
            "resetting env. episode 3478.000000, reward total was -21.000000. running mean: -18.941723\n",
            "resetting env. episode 3479.000000, reward total was -17.000000. running mean: -18.922306\n",
            "resetting env. episode 3480.000000, reward total was -21.000000. running mean: -18.943083\n",
            "resetting env. episode 3481.000000, reward total was -20.000000. running mean: -18.953652\n",
            "resetting env. episode 3482.000000, reward total was -19.000000. running mean: -18.954115\n",
            "resetting env. episode 3483.000000, reward total was -20.000000. running mean: -18.964574\n",
            "resetting env. episode 3484.000000, reward total was -20.000000. running mean: -18.974928\n",
            "resetting env. episode 3485.000000, reward total was -19.000000. running mean: -18.975179\n",
            "resetting env. episode 3486.000000, reward total was -21.000000. running mean: -18.995427\n",
            "resetting env. episode 3487.000000, reward total was -19.000000. running mean: -18.995473\n",
            "resetting env. episode 3488.000000, reward total was -19.000000. running mean: -18.995518\n",
            "resetting env. episode 3489.000000, reward total was -21.000000. running mean: -19.015563\n",
            "resetting env. episode 3490.000000, reward total was -17.000000. running mean: -18.995407\n",
            "resetting env. episode 3491.000000, reward total was -17.000000. running mean: -18.975453\n",
            "resetting env. episode 3492.000000, reward total was -16.000000. running mean: -18.945699\n",
            "resetting env. episode 3493.000000, reward total was -19.000000. running mean: -18.946242\n",
            "resetting env. episode 3494.000000, reward total was -17.000000. running mean: -18.926779\n",
            "resetting env. episode 3495.000000, reward total was -20.000000. running mean: -18.937512\n",
            "resetting env. episode 3496.000000, reward total was -18.000000. running mean: -18.928136\n",
            "resetting env. episode 3497.000000, reward total was -17.000000. running mean: -18.908855\n",
            "resetting env. episode 3498.000000, reward total was -18.000000. running mean: -18.899767\n",
            "resetting env. episode 3499.000000, reward total was -20.000000. running mean: -18.910769\n",
            "resetting env. episode 3500.000000, reward total was -19.000000. running mean: -18.911661\n",
            "CPU times: user 3h 32min 47s, sys: 1h 39min 32s, total: 5h 12min 20s\n",
            "Wall time: 2h 41min 32s\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "w2NblmwDsL3y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "334b457f-cf67-466b-f60f-d5d1056679d2"
      },
      "cell_type": "code",
      "source": [
        "play_game(env, model)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time hist4 = train_model(env, model, total_episodes=1500)"
      ],
      "metadata": {
        "id": "txYQV0szVGX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b033c6fe-1460-46ac-f8f0-54879ea69111"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resetting env. episode 1.000000, reward total was -18.000000. running mean: -18.000000\n",
            "resetting env. episode 2.000000, reward total was -19.000000. running mean: -18.010000\n",
            "resetting env. episode 3.000000, reward total was -20.000000. running mean: -18.029900\n",
            "resetting env. episode 4.000000, reward total was -19.000000. running mean: -18.039601\n",
            "resetting env. episode 5.000000, reward total was -19.000000. running mean: -18.049205\n",
            "resetting env. episode 6.000000, reward total was -19.000000. running mean: -18.058713\n",
            "resetting env. episode 7.000000, reward total was -20.000000. running mean: -18.078126\n",
            "resetting env. episode 8.000000, reward total was -18.000000. running mean: -18.077345\n",
            "resetting env. episode 9.000000, reward total was -21.000000. running mean: -18.106571\n",
            "resetting env. episode 10.000000, reward total was -18.000000. running mean: -18.105505\n",
            "resetting env. episode 11.000000, reward total was -21.000000. running mean: -18.134450\n",
            "resetting env. episode 12.000000, reward total was -20.000000. running mean: -18.153106\n",
            "resetting env. episode 13.000000, reward total was -17.000000. running mean: -18.141575\n",
            "resetting env. episode 14.000000, reward total was -20.000000. running mean: -18.160159\n",
            "resetting env. episode 15.000000, reward total was -17.000000. running mean: -18.148557\n",
            "resetting env. episode 16.000000, reward total was -15.000000. running mean: -18.117072\n",
            "resetting env. episode 17.000000, reward total was -19.000000. running mean: -18.125901\n",
            "resetting env. episode 18.000000, reward total was -21.000000. running mean: -18.154642\n",
            "resetting env. episode 19.000000, reward total was -21.000000. running mean: -18.183096\n",
            "resetting env. episode 20.000000, reward total was -20.000000. running mean: -18.201265\n",
            "resetting env. episode 21.000000, reward total was -20.000000. running mean: -18.219252\n",
            "resetting env. episode 22.000000, reward total was -19.000000. running mean: -18.227060\n",
            "resetting env. episode 23.000000, reward total was -20.000000. running mean: -18.244789\n",
            "resetting env. episode 24.000000, reward total was -16.000000. running mean: -18.222341\n",
            "resetting env. episode 25.000000, reward total was -20.000000. running mean: -18.240118\n",
            "resetting env. episode 26.000000, reward total was -17.000000. running mean: -18.227717\n",
            "resetting env. episode 27.000000, reward total was -21.000000. running mean: -18.255439\n",
            "resetting env. episode 28.000000, reward total was -18.000000. running mean: -18.252885\n",
            "resetting env. episode 29.000000, reward total was -19.000000. running mean: -18.260356\n",
            "resetting env. episode 30.000000, reward total was -20.000000. running mean: -18.277753\n",
            "resetting env. episode 31.000000, reward total was -16.000000. running mean: -18.254975\n",
            "resetting env. episode 32.000000, reward total was -21.000000. running mean: -18.282425\n",
            "resetting env. episode 33.000000, reward total was -21.000000. running mean: -18.309601\n",
            "resetting env. episode 34.000000, reward total was -14.000000. running mean: -18.266505\n",
            "resetting env. episode 35.000000, reward total was -19.000000. running mean: -18.273840\n",
            "resetting env. episode 36.000000, reward total was -17.000000. running mean: -18.261102\n",
            "resetting env. episode 37.000000, reward total was -19.000000. running mean: -18.268491\n",
            "resetting env. episode 38.000000, reward total was -17.000000. running mean: -18.255806\n",
            "resetting env. episode 39.000000, reward total was -17.000000. running mean: -18.243248\n",
            "resetting env. episode 40.000000, reward total was -19.000000. running mean: -18.250815\n",
            "resetting env. episode 41.000000, reward total was -19.000000. running mean: -18.258307\n",
            "resetting env. episode 42.000000, reward total was -20.000000. running mean: -18.275724\n",
            "resetting env. episode 43.000000, reward total was -19.000000. running mean: -18.282967\n",
            "resetting env. episode 44.000000, reward total was -18.000000. running mean: -18.280137\n",
            "resetting env. episode 45.000000, reward total was -20.000000. running mean: -18.297336\n",
            "resetting env. episode 46.000000, reward total was -16.000000. running mean: -18.274362\n",
            "resetting env. episode 47.000000, reward total was -20.000000. running mean: -18.291619\n",
            "resetting env. episode 48.000000, reward total was -20.000000. running mean: -18.308702\n",
            "resetting env. episode 49.000000, reward total was -18.000000. running mean: -18.305615\n",
            "resetting env. episode 50.000000, reward total was -19.000000. running mean: -18.312559\n",
            "resetting env. episode 51.000000, reward total was -18.000000. running mean: -18.309434\n",
            "resetting env. episode 52.000000, reward total was -19.000000. running mean: -18.316339\n",
            "resetting env. episode 53.000000, reward total was -21.000000. running mean: -18.343176\n",
            "resetting env. episode 54.000000, reward total was -18.000000. running mean: -18.339744\n",
            "resetting env. episode 55.000000, reward total was -19.000000. running mean: -18.346347\n",
            "resetting env. episode 56.000000, reward total was -19.000000. running mean: -18.352883\n",
            "resetting env. episode 57.000000, reward total was -21.000000. running mean: -18.379354\n",
            "resetting env. episode 58.000000, reward total was -19.000000. running mean: -18.385561\n",
            "resetting env. episode 59.000000, reward total was -21.000000. running mean: -18.411705\n",
            "resetting env. episode 60.000000, reward total was -19.000000. running mean: -18.417588\n",
            "resetting env. episode 61.000000, reward total was -20.000000. running mean: -18.433412\n",
            "resetting env. episode 62.000000, reward total was -21.000000. running mean: -18.459078\n",
            "resetting env. episode 63.000000, reward total was -17.000000. running mean: -18.444487\n",
            "resetting env. episode 64.000000, reward total was -17.000000. running mean: -18.430043\n",
            "resetting env. episode 65.000000, reward total was -18.000000. running mean: -18.425742\n",
            "resetting env. episode 66.000000, reward total was -21.000000. running mean: -18.451485\n",
            "resetting env. episode 67.000000, reward total was -21.000000. running mean: -18.476970\n",
            "resetting env. episode 68.000000, reward total was -21.000000. running mean: -18.502200\n",
            "resetting env. episode 69.000000, reward total was -20.000000. running mean: -18.517178\n",
            "resetting env. episode 70.000000, reward total was -19.000000. running mean: -18.522006\n",
            "resetting env. episode 71.000000, reward total was -19.000000. running mean: -18.526786\n",
            "resetting env. episode 72.000000, reward total was -21.000000. running mean: -18.551518\n",
            "resetting env. episode 73.000000, reward total was -18.000000. running mean: -18.546003\n",
            "resetting env. episode 74.000000, reward total was -17.000000. running mean: -18.530543\n",
            "resetting env. episode 75.000000, reward total was -19.000000. running mean: -18.535238\n",
            "resetting env. episode 76.000000, reward total was -19.000000. running mean: -18.539885\n",
            "resetting env. episode 77.000000, reward total was -18.000000. running mean: -18.534487\n",
            "resetting env. episode 78.000000, reward total was -19.000000. running mean: -18.539142\n",
            "resetting env. episode 79.000000, reward total was -21.000000. running mean: -18.563750\n",
            "resetting env. episode 80.000000, reward total was -21.000000. running mean: -18.588113\n",
            "resetting env. episode 81.000000, reward total was -19.000000. running mean: -18.592232\n",
            "resetting env. episode 82.000000, reward total was -16.000000. running mean: -18.566309\n",
            "resetting env. episode 83.000000, reward total was -19.000000. running mean: -18.570646\n",
            "resetting env. episode 84.000000, reward total was -21.000000. running mean: -18.594940\n",
            "resetting env. episode 85.000000, reward total was -18.000000. running mean: -18.588990\n",
            "resetting env. episode 86.000000, reward total was -19.000000. running mean: -18.593100\n",
            "resetting env. episode 87.000000, reward total was -18.000000. running mean: -18.587169\n",
            "resetting env. episode 88.000000, reward total was -16.000000. running mean: -18.561298\n",
            "resetting env. episode 89.000000, reward total was -19.000000. running mean: -18.565685\n",
            "resetting env. episode 90.000000, reward total was -19.000000. running mean: -18.570028\n",
            "resetting env. episode 91.000000, reward total was -19.000000. running mean: -18.574328\n",
            "resetting env. episode 92.000000, reward total was -16.000000. running mean: -18.548584\n",
            "resetting env. episode 93.000000, reward total was -18.000000. running mean: -18.543099\n",
            "resetting env. episode 94.000000, reward total was -19.000000. running mean: -18.547668\n",
            "resetting env. episode 95.000000, reward total was -20.000000. running mean: -18.562191\n",
            "resetting env. episode 96.000000, reward total was -19.000000. running mean: -18.566569\n",
            "resetting env. episode 97.000000, reward total was -21.000000. running mean: -18.590903\n",
            "resetting env. episode 98.000000, reward total was -17.000000. running mean: -18.574994\n",
            "resetting env. episode 99.000000, reward total was -19.000000. running mean: -18.579244\n",
            "resetting env. episode 100.000000, reward total was -20.000000. running mean: -18.593452\n",
            "resetting env. episode 101.000000, reward total was -21.000000. running mean: -18.617517\n",
            "resetting env. episode 102.000000, reward total was -19.000000. running mean: -18.621342\n",
            "resetting env. episode 103.000000, reward total was -21.000000. running mean: -18.645129\n",
            "resetting env. episode 104.000000, reward total was -14.000000. running mean: -18.598677\n",
            "resetting env. episode 105.000000, reward total was -18.000000. running mean: -18.592691\n",
            "resetting env. episode 106.000000, reward total was -17.000000. running mean: -18.576764\n",
            "resetting env. episode 107.000000, reward total was -19.000000. running mean: -18.580996\n",
            "resetting env. episode 108.000000, reward total was -16.000000. running mean: -18.555186\n",
            "resetting env. episode 109.000000, reward total was -19.000000. running mean: -18.559634\n",
            "resetting env. episode 110.000000, reward total was -19.000000. running mean: -18.564038\n",
            "resetting env. episode 111.000000, reward total was -16.000000. running mean: -18.538398\n",
            "resetting env. episode 112.000000, reward total was -20.000000. running mean: -18.553014\n",
            "resetting env. episode 113.000000, reward total was -21.000000. running mean: -18.577484\n",
            "resetting env. episode 114.000000, reward total was -17.000000. running mean: -18.561709\n",
            "resetting env. episode 115.000000, reward total was -18.000000. running mean: -18.556092\n",
            "resetting env. episode 116.000000, reward total was -21.000000. running mean: -18.580531\n",
            "resetting env. episode 117.000000, reward total was -20.000000. running mean: -18.594725\n",
            "resetting env. episode 118.000000, reward total was -19.000000. running mean: -18.598778\n",
            "resetting env. episode 119.000000, reward total was -19.000000. running mean: -18.602790\n",
            "resetting env. episode 120.000000, reward total was -21.000000. running mean: -18.626762\n",
            "resetting env. episode 121.000000, reward total was -18.000000. running mean: -18.620495\n",
            "resetting env. episode 122.000000, reward total was -19.000000. running mean: -18.624290\n",
            "resetting env. episode 123.000000, reward total was -21.000000. running mean: -18.648047\n",
            "resetting env. episode 124.000000, reward total was -19.000000. running mean: -18.651566\n",
            "resetting env. episode 125.000000, reward total was -19.000000. running mean: -18.655051\n",
            "resetting env. episode 126.000000, reward total was -17.000000. running mean: -18.638500\n",
            "resetting env. episode 127.000000, reward total was -20.000000. running mean: -18.652115\n",
            "resetting env. episode 128.000000, reward total was -19.000000. running mean: -18.655594\n",
            "resetting env. episode 129.000000, reward total was -18.000000. running mean: -18.649038\n",
            "resetting env. episode 130.000000, reward total was -17.000000. running mean: -18.632548\n",
            "resetting env. episode 131.000000, reward total was -20.000000. running mean: -18.646222\n",
            "resetting env. episode 132.000000, reward total was -17.000000. running mean: -18.629760\n",
            "resetting env. episode 133.000000, reward total was -19.000000. running mean: -18.633463\n",
            "resetting env. episode 134.000000, reward total was -18.000000. running mean: -18.627128\n",
            "resetting env. episode 135.000000, reward total was -17.000000. running mean: -18.610857\n",
            "resetting env. episode 136.000000, reward total was -21.000000. running mean: -18.634748\n",
            "resetting env. episode 137.000000, reward total was -20.000000. running mean: -18.648401\n",
            "resetting env. episode 138.000000, reward total was -20.000000. running mean: -18.661917\n",
            "resetting env. episode 139.000000, reward total was -21.000000. running mean: -18.685297\n",
            "resetting env. episode 140.000000, reward total was -18.000000. running mean: -18.678444\n",
            "resetting env. episode 141.000000, reward total was -21.000000. running mean: -18.701660\n",
            "resetting env. episode 142.000000, reward total was -17.000000. running mean: -18.684643\n",
            "resetting env. episode 143.000000, reward total was -19.000000. running mean: -18.687797\n",
            "resetting env. episode 144.000000, reward total was -19.000000. running mean: -18.690919\n",
            "resetting env. episode 145.000000, reward total was -19.000000. running mean: -18.694010\n",
            "resetting env. episode 146.000000, reward total was -20.000000. running mean: -18.707070\n",
            "resetting env. episode 147.000000, reward total was -17.000000. running mean: -18.689999\n",
            "resetting env. episode 148.000000, reward total was -17.000000. running mean: -18.673099\n",
            "resetting env. episode 149.000000, reward total was -19.000000. running mean: -18.676368\n",
            "resetting env. episode 150.000000, reward total was -20.000000. running mean: -18.689604\n",
            "resetting env. episode 151.000000, reward total was -18.000000. running mean: -18.682708\n",
            "resetting env. episode 152.000000, reward total was -20.000000. running mean: -18.695881\n",
            "resetting env. episode 153.000000, reward total was -18.000000. running mean: -18.688922\n",
            "resetting env. episode 154.000000, reward total was -19.000000. running mean: -18.692033\n",
            "resetting env. episode 155.000000, reward total was -20.000000. running mean: -18.705113\n",
            "resetting env. episode 156.000000, reward total was -18.000000. running mean: -18.698062\n",
            "resetting env. episode 157.000000, reward total was -17.000000. running mean: -18.681081\n",
            "resetting env. episode 158.000000, reward total was -19.000000. running mean: -18.684270\n",
            "resetting env. episode 159.000000, reward total was -21.000000. running mean: -18.707428\n",
            "resetting env. episode 160.000000, reward total was -20.000000. running mean: -18.720353\n",
            "resetting env. episode 161.000000, reward total was -17.000000. running mean: -18.703150\n",
            "resetting env. episode 162.000000, reward total was -17.000000. running mean: -18.686118\n",
            "resetting env. episode 163.000000, reward total was -15.000000. running mean: -18.649257\n",
            "resetting env. episode 164.000000, reward total was -19.000000. running mean: -18.652765\n",
            "resetting env. episode 165.000000, reward total was -21.000000. running mean: -18.676237\n",
            "resetting env. episode 166.000000, reward total was -21.000000. running mean: -18.699475\n",
            "resetting env. episode 167.000000, reward total was -19.000000. running mean: -18.702480\n",
            "resetting env. episode 168.000000, reward total was -14.000000. running mean: -18.655455\n",
            "resetting env. episode 169.000000, reward total was -16.000000. running mean: -18.628900\n",
            "resetting env. episode 170.000000, reward total was -19.000000. running mean: -18.632611\n",
            "resetting env. episode 171.000000, reward total was -19.000000. running mean: -18.636285\n",
            "resetting env. episode 172.000000, reward total was -16.000000. running mean: -18.609922\n",
            "resetting env. episode 173.000000, reward total was -15.000000. running mean: -18.573823\n",
            "resetting env. episode 174.000000, reward total was -18.000000. running mean: -18.568085\n",
            "resetting env. episode 175.000000, reward total was -17.000000. running mean: -18.552404\n",
            "resetting env. episode 176.000000, reward total was -19.000000. running mean: -18.556880\n",
            "resetting env. episode 177.000000, reward total was -14.000000. running mean: -18.511311\n",
            "resetting env. episode 178.000000, reward total was -17.000000. running mean: -18.496198\n",
            "resetting env. episode 179.000000, reward total was -17.000000. running mean: -18.481236\n",
            "resetting env. episode 180.000000, reward total was -18.000000. running mean: -18.476424\n",
            "resetting env. episode 181.000000, reward total was -16.000000. running mean: -18.451660\n",
            "resetting env. episode 182.000000, reward total was -19.000000. running mean: -18.457143\n",
            "resetting env. episode 183.000000, reward total was -18.000000. running mean: -18.452572\n",
            "resetting env. episode 184.000000, reward total was -16.000000. running mean: -18.428046\n",
            "resetting env. episode 185.000000, reward total was -20.000000. running mean: -18.443765\n",
            "resetting env. episode 186.000000, reward total was -17.000000. running mean: -18.429328\n",
            "resetting env. episode 187.000000, reward total was -19.000000. running mean: -18.435034\n",
            "resetting env. episode 188.000000, reward total was -15.000000. running mean: -18.400684\n",
            "resetting env. episode 189.000000, reward total was -16.000000. running mean: -18.376677\n",
            "resetting env. episode 190.000000, reward total was -19.000000. running mean: -18.382911\n",
            "resetting env. episode 191.000000, reward total was -18.000000. running mean: -18.379081\n",
            "resetting env. episode 192.000000, reward total was -20.000000. running mean: -18.395291\n",
            "resetting env. episode 193.000000, reward total was -17.000000. running mean: -18.381338\n",
            "resetting env. episode 194.000000, reward total was -17.000000. running mean: -18.367524\n",
            "resetting env. episode 195.000000, reward total was -18.000000. running mean: -18.363849\n",
            "resetting env. episode 196.000000, reward total was -20.000000. running mean: -18.380211\n",
            "resetting env. episode 197.000000, reward total was -18.000000. running mean: -18.376408\n",
            "resetting env. episode 198.000000, reward total was -20.000000. running mean: -18.392644\n",
            "resetting env. episode 199.000000, reward total was -19.000000. running mean: -18.398718\n",
            "resetting env. episode 200.000000, reward total was -19.000000. running mean: -18.404731\n",
            "resetting env. episode 201.000000, reward total was -17.000000. running mean: -18.390683\n",
            "resetting env. episode 202.000000, reward total was -18.000000. running mean: -18.386777\n",
            "resetting env. episode 203.000000, reward total was -17.000000. running mean: -18.372909\n",
            "resetting env. episode 204.000000, reward total was -15.000000. running mean: -18.339180\n",
            "resetting env. episode 205.000000, reward total was -17.000000. running mean: -18.325788\n",
            "resetting env. episode 206.000000, reward total was -14.000000. running mean: -18.282530\n",
            "resetting env. episode 207.000000, reward total was -17.000000. running mean: -18.269705\n",
            "resetting env. episode 208.000000, reward total was -18.000000. running mean: -18.267008\n",
            "resetting env. episode 209.000000, reward total was -13.000000. running mean: -18.214338\n",
            "resetting env. episode 210.000000, reward total was -21.000000. running mean: -18.242194\n",
            "resetting env. episode 211.000000, reward total was -15.000000. running mean: -18.209772\n",
            "resetting env. episode 212.000000, reward total was -19.000000. running mean: -18.217675\n",
            "resetting env. episode 213.000000, reward total was -16.000000. running mean: -18.195498\n",
            "resetting env. episode 214.000000, reward total was -20.000000. running mean: -18.213543\n",
            "resetting env. episode 215.000000, reward total was -16.000000. running mean: -18.191407\n",
            "resetting env. episode 216.000000, reward total was -19.000000. running mean: -18.199493\n",
            "resetting env. episode 217.000000, reward total was -18.000000. running mean: -18.197498\n",
            "resetting env. episode 218.000000, reward total was -17.000000. running mean: -18.185523\n",
            "resetting env. episode 219.000000, reward total was -21.000000. running mean: -18.213668\n",
            "resetting env. episode 220.000000, reward total was -21.000000. running mean: -18.241532\n",
            "resetting env. episode 221.000000, reward total was -20.000000. running mean: -18.259116\n",
            "resetting env. episode 222.000000, reward total was -17.000000. running mean: -18.246525\n",
            "resetting env. episode 223.000000, reward total was -17.000000. running mean: -18.234060\n",
            "resetting env. episode 224.000000, reward total was -21.000000. running mean: -18.261719\n",
            "resetting env. episode 225.000000, reward total was -20.000000. running mean: -18.279102\n",
            "resetting env. episode 226.000000, reward total was -20.000000. running mean: -18.296311\n",
            "resetting env. episode 227.000000, reward total was -19.000000. running mean: -18.303348\n",
            "resetting env. episode 228.000000, reward total was -15.000000. running mean: -18.270314\n",
            "resetting env. episode 229.000000, reward total was -20.000000. running mean: -18.287611\n",
            "resetting env. episode 230.000000, reward total was -20.000000. running mean: -18.304735\n",
            "resetting env. episode 231.000000, reward total was -14.000000. running mean: -18.261688\n",
            "resetting env. episode 232.000000, reward total was -18.000000. running mean: -18.259071\n",
            "resetting env. episode 233.000000, reward total was -18.000000. running mean: -18.256480\n",
            "resetting env. episode 234.000000, reward total was -19.000000. running mean: -18.263915\n",
            "resetting env. episode 235.000000, reward total was -15.000000. running mean: -18.231276\n",
            "resetting env. episode 236.000000, reward total was -20.000000. running mean: -18.248964\n",
            "resetting env. episode 237.000000, reward total was -18.000000. running mean: -18.246474\n",
            "resetting env. episode 238.000000, reward total was -20.000000. running mean: -18.264009\n",
            "resetting env. episode 239.000000, reward total was -15.000000. running mean: -18.231369\n",
            "resetting env. episode 240.000000, reward total was -17.000000. running mean: -18.219055\n",
            "resetting env. episode 241.000000, reward total was -20.000000. running mean: -18.236865\n",
            "resetting env. episode 242.000000, reward total was -20.000000. running mean: -18.254496\n",
            "resetting env. episode 243.000000, reward total was -17.000000. running mean: -18.241951\n",
            "resetting env. episode 244.000000, reward total was -19.000000. running mean: -18.249532\n",
            "resetting env. episode 245.000000, reward total was -20.000000. running mean: -18.267036\n",
            "resetting env. episode 246.000000, reward total was -20.000000. running mean: -18.284366\n",
            "resetting env. episode 247.000000, reward total was -19.000000. running mean: -18.291522\n",
            "resetting env. episode 248.000000, reward total was -18.000000. running mean: -18.288607\n",
            "resetting env. episode 249.000000, reward total was -18.000000. running mean: -18.285721\n",
            "resetting env. episode 250.000000, reward total was -18.000000. running mean: -18.282864\n",
            "resetting env. episode 251.000000, reward total was -18.000000. running mean: -18.280035\n",
            "resetting env. episode 252.000000, reward total was -21.000000. running mean: -18.307235\n",
            "resetting env. episode 253.000000, reward total was -18.000000. running mean: -18.304162\n",
            "resetting env. episode 254.000000, reward total was -17.000000. running mean: -18.291121\n",
            "resetting env. episode 255.000000, reward total was -17.000000. running mean: -18.278210\n",
            "resetting env. episode 256.000000, reward total was -18.000000. running mean: -18.275428\n",
            "resetting env. episode 257.000000, reward total was -21.000000. running mean: -18.302673\n",
            "resetting env. episode 258.000000, reward total was -19.000000. running mean: -18.309647\n",
            "resetting env. episode 259.000000, reward total was -21.000000. running mean: -18.336550\n",
            "resetting env. episode 260.000000, reward total was -17.000000. running mean: -18.323185\n",
            "resetting env. episode 261.000000, reward total was -19.000000. running mean: -18.329953\n",
            "resetting env. episode 262.000000, reward total was -18.000000. running mean: -18.326653\n",
            "resetting env. episode 263.000000, reward total was -16.000000. running mean: -18.303387\n",
            "resetting env. episode 264.000000, reward total was -18.000000. running mean: -18.300353\n",
            "resetting env. episode 265.000000, reward total was -19.000000. running mean: -18.307349\n",
            "resetting env. episode 266.000000, reward total was -21.000000. running mean: -18.334276\n",
            "resetting env. episode 267.000000, reward total was -19.000000. running mean: -18.340933\n",
            "resetting env. episode 268.000000, reward total was -19.000000. running mean: -18.347524\n",
            "resetting env. episode 269.000000, reward total was -18.000000. running mean: -18.344048\n",
            "resetting env. episode 270.000000, reward total was -21.000000. running mean: -18.370608\n",
            "resetting env. episode 271.000000, reward total was -18.000000. running mean: -18.366902\n",
            "resetting env. episode 272.000000, reward total was -21.000000. running mean: -18.393233\n",
            "resetting env. episode 273.000000, reward total was -20.000000. running mean: -18.409301\n",
            "resetting env. episode 274.000000, reward total was -20.000000. running mean: -18.425208\n",
            "resetting env. episode 275.000000, reward total was -18.000000. running mean: -18.420955\n",
            "resetting env. episode 276.000000, reward total was -18.000000. running mean: -18.416746\n",
            "resetting env. episode 277.000000, reward total was -18.000000. running mean: -18.412578\n",
            "resetting env. episode 278.000000, reward total was -19.000000. running mean: -18.418453\n",
            "resetting env. episode 279.000000, reward total was -21.000000. running mean: -18.444268\n",
            "resetting env. episode 280.000000, reward total was -18.000000. running mean: -18.439825\n",
            "resetting env. episode 281.000000, reward total was -18.000000. running mean: -18.435427\n",
            "resetting env. episode 282.000000, reward total was -21.000000. running mean: -18.461073\n",
            "resetting env. episode 283.000000, reward total was -15.000000. running mean: -18.426462\n",
            "resetting env. episode 284.000000, reward total was -21.000000. running mean: -18.452198\n",
            "resetting env. episode 285.000000, reward total was -19.000000. running mean: -18.457676\n",
            "resetting env. episode 286.000000, reward total was -20.000000. running mean: -18.473099\n",
            "resetting env. episode 287.000000, reward total was -17.000000. running mean: -18.458368\n",
            "resetting env. episode 288.000000, reward total was -20.000000. running mean: -18.473784\n",
            "resetting env. episode 289.000000, reward total was -19.000000. running mean: -18.479046\n",
            "resetting env. episode 290.000000, reward total was -19.000000. running mean: -18.484256\n",
            "resetting env. episode 291.000000, reward total was -20.000000. running mean: -18.499413\n",
            "resetting env. episode 292.000000, reward total was -17.000000. running mean: -18.484419\n",
            "resetting env. episode 293.000000, reward total was -19.000000. running mean: -18.489575\n",
            "resetting env. episode 294.000000, reward total was -16.000000. running mean: -18.464679\n",
            "resetting env. episode 295.000000, reward total was -20.000000. running mean: -18.480032\n",
            "resetting env. episode 296.000000, reward total was -17.000000. running mean: -18.465232\n",
            "resetting env. episode 297.000000, reward total was -17.000000. running mean: -18.450580\n",
            "resetting env. episode 298.000000, reward total was -20.000000. running mean: -18.466074\n",
            "resetting env. episode 299.000000, reward total was -19.000000. running mean: -18.471413\n",
            "resetting env. episode 300.000000, reward total was -20.000000. running mean: -18.486699\n",
            "resetting env. episode 301.000000, reward total was -20.000000. running mean: -18.501832\n",
            "resetting env. episode 302.000000, reward total was -18.000000. running mean: -18.496814\n",
            "resetting env. episode 303.000000, reward total was -18.000000. running mean: -18.491846\n",
            "resetting env. episode 304.000000, reward total was -17.000000. running mean: -18.476927\n",
            "resetting env. episode 305.000000, reward total was -19.000000. running mean: -18.482158\n",
            "resetting env. episode 306.000000, reward total was -18.000000. running mean: -18.477336\n",
            "resetting env. episode 307.000000, reward total was -21.000000. running mean: -18.502563\n",
            "resetting env. episode 308.000000, reward total was -18.000000. running mean: -18.497537\n",
            "resetting env. episode 309.000000, reward total was -19.000000. running mean: -18.502562\n",
            "resetting env. episode 310.000000, reward total was -18.000000. running mean: -18.497536\n",
            "resetting env. episode 311.000000, reward total was -15.000000. running mean: -18.462561\n",
            "resetting env. episode 312.000000, reward total was -14.000000. running mean: -18.417935\n",
            "resetting env. episode 313.000000, reward total was -19.000000. running mean: -18.423756\n",
            "resetting env. episode 314.000000, reward total was -18.000000. running mean: -18.419519\n",
            "resetting env. episode 315.000000, reward total was -19.000000. running mean: -18.425323\n",
            "resetting env. episode 316.000000, reward total was -19.000000. running mean: -18.431070\n",
            "resetting env. episode 317.000000, reward total was -18.000000. running mean: -18.426759\n",
            "resetting env. episode 318.000000, reward total was -17.000000. running mean: -18.412492\n",
            "resetting env. episode 319.000000, reward total was -19.000000. running mean: -18.418367\n",
            "resetting env. episode 320.000000, reward total was -19.000000. running mean: -18.424183\n",
            "resetting env. episode 321.000000, reward total was -18.000000. running mean: -18.419941\n",
            "resetting env. episode 322.000000, reward total was -15.000000. running mean: -18.385742\n",
            "resetting env. episode 323.000000, reward total was -19.000000. running mean: -18.391885\n",
            "resetting env. episode 324.000000, reward total was -20.000000. running mean: -18.407966\n",
            "resetting env. episode 325.000000, reward total was -19.000000. running mean: -18.413886\n",
            "resetting env. episode 326.000000, reward total was -21.000000. running mean: -18.439747\n",
            "resetting env. episode 327.000000, reward total was -19.000000. running mean: -18.445350\n",
            "resetting env. episode 328.000000, reward total was -19.000000. running mean: -18.450896\n",
            "resetting env. episode 329.000000, reward total was -20.000000. running mean: -18.466387\n",
            "resetting env. episode 330.000000, reward total was -19.000000. running mean: -18.471723\n",
            "resetting env. episode 331.000000, reward total was -15.000000. running mean: -18.437006\n",
            "resetting env. episode 332.000000, reward total was -17.000000. running mean: -18.422636\n",
            "resetting env. episode 333.000000, reward total was -21.000000. running mean: -18.448410\n",
            "resetting env. episode 334.000000, reward total was -17.000000. running mean: -18.433926\n",
            "resetting env. episode 335.000000, reward total was -16.000000. running mean: -18.409586\n",
            "resetting env. episode 336.000000, reward total was -20.000000. running mean: -18.425491\n",
            "resetting env. episode 337.000000, reward total was -18.000000. running mean: -18.421236\n",
            "resetting env. episode 338.000000, reward total was -19.000000. running mean: -18.427023\n",
            "resetting env. episode 339.000000, reward total was -18.000000. running mean: -18.422753\n",
            "resetting env. episode 340.000000, reward total was -20.000000. running mean: -18.438525\n",
            "resetting env. episode 341.000000, reward total was -18.000000. running mean: -18.434140\n",
            "resetting env. episode 342.000000, reward total was -14.000000. running mean: -18.389799\n",
            "resetting env. episode 343.000000, reward total was -19.000000. running mean: -18.395901\n",
            "resetting env. episode 344.000000, reward total was -18.000000. running mean: -18.391942\n",
            "resetting env. episode 345.000000, reward total was -19.000000. running mean: -18.398022\n",
            "resetting env. episode 346.000000, reward total was -18.000000. running mean: -18.394042\n",
            "resetting env. episode 347.000000, reward total was -18.000000. running mean: -18.390102\n",
            "resetting env. episode 348.000000, reward total was -19.000000. running mean: -18.396201\n",
            "resetting env. episode 349.000000, reward total was -21.000000. running mean: -18.422239\n",
            "resetting env. episode 350.000000, reward total was -20.000000. running mean: -18.438016\n",
            "resetting env. episode 351.000000, reward total was -18.000000. running mean: -18.433636\n",
            "resetting env. episode 352.000000, reward total was -16.000000. running mean: -18.409300\n",
            "resetting env. episode 353.000000, reward total was -15.000000. running mean: -18.375207\n",
            "resetting env. episode 354.000000, reward total was -16.000000. running mean: -18.351455\n",
            "resetting env. episode 355.000000, reward total was -18.000000. running mean: -18.347940\n",
            "resetting env. episode 356.000000, reward total was -19.000000. running mean: -18.354461\n",
            "resetting env. episode 357.000000, reward total was -19.000000. running mean: -18.360916\n",
            "resetting env. episode 358.000000, reward total was -16.000000. running mean: -18.337307\n",
            "resetting env. episode 359.000000, reward total was -19.000000. running mean: -18.343934\n",
            "resetting env. episode 360.000000, reward total was -19.000000. running mean: -18.350495\n",
            "resetting env. episode 361.000000, reward total was -21.000000. running mean: -18.376990\n",
            "resetting env. episode 362.000000, reward total was -17.000000. running mean: -18.363220\n",
            "resetting env. episode 363.000000, reward total was -20.000000. running mean: -18.379588\n",
            "resetting env. episode 364.000000, reward total was -20.000000. running mean: -18.395792\n",
            "resetting env. episode 365.000000, reward total was -16.000000. running mean: -18.371834\n",
            "resetting env. episode 366.000000, reward total was -20.000000. running mean: -18.388115\n",
            "resetting env. episode 367.000000, reward total was -19.000000. running mean: -18.394234\n",
            "resetting env. episode 368.000000, reward total was -20.000000. running mean: -18.410292\n",
            "resetting env. episode 369.000000, reward total was -18.000000. running mean: -18.406189\n",
            "resetting env. episode 370.000000, reward total was -17.000000. running mean: -18.392127\n",
            "resetting env. episode 371.000000, reward total was -15.000000. running mean: -18.358206\n",
            "resetting env. episode 372.000000, reward total was -19.000000. running mean: -18.364624\n",
            "resetting env. episode 373.000000, reward total was -18.000000. running mean: -18.360978\n",
            "resetting env. episode 374.000000, reward total was -19.000000. running mean: -18.367368\n",
            "resetting env. episode 375.000000, reward total was -18.000000. running mean: -18.363694\n",
            "resetting env. episode 376.000000, reward total was -20.000000. running mean: -18.380057\n",
            "resetting env. episode 377.000000, reward total was -20.000000. running mean: -18.396257\n",
            "resetting env. episode 378.000000, reward total was -18.000000. running mean: -18.392294\n",
            "resetting env. episode 379.000000, reward total was -17.000000. running mean: -18.378371\n",
            "resetting env. episode 380.000000, reward total was -19.000000. running mean: -18.384587\n",
            "resetting env. episode 381.000000, reward total was -18.000000. running mean: -18.380742\n",
            "resetting env. episode 382.000000, reward total was -19.000000. running mean: -18.386934\n",
            "resetting env. episode 383.000000, reward total was -17.000000. running mean: -18.373065\n",
            "resetting env. episode 384.000000, reward total was -19.000000. running mean: -18.379334\n",
            "resetting env. episode 385.000000, reward total was -21.000000. running mean: -18.405541\n",
            "resetting env. episode 386.000000, reward total was -21.000000. running mean: -18.431485\n",
            "resetting env. episode 387.000000, reward total was -18.000000. running mean: -18.427171\n",
            "resetting env. episode 388.000000, reward total was -15.000000. running mean: -18.392899\n",
            "resetting env. episode 389.000000, reward total was -19.000000. running mean: -18.398970\n",
            "resetting env. episode 390.000000, reward total was -19.000000. running mean: -18.404980\n",
            "resetting env. episode 391.000000, reward total was -16.000000. running mean: -18.380930\n",
            "resetting env. episode 392.000000, reward total was -18.000000. running mean: -18.377121\n",
            "resetting env. episode 393.000000, reward total was -18.000000. running mean: -18.373350\n",
            "resetting env. episode 394.000000, reward total was -19.000000. running mean: -18.379616\n",
            "resetting env. episode 395.000000, reward total was -20.000000. running mean: -18.395820\n",
            "resetting env. episode 396.000000, reward total was -20.000000. running mean: -18.411862\n",
            "resetting env. episode 397.000000, reward total was -21.000000. running mean: -18.437743\n",
            "resetting env. episode 398.000000, reward total was -20.000000. running mean: -18.453366\n",
            "resetting env. episode 399.000000, reward total was -21.000000. running mean: -18.478832\n",
            "resetting env. episode 400.000000, reward total was -18.000000. running mean: -18.474044\n",
            "resetting env. episode 401.000000, reward total was -17.000000. running mean: -18.459303\n",
            "resetting env. episode 402.000000, reward total was -18.000000. running mean: -18.454710\n",
            "resetting env. episode 403.000000, reward total was -18.000000. running mean: -18.450163\n",
            "resetting env. episode 404.000000, reward total was -21.000000. running mean: -18.475662\n",
            "resetting env. episode 405.000000, reward total was -18.000000. running mean: -18.470905\n",
            "resetting env. episode 406.000000, reward total was -20.000000. running mean: -18.486196\n",
            "resetting env. episode 407.000000, reward total was -17.000000. running mean: -18.471334\n",
            "resetting env. episode 408.000000, reward total was -18.000000. running mean: -18.466621\n",
            "resetting env. episode 409.000000, reward total was -18.000000. running mean: -18.461955\n",
            "resetting env. episode 410.000000, reward total was -19.000000. running mean: -18.467335\n",
            "resetting env. episode 411.000000, reward total was -17.000000. running mean: -18.452662\n",
            "resetting env. episode 412.000000, reward total was -17.000000. running mean: -18.438135\n",
            "resetting env. episode 413.000000, reward total was -19.000000. running mean: -18.443754\n",
            "resetting env. episode 414.000000, reward total was -21.000000. running mean: -18.469316\n",
            "resetting env. episode 415.000000, reward total was -17.000000. running mean: -18.454623\n",
            "resetting env. episode 416.000000, reward total was -17.000000. running mean: -18.440077\n",
            "resetting env. episode 417.000000, reward total was -19.000000. running mean: -18.445676\n",
            "resetting env. episode 418.000000, reward total was -18.000000. running mean: -18.441219\n",
            "resetting env. episode 419.000000, reward total was -18.000000. running mean: -18.436807\n",
            "resetting env. episode 420.000000, reward total was -17.000000. running mean: -18.422439\n",
            "resetting env. episode 421.000000, reward total was -16.000000. running mean: -18.398215\n",
            "resetting env. episode 422.000000, reward total was -18.000000. running mean: -18.394232\n",
            "resetting env. episode 423.000000, reward total was -21.000000. running mean: -18.420290\n",
            "resetting env. episode 424.000000, reward total was -19.000000. running mean: -18.426087\n",
            "resetting env. episode 425.000000, reward total was -17.000000. running mean: -18.411826\n",
            "resetting env. episode 426.000000, reward total was -16.000000. running mean: -18.387708\n",
            "resetting env. episode 427.000000, reward total was -19.000000. running mean: -18.393831\n",
            "resetting env. episode 428.000000, reward total was -21.000000. running mean: -18.419893\n",
            "resetting env. episode 429.000000, reward total was -19.000000. running mean: -18.425694\n",
            "resetting env. episode 430.000000, reward total was -20.000000. running mean: -18.441437\n",
            "resetting env. episode 431.000000, reward total was -19.000000. running mean: -18.447022\n",
            "resetting env. episode 432.000000, reward total was -19.000000. running mean: -18.452552\n",
            "resetting env. episode 433.000000, reward total was -20.000000. running mean: -18.468027\n",
            "resetting env. episode 434.000000, reward total was -19.000000. running mean: -18.473346\n",
            "resetting env. episode 435.000000, reward total was -20.000000. running mean: -18.488613\n",
            "resetting env. episode 436.000000, reward total was -16.000000. running mean: -18.463727\n",
            "resetting env. episode 437.000000, reward total was -19.000000. running mean: -18.469090\n",
            "resetting env. episode 438.000000, reward total was -19.000000. running mean: -18.474399\n",
            "resetting env. episode 439.000000, reward total was -16.000000. running mean: -18.449655\n",
            "resetting env. episode 440.000000, reward total was -16.000000. running mean: -18.425158\n",
            "resetting env. episode 441.000000, reward total was -20.000000. running mean: -18.440907\n",
            "resetting env. episode 442.000000, reward total was -19.000000. running mean: -18.446497\n",
            "resetting env. episode 443.000000, reward total was -17.000000. running mean: -18.432033\n",
            "resetting env. episode 444.000000, reward total was -16.000000. running mean: -18.407712\n",
            "resetting env. episode 445.000000, reward total was -17.000000. running mean: -18.393635\n",
            "resetting env. episode 446.000000, reward total was -18.000000. running mean: -18.389699\n",
            "resetting env. episode 447.000000, reward total was -19.000000. running mean: -18.395802\n",
            "resetting env. episode 448.000000, reward total was -19.000000. running mean: -18.401844\n",
            "resetting env. episode 449.000000, reward total was -20.000000. running mean: -18.417825\n",
            "resetting env. episode 450.000000, reward total was -19.000000. running mean: -18.423647\n",
            "resetting env. episode 451.000000, reward total was -17.000000. running mean: -18.409411\n",
            "resetting env. episode 452.000000, reward total was -17.000000. running mean: -18.395316\n",
            "resetting env. episode 453.000000, reward total was -20.000000. running mean: -18.411363\n",
            "resetting env. episode 454.000000, reward total was -20.000000. running mean: -18.427250\n",
            "resetting env. episode 455.000000, reward total was -17.000000. running mean: -18.412977\n",
            "resetting env. episode 456.000000, reward total was -17.000000. running mean: -18.398847\n",
            "resetting env. episode 457.000000, reward total was -19.000000. running mean: -18.404859\n",
            "resetting env. episode 458.000000, reward total was -21.000000. running mean: -18.430810\n",
            "resetting env. episode 459.000000, reward total was -20.000000. running mean: -18.446502\n",
            "resetting env. episode 460.000000, reward total was -18.000000. running mean: -18.442037\n",
            "resetting env. episode 461.000000, reward total was -18.000000. running mean: -18.437617\n",
            "resetting env. episode 462.000000, reward total was -21.000000. running mean: -18.463241\n",
            "resetting env. episode 463.000000, reward total was -17.000000. running mean: -18.448608\n",
            "resetting env. episode 464.000000, reward total was -21.000000. running mean: -18.474122\n",
            "resetting env. episode 465.000000, reward total was -19.000000. running mean: -18.479381\n",
            "resetting env. episode 466.000000, reward total was -21.000000. running mean: -18.504587\n",
            "resetting env. episode 467.000000, reward total was -17.000000. running mean: -18.489541\n",
            "resetting env. episode 468.000000, reward total was -18.000000. running mean: -18.484646\n",
            "resetting env. episode 469.000000, reward total was -17.000000. running mean: -18.469799\n",
            "resetting env. episode 470.000000, reward total was -19.000000. running mean: -18.475101\n",
            "resetting env. episode 471.000000, reward total was -19.000000. running mean: -18.480350\n",
            "resetting env. episode 472.000000, reward total was -19.000000. running mean: -18.485547\n",
            "resetting env. episode 473.000000, reward total was -14.000000. running mean: -18.440691\n",
            "resetting env. episode 474.000000, reward total was -18.000000. running mean: -18.436284\n",
            "resetting env. episode 475.000000, reward total was -19.000000. running mean: -18.441922\n",
            "resetting env. episode 476.000000, reward total was -19.000000. running mean: -18.447502\n",
            "resetting env. episode 477.000000, reward total was -16.000000. running mean: -18.423027\n",
            "resetting env. episode 478.000000, reward total was -20.000000. running mean: -18.438797\n",
            "resetting env. episode 479.000000, reward total was -19.000000. running mean: -18.444409\n",
            "resetting env. episode 480.000000, reward total was -18.000000. running mean: -18.439965\n",
            "resetting env. episode 481.000000, reward total was -18.000000. running mean: -18.435565\n",
            "resetting env. episode 482.000000, reward total was -18.000000. running mean: -18.431210\n",
            "resetting env. episode 483.000000, reward total was -18.000000. running mean: -18.426898\n",
            "resetting env. episode 484.000000, reward total was -17.000000. running mean: -18.412629\n",
            "resetting env. episode 485.000000, reward total was -17.000000. running mean: -18.398502\n",
            "resetting env. episode 486.000000, reward total was -20.000000. running mean: -18.414517\n",
            "resetting env. episode 487.000000, reward total was -17.000000. running mean: -18.400372\n",
            "resetting env. episode 488.000000, reward total was -20.000000. running mean: -18.416368\n",
            "resetting env. episode 489.000000, reward total was -17.000000. running mean: -18.402205\n",
            "resetting env. episode 490.000000, reward total was -18.000000. running mean: -18.398183\n",
            "resetting env. episode 491.000000, reward total was -21.000000. running mean: -18.424201\n",
            "resetting env. episode 492.000000, reward total was -18.000000. running mean: -18.419959\n",
            "resetting env. episode 493.000000, reward total was -19.000000. running mean: -18.425759\n",
            "resetting env. episode 494.000000, reward total was -16.000000. running mean: -18.401502\n",
            "resetting env. episode 495.000000, reward total was -15.000000. running mean: -18.367487\n",
            "resetting env. episode 496.000000, reward total was -19.000000. running mean: -18.373812\n",
            "resetting env. episode 497.000000, reward total was -19.000000. running mean: -18.380074\n",
            "resetting env. episode 498.000000, reward total was -17.000000. running mean: -18.366273\n",
            "resetting env. episode 499.000000, reward total was -17.000000. running mean: -18.352610\n",
            "resetting env. episode 500.000000, reward total was -18.000000. running mean: -18.349084\n",
            "resetting env. episode 501.000000, reward total was -21.000000. running mean: -18.375593\n",
            "resetting env. episode 502.000000, reward total was -19.000000. running mean: -18.381837\n",
            "resetting env. episode 503.000000, reward total was -18.000000. running mean: -18.378019\n",
            "resetting env. episode 504.000000, reward total was -15.000000. running mean: -18.344239\n",
            "resetting env. episode 505.000000, reward total was -18.000000. running mean: -18.340796\n",
            "resetting env. episode 506.000000, reward total was -18.000000. running mean: -18.337388\n",
            "resetting env. episode 507.000000, reward total was -20.000000. running mean: -18.354015\n",
            "resetting env. episode 508.000000, reward total was -10.000000. running mean: -18.270474\n",
            "resetting env. episode 509.000000, reward total was -19.000000. running mean: -18.277770\n",
            "resetting env. episode 510.000000, reward total was -16.000000. running mean: -18.254992\n",
            "resetting env. episode 511.000000, reward total was -18.000000. running mean: -18.252442\n",
            "resetting env. episode 512.000000, reward total was -18.000000. running mean: -18.249918\n",
            "resetting env. episode 513.000000, reward total was -17.000000. running mean: -18.237418\n",
            "resetting env. episode 514.000000, reward total was -19.000000. running mean: -18.245044\n",
            "resetting env. episode 515.000000, reward total was -19.000000. running mean: -18.252594\n",
            "resetting env. episode 516.000000, reward total was -21.000000. running mean: -18.280068\n",
            "resetting env. episode 517.000000, reward total was -17.000000. running mean: -18.267267\n",
            "resetting env. episode 518.000000, reward total was -19.000000. running mean: -18.274595\n",
            "resetting env. episode 519.000000, reward total was -17.000000. running mean: -18.261849\n",
            "resetting env. episode 520.000000, reward total was -19.000000. running mean: -18.269230\n",
            "resetting env. episode 521.000000, reward total was -17.000000. running mean: -18.256538\n",
            "resetting env. episode 522.000000, reward total was -19.000000. running mean: -18.263972\n",
            "resetting env. episode 523.000000, reward total was -21.000000. running mean: -18.291333\n",
            "resetting env. episode 524.000000, reward total was -15.000000. running mean: -18.258419\n",
            "resetting env. episode 525.000000, reward total was -17.000000. running mean: -18.245835\n",
            "resetting env. episode 526.000000, reward total was -20.000000. running mean: -18.263377\n",
            "resetting env. episode 527.000000, reward total was -20.000000. running mean: -18.280743\n",
            "resetting env. episode 528.000000, reward total was -20.000000. running mean: -18.297936\n",
            "resetting env. episode 529.000000, reward total was -19.000000. running mean: -18.304956\n",
            "resetting env. episode 530.000000, reward total was -15.000000. running mean: -18.271907\n",
            "resetting env. episode 531.000000, reward total was -14.000000. running mean: -18.229188\n",
            "resetting env. episode 532.000000, reward total was -18.000000. running mean: -18.226896\n",
            "resetting env. episode 533.000000, reward total was -16.000000. running mean: -18.204627\n",
            "resetting env. episode 534.000000, reward total was -18.000000. running mean: -18.202581\n",
            "resetting env. episode 535.000000, reward total was -19.000000. running mean: -18.210555\n",
            "resetting env. episode 536.000000, reward total was -12.000000. running mean: -18.148449\n",
            "resetting env. episode 537.000000, reward total was -14.000000. running mean: -18.106965\n",
            "resetting env. episode 538.000000, reward total was -17.000000. running mean: -18.095895\n",
            "resetting env. episode 539.000000, reward total was -17.000000. running mean: -18.084936\n",
            "resetting env. episode 540.000000, reward total was -19.000000. running mean: -18.094087\n",
            "resetting env. episode 541.000000, reward total was -19.000000. running mean: -18.103146\n",
            "resetting env. episode 542.000000, reward total was -17.000000. running mean: -18.092114\n",
            "resetting env. episode 543.000000, reward total was -18.000000. running mean: -18.091193\n",
            "resetting env. episode 544.000000, reward total was -16.000000. running mean: -18.070281\n",
            "resetting env. episode 545.000000, reward total was -16.000000. running mean: -18.049579\n",
            "resetting env. episode 546.000000, reward total was -20.000000. running mean: -18.069083\n",
            "resetting env. episode 547.000000, reward total was -19.000000. running mean: -18.078392\n",
            "resetting env. episode 548.000000, reward total was -21.000000. running mean: -18.107608\n",
            "resetting env. episode 549.000000, reward total was -21.000000. running mean: -18.136532\n",
            "resetting env. episode 550.000000, reward total was -19.000000. running mean: -18.145167\n",
            "resetting env. episode 551.000000, reward total was -16.000000. running mean: -18.123715\n",
            "resetting env. episode 552.000000, reward total was -20.000000. running mean: -18.142478\n",
            "resetting env. episode 553.000000, reward total was -18.000000. running mean: -18.141053\n",
            "resetting env. episode 554.000000, reward total was -20.000000. running mean: -18.159642\n",
            "resetting env. episode 555.000000, reward total was -19.000000. running mean: -18.168046\n",
            "resetting env. episode 556.000000, reward total was -20.000000. running mean: -18.186366\n",
            "resetting env. episode 557.000000, reward total was -20.000000. running mean: -18.204502\n",
            "resetting env. episode 558.000000, reward total was -19.000000. running mean: -18.212457\n",
            "resetting env. episode 559.000000, reward total was -17.000000. running mean: -18.200332\n",
            "resetting env. episode 560.000000, reward total was -18.000000. running mean: -18.198329\n",
            "resetting env. episode 561.000000, reward total was -17.000000. running mean: -18.186346\n",
            "resetting env. episode 562.000000, reward total was -17.000000. running mean: -18.174482\n",
            "resetting env. episode 563.000000, reward total was -19.000000. running mean: -18.182737\n",
            "resetting env. episode 564.000000, reward total was -16.000000. running mean: -18.160910\n",
            "resetting env. episode 565.000000, reward total was -17.000000. running mean: -18.149301\n",
            "resetting env. episode 566.000000, reward total was -18.000000. running mean: -18.147808\n",
            "resetting env. episode 567.000000, reward total was -17.000000. running mean: -18.136330\n",
            "resetting env. episode 568.000000, reward total was -20.000000. running mean: -18.154967\n",
            "resetting env. episode 569.000000, reward total was -20.000000. running mean: -18.173417\n",
            "resetting env. episode 570.000000, reward total was -19.000000. running mean: -18.181683\n",
            "resetting env. episode 571.000000, reward total was -20.000000. running mean: -18.199866\n",
            "resetting env. episode 572.000000, reward total was -19.000000. running mean: -18.207867\n",
            "resetting env. episode 573.000000, reward total was -16.000000. running mean: -18.185789\n",
            "resetting env. episode 574.000000, reward total was -18.000000. running mean: -18.183931\n",
            "resetting env. episode 575.000000, reward total was -17.000000. running mean: -18.172091\n",
            "resetting env. episode 576.000000, reward total was -19.000000. running mean: -18.180370\n",
            "resetting env. episode 577.000000, reward total was -17.000000. running mean: -18.168567\n",
            "resetting env. episode 578.000000, reward total was -18.000000. running mean: -18.166881\n",
            "resetting env. episode 579.000000, reward total was -16.000000. running mean: -18.145212\n",
            "resetting env. episode 580.000000, reward total was -18.000000. running mean: -18.143760\n",
            "resetting env. episode 581.000000, reward total was -20.000000. running mean: -18.162323\n",
            "resetting env. episode 582.000000, reward total was -17.000000. running mean: -18.150699\n",
            "resetting env. episode 583.000000, reward total was -16.000000. running mean: -18.129192\n",
            "resetting env. episode 584.000000, reward total was -16.000000. running mean: -18.107900\n",
            "resetting env. episode 585.000000, reward total was -17.000000. running mean: -18.096821\n",
            "resetting env. episode 586.000000, reward total was -18.000000. running mean: -18.095853\n",
            "resetting env. episode 587.000000, reward total was -18.000000. running mean: -18.094895\n",
            "resetting env. episode 588.000000, reward total was -17.000000. running mean: -18.083946\n",
            "resetting env. episode 589.000000, reward total was -18.000000. running mean: -18.083106\n",
            "resetting env. episode 590.000000, reward total was -19.000000. running mean: -18.092275\n",
            "resetting env. episode 591.000000, reward total was -17.000000. running mean: -18.081352\n",
            "resetting env. episode 592.000000, reward total was -16.000000. running mean: -18.060539\n",
            "resetting env. episode 593.000000, reward total was -21.000000. running mean: -18.089934\n",
            "resetting env. episode 594.000000, reward total was -18.000000. running mean: -18.089034\n",
            "resetting env. episode 595.000000, reward total was -19.000000. running mean: -18.098144\n",
            "resetting env. episode 596.000000, reward total was -19.000000. running mean: -18.107162\n",
            "resetting env. episode 597.000000, reward total was -19.000000. running mean: -18.116091\n",
            "resetting env. episode 598.000000, reward total was -20.000000. running mean: -18.134930\n",
            "resetting env. episode 599.000000, reward total was -19.000000. running mean: -18.143581\n",
            "resetting env. episode 600.000000, reward total was -20.000000. running mean: -18.162145\n",
            "resetting env. episode 601.000000, reward total was -19.000000. running mean: -18.170523\n",
            "resetting env. episode 602.000000, reward total was -20.000000. running mean: -18.188818\n",
            "resetting env. episode 603.000000, reward total was -18.000000. running mean: -18.186930\n",
            "resetting env. episode 604.000000, reward total was -19.000000. running mean: -18.195061\n",
            "resetting env. episode 605.000000, reward total was -16.000000. running mean: -18.173110\n",
            "resetting env. episode 606.000000, reward total was -19.000000. running mean: -18.181379\n",
            "resetting env. episode 607.000000, reward total was -19.000000. running mean: -18.189565\n",
            "resetting env. episode 608.000000, reward total was -19.000000. running mean: -18.197669\n",
            "resetting env. episode 609.000000, reward total was -17.000000. running mean: -18.185693\n",
            "resetting env. episode 610.000000, reward total was -19.000000. running mean: -18.193836\n",
            "resetting env. episode 611.000000, reward total was -19.000000. running mean: -18.201898\n",
            "resetting env. episode 612.000000, reward total was -19.000000. running mean: -18.209879\n",
            "resetting env. episode 613.000000, reward total was -20.000000. running mean: -18.227780\n",
            "resetting env. episode 614.000000, reward total was -20.000000. running mean: -18.245502\n",
            "resetting env. episode 615.000000, reward total was -19.000000. running mean: -18.253047\n",
            "resetting env. episode 616.000000, reward total was -20.000000. running mean: -18.270516\n",
            "resetting env. episode 617.000000, reward total was -20.000000. running mean: -18.287811\n",
            "resetting env. episode 618.000000, reward total was -18.000000. running mean: -18.284933\n",
            "resetting env. episode 619.000000, reward total was -19.000000. running mean: -18.292084\n",
            "resetting env. episode 620.000000, reward total was -18.000000. running mean: -18.289163\n",
            "resetting env. episode 621.000000, reward total was -21.000000. running mean: -18.316271\n",
            "resetting env. episode 622.000000, reward total was -18.000000. running mean: -18.313109\n",
            "resetting env. episode 623.000000, reward total was -14.000000. running mean: -18.269978\n",
            "resetting env. episode 624.000000, reward total was -20.000000. running mean: -18.287278\n",
            "resetting env. episode 625.000000, reward total was -17.000000. running mean: -18.274405\n",
            "resetting env. episode 626.000000, reward total was -19.000000. running mean: -18.281661\n",
            "resetting env. episode 627.000000, reward total was -18.000000. running mean: -18.278844\n",
            "resetting env. episode 628.000000, reward total was -17.000000. running mean: -18.266056\n",
            "resetting env. episode 629.000000, reward total was -15.000000. running mean: -18.233395\n",
            "resetting env. episode 630.000000, reward total was -20.000000. running mean: -18.251061\n",
            "resetting env. episode 631.000000, reward total was -18.000000. running mean: -18.248551\n",
            "resetting env. episode 632.000000, reward total was -19.000000. running mean: -18.256065\n",
            "resetting env. episode 633.000000, reward total was -16.000000. running mean: -18.233505\n",
            "resetting env. episode 634.000000, reward total was -17.000000. running mean: -18.221170\n",
            "resetting env. episode 635.000000, reward total was -20.000000. running mean: -18.238958\n",
            "resetting env. episode 636.000000, reward total was -16.000000. running mean: -18.216568\n",
            "resetting env. episode 637.000000, reward total was -19.000000. running mean: -18.224403\n",
            "resetting env. episode 638.000000, reward total was -19.000000. running mean: -18.232159\n",
            "resetting env. episode 639.000000, reward total was -20.000000. running mean: -18.249837\n",
            "resetting env. episode 640.000000, reward total was -18.000000. running mean: -18.247339\n",
            "resetting env. episode 641.000000, reward total was -18.000000. running mean: -18.244865\n",
            "resetting env. episode 642.000000, reward total was -19.000000. running mean: -18.252417\n",
            "resetting env. episode 643.000000, reward total was -16.000000. running mean: -18.229892\n",
            "resetting env. episode 644.000000, reward total was -18.000000. running mean: -18.227594\n",
            "resetting env. episode 645.000000, reward total was -20.000000. running mean: -18.245318\n",
            "resetting env. episode 646.000000, reward total was -19.000000. running mean: -18.252864\n",
            "resetting env. episode 647.000000, reward total was -17.000000. running mean: -18.240336\n",
            "resetting env. episode 648.000000, reward total was -17.000000. running mean: -18.227932\n",
            "resetting env. episode 649.000000, reward total was -19.000000. running mean: -18.235653\n",
            "resetting env. episode 650.000000, reward total was -20.000000. running mean: -18.253297\n",
            "resetting env. episode 651.000000, reward total was -16.000000. running mean: -18.230764\n",
            "resetting env. episode 652.000000, reward total was -17.000000. running mean: -18.218456\n",
            "resetting env. episode 653.000000, reward total was -21.000000. running mean: -18.246271\n",
            "resetting env. episode 654.000000, reward total was -17.000000. running mean: -18.233809\n",
            "resetting env. episode 655.000000, reward total was -17.000000. running mean: -18.221471\n",
            "resetting env. episode 656.000000, reward total was -15.000000. running mean: -18.189256\n",
            "resetting env. episode 657.000000, reward total was -21.000000. running mean: -18.217363\n",
            "resetting env. episode 658.000000, reward total was -21.000000. running mean: -18.245190\n",
            "resetting env. episode 659.000000, reward total was -18.000000. running mean: -18.242738\n",
            "resetting env. episode 660.000000, reward total was -20.000000. running mean: -18.260310\n",
            "resetting env. episode 661.000000, reward total was -19.000000. running mean: -18.267707\n",
            "resetting env. episode 662.000000, reward total was -16.000000. running mean: -18.245030\n",
            "resetting env. episode 663.000000, reward total was -16.000000. running mean: -18.222580\n",
            "resetting env. episode 664.000000, reward total was -16.000000. running mean: -18.200354\n",
            "resetting env. episode 665.000000, reward total was -17.000000. running mean: -18.188351\n",
            "resetting env. episode 666.000000, reward total was -13.000000. running mean: -18.136467\n",
            "resetting env. episode 667.000000, reward total was -20.000000. running mean: -18.155102\n",
            "resetting env. episode 668.000000, reward total was -19.000000. running mean: -18.163551\n",
            "resetting env. episode 669.000000, reward total was -17.000000. running mean: -18.151916\n",
            "resetting env. episode 670.000000, reward total was -14.000000. running mean: -18.110397\n",
            "resetting env. episode 671.000000, reward total was -19.000000. running mean: -18.119293\n",
            "resetting env. episode 672.000000, reward total was -15.000000. running mean: -18.088100\n",
            "resetting env. episode 673.000000, reward total was -19.000000. running mean: -18.097219\n",
            "resetting env. episode 674.000000, reward total was -16.000000. running mean: -18.076247\n",
            "resetting env. episode 675.000000, reward total was -19.000000. running mean: -18.085484\n",
            "resetting env. episode 676.000000, reward total was -21.000000. running mean: -18.114629\n",
            "resetting env. episode 677.000000, reward total was -20.000000. running mean: -18.133483\n",
            "resetting env. episode 678.000000, reward total was -17.000000. running mean: -18.122148\n",
            "resetting env. episode 679.000000, reward total was -18.000000. running mean: -18.120927\n",
            "resetting env. episode 680.000000, reward total was -17.000000. running mean: -18.109717\n",
            "resetting env. episode 681.000000, reward total was -15.000000. running mean: -18.078620\n",
            "resetting env. episode 682.000000, reward total was -18.000000. running mean: -18.077834\n",
            "resetting env. episode 683.000000, reward total was -19.000000. running mean: -18.087056\n",
            "resetting env. episode 684.000000, reward total was -19.000000. running mean: -18.096185\n",
            "resetting env. episode 685.000000, reward total was -19.000000. running mean: -18.105223\n",
            "resetting env. episode 686.000000, reward total was -17.000000. running mean: -18.094171\n",
            "resetting env. episode 687.000000, reward total was -16.000000. running mean: -18.073229\n",
            "resetting env. episode 688.000000, reward total was -16.000000. running mean: -18.052497\n",
            "resetting env. episode 689.000000, reward total was -19.000000. running mean: -18.061972\n",
            "resetting env. episode 690.000000, reward total was -17.000000. running mean: -18.051352\n",
            "resetting env. episode 691.000000, reward total was -19.000000. running mean: -18.060839\n",
            "resetting env. episode 692.000000, reward total was -19.000000. running mean: -18.070230\n",
            "resetting env. episode 693.000000, reward total was -21.000000. running mean: -18.099528\n",
            "resetting env. episode 694.000000, reward total was -20.000000. running mean: -18.118533\n",
            "resetting env. episode 695.000000, reward total was -17.000000. running mean: -18.107348\n",
            "resetting env. episode 696.000000, reward total was -21.000000. running mean: -18.136274\n",
            "resetting env. episode 697.000000, reward total was -20.000000. running mean: -18.154911\n",
            "resetting env. episode 698.000000, reward total was -18.000000. running mean: -18.153362\n",
            "resetting env. episode 699.000000, reward total was -18.000000. running mean: -18.151829\n",
            "resetting env. episode 700.000000, reward total was -18.000000. running mean: -18.150310\n",
            "resetting env. episode 701.000000, reward total was -17.000000. running mean: -18.138807\n",
            "resetting env. episode 702.000000, reward total was -17.000000. running mean: -18.127419\n",
            "resetting env. episode 703.000000, reward total was -20.000000. running mean: -18.146145\n",
            "resetting env. episode 704.000000, reward total was -18.000000. running mean: -18.144684\n",
            "resetting env. episode 705.000000, reward total was -21.000000. running mean: -18.173237\n",
            "resetting env. episode 706.000000, reward total was -20.000000. running mean: -18.191504\n",
            "resetting env. episode 707.000000, reward total was -18.000000. running mean: -18.189589\n",
            "resetting env. episode 708.000000, reward total was -19.000000. running mean: -18.197693\n",
            "resetting env. episode 709.000000, reward total was -20.000000. running mean: -18.215716\n",
            "resetting env. episode 710.000000, reward total was -18.000000. running mean: -18.213559\n",
            "resetting env. episode 711.000000, reward total was -18.000000. running mean: -18.211424\n",
            "resetting env. episode 712.000000, reward total was -19.000000. running mean: -18.219309\n",
            "resetting env. episode 713.000000, reward total was -19.000000. running mean: -18.227116\n",
            "resetting env. episode 714.000000, reward total was -16.000000. running mean: -18.204845\n",
            "resetting env. episode 715.000000, reward total was -19.000000. running mean: -18.212797\n",
            "resetting env. episode 716.000000, reward total was -19.000000. running mean: -18.220669\n",
            "resetting env. episode 717.000000, reward total was -14.000000. running mean: -18.178462\n",
            "resetting env. episode 718.000000, reward total was -20.000000. running mean: -18.196677\n",
            "resetting env. episode 719.000000, reward total was -18.000000. running mean: -18.194711\n",
            "resetting env. episode 720.000000, reward total was -15.000000. running mean: -18.162764\n",
            "resetting env. episode 721.000000, reward total was -20.000000. running mean: -18.181136\n",
            "resetting env. episode 722.000000, reward total was -17.000000. running mean: -18.169325\n",
            "resetting env. episode 723.000000, reward total was -19.000000. running mean: -18.177631\n",
            "resetting env. episode 724.000000, reward total was -19.000000. running mean: -18.185855\n",
            "resetting env. episode 725.000000, reward total was -18.000000. running mean: -18.183996\n",
            "resetting env. episode 726.000000, reward total was -17.000000. running mean: -18.172157\n",
            "resetting env. episode 727.000000, reward total was -20.000000. running mean: -18.190435\n",
            "resetting env. episode 728.000000, reward total was -17.000000. running mean: -18.178531\n",
            "resetting env. episode 729.000000, reward total was -20.000000. running mean: -18.196745\n",
            "resetting env. episode 730.000000, reward total was -20.000000. running mean: -18.214778\n",
            "resetting env. episode 731.000000, reward total was -19.000000. running mean: -18.222630\n",
            "resetting env. episode 732.000000, reward total was -18.000000. running mean: -18.220404\n",
            "resetting env. episode 733.000000, reward total was -19.000000. running mean: -18.228200\n",
            "resetting env. episode 734.000000, reward total was -18.000000. running mean: -18.225918\n",
            "resetting env. episode 735.000000, reward total was -20.000000. running mean: -18.243659\n",
            "resetting env. episode 736.000000, reward total was -19.000000. running mean: -18.251222\n",
            "resetting env. episode 737.000000, reward total was -17.000000. running mean: -18.238710\n",
            "resetting env. episode 738.000000, reward total was -17.000000. running mean: -18.226323\n",
            "resetting env. episode 739.000000, reward total was -19.000000. running mean: -18.234059\n",
            "resetting env. episode 740.000000, reward total was -18.000000. running mean: -18.231719\n",
            "resetting env. episode 741.000000, reward total was -20.000000. running mean: -18.249402\n",
            "resetting env. episode 742.000000, reward total was -16.000000. running mean: -18.226908\n",
            "resetting env. episode 743.000000, reward total was -19.000000. running mean: -18.234639\n",
            "resetting env. episode 744.000000, reward total was -20.000000. running mean: -18.252292\n",
            "resetting env. episode 745.000000, reward total was -17.000000. running mean: -18.239769\n",
            "resetting env. episode 746.000000, reward total was -16.000000. running mean: -18.217372\n",
            "resetting env. episode 747.000000, reward total was -20.000000. running mean: -18.235198\n",
            "resetting env. episode 748.000000, reward total was -20.000000. running mean: -18.252846\n",
            "resetting env. episode 749.000000, reward total was -17.000000. running mean: -18.240317\n",
            "resetting env. episode 750.000000, reward total was -19.000000. running mean: -18.247914\n",
            "resetting env. episode 751.000000, reward total was -19.000000. running mean: -18.255435\n",
            "resetting env. episode 752.000000, reward total was -17.000000. running mean: -18.242881\n",
            "resetting env. episode 753.000000, reward total was -21.000000. running mean: -18.270452\n",
            "resetting env. episode 754.000000, reward total was -18.000000. running mean: -18.267747\n",
            "resetting env. episode 755.000000, reward total was -16.000000. running mean: -18.245070\n",
            "resetting env. episode 756.000000, reward total was -17.000000. running mean: -18.232619\n",
            "resetting env. episode 757.000000, reward total was -16.000000. running mean: -18.210293\n",
            "resetting env. episode 758.000000, reward total was -19.000000. running mean: -18.218190\n",
            "resetting env. episode 759.000000, reward total was -19.000000. running mean: -18.226008\n",
            "resetting env. episode 760.000000, reward total was -21.000000. running mean: -18.253748\n",
            "resetting env. episode 761.000000, reward total was -19.000000. running mean: -18.261211\n",
            "resetting env. episode 762.000000, reward total was -19.000000. running mean: -18.268599\n",
            "resetting env. episode 763.000000, reward total was -17.000000. running mean: -18.255913\n",
            "resetting env. episode 764.000000, reward total was -20.000000. running mean: -18.273353\n",
            "resetting env. episode 765.000000, reward total was -18.000000. running mean: -18.270620\n",
            "resetting env. episode 766.000000, reward total was -18.000000. running mean: -18.267914\n",
            "resetting env. episode 767.000000, reward total was -15.000000. running mean: -18.235235\n",
            "resetting env. episode 768.000000, reward total was -16.000000. running mean: -18.212882\n",
            "resetting env. episode 769.000000, reward total was -19.000000. running mean: -18.220753\n",
            "resetting env. episode 770.000000, reward total was -19.000000. running mean: -18.228546\n",
            "resetting env. episode 771.000000, reward total was -17.000000. running mean: -18.216260\n",
            "resetting env. episode 772.000000, reward total was -17.000000. running mean: -18.204098\n",
            "resetting env. episode 773.000000, reward total was -19.000000. running mean: -18.212057\n",
            "resetting env. episode 774.000000, reward total was -19.000000. running mean: -18.219936\n",
            "resetting env. episode 775.000000, reward total was -17.000000. running mean: -18.207737\n",
            "resetting env. episode 776.000000, reward total was -19.000000. running mean: -18.215660\n",
            "resetting env. episode 777.000000, reward total was -19.000000. running mean: -18.223503\n",
            "resetting env. episode 778.000000, reward total was -19.000000. running mean: -18.231268\n",
            "resetting env. episode 779.000000, reward total was -19.000000. running mean: -18.238955\n",
            "resetting env. episode 780.000000, reward total was -19.000000. running mean: -18.246566\n",
            "resetting env. episode 781.000000, reward total was -17.000000. running mean: -18.234100\n",
            "resetting env. episode 782.000000, reward total was -13.000000. running mean: -18.181759\n",
            "resetting env. episode 783.000000, reward total was -20.000000. running mean: -18.199941\n",
            "resetting env. episode 784.000000, reward total was -12.000000. running mean: -18.137942\n",
            "resetting env. episode 785.000000, reward total was -18.000000. running mean: -18.136563\n",
            "resetting env. episode 786.000000, reward total was -19.000000. running mean: -18.145197\n",
            "resetting env. episode 787.000000, reward total was -21.000000. running mean: -18.173745\n",
            "resetting env. episode 788.000000, reward total was -19.000000. running mean: -18.182008\n",
            "resetting env. episode 789.000000, reward total was -20.000000. running mean: -18.200187\n",
            "resetting env. episode 790.000000, reward total was -21.000000. running mean: -18.228186\n",
            "resetting env. episode 791.000000, reward total was -18.000000. running mean: -18.225904\n",
            "resetting env. episode 792.000000, reward total was -15.000000. running mean: -18.193645\n",
            "resetting env. episode 793.000000, reward total was -17.000000. running mean: -18.181708\n",
            "resetting env. episode 794.000000, reward total was -19.000000. running mean: -18.189891\n",
            "resetting env. episode 795.000000, reward total was -18.000000. running mean: -18.187992\n",
            "resetting env. episode 796.000000, reward total was -19.000000. running mean: -18.196112\n",
            "resetting env. episode 797.000000, reward total was -18.000000. running mean: -18.194151\n",
            "resetting env. episode 798.000000, reward total was -16.000000. running mean: -18.172210\n",
            "resetting env. episode 799.000000, reward total was -17.000000. running mean: -18.160488\n",
            "resetting env. episode 800.000000, reward total was -19.000000. running mean: -18.168883\n",
            "resetting env. episode 801.000000, reward total was -17.000000. running mean: -18.157194\n",
            "resetting env. episode 802.000000, reward total was -18.000000. running mean: -18.155622\n",
            "resetting env. episode 803.000000, reward total was -18.000000. running mean: -18.154066\n",
            "resetting env. episode 804.000000, reward total was -19.000000. running mean: -18.162525\n",
            "resetting env. episode 805.000000, reward total was -19.000000. running mean: -18.170900\n",
            "resetting env. episode 806.000000, reward total was -18.000000. running mean: -18.169191\n",
            "resetting env. episode 807.000000, reward total was -20.000000. running mean: -18.187499\n",
            "resetting env. episode 808.000000, reward total was -17.000000. running mean: -18.175624\n",
            "resetting env. episode 809.000000, reward total was -19.000000. running mean: -18.183868\n",
            "resetting env. episode 810.000000, reward total was -19.000000. running mean: -18.192029\n",
            "resetting env. episode 811.000000, reward total was -19.000000. running mean: -18.200109\n",
            "resetting env. episode 812.000000, reward total was -19.000000. running mean: -18.208108\n",
            "resetting env. episode 813.000000, reward total was -19.000000. running mean: -18.216027\n",
            "resetting env. episode 814.000000, reward total was -17.000000. running mean: -18.203866\n",
            "resetting env. episode 815.000000, reward total was -19.000000. running mean: -18.211828\n",
            "resetting env. episode 816.000000, reward total was -19.000000. running mean: -18.219709\n",
            "resetting env. episode 817.000000, reward total was -18.000000. running mean: -18.217512\n",
            "resetting env. episode 818.000000, reward total was -19.000000. running mean: -18.225337\n",
            "resetting env. episode 819.000000, reward total was -17.000000. running mean: -18.213084\n",
            "resetting env. episode 820.000000, reward total was -19.000000. running mean: -18.220953\n",
            "resetting env. episode 821.000000, reward total was -19.000000. running mean: -18.228743\n",
            "resetting env. episode 822.000000, reward total was -19.000000. running mean: -18.236456\n",
            "resetting env. episode 823.000000, reward total was -19.000000. running mean: -18.244091\n",
            "resetting env. episode 824.000000, reward total was -16.000000. running mean: -18.221650\n",
            "resetting env. episode 825.000000, reward total was -20.000000. running mean: -18.239434\n",
            "resetting env. episode 826.000000, reward total was -16.000000. running mean: -18.217040\n",
            "resetting env. episode 827.000000, reward total was -20.000000. running mean: -18.234869\n",
            "resetting env. episode 828.000000, reward total was -19.000000. running mean: -18.242521\n",
            "resetting env. episode 829.000000, reward total was -17.000000. running mean: -18.230095\n",
            "resetting env. episode 830.000000, reward total was -18.000000. running mean: -18.227794\n",
            "resetting env. episode 831.000000, reward total was -17.000000. running mean: -18.215516\n",
            "resetting env. episode 832.000000, reward total was -16.000000. running mean: -18.193361\n",
            "resetting env. episode 833.000000, reward total was -17.000000. running mean: -18.181428\n",
            "resetting env. episode 834.000000, reward total was -16.000000. running mean: -18.159613\n",
            "resetting env. episode 835.000000, reward total was -17.000000. running mean: -18.148017\n",
            "resetting env. episode 836.000000, reward total was -18.000000. running mean: -18.146537\n",
            "resetting env. episode 837.000000, reward total was -19.000000. running mean: -18.155072\n",
            "resetting env. episode 838.000000, reward total was -20.000000. running mean: -18.173521\n",
            "resetting env. episode 839.000000, reward total was -17.000000. running mean: -18.161786\n",
            "resetting env. episode 840.000000, reward total was -19.000000. running mean: -18.170168\n",
            "resetting env. episode 841.000000, reward total was -18.000000. running mean: -18.168466\n",
            "resetting env. episode 842.000000, reward total was -18.000000. running mean: -18.166782\n",
            "resetting env. episode 843.000000, reward total was -20.000000. running mean: -18.185114\n",
            "resetting env. episode 844.000000, reward total was -17.000000. running mean: -18.173263\n",
            "resetting env. episode 845.000000, reward total was -18.000000. running mean: -18.171530\n",
            "resetting env. episode 846.000000, reward total was -15.000000. running mean: -18.139815\n",
            "resetting env. episode 847.000000, reward total was -18.000000. running mean: -18.138417\n",
            "resetting env. episode 848.000000, reward total was -11.000000. running mean: -18.067032\n",
            "resetting env. episode 849.000000, reward total was -14.000000. running mean: -18.026362\n",
            "resetting env. episode 850.000000, reward total was -14.000000. running mean: -17.986098\n",
            "resetting env. episode 851.000000, reward total was -19.000000. running mean: -17.996237\n",
            "resetting env. episode 852.000000, reward total was -18.000000. running mean: -17.996275\n",
            "resetting env. episode 853.000000, reward total was -13.000000. running mean: -17.946312\n",
            "resetting env. episode 854.000000, reward total was -17.000000. running mean: -17.936849\n",
            "resetting env. episode 855.000000, reward total was -17.000000. running mean: -17.927481\n",
            "resetting env. episode 856.000000, reward total was -16.000000. running mean: -17.908206\n",
            "resetting env. episode 857.000000, reward total was -17.000000. running mean: -17.899124\n",
            "resetting env. episode 858.000000, reward total was -19.000000. running mean: -17.910133\n",
            "resetting env. episode 859.000000, reward total was -19.000000. running mean: -17.921031\n",
            "resetting env. episode 860.000000, reward total was -18.000000. running mean: -17.921821\n",
            "resetting env. episode 861.000000, reward total was -20.000000. running mean: -17.942603\n",
            "resetting env. episode 862.000000, reward total was -18.000000. running mean: -17.943177\n",
            "resetting env. episode 863.000000, reward total was -17.000000. running mean: -17.933745\n",
            "resetting env. episode 864.000000, reward total was -18.000000. running mean: -17.934408\n",
            "resetting env. episode 865.000000, reward total was -15.000000. running mean: -17.905063\n",
            "resetting env. episode 866.000000, reward total was -21.000000. running mean: -17.936013\n",
            "resetting env. episode 867.000000, reward total was -18.000000. running mean: -17.936653\n",
            "resetting env. episode 868.000000, reward total was -17.000000. running mean: -17.927286\n",
            "resetting env. episode 869.000000, reward total was -17.000000. running mean: -17.918013\n",
            "resetting env. episode 870.000000, reward total was -15.000000. running mean: -17.888833\n",
            "resetting env. episode 871.000000, reward total was -16.000000. running mean: -17.869945\n",
            "resetting env. episode 872.000000, reward total was -19.000000. running mean: -17.881245\n",
            "resetting env. episode 873.000000, reward total was -20.000000. running mean: -17.902433\n",
            "resetting env. episode 874.000000, reward total was -15.000000. running mean: -17.873409\n",
            "resetting env. episode 875.000000, reward total was -21.000000. running mean: -17.904675\n",
            "resetting env. episode 876.000000, reward total was -12.000000. running mean: -17.845628\n",
            "resetting env. episode 877.000000, reward total was -18.000000. running mean: -17.847171\n",
            "resetting env. episode 878.000000, reward total was -17.000000. running mean: -17.838700\n",
            "resetting env. episode 879.000000, reward total was -17.000000. running mean: -17.830313\n",
            "resetting env. episode 880.000000, reward total was -21.000000. running mean: -17.862010\n",
            "resetting env. episode 881.000000, reward total was -17.000000. running mean: -17.853390\n",
            "resetting env. episode 882.000000, reward total was -17.000000. running mean: -17.844856\n",
            "resetting env. episode 883.000000, reward total was -16.000000. running mean: -17.826407\n",
            "resetting env. episode 884.000000, reward total was -14.000000. running mean: -17.788143\n",
            "resetting env. episode 885.000000, reward total was -16.000000. running mean: -17.770262\n",
            "resetting env. episode 886.000000, reward total was -19.000000. running mean: -17.782559\n",
            "resetting env. episode 887.000000, reward total was -18.000000. running mean: -17.784733\n",
            "resetting env. episode 888.000000, reward total was -17.000000. running mean: -17.776886\n",
            "resetting env. episode 889.000000, reward total was -20.000000. running mean: -17.799117\n",
            "resetting env. episode 890.000000, reward total was -16.000000. running mean: -17.781126\n",
            "resetting env. episode 891.000000, reward total was -18.000000. running mean: -17.783315\n",
            "resetting env. episode 892.000000, reward total was -19.000000. running mean: -17.795482\n",
            "resetting env. episode 893.000000, reward total was -15.000000. running mean: -17.767527\n",
            "resetting env. episode 894.000000, reward total was -18.000000. running mean: -17.769852\n",
            "resetting env. episode 895.000000, reward total was -19.000000. running mean: -17.782153\n",
            "resetting env. episode 896.000000, reward total was -13.000000. running mean: -17.734331\n",
            "resetting env. episode 897.000000, reward total was -15.000000. running mean: -17.706988\n",
            "resetting env. episode 898.000000, reward total was -16.000000. running mean: -17.689918\n",
            "resetting env. episode 899.000000, reward total was -19.000000. running mean: -17.703019\n",
            "resetting env. episode 900.000000, reward total was -15.000000. running mean: -17.675989\n",
            "resetting env. episode 901.000000, reward total was -18.000000. running mean: -17.679229\n",
            "resetting env. episode 902.000000, reward total was -19.000000. running mean: -17.692437\n",
            "resetting env. episode 903.000000, reward total was -17.000000. running mean: -17.685512\n",
            "resetting env. episode 904.000000, reward total was -21.000000. running mean: -17.718657\n",
            "resetting env. episode 905.000000, reward total was -21.000000. running mean: -17.751471\n",
            "resetting env. episode 906.000000, reward total was -19.000000. running mean: -17.763956\n",
            "resetting env. episode 907.000000, reward total was -16.000000. running mean: -17.746316\n",
            "resetting env. episode 908.000000, reward total was -18.000000. running mean: -17.748853\n",
            "resetting env. episode 909.000000, reward total was -17.000000. running mean: -17.741365\n",
            "resetting env. episode 910.000000, reward total was -15.000000. running mean: -17.713951\n",
            "resetting env. episode 911.000000, reward total was -19.000000. running mean: -17.726812\n",
            "resetting env. episode 912.000000, reward total was -19.000000. running mean: -17.739543\n",
            "resetting env. episode 913.000000, reward total was -21.000000. running mean: -17.772148\n",
            "resetting env. episode 914.000000, reward total was -19.000000. running mean: -17.784427\n",
            "resetting env. episode 915.000000, reward total was -13.000000. running mean: -17.736582\n",
            "resetting env. episode 916.000000, reward total was -17.000000. running mean: -17.729216\n",
            "resetting env. episode 917.000000, reward total was -16.000000. running mean: -17.711924\n",
            "resetting env. episode 918.000000, reward total was -16.000000. running mean: -17.694805\n",
            "resetting env. episode 919.000000, reward total was -18.000000. running mean: -17.697857\n",
            "resetting env. episode 920.000000, reward total was -21.000000. running mean: -17.730878\n",
            "resetting env. episode 921.000000, reward total was -19.000000. running mean: -17.743570\n",
            "resetting env. episode 922.000000, reward total was -14.000000. running mean: -17.706134\n",
            "resetting env. episode 923.000000, reward total was -16.000000. running mean: -17.689073\n",
            "resetting env. episode 924.000000, reward total was -18.000000. running mean: -17.692182\n",
            "resetting env. episode 925.000000, reward total was -15.000000. running mean: -17.665260\n",
            "resetting env. episode 926.000000, reward total was -19.000000. running mean: -17.678607\n",
            "resetting env. episode 927.000000, reward total was -12.000000. running mean: -17.621821\n",
            "resetting env. episode 928.000000, reward total was -17.000000. running mean: -17.615603\n",
            "resetting env. episode 929.000000, reward total was -16.000000. running mean: -17.599447\n",
            "resetting env. episode 930.000000, reward total was -18.000000. running mean: -17.603453\n",
            "resetting env. episode 931.000000, reward total was -17.000000. running mean: -17.597418\n",
            "resetting env. episode 932.000000, reward total was -18.000000. running mean: -17.601444\n",
            "resetting env. episode 933.000000, reward total was -18.000000. running mean: -17.605430\n",
            "resetting env. episode 934.000000, reward total was -19.000000. running mean: -17.619375\n",
            "resetting env. episode 935.000000, reward total was -19.000000. running mean: -17.633181\n",
            "resetting env. episode 936.000000, reward total was -17.000000. running mean: -17.626850\n",
            "resetting env. episode 937.000000, reward total was -20.000000. running mean: -17.650581\n",
            "resetting env. episode 938.000000, reward total was -17.000000. running mean: -17.644075\n",
            "resetting env. episode 939.000000, reward total was -19.000000. running mean: -17.657635\n",
            "resetting env. episode 940.000000, reward total was -13.000000. running mean: -17.611058\n",
            "resetting env. episode 941.000000, reward total was -19.000000. running mean: -17.624948\n",
            "resetting env. episode 942.000000, reward total was -18.000000. running mean: -17.628698\n",
            "resetting env. episode 943.000000, reward total was -17.000000. running mean: -17.622411\n",
            "resetting env. episode 944.000000, reward total was -18.000000. running mean: -17.626187\n",
            "resetting env. episode 945.000000, reward total was -17.000000. running mean: -17.619925\n",
            "resetting env. episode 946.000000, reward total was -21.000000. running mean: -17.653726\n",
            "resetting env. episode 947.000000, reward total was -18.000000. running mean: -17.657189\n",
            "resetting env. episode 948.000000, reward total was -19.000000. running mean: -17.670617\n",
            "resetting env. episode 949.000000, reward total was -21.000000. running mean: -17.703911\n",
            "resetting env. episode 950.000000, reward total was -20.000000. running mean: -17.726872\n",
            "resetting env. episode 951.000000, reward total was -15.000000. running mean: -17.699603\n",
            "resetting env. episode 952.000000, reward total was -18.000000. running mean: -17.702607\n",
            "resetting env. episode 953.000000, reward total was -14.000000. running mean: -17.665581\n",
            "resetting env. episode 954.000000, reward total was -18.000000. running mean: -17.668925\n",
            "resetting env. episode 955.000000, reward total was -19.000000. running mean: -17.682236\n",
            "resetting env. episode 956.000000, reward total was -18.000000. running mean: -17.685413\n",
            "resetting env. episode 957.000000, reward total was -18.000000. running mean: -17.688559\n",
            "resetting env. episode 958.000000, reward total was -19.000000. running mean: -17.701674\n",
            "resetting env. episode 959.000000, reward total was -17.000000. running mean: -17.694657\n",
            "resetting env. episode 960.000000, reward total was -13.000000. running mean: -17.647710\n",
            "resetting env. episode 961.000000, reward total was -15.000000. running mean: -17.621233\n",
            "resetting env. episode 962.000000, reward total was -16.000000. running mean: -17.605021\n",
            "resetting env. episode 963.000000, reward total was -19.000000. running mean: -17.618971\n",
            "resetting env. episode 964.000000, reward total was -13.000000. running mean: -17.572781\n",
            "resetting env. episode 965.000000, reward total was -16.000000. running mean: -17.557053\n",
            "resetting env. episode 966.000000, reward total was -16.000000. running mean: -17.541483\n",
            "resetting env. episode 967.000000, reward total was -20.000000. running mean: -17.566068\n",
            "resetting env. episode 968.000000, reward total was -20.000000. running mean: -17.590407\n",
            "resetting env. episode 969.000000, reward total was -21.000000. running mean: -17.624503\n",
            "resetting env. episode 970.000000, reward total was -18.000000. running mean: -17.628258\n",
            "resetting env. episode 971.000000, reward total was -16.000000. running mean: -17.611975\n",
            "resetting env. episode 972.000000, reward total was -18.000000. running mean: -17.615856\n",
            "resetting env. episode 973.000000, reward total was -19.000000. running mean: -17.629697\n",
            "resetting env. episode 974.000000, reward total was -17.000000. running mean: -17.623400\n",
            "resetting env. episode 975.000000, reward total was -16.000000. running mean: -17.607166\n",
            "resetting env. episode 976.000000, reward total was -19.000000. running mean: -17.621094\n",
            "resetting env. episode 977.000000, reward total was -19.000000. running mean: -17.634884\n",
            "resetting env. episode 978.000000, reward total was -19.000000. running mean: -17.648535\n",
            "resetting env. episode 979.000000, reward total was -17.000000. running mean: -17.642049\n",
            "resetting env. episode 980.000000, reward total was -20.000000. running mean: -17.665629\n",
            "resetting env. episode 981.000000, reward total was -21.000000. running mean: -17.698973\n",
            "resetting env. episode 982.000000, reward total was -17.000000. running mean: -17.691983\n",
            "resetting env. episode 983.000000, reward total was -19.000000. running mean: -17.705063\n",
            "resetting env. episode 984.000000, reward total was -17.000000. running mean: -17.698012\n",
            "resetting env. episode 985.000000, reward total was -19.000000. running mean: -17.711032\n",
            "resetting env. episode 986.000000, reward total was -16.000000. running mean: -17.693922\n",
            "resetting env. episode 987.000000, reward total was -19.000000. running mean: -17.706983\n",
            "resetting env. episode 988.000000, reward total was -17.000000. running mean: -17.699913\n",
            "resetting env. episode 989.000000, reward total was -18.000000. running mean: -17.702914\n",
            "resetting env. episode 990.000000, reward total was -18.000000. running mean: -17.705885\n",
            "resetting env. episode 991.000000, reward total was -19.000000. running mean: -17.718826\n",
            "resetting env. episode 992.000000, reward total was -13.000000. running mean: -17.671638\n",
            "resetting env. episode 993.000000, reward total was -17.000000. running mean: -17.664921\n",
            "resetting env. episode 994.000000, reward total was -17.000000. running mean: -17.658272\n",
            "resetting env. episode 995.000000, reward total was -21.000000. running mean: -17.691689\n",
            "resetting env. episode 996.000000, reward total was -17.000000. running mean: -17.684772\n",
            "resetting env. episode 997.000000, reward total was -16.000000. running mean: -17.667925\n",
            "resetting env. episode 998.000000, reward total was -18.000000. running mean: -17.671245\n",
            "resetting env. episode 999.000000, reward total was -15.000000. running mean: -17.644533\n",
            "resetting env. episode 1000.000000, reward total was -18.000000. running mean: -17.648088\n",
            "resetting env. episode 1001.000000, reward total was -21.000000. running mean: -17.681607\n",
            "resetting env. episode 1002.000000, reward total was -19.000000. running mean: -17.694791\n",
            "resetting env. episode 1003.000000, reward total was -16.000000. running mean: -17.677843\n",
            "resetting env. episode 1004.000000, reward total was -16.000000. running mean: -17.661064\n",
            "resetting env. episode 1005.000000, reward total was -21.000000. running mean: -17.694454\n",
            "resetting env. episode 1006.000000, reward total was -16.000000. running mean: -17.677509\n",
            "resetting env. episode 1007.000000, reward total was -14.000000. running mean: -17.640734\n",
            "resetting env. episode 1008.000000, reward total was -20.000000. running mean: -17.664327\n",
            "resetting env. episode 1009.000000, reward total was -14.000000. running mean: -17.627683\n",
            "resetting env. episode 1010.000000, reward total was -19.000000. running mean: -17.641407\n",
            "resetting env. episode 1011.000000, reward total was -20.000000. running mean: -17.664993\n",
            "resetting env. episode 1012.000000, reward total was -13.000000. running mean: -17.618343\n",
            "resetting env. episode 1013.000000, reward total was -20.000000. running mean: -17.642159\n",
            "resetting env. episode 1014.000000, reward total was -15.000000. running mean: -17.615738\n",
            "resetting env. episode 1015.000000, reward total was -16.000000. running mean: -17.599580\n",
            "resetting env. episode 1016.000000, reward total was -15.000000. running mean: -17.573584\n",
            "resetting env. episode 1017.000000, reward total was -18.000000. running mean: -17.577849\n",
            "resetting env. episode 1018.000000, reward total was -15.000000. running mean: -17.552070\n",
            "resetting env. episode 1019.000000, reward total was -19.000000. running mean: -17.566549\n",
            "resetting env. episode 1020.000000, reward total was -20.000000. running mean: -17.590884\n",
            "resetting env. episode 1021.000000, reward total was -21.000000. running mean: -17.624975\n",
            "resetting env. episode 1022.000000, reward total was -16.000000. running mean: -17.608725\n",
            "resetting env. episode 1023.000000, reward total was -18.000000. running mean: -17.612638\n",
            "resetting env. episode 1024.000000, reward total was -19.000000. running mean: -17.626512\n",
            "resetting env. episode 1025.000000, reward total was -18.000000. running mean: -17.630247\n",
            "resetting env. episode 1026.000000, reward total was -20.000000. running mean: -17.653944\n",
            "resetting env. episode 1027.000000, reward total was -21.000000. running mean: -17.687405\n",
            "resetting env. episode 1028.000000, reward total was -18.000000. running mean: -17.690531\n",
            "resetting env. episode 1029.000000, reward total was -18.000000. running mean: -17.693625\n",
            "resetting env. episode 1030.000000, reward total was -18.000000. running mean: -17.696689\n",
            "resetting env. episode 1031.000000, reward total was -18.000000. running mean: -17.699722\n",
            "resetting env. episode 1032.000000, reward total was -19.000000. running mean: -17.712725\n",
            "resetting env. episode 1033.000000, reward total was -18.000000. running mean: -17.715598\n",
            "resetting env. episode 1034.000000, reward total was -18.000000. running mean: -17.718442\n",
            "resetting env. episode 1035.000000, reward total was -20.000000. running mean: -17.741257\n",
            "resetting env. episode 1036.000000, reward total was -17.000000. running mean: -17.733845\n",
            "resetting env. episode 1037.000000, reward total was -17.000000. running mean: -17.726506\n",
            "resetting env. episode 1038.000000, reward total was -20.000000. running mean: -17.749241\n",
            "resetting env. episode 1039.000000, reward total was -17.000000. running mean: -17.741749\n",
            "resetting env. episode 1040.000000, reward total was -20.000000. running mean: -17.764331\n",
            "resetting env. episode 1041.000000, reward total was -21.000000. running mean: -17.796688\n",
            "resetting env. episode 1042.000000, reward total was -19.000000. running mean: -17.808721\n",
            "resetting env. episode 1043.000000, reward total was -19.000000. running mean: -17.820634\n",
            "resetting env. episode 1044.000000, reward total was -19.000000. running mean: -17.832428\n",
            "resetting env. episode 1045.000000, reward total was -16.000000. running mean: -17.814103\n",
            "resetting env. episode 1046.000000, reward total was -20.000000. running mean: -17.835962\n",
            "resetting env. episode 1047.000000, reward total was -21.000000. running mean: -17.867603\n",
            "resetting env. episode 1048.000000, reward total was -16.000000. running mean: -17.848927\n",
            "resetting env. episode 1049.000000, reward total was -17.000000. running mean: -17.840437\n",
            "resetting env. episode 1050.000000, reward total was -17.000000. running mean: -17.832033\n",
            "resetting env. episode 1051.000000, reward total was -17.000000. running mean: -17.823713\n",
            "resetting env. episode 1052.000000, reward total was -16.000000. running mean: -17.805475\n",
            "resetting env. episode 1053.000000, reward total was -16.000000. running mean: -17.787421\n",
            "resetting env. episode 1054.000000, reward total was -21.000000. running mean: -17.819547\n",
            "resetting env. episode 1055.000000, reward total was -21.000000. running mean: -17.851351\n",
            "resetting env. episode 1056.000000, reward total was -21.000000. running mean: -17.882838\n",
            "resetting env. episode 1057.000000, reward total was -19.000000. running mean: -17.894009\n",
            "resetting env. episode 1058.000000, reward total was -21.000000. running mean: -17.925069\n",
            "resetting env. episode 1059.000000, reward total was -16.000000. running mean: -17.905818\n",
            "resetting env. episode 1060.000000, reward total was -20.000000. running mean: -17.926760\n",
            "resetting env. episode 1061.000000, reward total was -17.000000. running mean: -17.917493\n",
            "resetting env. episode 1062.000000, reward total was -18.000000. running mean: -17.918318\n",
            "resetting env. episode 1063.000000, reward total was -18.000000. running mean: -17.919135\n",
            "resetting env. episode 1064.000000, reward total was -15.000000. running mean: -17.889943\n",
            "resetting env. episode 1065.000000, reward total was -17.000000. running mean: -17.881044\n",
            "resetting env. episode 1066.000000, reward total was -20.000000. running mean: -17.902233\n",
            "resetting env. episode 1067.000000, reward total was -17.000000. running mean: -17.893211\n",
            "resetting env. episode 1068.000000, reward total was -17.000000. running mean: -17.884279\n",
            "resetting env. episode 1069.000000, reward total was -19.000000. running mean: -17.895436\n",
            "resetting env. episode 1070.000000, reward total was -18.000000. running mean: -17.896482\n",
            "resetting env. episode 1071.000000, reward total was -21.000000. running mean: -17.927517\n",
            "resetting env. episode 1072.000000, reward total was -19.000000. running mean: -17.938242\n",
            "resetting env. episode 1073.000000, reward total was -19.000000. running mean: -17.948859\n",
            "resetting env. episode 1074.000000, reward total was -21.000000. running mean: -17.979371\n",
            "resetting env. episode 1075.000000, reward total was -18.000000. running mean: -17.979577\n",
            "resetting env. episode 1076.000000, reward total was -13.000000. running mean: -17.929781\n",
            "resetting env. episode 1077.000000, reward total was -17.000000. running mean: -17.920483\n",
            "resetting env. episode 1078.000000, reward total was -19.000000. running mean: -17.931279\n",
            "resetting env. episode 1079.000000, reward total was -15.000000. running mean: -17.901966\n",
            "resetting env. episode 1080.000000, reward total was -17.000000. running mean: -17.892946\n",
            "resetting env. episode 1081.000000, reward total was -18.000000. running mean: -17.894017\n",
            "resetting env. episode 1082.000000, reward total was -19.000000. running mean: -17.905077\n",
            "resetting env. episode 1083.000000, reward total was -17.000000. running mean: -17.896026\n",
            "resetting env. episode 1084.000000, reward total was -19.000000. running mean: -17.907065\n",
            "resetting env. episode 1085.000000, reward total was -21.000000. running mean: -17.937995\n",
            "resetting env. episode 1086.000000, reward total was -16.000000. running mean: -17.918615\n",
            "resetting env. episode 1087.000000, reward total was -19.000000. running mean: -17.929429\n",
            "resetting env. episode 1088.000000, reward total was -15.000000. running mean: -17.900134\n",
            "resetting env. episode 1089.000000, reward total was -15.000000. running mean: -17.871133\n",
            "resetting env. episode 1090.000000, reward total was -18.000000. running mean: -17.872422\n",
            "resetting env. episode 1091.000000, reward total was -17.000000. running mean: -17.863698\n",
            "resetting env. episode 1092.000000, reward total was -19.000000. running mean: -17.875061\n",
            "resetting env. episode 1093.000000, reward total was -14.000000. running mean: -17.836310\n",
            "resetting env. episode 1094.000000, reward total was -20.000000. running mean: -17.857947\n",
            "resetting env. episode 1095.000000, reward total was -15.000000. running mean: -17.829367\n",
            "resetting env. episode 1096.000000, reward total was -19.000000. running mean: -17.841074\n",
            "resetting env. episode 1097.000000, reward total was -15.000000. running mean: -17.812663\n",
            "resetting env. episode 1098.000000, reward total was -19.000000. running mean: -17.824536\n",
            "resetting env. episode 1099.000000, reward total was -20.000000. running mean: -17.846291\n",
            "resetting env. episode 1100.000000, reward total was -20.000000. running mean: -17.867828\n",
            "resetting env. episode 1101.000000, reward total was -17.000000. running mean: -17.859150\n",
            "resetting env. episode 1102.000000, reward total was -17.000000. running mean: -17.850558\n",
            "resetting env. episode 1103.000000, reward total was -18.000000. running mean: -17.852053\n",
            "resetting env. episode 1104.000000, reward total was -15.000000. running mean: -17.823532\n",
            "resetting env. episode 1105.000000, reward total was -19.000000. running mean: -17.835297\n",
            "resetting env. episode 1106.000000, reward total was -17.000000. running mean: -17.826944\n",
            "resetting env. episode 1107.000000, reward total was -21.000000. running mean: -17.858674\n",
            "resetting env. episode 1108.000000, reward total was -17.000000. running mean: -17.850088\n",
            "resetting env. episode 1109.000000, reward total was -18.000000. running mean: -17.851587\n",
            "resetting env. episode 1110.000000, reward total was -17.000000. running mean: -17.843071\n",
            "resetting env. episode 1111.000000, reward total was -17.000000. running mean: -17.834640\n",
            "resetting env. episode 1112.000000, reward total was -21.000000. running mean: -17.866294\n",
            "resetting env. episode 1113.000000, reward total was -16.000000. running mean: -17.847631\n",
            "resetting env. episode 1114.000000, reward total was -17.000000. running mean: -17.839155\n",
            "resetting env. episode 1115.000000, reward total was -19.000000. running mean: -17.850763\n",
            "resetting env. episode 1116.000000, reward total was -20.000000. running mean: -17.872255\n",
            "resetting env. episode 1117.000000, reward total was -17.000000. running mean: -17.863533\n",
            "resetting env. episode 1118.000000, reward total was -17.000000. running mean: -17.854898\n",
            "resetting env. episode 1119.000000, reward total was -18.000000. running mean: -17.856349\n",
            "resetting env. episode 1120.000000, reward total was -19.000000. running mean: -17.867785\n",
            "resetting env. episode 1121.000000, reward total was -17.000000. running mean: -17.859107\n",
            "resetting env. episode 1122.000000, reward total was -18.000000. running mean: -17.860516\n",
            "resetting env. episode 1123.000000, reward total was -18.000000. running mean: -17.861911\n",
            "resetting env. episode 1124.000000, reward total was -19.000000. running mean: -17.873292\n",
            "resetting env. episode 1125.000000, reward total was -19.000000. running mean: -17.884559\n",
            "resetting env. episode 1126.000000, reward total was -16.000000. running mean: -17.865713\n",
            "resetting env. episode 1127.000000, reward total was -16.000000. running mean: -17.847056\n",
            "resetting env. episode 1128.000000, reward total was -14.000000. running mean: -17.808586\n",
            "resetting env. episode 1129.000000, reward total was -19.000000. running mean: -17.820500\n",
            "resetting env. episode 1130.000000, reward total was -18.000000. running mean: -17.822295\n",
            "resetting env. episode 1131.000000, reward total was -18.000000. running mean: -17.824072\n",
            "resetting env. episode 1132.000000, reward total was -16.000000. running mean: -17.805831\n",
            "resetting env. episode 1133.000000, reward total was -17.000000. running mean: -17.797773\n",
            "resetting env. episode 1134.000000, reward total was -17.000000. running mean: -17.789795\n",
            "resetting env. episode 1135.000000, reward total was -18.000000. running mean: -17.791897\n",
            "resetting env. episode 1136.000000, reward total was -21.000000. running mean: -17.823978\n",
            "resetting env. episode 1137.000000, reward total was -20.000000. running mean: -17.845738\n",
            "resetting env. episode 1138.000000, reward total was -16.000000. running mean: -17.827281\n",
            "resetting env. episode 1139.000000, reward total was -14.000000. running mean: -17.789008\n",
            "resetting env. episode 1140.000000, reward total was -20.000000. running mean: -17.811118\n",
            "resetting env. episode 1141.000000, reward total was -18.000000. running mean: -17.813007\n",
            "resetting env. episode 1142.000000, reward total was -16.000000. running mean: -17.794877\n",
            "resetting env. episode 1143.000000, reward total was -15.000000. running mean: -17.766928\n",
            "resetting env. episode 1144.000000, reward total was -19.000000. running mean: -17.779259\n",
            "resetting env. episode 1145.000000, reward total was -17.000000. running mean: -17.771466\n",
            "resetting env. episode 1146.000000, reward total was -19.000000. running mean: -17.783752\n",
            "resetting env. episode 1147.000000, reward total was -17.000000. running mean: -17.775914\n",
            "resetting env. episode 1148.000000, reward total was -19.000000. running mean: -17.788155\n",
            "resetting env. episode 1149.000000, reward total was -18.000000. running mean: -17.790273\n",
            "resetting env. episode 1150.000000, reward total was -16.000000. running mean: -17.772371\n",
            "resetting env. episode 1151.000000, reward total was -9.000000. running mean: -17.684647\n",
            "resetting env. episode 1152.000000, reward total was -19.000000. running mean: -17.697800\n",
            "resetting env. episode 1153.000000, reward total was -21.000000. running mean: -17.730822\n",
            "resetting env. episode 1154.000000, reward total was -19.000000. running mean: -17.743514\n",
            "resetting env. episode 1155.000000, reward total was -18.000000. running mean: -17.746079\n",
            "resetting env. episode 1156.000000, reward total was -19.000000. running mean: -17.758618\n",
            "resetting env. episode 1157.000000, reward total was -21.000000. running mean: -17.791032\n",
            "resetting env. episode 1158.000000, reward total was -17.000000. running mean: -17.783122\n",
            "resetting env. episode 1159.000000, reward total was -21.000000. running mean: -17.815291\n",
            "resetting env. episode 1160.000000, reward total was -19.000000. running mean: -17.827138\n",
            "resetting env. episode 1161.000000, reward total was -19.000000. running mean: -17.838866\n",
            "resetting env. episode 1162.000000, reward total was -19.000000. running mean: -17.850478\n",
            "resetting env. episode 1163.000000, reward total was -21.000000. running mean: -17.881973\n",
            "resetting env. episode 1164.000000, reward total was -13.000000. running mean: -17.833153\n",
            "resetting env. episode 1165.000000, reward total was -18.000000. running mean: -17.834822\n",
            "resetting env. episode 1166.000000, reward total was -21.000000. running mean: -17.866473\n",
            "resetting env. episode 1167.000000, reward total was -19.000000. running mean: -17.877809\n",
            "resetting env. episode 1168.000000, reward total was -20.000000. running mean: -17.899031\n",
            "resetting env. episode 1169.000000, reward total was -17.000000. running mean: -17.890040\n",
            "resetting env. episode 1170.000000, reward total was -16.000000. running mean: -17.871140\n",
            "resetting env. episode 1171.000000, reward total was -20.000000. running mean: -17.892428\n",
            "resetting env. episode 1172.000000, reward total was -17.000000. running mean: -17.883504\n",
            "resetting env. episode 1173.000000, reward total was -20.000000. running mean: -17.904669\n",
            "resetting env. episode 1174.000000, reward total was -20.000000. running mean: -17.925622\n",
            "resetting env. episode 1175.000000, reward total was -21.000000. running mean: -17.956366\n",
            "resetting env. episode 1176.000000, reward total was -15.000000. running mean: -17.926803\n",
            "resetting env. episode 1177.000000, reward total was -20.000000. running mean: -17.947535\n",
            "resetting env. episode 1178.000000, reward total was -19.000000. running mean: -17.958059\n",
            "resetting env. episode 1179.000000, reward total was -19.000000. running mean: -17.968479\n",
            "resetting env. episode 1180.000000, reward total was -15.000000. running mean: -17.938794\n",
            "resetting env. episode 1181.000000, reward total was -17.000000. running mean: -17.929406\n",
            "resetting env. episode 1182.000000, reward total was -14.000000. running mean: -17.890112\n",
            "resetting env. episode 1183.000000, reward total was -19.000000. running mean: -17.901211\n",
            "resetting env. episode 1184.000000, reward total was -18.000000. running mean: -17.902199\n",
            "resetting env. episode 1185.000000, reward total was -20.000000. running mean: -17.923177\n",
            "resetting env. episode 1186.000000, reward total was -16.000000. running mean: -17.903945\n",
            "resetting env. episode 1187.000000, reward total was -12.000000. running mean: -17.844905\n",
            "resetting env. episode 1188.000000, reward total was -19.000000. running mean: -17.856456\n",
            "resetting env. episode 1189.000000, reward total was -19.000000. running mean: -17.867892\n",
            "resetting env. episode 1190.000000, reward total was -16.000000. running mean: -17.849213\n",
            "resetting env. episode 1191.000000, reward total was -16.000000. running mean: -17.830721\n",
            "resetting env. episode 1192.000000, reward total was -20.000000. running mean: -17.852414\n",
            "resetting env. episode 1193.000000, reward total was -18.000000. running mean: -17.853889\n",
            "resetting env. episode 1194.000000, reward total was -21.000000. running mean: -17.885350\n",
            "resetting env. episode 1195.000000, reward total was -15.000000. running mean: -17.856497\n",
            "resetting env. episode 1196.000000, reward total was -17.000000. running mean: -17.847932\n",
            "resetting env. episode 1197.000000, reward total was -13.000000. running mean: -17.799453\n",
            "resetting env. episode 1198.000000, reward total was -15.000000. running mean: -17.771458\n",
            "resetting env. episode 1199.000000, reward total was -19.000000. running mean: -17.783744\n",
            "resetting env. episode 1200.000000, reward total was -17.000000. running mean: -17.775906\n",
            "resetting env. episode 1201.000000, reward total was -12.000000. running mean: -17.718147\n",
            "resetting env. episode 1202.000000, reward total was -18.000000. running mean: -17.720966\n",
            "resetting env. episode 1203.000000, reward total was -19.000000. running mean: -17.733756\n",
            "resetting env. episode 1204.000000, reward total was -19.000000. running mean: -17.746418\n",
            "resetting env. episode 1205.000000, reward total was -17.000000. running mean: -17.738954\n",
            "resetting env. episode 1206.000000, reward total was -9.000000. running mean: -17.651565\n",
            "resetting env. episode 1207.000000, reward total was -19.000000. running mean: -17.665049\n",
            "resetting env. episode 1208.000000, reward total was -15.000000. running mean: -17.638399\n",
            "resetting env. episode 1209.000000, reward total was -19.000000. running mean: -17.652015\n",
            "resetting env. episode 1210.000000, reward total was -17.000000. running mean: -17.645494\n",
            "resetting env. episode 1211.000000, reward total was -17.000000. running mean: -17.639039\n",
            "resetting env. episode 1212.000000, reward total was -16.000000. running mean: -17.622649\n",
            "resetting env. episode 1213.000000, reward total was -21.000000. running mean: -17.656423\n",
            "resetting env. episode 1214.000000, reward total was -17.000000. running mean: -17.649858\n",
            "resetting env. episode 1215.000000, reward total was -20.000000. running mean: -17.673360\n",
            "resetting env. episode 1216.000000, reward total was -16.000000. running mean: -17.656626\n",
            "resetting env. episode 1217.000000, reward total was -15.000000. running mean: -17.630060\n",
            "resetting env. episode 1218.000000, reward total was -15.000000. running mean: -17.603759\n",
            "resetting env. episode 1219.000000, reward total was -15.000000. running mean: -17.577722\n",
            "resetting env. episode 1220.000000, reward total was -19.000000. running mean: -17.591945\n",
            "resetting env. episode 1221.000000, reward total was -18.000000. running mean: -17.596025\n",
            "resetting env. episode 1222.000000, reward total was -15.000000. running mean: -17.570065\n",
            "resetting env. episode 1223.000000, reward total was -14.000000. running mean: -17.534364\n",
            "resetting env. episode 1224.000000, reward total was -19.000000. running mean: -17.549021\n",
            "resetting env. episode 1225.000000, reward total was -17.000000. running mean: -17.543530\n",
            "resetting env. episode 1226.000000, reward total was -18.000000. running mean: -17.548095\n",
            "resetting env. episode 1227.000000, reward total was -15.000000. running mean: -17.522614\n",
            "resetting env. episode 1228.000000, reward total was -13.000000. running mean: -17.477388\n",
            "resetting env. episode 1229.000000, reward total was -18.000000. running mean: -17.482614\n",
            "resetting env. episode 1230.000000, reward total was -14.000000. running mean: -17.447788\n",
            "resetting env. episode 1231.000000, reward total was -14.000000. running mean: -17.413310\n",
            "resetting env. episode 1232.000000, reward total was -17.000000. running mean: -17.409177\n",
            "resetting env. episode 1233.000000, reward total was -15.000000. running mean: -17.385085\n",
            "resetting env. episode 1234.000000, reward total was -20.000000. running mean: -17.411234\n",
            "resetting env. episode 1235.000000, reward total was -19.000000. running mean: -17.427122\n",
            "resetting env. episode 1236.000000, reward total was -19.000000. running mean: -17.442851\n",
            "resetting env. episode 1237.000000, reward total was -19.000000. running mean: -17.458422\n",
            "resetting env. episode 1238.000000, reward total was -17.000000. running mean: -17.453838\n",
            "resetting env. episode 1239.000000, reward total was -19.000000. running mean: -17.469300\n",
            "resetting env. episode 1240.000000, reward total was -18.000000. running mean: -17.474607\n",
            "resetting env. episode 1241.000000, reward total was -17.000000. running mean: -17.469861\n",
            "resetting env. episode 1242.000000, reward total was -18.000000. running mean: -17.475162\n",
            "resetting env. episode 1243.000000, reward total was -19.000000. running mean: -17.490410\n",
            "resetting env. episode 1244.000000, reward total was -19.000000. running mean: -17.505506\n",
            "resetting env. episode 1245.000000, reward total was -17.000000. running mean: -17.500451\n",
            "resetting env. episode 1246.000000, reward total was -16.000000. running mean: -17.485447\n",
            "resetting env. episode 1247.000000, reward total was -20.000000. running mean: -17.510592\n",
            "resetting env. episode 1248.000000, reward total was -18.000000. running mean: -17.515486\n",
            "resetting env. episode 1249.000000, reward total was -17.000000. running mean: -17.510331\n",
            "resetting env. episode 1250.000000, reward total was -19.000000. running mean: -17.525228\n",
            "resetting env. episode 1251.000000, reward total was -16.000000. running mean: -17.509976\n",
            "resetting env. episode 1252.000000, reward total was -15.000000. running mean: -17.484876\n",
            "resetting env. episode 1253.000000, reward total was -21.000000. running mean: -17.520027\n",
            "resetting env. episode 1254.000000, reward total was -18.000000. running mean: -17.524827\n",
            "resetting env. episode 1255.000000, reward total was -17.000000. running mean: -17.519579\n",
            "resetting env. episode 1256.000000, reward total was -17.000000. running mean: -17.514383\n",
            "resetting env. episode 1257.000000, reward total was -20.000000. running mean: -17.539239\n",
            "resetting env. episode 1258.000000, reward total was -21.000000. running mean: -17.573847\n",
            "resetting env. episode 1259.000000, reward total was -21.000000. running mean: -17.608108\n",
            "resetting env. episode 1260.000000, reward total was -19.000000. running mean: -17.622027\n",
            "resetting env. episode 1261.000000, reward total was -17.000000. running mean: -17.615807\n",
            "resetting env. episode 1262.000000, reward total was -17.000000. running mean: -17.609649\n",
            "resetting env. episode 1263.000000, reward total was -19.000000. running mean: -17.623552\n",
            "resetting env. episode 1264.000000, reward total was -18.000000. running mean: -17.627317\n",
            "resetting env. episode 1265.000000, reward total was -15.000000. running mean: -17.601044\n",
            "resetting env. episode 1266.000000, reward total was -17.000000. running mean: -17.595033\n",
            "resetting env. episode 1267.000000, reward total was -18.000000. running mean: -17.599083\n",
            "resetting env. episode 1268.000000, reward total was -19.000000. running mean: -17.613092\n",
            "resetting env. episode 1269.000000, reward total was -19.000000. running mean: -17.626961\n",
            "resetting env. episode 1270.000000, reward total was -14.000000. running mean: -17.590692\n",
            "resetting env. episode 1271.000000, reward total was -19.000000. running mean: -17.604785\n",
            "resetting env. episode 1272.000000, reward total was -19.000000. running mean: -17.618737\n",
            "resetting env. episode 1273.000000, reward total was -15.000000. running mean: -17.592549\n",
            "resetting env. episode 1274.000000, reward total was -19.000000. running mean: -17.606624\n",
            "resetting env. episode 1275.000000, reward total was -17.000000. running mean: -17.600558\n",
            "resetting env. episode 1276.000000, reward total was -20.000000. running mean: -17.624552\n",
            "resetting env. episode 1277.000000, reward total was -17.000000. running mean: -17.618307\n",
            "resetting env. episode 1278.000000, reward total was -15.000000. running mean: -17.592124\n",
            "resetting env. episode 1279.000000, reward total was -19.000000. running mean: -17.606202\n",
            "resetting env. episode 1280.000000, reward total was -20.000000. running mean: -17.630140\n",
            "resetting env. episode 1281.000000, reward total was -16.000000. running mean: -17.613839\n",
            "resetting env. episode 1282.000000, reward total was -19.000000. running mean: -17.627700\n",
            "resetting env. episode 1283.000000, reward total was -19.000000. running mean: -17.641423\n",
            "resetting env. episode 1284.000000, reward total was -18.000000. running mean: -17.645009\n",
            "resetting env. episode 1285.000000, reward total was -18.000000. running mean: -17.648559\n",
            "resetting env. episode 1286.000000, reward total was -17.000000. running mean: -17.642074\n",
            "resetting env. episode 1287.000000, reward total was -19.000000. running mean: -17.655653\n",
            "resetting env. episode 1288.000000, reward total was -17.000000. running mean: -17.649096\n",
            "resetting env. episode 1289.000000, reward total was -18.000000. running mean: -17.652605\n",
            "resetting env. episode 1290.000000, reward total was -21.000000. running mean: -17.686079\n",
            "resetting env. episode 1291.000000, reward total was -15.000000. running mean: -17.659218\n",
            "resetting env. episode 1292.000000, reward total was -16.000000. running mean: -17.642626\n",
            "resetting env. episode 1293.000000, reward total was -17.000000. running mean: -17.636200\n",
            "resetting env. episode 1294.000000, reward total was -17.000000. running mean: -17.629838\n",
            "resetting env. episode 1295.000000, reward total was -19.000000. running mean: -17.643540\n",
            "resetting env. episode 1296.000000, reward total was -16.000000. running mean: -17.627104\n",
            "resetting env. episode 1297.000000, reward total was -17.000000. running mean: -17.620833\n",
            "resetting env. episode 1298.000000, reward total was -16.000000. running mean: -17.604625\n",
            "resetting env. episode 1299.000000, reward total was -16.000000. running mean: -17.588579\n",
            "resetting env. episode 1300.000000, reward total was -19.000000. running mean: -17.602693\n",
            "resetting env. episode 1301.000000, reward total was -15.000000. running mean: -17.576666\n",
            "resetting env. episode 1302.000000, reward total was -18.000000. running mean: -17.580899\n",
            "resetting env. episode 1303.000000, reward total was -17.000000. running mean: -17.575090\n",
            "resetting env. episode 1304.000000, reward total was -19.000000. running mean: -17.589339\n",
            "resetting env. episode 1305.000000, reward total was -16.000000. running mean: -17.573446\n",
            "resetting env. episode 1306.000000, reward total was -19.000000. running mean: -17.587712\n",
            "resetting env. episode 1307.000000, reward total was -15.000000. running mean: -17.561834\n",
            "resetting env. episode 1308.000000, reward total was -19.000000. running mean: -17.576216\n",
            "resetting env. episode 1309.000000, reward total was -14.000000. running mean: -17.540454\n",
            "resetting env. episode 1310.000000, reward total was -17.000000. running mean: -17.535049\n",
            "resetting env. episode 1311.000000, reward total was -15.000000. running mean: -17.509699\n",
            "resetting env. episode 1312.000000, reward total was -16.000000. running mean: -17.494602\n",
            "resetting env. episode 1313.000000, reward total was -19.000000. running mean: -17.509656\n",
            "resetting env. episode 1314.000000, reward total was -18.000000. running mean: -17.514559\n",
            "resetting env. episode 1315.000000, reward total was -17.000000. running mean: -17.509414\n",
            "resetting env. episode 1316.000000, reward total was -19.000000. running mean: -17.524320\n",
            "resetting env. episode 1317.000000, reward total was -19.000000. running mean: -17.539076\n",
            "resetting env. episode 1318.000000, reward total was -17.000000. running mean: -17.533686\n",
            "resetting env. episode 1319.000000, reward total was -17.000000. running mean: -17.528349\n",
            "resetting env. episode 1320.000000, reward total was -13.000000. running mean: -17.483065\n",
            "resetting env. episode 1321.000000, reward total was -13.000000. running mean: -17.438235\n",
            "resetting env. episode 1322.000000, reward total was -15.000000. running mean: -17.413852\n",
            "resetting env. episode 1323.000000, reward total was -19.000000. running mean: -17.429714\n",
            "resetting env. episode 1324.000000, reward total was -17.000000. running mean: -17.425417\n",
            "resetting env. episode 1325.000000, reward total was -17.000000. running mean: -17.421162\n",
            "resetting env. episode 1326.000000, reward total was -15.000000. running mean: -17.396951\n",
            "resetting env. episode 1327.000000, reward total was -19.000000. running mean: -17.412981\n",
            "resetting env. episode 1328.000000, reward total was -19.000000. running mean: -17.428851\n",
            "resetting env. episode 1329.000000, reward total was -16.000000. running mean: -17.414563\n",
            "resetting env. episode 1330.000000, reward total was -17.000000. running mean: -17.410417\n",
            "resetting env. episode 1331.000000, reward total was -21.000000. running mean: -17.446313\n",
            "resetting env. episode 1332.000000, reward total was -20.000000. running mean: -17.471850\n",
            "resetting env. episode 1333.000000, reward total was -15.000000. running mean: -17.447132\n",
            "resetting env. episode 1334.000000, reward total was -19.000000. running mean: -17.462660\n",
            "resetting env. episode 1335.000000, reward total was -21.000000. running mean: -17.498034\n",
            "resetting env. episode 1336.000000, reward total was -21.000000. running mean: -17.533053\n",
            "resetting env. episode 1337.000000, reward total was -19.000000. running mean: -17.547723\n",
            "resetting env. episode 1338.000000, reward total was -15.000000. running mean: -17.522246\n",
            "resetting env. episode 1339.000000, reward total was -14.000000. running mean: -17.487023\n",
            "resetting env. episode 1340.000000, reward total was -19.000000. running mean: -17.502153\n",
            "resetting env. episode 1341.000000, reward total was -14.000000. running mean: -17.467131\n",
            "resetting env. episode 1342.000000, reward total was -19.000000. running mean: -17.482460\n",
            "resetting env. episode 1343.000000, reward total was -19.000000. running mean: -17.497635\n",
            "resetting env. episode 1344.000000, reward total was -19.000000. running mean: -17.512659\n",
            "resetting env. episode 1345.000000, reward total was -21.000000. running mean: -17.547532\n",
            "resetting env. episode 1346.000000, reward total was -18.000000. running mean: -17.552057\n",
            "resetting env. episode 1347.000000, reward total was -15.000000. running mean: -17.526537\n",
            "resetting env. episode 1348.000000, reward total was -19.000000. running mean: -17.541271\n",
            "resetting env. episode 1349.000000, reward total was -19.000000. running mean: -17.555858\n",
            "resetting env. episode 1350.000000, reward total was -18.000000. running mean: -17.560300\n",
            "resetting env. episode 1351.000000, reward total was -19.000000. running mean: -17.574697\n",
            "resetting env. episode 1352.000000, reward total was -17.000000. running mean: -17.568950\n",
            "resetting env. episode 1353.000000, reward total was -19.000000. running mean: -17.583260\n",
            "resetting env. episode 1354.000000, reward total was -15.000000. running mean: -17.557428\n",
            "resetting env. episode 1355.000000, reward total was -16.000000. running mean: -17.541854\n",
            "resetting env. episode 1356.000000, reward total was -19.000000. running mean: -17.556435\n",
            "resetting env. episode 1357.000000, reward total was -13.000000. running mean: -17.510871\n",
            "resetting env. episode 1358.000000, reward total was -19.000000. running mean: -17.525762\n",
            "resetting env. episode 1359.000000, reward total was -16.000000. running mean: -17.510504\n",
            "resetting env. episode 1360.000000, reward total was -17.000000. running mean: -17.505399\n",
            "resetting env. episode 1361.000000, reward total was -16.000000. running mean: -17.490345\n",
            "resetting env. episode 1362.000000, reward total was -16.000000. running mean: -17.475442\n",
            "resetting env. episode 1363.000000, reward total was -16.000000. running mean: -17.460687\n",
            "resetting env. episode 1364.000000, reward total was -19.000000. running mean: -17.476081\n",
            "resetting env. episode 1365.000000, reward total was -14.000000. running mean: -17.441320\n",
            "resetting env. episode 1366.000000, reward total was -17.000000. running mean: -17.436907\n",
            "resetting env. episode 1367.000000, reward total was -16.000000. running mean: -17.422537\n",
            "resetting env. episode 1368.000000, reward total was -14.000000. running mean: -17.388312\n",
            "resetting env. episode 1369.000000, reward total was -17.000000. running mean: -17.384429\n",
            "resetting env. episode 1370.000000, reward total was -19.000000. running mean: -17.400585\n",
            "resetting env. episode 1371.000000, reward total was -19.000000. running mean: -17.416579\n",
            "resetting env. episode 1372.000000, reward total was -17.000000. running mean: -17.412413\n",
            "resetting env. episode 1373.000000, reward total was -15.000000. running mean: -17.388289\n",
            "resetting env. episode 1374.000000, reward total was -19.000000. running mean: -17.404406\n",
            "resetting env. episode 1375.000000, reward total was -17.000000. running mean: -17.400362\n",
            "resetting env. episode 1376.000000, reward total was -20.000000. running mean: -17.426358\n",
            "resetting env. episode 1377.000000, reward total was -19.000000. running mean: -17.442095\n",
            "resetting env. episode 1378.000000, reward total was -18.000000. running mean: -17.447674\n",
            "resetting env. episode 1379.000000, reward total was -19.000000. running mean: -17.463197\n",
            "resetting env. episode 1380.000000, reward total was -16.000000. running mean: -17.448565\n",
            "resetting env. episode 1381.000000, reward total was -17.000000. running mean: -17.444079\n",
            "resetting env. episode 1382.000000, reward total was -17.000000. running mean: -17.439639\n",
            "resetting env. episode 1383.000000, reward total was -19.000000. running mean: -17.455242\n",
            "resetting env. episode 1384.000000, reward total was -19.000000. running mean: -17.470690\n",
            "resetting env. episode 1385.000000, reward total was -20.000000. running mean: -17.495983\n",
            "resetting env. episode 1386.000000, reward total was -13.000000. running mean: -17.451023\n",
            "resetting env. episode 1387.000000, reward total was -20.000000. running mean: -17.476513\n",
            "resetting env. episode 1388.000000, reward total was -13.000000. running mean: -17.431748\n",
            "resetting env. episode 1389.000000, reward total was -20.000000. running mean: -17.457430\n",
            "resetting env. episode 1390.000000, reward total was -18.000000. running mean: -17.462856\n",
            "resetting env. episode 1391.000000, reward total was -12.000000. running mean: -17.408227\n",
            "resetting env. episode 1392.000000, reward total was -21.000000. running mean: -17.444145\n",
            "resetting env. episode 1393.000000, reward total was -16.000000. running mean: -17.429704\n",
            "resetting env. episode 1394.000000, reward total was -13.000000. running mean: -17.385407\n",
            "resetting env. episode 1395.000000, reward total was -14.000000. running mean: -17.351553\n",
            "resetting env. episode 1396.000000, reward total was -14.000000. running mean: -17.318037\n",
            "resetting env. episode 1397.000000, reward total was -18.000000. running mean: -17.324857\n",
            "resetting env. episode 1398.000000, reward total was -17.000000. running mean: -17.321608\n",
            "resetting env. episode 1399.000000, reward total was -15.000000. running mean: -17.298392\n",
            "resetting env. episode 1400.000000, reward total was -17.000000. running mean: -17.295408\n",
            "resetting env. episode 1401.000000, reward total was -16.000000. running mean: -17.282454\n",
            "resetting env. episode 1402.000000, reward total was -19.000000. running mean: -17.299630\n",
            "resetting env. episode 1403.000000, reward total was -17.000000. running mean: -17.296633\n",
            "resetting env. episode 1404.000000, reward total was -18.000000. running mean: -17.303667\n",
            "resetting env. episode 1405.000000, reward total was -21.000000. running mean: -17.340630\n",
            "resetting env. episode 1406.000000, reward total was -20.000000. running mean: -17.367224\n",
            "resetting env. episode 1407.000000, reward total was -15.000000. running mean: -17.343552\n",
            "resetting env. episode 1408.000000, reward total was -17.000000. running mean: -17.340116\n",
            "resetting env. episode 1409.000000, reward total was -19.000000. running mean: -17.356715\n",
            "resetting env. episode 1410.000000, reward total was -18.000000. running mean: -17.363148\n",
            "resetting env. episode 1411.000000, reward total was -16.000000. running mean: -17.349516\n",
            "resetting env. episode 1412.000000, reward total was -17.000000. running mean: -17.346021\n",
            "resetting env. episode 1413.000000, reward total was -21.000000. running mean: -17.382561\n",
            "resetting env. episode 1414.000000, reward total was -21.000000. running mean: -17.418735\n",
            "resetting env. episode 1415.000000, reward total was -17.000000. running mean: -17.414548\n",
            "resetting env. episode 1416.000000, reward total was -12.000000. running mean: -17.360403\n",
            "resetting env. episode 1417.000000, reward total was -17.000000. running mean: -17.356799\n",
            "resetting env. episode 1418.000000, reward total was -18.000000. running mean: -17.363231\n",
            "resetting env. episode 1419.000000, reward total was -15.000000. running mean: -17.339598\n",
            "resetting env. episode 1420.000000, reward total was -19.000000. running mean: -17.356202\n",
            "resetting env. episode 1421.000000, reward total was -17.000000. running mean: -17.352640\n",
            "resetting env. episode 1422.000000, reward total was -16.000000. running mean: -17.339114\n",
            "resetting env. episode 1423.000000, reward total was -11.000000. running mean: -17.275723\n",
            "resetting env. episode 1424.000000, reward total was -19.000000. running mean: -17.292965\n",
            "resetting env. episode 1425.000000, reward total was -18.000000. running mean: -17.300036\n",
            "resetting env. episode 1426.000000, reward total was -18.000000. running mean: -17.307035\n",
            "resetting env. episode 1427.000000, reward total was -17.000000. running mean: -17.303965\n",
            "resetting env. episode 1428.000000, reward total was -17.000000. running mean: -17.300925\n",
            "resetting env. episode 1429.000000, reward total was -20.000000. running mean: -17.327916\n",
            "resetting env. episode 1430.000000, reward total was -16.000000. running mean: -17.314637\n",
            "resetting env. episode 1431.000000, reward total was -19.000000. running mean: -17.331491\n",
            "resetting env. episode 1432.000000, reward total was -13.000000. running mean: -17.288176\n",
            "resetting env. episode 1433.000000, reward total was -18.000000. running mean: -17.295294\n",
            "resetting env. episode 1434.000000, reward total was -19.000000. running mean: -17.312341\n",
            "resetting env. episode 1435.000000, reward total was -17.000000. running mean: -17.309218\n",
            "resetting env. episode 1436.000000, reward total was -17.000000. running mean: -17.306125\n",
            "resetting env. episode 1437.000000, reward total was -15.000000. running mean: -17.283064\n",
            "resetting env. episode 1438.000000, reward total was -19.000000. running mean: -17.300234\n",
            "resetting env. episode 1439.000000, reward total was -16.000000. running mean: -17.287231\n",
            "resetting env. episode 1440.000000, reward total was -19.000000. running mean: -17.304359\n",
            "resetting env. episode 1441.000000, reward total was -19.000000. running mean: -17.321315\n",
            "resetting env. episode 1442.000000, reward total was -19.000000. running mean: -17.338102\n",
            "resetting env. episode 1443.000000, reward total was -18.000000. running mean: -17.344721\n",
            "resetting env. episode 1444.000000, reward total was -15.000000. running mean: -17.321274\n",
            "resetting env. episode 1445.000000, reward total was -16.000000. running mean: -17.308061\n",
            "resetting env. episode 1446.000000, reward total was -14.000000. running mean: -17.274981\n",
            "resetting env. episode 1447.000000, reward total was -18.000000. running mean: -17.282231\n",
            "resetting env. episode 1448.000000, reward total was -13.000000. running mean: -17.239408\n",
            "resetting env. episode 1449.000000, reward total was -16.000000. running mean: -17.227014\n",
            "resetting env. episode 1450.000000, reward total was -21.000000. running mean: -17.264744\n",
            "resetting env. episode 1451.000000, reward total was -19.000000. running mean: -17.282097\n",
            "resetting env. episode 1452.000000, reward total was -20.000000. running mean: -17.309276\n",
            "resetting env. episode 1453.000000, reward total was -19.000000. running mean: -17.326183\n",
            "resetting env. episode 1454.000000, reward total was -19.000000. running mean: -17.342921\n",
            "resetting env. episode 1455.000000, reward total was -15.000000. running mean: -17.319492\n",
            "resetting env. episode 1456.000000, reward total was -20.000000. running mean: -17.346297\n",
            "resetting env. episode 1457.000000, reward total was -21.000000. running mean: -17.382834\n",
            "resetting env. episode 1458.000000, reward total was -19.000000. running mean: -17.399006\n",
            "resetting env. episode 1459.000000, reward total was -17.000000. running mean: -17.395016\n",
            "resetting env. episode 1460.000000, reward total was -17.000000. running mean: -17.391066\n",
            "resetting env. episode 1461.000000, reward total was -17.000000. running mean: -17.387155\n",
            "resetting env. episode 1462.000000, reward total was -20.000000. running mean: -17.413283\n",
            "resetting env. episode 1463.000000, reward total was -20.000000. running mean: -17.439151\n",
            "resetting env. episode 1464.000000, reward total was -17.000000. running mean: -17.434759\n",
            "resetting env. episode 1465.000000, reward total was -19.000000. running mean: -17.450411\n",
            "resetting env. episode 1466.000000, reward total was -17.000000. running mean: -17.445907\n",
            "resetting env. episode 1467.000000, reward total was -18.000000. running mean: -17.451448\n",
            "resetting env. episode 1468.000000, reward total was -16.000000. running mean: -17.436934\n",
            "resetting env. episode 1469.000000, reward total was -16.000000. running mean: -17.422564\n",
            "resetting env. episode 1470.000000, reward total was -20.000000. running mean: -17.448339\n",
            "resetting env. episode 1471.000000, reward total was -15.000000. running mean: -17.423855\n",
            "resetting env. episode 1472.000000, reward total was -18.000000. running mean: -17.429617\n",
            "resetting env. episode 1473.000000, reward total was -21.000000. running mean: -17.465321\n",
            "resetting env. episode 1474.000000, reward total was -16.000000. running mean: -17.450667\n",
            "resetting env. episode 1475.000000, reward total was -19.000000. running mean: -17.466161\n",
            "resetting env. episode 1476.000000, reward total was -13.000000. running mean: -17.421499\n",
            "resetting env. episode 1477.000000, reward total was -17.000000. running mean: -17.417284\n",
            "resetting env. episode 1478.000000, reward total was -19.000000. running mean: -17.433111\n",
            "resetting env. episode 1479.000000, reward total was -14.000000. running mean: -17.398780\n",
            "resetting env. episode 1480.000000, reward total was -15.000000. running mean: -17.374792\n",
            "resetting env. episode 1481.000000, reward total was -16.000000. running mean: -17.361045\n",
            "resetting env. episode 1482.000000, reward total was -13.000000. running mean: -17.317434\n",
            "resetting env. episode 1483.000000, reward total was -18.000000. running mean: -17.324260\n",
            "resetting env. episode 1484.000000, reward total was -21.000000. running mean: -17.361017\n",
            "resetting env. episode 1485.000000, reward total was -20.000000. running mean: -17.387407\n",
            "resetting env. episode 1486.000000, reward total was -19.000000. running mean: -17.403533\n",
            "resetting env. episode 1487.000000, reward total was -15.000000. running mean: -17.379498\n",
            "resetting env. episode 1488.000000, reward total was -18.000000. running mean: -17.385703\n",
            "resetting env. episode 1489.000000, reward total was -21.000000. running mean: -17.421846\n",
            "resetting env. episode 1490.000000, reward total was -20.000000. running mean: -17.447627\n",
            "resetting env. episode 1491.000000, reward total was -15.000000. running mean: -17.423151\n",
            "resetting env. episode 1492.000000, reward total was -17.000000. running mean: -17.418919\n",
            "resetting env. episode 1493.000000, reward total was -19.000000. running mean: -17.434730\n",
            "resetting env. episode 1494.000000, reward total was -17.000000. running mean: -17.430383\n",
            "resetting env. episode 1495.000000, reward total was -18.000000. running mean: -17.436079\n",
            "resetting env. episode 1496.000000, reward total was -17.000000. running mean: -17.431718\n",
            "resetting env. episode 1497.000000, reward total was -17.000000. running mean: -17.427401\n",
            "resetting env. episode 1498.000000, reward total was -17.000000. running mean: -17.423127\n",
            "resetting env. episode 1499.000000, reward total was -19.000000. running mean: -17.438896\n",
            "resetting env. episode 1500.000000, reward total was -16.000000. running mean: -17.424507\n",
            "CPU times: user 2h 8min 49s, sys: 1h 43s, total: 3h 9min 32s\n",
            "Wall time: 1h 37min 58s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "play_game(env, model)"
      ],
      "metadata": {
        "id": "CteN7XKMVGqg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "40700f40-515b-4338-9ffa-cd251e868669"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_yNATrbN0W3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZYA0HgMoO77a"
      },
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# pickle.dump(model, open('model.pkl', 'wb'))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Vu9PonFR5NA"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}