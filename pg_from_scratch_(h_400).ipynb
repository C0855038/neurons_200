{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pg_from_scratch_(h_400).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "0l9hHvTk6ec8"
      },
      "cell_type": "markdown",
      "source": [
        "# Policy Gradient\n",
        "\n",
        "* http://karpathy.github.io/2016/05/31/rl/\n",
        "* https://gist.github.com/karpathy/a4166c7fe253700972fcbc77e4ea32c5\n",
        "* https://github.com/gameofdimension/policy-gradient-pong\n",
        "* https://www.youtube.com/watch?v=tqrcjHuNdmQ\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "mqkOdLyN9Ylm"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 1: Installation for Colab - just execute these cells and do not worry too much\n",
        "\n",
        "* http://nbviewer.jupyter.org/github/patrickmineault/xcorr-notebooks/blob/master/Render%20OpenAI%20gym%20as%20GIF.ipynb \n",
        "* https://docs.microsoft.com/en-us/message-passing-interface/microsoft-mpi\n",
        "* https://nyu-cds.github.io/python-mpi/setup/\n",
        "* https://medium.com/@kaleajit27/reinforcement-learning-on-google-colab-9cb2e1ef51e\n"
      ]
    },
    {
      "metadata": {
        "id": "uF9MAVI16huj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c17806b-d4d2-44fe-9013-241d8259d424"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install python-opengl -y  >/dev/null\n",
        "!apt install xvfb -y >/dev/null"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "fSC11TfN6p69"
      },
      "cell_type": "code",
      "source": [
        "!pip install pyvirtualdisplay >/dev/null\n",
        "!pip install piglet >/dev/null"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "caiHE2hy6xrf"
      },
      "cell_type": "code",
      "source": [
        "# from pyvirtualdisplay import Display\n",
        "# display = Display(visible=0, size=(1400, 900))\n",
        "# display.start()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cWACPRL869I4"
      },
      "cell_type": "code",
      "source": [
        "!pip install gym >/dev/null"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Os6feRY6ec_"
      },
      "cell_type": "code",
      "source": [
        "!pip install JSAnimation >/dev/null"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wotUOa_e6edP"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from JSAnimation.IPython_display import display_animation\n",
        "from matplotlib import animation\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def display_frames_as_gif(frames):\n",
        "    \"\"\"\n",
        "    Displays a list of frames as a gif, with controls\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n",
        "    patch = plt.imshow(frames[0])\n",
        "    plt.axis('off')\n",
        "\n",
        "    def animate(i):\n",
        "        patch.set_data(frames[i])\n",
        "\n",
        "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
        "    HTML(anim.to_jshtml())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R66_INeZ9nYX"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2: Playing Pong"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U gym>=0.21.0\n",
        "%pip install -U gym[atari,accept-rom-license]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ngMhg3fB9aA",
        "outputId": "a4f6e50c-6406-4572-98f8-2c4876391a06"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.25.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.12.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n",
            "Collecting ale-py~=0.7.5\n",
            "  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 26.6 MB/s \n",
            "\u001b[?25hCollecting autorom[accept-rom-license]~=0.4.2\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n",
            "Collecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=080163bff56ccc2cb54b3775c7680a08eaba6735f58083ada401474c3f36cb31\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: AutoROM.accept-rom-license, autorom, ale-py\n",
            "Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "MtT2GyK_6edc",
        "outputId": "455fd459-fb28-4b4f-d9ce-ef2219c9d146",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "env = gym.make('Pong-v0')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:594: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  f\"The environment {id} is out of date. You should consider \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "oRE6WmXQJ1Z0",
        "outputId": "253bd254-97f6-4237-a160-7a26ae2e4d6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "env.action_space"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(6)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "yl_9d4HFJ31W",
        "outputId": "9ee32ac9-bb2e-4df5-e6cd-6b1a6fe6afb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "env.observation_space"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Box(0, 255, (210, 160, 3), uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "trwRXI-h6eeI",
        "outputId": "fa47987e-80c0-46c8-d3d8-e852e55b907a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Run a demo of the environment\n",
        "observation = env.reset()\n",
        "cumulated_reward = 0\n",
        "\n",
        "frames = []\n",
        "for t in range(1000):\n",
        "#     print(observation)\n",
        "    frames.append(env.render(mode = 'rgb_array'))\n",
        "    # very stupid agent, just makes a random action within the allowd action space\n",
        "    action = env.action_space.sample()\n",
        "#     print(\"Action: {}\".format(t+1))    \n",
        "    observation, reward, done, info = env.step(action)\n",
        "#     print(reward)\n",
        "    cumulated_reward += reward\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
        "        break\n",
        "print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
        "\n",
        "env.close()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
            "  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  \"Core environment is written in old step API which returns one bool instead of two. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -16.0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "3zZTecVWLLes"
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(x): \n",
        "  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n",
        "\n",
        "def prepro(I):\n",
        "  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
        "  I = I[35:195] # crop\n",
        "  I = I[::2,::2,0] # downsample by factor of 2\n",
        "  I[I == 144] = 0 # erase background (background type 1)\n",
        "  I[I == 109] = 0 # erase background (background type 2)\n",
        "  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
        "  return I.astype(np.float).ravel()\n",
        "\n",
        "def policy_forward(x):\n",
        "  h = np.dot(model['W1'], x)\n",
        "  h[h<0] = 0 # ReLU nonlinearity\n",
        "  logp = np.dot(model['W2'], h)\n",
        "  p = sigmoid(logp)\n",
        "  return p, h # return probability of taking action 2, and hidden state\n",
        "\n",
        "def model_step(model, observation, prev_x):\n",
        "  # preprocess the observation, set input to network to be difference image\n",
        "  cur_x = prepro(observation)\n",
        "  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
        "  prev_x = cur_x\n",
        "  \n",
        "  # forward the policy network and sample an action from the returned probability\n",
        "  aprob, _ = policy_forward(x)\n",
        "  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n",
        "  \n",
        "  return action, prev_x\n",
        "\n",
        "def play_game(env, model):\n",
        "  observation = env.reset()\n",
        "\n",
        "  frames = []\n",
        "  cumulated_reward = 0\n",
        "\n",
        "  prev_x = None # used in computing the difference frame\n",
        "\n",
        "  for t in range(1000):\n",
        "      frames.append(env.render(mode = 'rgb_array'))\n",
        "      action, prev_x = model_step(model, observation, prev_x)\n",
        "      observation, reward, done, info = env.step(action)\n",
        "      cumulated_reward += reward\n",
        "      if done:\n",
        "          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
        "          break\n",
        "  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
        "  env.close()\n",
        "  display_frames_as_gif(frames)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6gWvZQ7AQLQt"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3: Policy Gradient from Scratch"
      ]
    },
    {
      "metadata": {
        "id": "eqFm7hqcItWl"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# model initialization\n",
        "H = 400 # number of hidden layer neurons\n",
        "D = 80 * 80 # input dimensionality: 80x80 grid\n",
        "model = {}\n",
        "model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n",
        "model['W2'] = np.random.randn(H) / np.sqrt(H)\n",
        "\n",
        "# import pickle\n",
        "# model = pickle.load(open('model.pkl', 'rb'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TwjiwKisQM19"
      },
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "batch_size = 3 # every how many episodes to do a param update?\n",
        "# learning_rate = 1e-4\n",
        "learning_rate = 1e-4\n",
        " \n",
        "gamma = 0.99 # discount factor for reward\n",
        "decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n",
        "  \n",
        "grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n",
        "rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n",
        "\n",
        "def discount_rewards(r):\n",
        "  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
        "  discounted_r = np.zeros_like(r, dtype=np.float32)\n",
        "  running_add = 0\n",
        "  for t in reversed(range(0, r.size)):\n",
        "    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
        "    running_add = running_add * gamma + r[t]\n",
        "    discounted_r[t] = running_add\n",
        "  return discounted_r\n",
        "\n",
        "def policy_backward(epx, eph, epdlogp):\n",
        "  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n",
        "  dW2 = np.dot(eph.T, epdlogp).ravel()\n",
        "  dh = np.outer(epdlogp, model['W2'])\n",
        "  dh[eph <= 0] = 0 # backpro prelu\n",
        "  dW1 = np.dot(dh.T, epx)\n",
        "  return {'W1':dW1, 'W2':dW2}\n",
        "\n",
        "def train_model(env, model, total_episodes = 100):\n",
        "  hist = []\n",
        "  observation = env.reset()\n",
        "\n",
        "  prev_x = None # used in computing the difference frame\n",
        "  xs,hs,dlogps,drs = [],[],[],[]\n",
        "  running_reward = None\n",
        "  reward_sum = 0\n",
        "  episode_number = 0\n",
        "\n",
        "  while True:\n",
        "    # preprocess the observation, set input to network to be difference image\n",
        "    cur_x = prepro(observation)\n",
        "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
        "    prev_x = cur_x\n",
        "\n",
        "    # forward the policy network and sample an action from the returned probability\n",
        "    aprob, h = policy_forward(x)\n",
        "    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n",
        "\n",
        "    # record various intermediates (needed later for backprop)\n",
        "    xs.append(x) # observation\n",
        "    hs.append(h) # hidden state\n",
        "    y = 1 if action == 2 else 0 # a \"fake label\"\n",
        "    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n",
        "\n",
        "    # step the environment and get new measurements\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    reward_sum += reward\n",
        "\n",
        "    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
        "\n",
        "    if done: # an episode finished\n",
        "      episode_number += 1\n",
        "\n",
        "      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
        "      epx = np.vstack(xs)\n",
        "      eph = np.vstack(hs)\n",
        "      epdlogp = np.vstack(dlogps)\n",
        "      epr = np.vstack(drs)\n",
        "      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n",
        "\n",
        "      # compute the discounted reward backwards through time\n",
        "      discounted_epr = discount_rewards(epr)\n",
        "      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n",
        "      discounted_epr -= np.mean(discounted_epr)\n",
        "      discounted_epr /= np.std(discounted_epr)\n",
        "\n",
        "      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n",
        "      grad = policy_backward(epx, eph, epdlogp)\n",
        "      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n",
        "\n",
        "      # perform rmsprop parameter update every batch_size episodes\n",
        "      if episode_number % batch_size == 0:\n",
        "        for k,v in model.items():\n",
        "          g = grad_buffer[k] # gradient\n",
        "          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n",
        "          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
        "          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n",
        "\n",
        "      # boring book-keeping\n",
        "      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
        "      hist.append((episode_number, reward_sum, running_reward))\n",
        "      print ('resetting env. episode %f, reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n",
        "      reward_sum = 0\n",
        "      observation = env.reset() # reset env\n",
        "      prev_x = None\n",
        "      if episode_number == total_episodes: return hist\n",
        "\n",
        "      if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n",
        "        print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6Ka_5Vl9Orm",
        "outputId": "f3dc42f5-566a-464e-e097-b8b724dc8725",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "%time hist1 = train_model(env, model, total_episodes=500)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n",
            "resetting env. episode 2.000000, reward total was -20.000000. running mean: -20.990000\n",
            "resetting env. episode 3.000000, reward total was -20.000000. running mean: -20.980100\n",
            "resetting env. episode 4.000000, reward total was -21.000000. running mean: -20.980299\n",
            "resetting env. episode 5.000000, reward total was -18.000000. running mean: -20.950496\n",
            "resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.950991\n",
            "resetting env. episode 7.000000, reward total was -20.000000. running mean: -20.941481\n",
            "resetting env. episode 8.000000, reward total was -20.000000. running mean: -20.932066\n",
            "resetting env. episode 9.000000, reward total was -20.000000. running mean: -20.922746\n",
            "resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.923518\n",
            "resetting env. episode 11.000000, reward total was -21.000000. running mean: -20.924283\n",
            "resetting env. episode 12.000000, reward total was -21.000000. running mean: -20.925040\n",
            "resetting env. episode 13.000000, reward total was -20.000000. running mean: -20.915790\n",
            "resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.916632\n",
            "resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.917466\n",
            "resetting env. episode 16.000000, reward total was -20.000000. running mean: -20.908291\n",
            "resetting env. episode 17.000000, reward total was -20.000000. running mean: -20.899208\n",
            "resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.900216\n",
            "resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.901214\n",
            "resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.902202\n",
            "resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.903180\n",
            "resetting env. episode 22.000000, reward total was -20.000000. running mean: -20.894148\n",
            "resetting env. episode 23.000000, reward total was -21.000000. running mean: -20.895206\n",
            "resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.896254\n",
            "resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.897292\n",
            "resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.898319\n",
            "resetting env. episode 27.000000, reward total was -21.000000. running mean: -20.899336\n",
            "resetting env. episode 28.000000, reward total was -20.000000. running mean: -20.890342\n",
            "resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.891439\n",
            "resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.892524\n",
            "resetting env. episode 31.000000, reward total was -21.000000. running mean: -20.893599\n",
            "resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.894663\n",
            "resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.895717\n",
            "resetting env. episode 34.000000, reward total was -20.000000. running mean: -20.886759\n",
            "resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.887892\n",
            "resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.889013\n",
            "resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.890123\n",
            "resetting env. episode 38.000000, reward total was -20.000000. running mean: -20.881222\n",
            "resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.882409\n",
            "resetting env. episode 40.000000, reward total was -19.000000. running mean: -20.863585\n",
            "resetting env. episode 41.000000, reward total was -21.000000. running mean: -20.864949\n",
            "resetting env. episode 42.000000, reward total was -21.000000. running mean: -20.866300\n",
            "resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.867637\n",
            "resetting env. episode 44.000000, reward total was -21.000000. running mean: -20.868961\n",
            "resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.870271\n",
            "resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.871568\n",
            "resetting env. episode 47.000000, reward total was -21.000000. running mean: -20.872853\n",
            "resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.874124\n",
            "resetting env. episode 49.000000, reward total was -21.000000. running mean: -20.875383\n",
            "resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.876629\n",
            "resetting env. episode 51.000000, reward total was -20.000000. running mean: -20.867863\n",
            "resetting env. episode 52.000000, reward total was -20.000000. running mean: -20.859184\n",
            "resetting env. episode 53.000000, reward total was -21.000000. running mean: -20.860592\n",
            "resetting env. episode 54.000000, reward total was -18.000000. running mean: -20.831986\n",
            "resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.833666\n",
            "resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.835330\n",
            "resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.836976\n",
            "resetting env. episode 58.000000, reward total was -19.000000. running mean: -20.818607\n",
            "resetting env. episode 59.000000, reward total was -20.000000. running mean: -20.810421\n",
            "resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.812316\n",
            "resetting env. episode 61.000000, reward total was -20.000000. running mean: -20.804193\n",
            "resetting env. episode 62.000000, reward total was -20.000000. running mean: -20.796151\n",
            "resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.798190\n",
            "resetting env. episode 64.000000, reward total was -20.000000. running mean: -20.790208\n",
            "resetting env. episode 65.000000, reward total was -20.000000. running mean: -20.782306\n",
            "resetting env. episode 66.000000, reward total was -20.000000. running mean: -20.774483\n",
            "resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.776738\n",
            "resetting env. episode 68.000000, reward total was -19.000000. running mean: -20.758971\n",
            "resetting env. episode 69.000000, reward total was -21.000000. running mean: -20.761381\n",
            "resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.763767\n",
            "resetting env. episode 71.000000, reward total was -20.000000. running mean: -20.756129\n",
            "resetting env. episode 72.000000, reward total was -20.000000. running mean: -20.748568\n",
            "resetting env. episode 73.000000, reward total was -18.000000. running mean: -20.721082\n",
            "resetting env. episode 74.000000, reward total was -19.000000. running mean: -20.703872\n",
            "resetting env. episode 75.000000, reward total was -20.000000. running mean: -20.696833\n",
            "resetting env. episode 76.000000, reward total was -20.000000. running mean: -20.689865\n",
            "resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.692966\n",
            "resetting env. episode 78.000000, reward total was -21.000000. running mean: -20.696036\n",
            "resetting env. episode 79.000000, reward total was -20.000000. running mean: -20.689076\n",
            "resetting env. episode 80.000000, reward total was -19.000000. running mean: -20.672185\n",
            "resetting env. episode 81.000000, reward total was -20.000000. running mean: -20.665463\n",
            "resetting env. episode 82.000000, reward total was -21.000000. running mean: -20.668809\n",
            "resetting env. episode 83.000000, reward total was -20.000000. running mean: -20.662121\n",
            "resetting env. episode 84.000000, reward total was -19.000000. running mean: -20.645499\n",
            "resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.649044\n",
            "resetting env. episode 86.000000, reward total was -20.000000. running mean: -20.642554\n",
            "resetting env. episode 87.000000, reward total was -21.000000. running mean: -20.646128\n",
            "resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.649667\n",
            "resetting env. episode 89.000000, reward total was -20.000000. running mean: -20.643170\n",
            "resetting env. episode 90.000000, reward total was -19.000000. running mean: -20.626739\n",
            "resetting env. episode 91.000000, reward total was -19.000000. running mean: -20.610471\n",
            "resetting env. episode 92.000000, reward total was -21.000000. running mean: -20.614367\n",
            "resetting env. episode 93.000000, reward total was -18.000000. running mean: -20.588223\n",
            "resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.592341\n",
            "resetting env. episode 95.000000, reward total was -18.000000. running mean: -20.566417\n",
            "resetting env. episode 96.000000, reward total was -19.000000. running mean: -20.550753\n",
            "resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.555246\n",
            "resetting env. episode 98.000000, reward total was -20.000000. running mean: -20.549693\n",
            "resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.554196\n",
            "resetting env. episode 100.000000, reward total was -19.000000. running mean: -20.538654\n",
            "resetting env. episode 101.000000, reward total was -21.000000. running mean: -20.543268\n",
            "resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.547835\n",
            "resetting env. episode 103.000000, reward total was -20.000000. running mean: -20.542357\n",
            "resetting env. episode 104.000000, reward total was -20.000000. running mean: -20.536933\n",
            "resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.541564\n",
            "resetting env. episode 106.000000, reward total was -20.000000. running mean: -20.536148\n",
            "resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.540787\n",
            "resetting env. episode 108.000000, reward total was -19.000000. running mean: -20.525379\n",
            "resetting env. episode 109.000000, reward total was -19.000000. running mean: -20.510125\n",
            "resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.515024\n",
            "resetting env. episode 111.000000, reward total was -20.000000. running mean: -20.509874\n",
            "resetting env. episode 112.000000, reward total was -21.000000. running mean: -20.514775\n",
            "resetting env. episode 113.000000, reward total was -21.000000. running mean: -20.519627\n",
            "resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.524431\n",
            "resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.529186\n",
            "resetting env. episode 116.000000, reward total was -20.000000. running mean: -20.523895\n",
            "resetting env. episode 117.000000, reward total was -20.000000. running mean: -20.518656\n",
            "resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.523469\n",
            "resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.528234\n",
            "resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.532952\n",
            "resetting env. episode 121.000000, reward total was -20.000000. running mean: -20.527623\n",
            "resetting env. episode 122.000000, reward total was -20.000000. running mean: -20.522346\n",
            "resetting env. episode 123.000000, reward total was -20.000000. running mean: -20.517123\n",
            "resetting env. episode 124.000000, reward total was -21.000000. running mean: -20.521952\n",
            "resetting env. episode 125.000000, reward total was -21.000000. running mean: -20.526732\n",
            "resetting env. episode 126.000000, reward total was -20.000000. running mean: -20.521465\n",
            "resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.526250\n",
            "resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.530988\n",
            "resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.535678\n",
            "resetting env. episode 130.000000, reward total was -18.000000. running mean: -20.510321\n",
            "resetting env. episode 131.000000, reward total was -20.000000. running mean: -20.505218\n",
            "resetting env. episode 132.000000, reward total was -19.000000. running mean: -20.490166\n",
            "resetting env. episode 133.000000, reward total was -21.000000. running mean: -20.495264\n",
            "resetting env. episode 134.000000, reward total was -20.000000. running mean: -20.490311\n",
            "resetting env. episode 135.000000, reward total was -20.000000. running mean: -20.485408\n",
            "resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.490554\n",
            "resetting env. episode 137.000000, reward total was -20.000000. running mean: -20.485649\n",
            "resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.490792\n",
            "resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.495884\n",
            "resetting env. episode 140.000000, reward total was -20.000000. running mean: -20.490925\n",
            "resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.496016\n",
            "resetting env. episode 142.000000, reward total was -19.000000. running mean: -20.481056\n",
            "resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.486245\n",
            "resetting env. episode 144.000000, reward total was -20.000000. running mean: -20.481383\n",
            "resetting env. episode 145.000000, reward total was -20.000000. running mean: -20.476569\n",
            "resetting env. episode 146.000000, reward total was -19.000000. running mean: -20.461803\n",
            "resetting env. episode 147.000000, reward total was -18.000000. running mean: -20.437185\n",
            "resetting env. episode 148.000000, reward total was -20.000000. running mean: -20.432813\n",
            "resetting env. episode 149.000000, reward total was -21.000000. running mean: -20.438485\n",
            "resetting env. episode 150.000000, reward total was -20.000000. running mean: -20.434100\n",
            "resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.439759\n",
            "resetting env. episode 152.000000, reward total was -20.000000. running mean: -20.435362\n",
            "resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.441008\n",
            "resetting env. episode 154.000000, reward total was -20.000000. running mean: -20.436598\n",
            "resetting env. episode 155.000000, reward total was -20.000000. running mean: -20.432232\n",
            "resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.437910\n",
            "resetting env. episode 157.000000, reward total was -21.000000. running mean: -20.443531\n",
            "resetting env. episode 158.000000, reward total was -21.000000. running mean: -20.449095\n",
            "resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.454605\n",
            "resetting env. episode 160.000000, reward total was -20.000000. running mean: -20.450058\n",
            "resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.455558\n",
            "resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.461002\n",
            "resetting env. episode 163.000000, reward total was -20.000000. running mean: -20.456392\n",
            "resetting env. episode 164.000000, reward total was -21.000000. running mean: -20.461828\n",
            "resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.467210\n",
            "resetting env. episode 166.000000, reward total was -20.000000. running mean: -20.462538\n",
            "resetting env. episode 167.000000, reward total was -21.000000. running mean: -20.467913\n",
            "resetting env. episode 168.000000, reward total was -19.000000. running mean: -20.453233\n",
            "resetting env. episode 169.000000, reward total was -20.000000. running mean: -20.448701\n",
            "resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.454214\n",
            "resetting env. episode 171.000000, reward total was -20.000000. running mean: -20.449672\n",
            "resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.455175\n",
            "resetting env. episode 173.000000, reward total was -19.000000. running mean: -20.440624\n",
            "resetting env. episode 174.000000, reward total was -20.000000. running mean: -20.436217\n",
            "resetting env. episode 175.000000, reward total was -21.000000. running mean: -20.441855\n",
            "resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.447437\n",
            "resetting env. episode 177.000000, reward total was -20.000000. running mean: -20.442962\n",
            "resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.448533\n",
            "resetting env. episode 179.000000, reward total was -20.000000. running mean: -20.444047\n",
            "resetting env. episode 180.000000, reward total was -20.000000. running mean: -20.439607\n",
            "resetting env. episode 181.000000, reward total was -21.000000. running mean: -20.445211\n",
            "resetting env. episode 182.000000, reward total was -18.000000. running mean: -20.420759\n",
            "resetting env. episode 183.000000, reward total was -21.000000. running mean: -20.426551\n",
            "resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.432285\n",
            "resetting env. episode 185.000000, reward total was -20.000000. running mean: -20.427963\n",
            "resetting env. episode 186.000000, reward total was -18.000000. running mean: -20.403683\n",
            "resetting env. episode 187.000000, reward total was -21.000000. running mean: -20.409646\n",
            "resetting env. episode 188.000000, reward total was -20.000000. running mean: -20.405550\n",
            "resetting env. episode 189.000000, reward total was -20.000000. running mean: -20.401494\n",
            "resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.407479\n",
            "resetting env. episode 191.000000, reward total was -20.000000. running mean: -20.403404\n",
            "resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.409370\n",
            "resetting env. episode 193.000000, reward total was -20.000000. running mean: -20.405277\n",
            "resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.411224\n",
            "resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.417112\n",
            "resetting env. episode 196.000000, reward total was -20.000000. running mean: -20.412941\n",
            "resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.418811\n",
            "resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.424623\n",
            "resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.430377\n",
            "resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.436073\n",
            "resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.441712\n",
            "resetting env. episode 202.000000, reward total was -20.000000. running mean: -20.437295\n",
            "resetting env. episode 203.000000, reward total was -21.000000. running mean: -20.442922\n",
            "resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.448493\n",
            "resetting env. episode 205.000000, reward total was -21.000000. running mean: -20.454008\n",
            "resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.459468\n",
            "resetting env. episode 207.000000, reward total was -20.000000. running mean: -20.454873\n",
            "resetting env. episode 208.000000, reward total was -19.000000. running mean: -20.440325\n",
            "resetting env. episode 209.000000, reward total was -19.000000. running mean: -20.425921\n",
            "resetting env. episode 210.000000, reward total was -20.000000. running mean: -20.421662\n",
            "resetting env. episode 211.000000, reward total was -20.000000. running mean: -20.417446\n",
            "resetting env. episode 212.000000, reward total was -20.000000. running mean: -20.413271\n",
            "resetting env. episode 213.000000, reward total was -20.000000. running mean: -20.409138\n",
            "resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.415047\n",
            "resetting env. episode 215.000000, reward total was -20.000000. running mean: -20.410897\n",
            "resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.416788\n",
            "resetting env. episode 217.000000, reward total was -21.000000. running mean: -20.422620\n",
            "resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.428394\n",
            "resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.434110\n",
            "resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.439768\n",
            "resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.445371\n",
            "resetting env. episode 222.000000, reward total was -19.000000. running mean: -20.430917\n",
            "resetting env. episode 223.000000, reward total was -21.000000. running mean: -20.436608\n",
            "resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.442242\n",
            "resetting env. episode 225.000000, reward total was -20.000000. running mean: -20.437819\n",
            "resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.443441\n",
            "resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.449007\n",
            "resetting env. episode 228.000000, reward total was -21.000000. running mean: -20.454517\n",
            "resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.459972\n",
            "resetting env. episode 230.000000, reward total was -19.000000. running mean: -20.445372\n",
            "resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.450918\n",
            "resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.456409\n",
            "resetting env. episode 233.000000, reward total was -21.000000. running mean: -20.461845\n",
            "resetting env. episode 234.000000, reward total was -20.000000. running mean: -20.457226\n",
            "resetting env. episode 235.000000, reward total was -20.000000. running mean: -20.452654\n",
            "resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.458128\n",
            "resetting env. episode 237.000000, reward total was -19.000000. running mean: -20.443546\n",
            "resetting env. episode 238.000000, reward total was -21.000000. running mean: -20.449111\n",
            "resetting env. episode 239.000000, reward total was -19.000000. running mean: -20.434620\n",
            "resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.440274\n",
            "resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.445871\n",
            "resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.451412\n",
            "resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.456898\n",
            "resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.462329\n",
            "resetting env. episode 245.000000, reward total was -18.000000. running mean: -20.437706\n",
            "resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.443329\n",
            "resetting env. episode 247.000000, reward total was -19.000000. running mean: -20.428895\n",
            "resetting env. episode 248.000000, reward total was -20.000000. running mean: -20.424606\n",
            "resetting env. episode 249.000000, reward total was -20.000000. running mean: -20.420360\n",
            "resetting env. episode 250.000000, reward total was -21.000000. running mean: -20.426157\n",
            "resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.431895\n",
            "resetting env. episode 252.000000, reward total was -19.000000. running mean: -20.417576\n",
            "resetting env. episode 253.000000, reward total was -20.000000. running mean: -20.413400\n",
            "resetting env. episode 254.000000, reward total was -19.000000. running mean: -20.399266\n",
            "resetting env. episode 255.000000, reward total was -20.000000. running mean: -20.395274\n",
            "resetting env. episode 256.000000, reward total was -20.000000. running mean: -20.391321\n",
            "resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.397408\n",
            "resetting env. episode 258.000000, reward total was -20.000000. running mean: -20.393434\n",
            "resetting env. episode 259.000000, reward total was -20.000000. running mean: -20.389499\n",
            "resetting env. episode 260.000000, reward total was -19.000000. running mean: -20.375604\n",
            "resetting env. episode 261.000000, reward total was -19.000000. running mean: -20.361848\n",
            "resetting env. episode 262.000000, reward total was -21.000000. running mean: -20.368230\n",
            "resetting env. episode 263.000000, reward total was -20.000000. running mean: -20.364548\n",
            "resetting env. episode 264.000000, reward total was -20.000000. running mean: -20.360902\n",
            "resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.367293\n",
            "resetting env. episode 266.000000, reward total was -21.000000. running mean: -20.373620\n",
            "resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.379884\n",
            "resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.386085\n",
            "resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.392224\n",
            "resetting env. episode 270.000000, reward total was -19.000000. running mean: -20.378302\n",
            "resetting env. episode 271.000000, reward total was -21.000000. running mean: -20.384519\n",
            "resetting env. episode 272.000000, reward total was -20.000000. running mean: -20.380674\n",
            "resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.386867\n",
            "resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.392998\n",
            "resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.399068\n",
            "resetting env. episode 276.000000, reward total was -19.000000. running mean: -20.385078\n",
            "resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.391227\n",
            "resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.397315\n",
            "resetting env. episode 279.000000, reward total was -19.000000. running mean: -20.383342\n",
            "resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.389508\n",
            "resetting env. episode 281.000000, reward total was -20.000000. running mean: -20.385613\n",
            "resetting env. episode 282.000000, reward total was -19.000000. running mean: -20.371757\n",
            "resetting env. episode 283.000000, reward total was -18.000000. running mean: -20.348039\n",
            "resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.354559\n",
            "resetting env. episode 285.000000, reward total was -20.000000. running mean: -20.351013\n",
            "resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.357503\n",
            "resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.363928\n",
            "resetting env. episode 288.000000, reward total was -19.000000. running mean: -20.350289\n",
            "resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.356786\n",
            "resetting env. episode 290.000000, reward total was -21.000000. running mean: -20.363218\n",
            "resetting env. episode 291.000000, reward total was -20.000000. running mean: -20.359586\n",
            "resetting env. episode 292.000000, reward total was -20.000000. running mean: -20.355990\n",
            "resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.362430\n",
            "resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.368806\n",
            "resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.375118\n",
            "resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.381367\n",
            "resetting env. episode 297.000000, reward total was -20.000000. running mean: -20.377553\n",
            "resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.383778\n",
            "resetting env. episode 299.000000, reward total was -21.000000. running mean: -20.389940\n",
            "resetting env. episode 300.000000, reward total was -21.000000. running mean: -20.396040\n",
            "resetting env. episode 301.000000, reward total was -20.000000. running mean: -20.392080\n",
            "resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.398159\n",
            "resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.404178\n",
            "resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.410136\n",
            "resetting env. episode 305.000000, reward total was -20.000000. running mean: -20.406034\n",
            "resetting env. episode 306.000000, reward total was -20.000000. running mean: -20.401974\n",
            "resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.407954\n",
            "resetting env. episode 308.000000, reward total was -20.000000. running mean: -20.403875\n",
            "resetting env. episode 309.000000, reward total was -20.000000. running mean: -20.399836\n",
            "resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.405838\n",
            "resetting env. episode 311.000000, reward total was -20.000000. running mean: -20.401779\n",
            "resetting env. episode 312.000000, reward total was -19.000000. running mean: -20.387762\n",
            "resetting env. episode 313.000000, reward total was -19.000000. running mean: -20.373884\n",
            "resetting env. episode 314.000000, reward total was -20.000000. running mean: -20.370145\n",
            "resetting env. episode 315.000000, reward total was -21.000000. running mean: -20.376444\n",
            "resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.382679\n",
            "resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.388852\n",
            "resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.394964\n",
            "resetting env. episode 319.000000, reward total was -20.000000. running mean: -20.391014\n",
            "resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.397104\n",
            "resetting env. episode 321.000000, reward total was -21.000000. running mean: -20.403133\n",
            "resetting env. episode 322.000000, reward total was -21.000000. running mean: -20.409102\n",
            "resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.415011\n",
            "resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.420861\n",
            "resetting env. episode 325.000000, reward total was -20.000000. running mean: -20.416652\n",
            "resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.422485\n",
            "resetting env. episode 327.000000, reward total was -19.000000. running mean: -20.408261\n",
            "resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.414178\n",
            "resetting env. episode 329.000000, reward total was -20.000000. running mean: -20.410036\n",
            "resetting env. episode 330.000000, reward total was -20.000000. running mean: -20.405936\n",
            "resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.411876\n",
            "resetting env. episode 332.000000, reward total was -20.000000. running mean: -20.407758\n",
            "resetting env. episode 333.000000, reward total was -21.000000. running mean: -20.413680\n",
            "resetting env. episode 334.000000, reward total was -20.000000. running mean: -20.409543\n",
            "resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.415448\n",
            "resetting env. episode 336.000000, reward total was -20.000000. running mean: -20.411293\n",
            "resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.417180\n",
            "resetting env. episode 338.000000, reward total was -21.000000. running mean: -20.423009\n",
            "resetting env. episode 339.000000, reward total was -21.000000. running mean: -20.428779\n",
            "resetting env. episode 340.000000, reward total was -21.000000. running mean: -20.434491\n",
            "resetting env. episode 341.000000, reward total was -20.000000. running mean: -20.430146\n",
            "resetting env. episode 342.000000, reward total was -20.000000. running mean: -20.425844\n",
            "resetting env. episode 343.000000, reward total was -19.000000. running mean: -20.411586\n",
            "resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.417470\n",
            "resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.423295\n",
            "resetting env. episode 346.000000, reward total was -20.000000. running mean: -20.419062\n",
            "resetting env. episode 347.000000, reward total was -21.000000. running mean: -20.424872\n",
            "resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.430623\n",
            "resetting env. episode 349.000000, reward total was -19.000000. running mean: -20.416317\n",
            "resetting env. episode 350.000000, reward total was -21.000000. running mean: -20.422154\n",
            "resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.427932\n",
            "resetting env. episode 352.000000, reward total was -19.000000. running mean: -20.413653\n",
            "resetting env. episode 353.000000, reward total was -21.000000. running mean: -20.419516\n",
            "resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.425321\n",
            "resetting env. episode 355.000000, reward total was -19.000000. running mean: -20.411068\n",
            "resetting env. episode 356.000000, reward total was -19.000000. running mean: -20.396957\n",
            "resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.402988\n",
            "resetting env. episode 358.000000, reward total was -20.000000. running mean: -20.398958\n",
            "resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.404968\n",
            "resetting env. episode 360.000000, reward total was -21.000000. running mean: -20.410919\n",
            "resetting env. episode 361.000000, reward total was -20.000000. running mean: -20.406809\n",
            "resetting env. episode 362.000000, reward total was -18.000000. running mean: -20.382741\n",
            "resetting env. episode 363.000000, reward total was -19.000000. running mean: -20.368914\n",
            "resetting env. episode 364.000000, reward total was -21.000000. running mean: -20.375225\n",
            "resetting env. episode 365.000000, reward total was -20.000000. running mean: -20.371473\n",
            "resetting env. episode 366.000000, reward total was -20.000000. running mean: -20.367758\n",
            "resetting env. episode 367.000000, reward total was -19.000000. running mean: -20.354080\n",
            "resetting env. episode 368.000000, reward total was -21.000000. running mean: -20.360539\n",
            "resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.366934\n",
            "resetting env. episode 370.000000, reward total was -19.000000. running mean: -20.353265\n",
            "resetting env. episode 371.000000, reward total was -21.000000. running mean: -20.359732\n",
            "resetting env. episode 372.000000, reward total was -20.000000. running mean: -20.356135\n",
            "resetting env. episode 373.000000, reward total was -20.000000. running mean: -20.352573\n",
            "resetting env. episode 374.000000, reward total was -19.000000. running mean: -20.339048\n",
            "resetting env. episode 375.000000, reward total was -20.000000. running mean: -20.335657\n",
            "resetting env. episode 376.000000, reward total was -21.000000. running mean: -20.342301\n",
            "resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.348878\n",
            "resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.355389\n",
            "resetting env. episode 379.000000, reward total was -20.000000. running mean: -20.351835\n",
            "resetting env. episode 380.000000, reward total was -20.000000. running mean: -20.348317\n",
            "resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.354833\n",
            "resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.361285\n",
            "resetting env. episode 383.000000, reward total was -19.000000. running mean: -20.347672\n",
            "resetting env. episode 384.000000, reward total was -20.000000. running mean: -20.344195\n",
            "resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.350754\n",
            "resetting env. episode 386.000000, reward total was -21.000000. running mean: -20.357246\n",
            "resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.363674\n",
            "resetting env. episode 388.000000, reward total was -20.000000. running mean: -20.360037\n",
            "resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.366436\n",
            "resetting env. episode 390.000000, reward total was -19.000000. running mean: -20.352772\n",
            "resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.359244\n",
            "resetting env. episode 392.000000, reward total was -20.000000. running mean: -20.355652\n",
            "resetting env. episode 393.000000, reward total was -20.000000. running mean: -20.352095\n",
            "resetting env. episode 394.000000, reward total was -21.000000. running mean: -20.358574\n",
            "resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.364989\n",
            "resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.371339\n",
            "resetting env. episode 397.000000, reward total was -21.000000. running mean: -20.377625\n",
            "resetting env. episode 398.000000, reward total was -18.000000. running mean: -20.353849\n",
            "resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.360311\n",
            "resetting env. episode 400.000000, reward total was -21.000000. running mean: -20.366708\n",
            "resetting env. episode 401.000000, reward total was -20.000000. running mean: -20.363040\n",
            "resetting env. episode 402.000000, reward total was -20.000000. running mean: -20.359410\n",
            "resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.365816\n",
            "resetting env. episode 404.000000, reward total was -20.000000. running mean: -20.362158\n",
            "resetting env. episode 405.000000, reward total was -19.000000. running mean: -20.348536\n",
            "resetting env. episode 406.000000, reward total was -20.000000. running mean: -20.345051\n",
            "resetting env. episode 407.000000, reward total was -20.000000. running mean: -20.341600\n",
            "resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.348184\n",
            "resetting env. episode 409.000000, reward total was -20.000000. running mean: -20.344703\n",
            "resetting env. episode 410.000000, reward total was -20.000000. running mean: -20.341255\n",
            "resetting env. episode 411.000000, reward total was -19.000000. running mean: -20.327843\n",
            "resetting env. episode 412.000000, reward total was -21.000000. running mean: -20.334565\n",
            "resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.341219\n",
            "resetting env. episode 414.000000, reward total was -20.000000. running mean: -20.337807\n",
            "resetting env. episode 415.000000, reward total was -21.000000. running mean: -20.344429\n",
            "resetting env. episode 416.000000, reward total was -19.000000. running mean: -20.330984\n",
            "resetting env. episode 417.000000, reward total was -19.000000. running mean: -20.317674\n",
            "resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.324498\n",
            "resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.331253\n",
            "resetting env. episode 420.000000, reward total was -19.000000. running mean: -20.317940\n",
            "resetting env. episode 421.000000, reward total was -20.000000. running mean: -20.314761\n",
            "resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.321613\n",
            "resetting env. episode 423.000000, reward total was -21.000000. running mean: -20.328397\n",
            "resetting env. episode 424.000000, reward total was -19.000000. running mean: -20.315113\n",
            "resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.321962\n",
            "resetting env. episode 426.000000, reward total was -21.000000. running mean: -20.328742\n",
            "resetting env. episode 427.000000, reward total was -19.000000. running mean: -20.315455\n",
            "resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.322300\n",
            "resetting env. episode 429.000000, reward total was -20.000000. running mean: -20.319077\n",
            "resetting env. episode 430.000000, reward total was -18.000000. running mean: -20.295887\n",
            "resetting env. episode 431.000000, reward total was -20.000000. running mean: -20.292928\n",
            "resetting env. episode 432.000000, reward total was -20.000000. running mean: -20.289998\n",
            "resetting env. episode 433.000000, reward total was -19.000000. running mean: -20.277098\n",
            "resetting env. episode 434.000000, reward total was -19.000000. running mean: -20.264328\n",
            "resetting env. episode 435.000000, reward total was -20.000000. running mean: -20.261684\n",
            "resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.269067\n",
            "resetting env. episode 437.000000, reward total was -19.000000. running mean: -20.256377\n",
            "resetting env. episode 438.000000, reward total was -21.000000. running mean: -20.263813\n",
            "resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.271175\n",
            "resetting env. episode 440.000000, reward total was -18.000000. running mean: -20.248463\n",
            "resetting env. episode 441.000000, reward total was -20.000000. running mean: -20.245978\n",
            "resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.253519\n",
            "resetting env. episode 443.000000, reward total was -20.000000. running mean: -20.250983\n",
            "resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.258474\n",
            "resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.265889\n",
            "resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.273230\n",
            "resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.280498\n",
            "resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.287693\n",
            "resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.294816\n",
            "resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.301868\n",
            "resetting env. episode 451.000000, reward total was -21.000000. running mean: -20.308849\n",
            "resetting env. episode 452.000000, reward total was -21.000000. running mean: -20.315760\n",
            "resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.322603\n",
            "resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.329377\n",
            "resetting env. episode 455.000000, reward total was -20.000000. running mean: -20.326083\n",
            "resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.332822\n",
            "resetting env. episode 457.000000, reward total was -20.000000. running mean: -20.329494\n",
            "resetting env. episode 458.000000, reward total was -18.000000. running mean: -20.306199\n",
            "resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.313137\n",
            "resetting env. episode 460.000000, reward total was -21.000000. running mean: -20.320006\n",
            "resetting env. episode 461.000000, reward total was -20.000000. running mean: -20.316806\n",
            "resetting env. episode 462.000000, reward total was -21.000000. running mean: -20.323638\n",
            "resetting env. episode 463.000000, reward total was -21.000000. running mean: -20.330401\n",
            "resetting env. episode 464.000000, reward total was -20.000000. running mean: -20.327097\n",
            "resetting env. episode 465.000000, reward total was -20.000000. running mean: -20.323826\n",
            "resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.330588\n",
            "resetting env. episode 467.000000, reward total was -21.000000. running mean: -20.337282\n",
            "resetting env. episode 468.000000, reward total was -20.000000. running mean: -20.333909\n",
            "resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.340570\n",
            "resetting env. episode 470.000000, reward total was -20.000000. running mean: -20.337164\n",
            "resetting env. episode 471.000000, reward total was -19.000000. running mean: -20.323793\n",
            "resetting env. episode 472.000000, reward total was -19.000000. running mean: -20.310555\n",
            "resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.317449\n",
            "resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.324275\n",
            "resetting env. episode 475.000000, reward total was -20.000000. running mean: -20.321032\n",
            "resetting env. episode 476.000000, reward total was -20.000000. running mean: -20.317822\n",
            "resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.324644\n",
            "resetting env. episode 478.000000, reward total was -21.000000. running mean: -20.331397\n",
            "resetting env. episode 479.000000, reward total was -21.000000. running mean: -20.338083\n",
            "resetting env. episode 480.000000, reward total was -21.000000. running mean: -20.344702\n",
            "resetting env. episode 481.000000, reward total was -20.000000. running mean: -20.341255\n",
            "resetting env. episode 482.000000, reward total was -20.000000. running mean: -20.337843\n",
            "resetting env. episode 483.000000, reward total was -20.000000. running mean: -20.334464\n",
            "resetting env. episode 484.000000, reward total was -21.000000. running mean: -20.341120\n",
            "resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.347709\n",
            "resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.354231\n",
            "resetting env. episode 487.000000, reward total was -20.000000. running mean: -20.350689\n",
            "resetting env. episode 488.000000, reward total was -20.000000. running mean: -20.347182\n",
            "resetting env. episode 489.000000, reward total was -19.000000. running mean: -20.333710\n",
            "resetting env. episode 490.000000, reward total was -20.000000. running mean: -20.330373\n",
            "resetting env. episode 491.000000, reward total was -21.000000. running mean: -20.337070\n",
            "resetting env. episode 492.000000, reward total was -21.000000. running mean: -20.343699\n",
            "resetting env. episode 493.000000, reward total was -21.000000. running mean: -20.350262\n",
            "resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.356759\n",
            "resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.363192\n",
            "resetting env. episode 496.000000, reward total was -21.000000. running mean: -20.369560\n",
            "resetting env. episode 497.000000, reward total was -21.000000. running mean: -20.375864\n",
            "resetting env. episode 498.000000, reward total was -20.000000. running mean: -20.372106\n",
            "resetting env. episode 499.000000, reward total was -19.000000. running mean: -20.358384\n",
            "resetting env. episode 500.000000, reward total was -21.000000. running mean: -20.364801\n",
            "CPU times: user 35min 1s, sys: 11min 2s, total: 46min 4s\n",
            "Wall time: 23min 37s\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "cHYCDYwhlVLV",
        "outputId": "21ceeb69-163d-46a3-ebee-47e0e906e458",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "%time hist2 = train_model(env, model, total_episodes=500)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n",
            "resetting env. episode 2.000000, reward total was -21.000000. running mean: -21.000000\n",
            "resetting env. episode 3.000000, reward total was -20.000000. running mean: -20.990000\n",
            "resetting env. episode 4.000000, reward total was -21.000000. running mean: -20.990100\n",
            "resetting env. episode 5.000000, reward total was -21.000000. running mean: -20.990199\n",
            "resetting env. episode 6.000000, reward total was -20.000000. running mean: -20.980297\n",
            "resetting env. episode 7.000000, reward total was -20.000000. running mean: -20.970494\n",
            "resetting env. episode 8.000000, reward total was -19.000000. running mean: -20.950789\n",
            "resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.951281\n",
            "resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.951768\n",
            "resetting env. episode 11.000000, reward total was -20.000000. running mean: -20.942251\n",
            "resetting env. episode 12.000000, reward total was -20.000000. running mean: -20.932828\n",
            "resetting env. episode 13.000000, reward total was -21.000000. running mean: -20.933500\n",
            "resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.934165\n",
            "resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.934823\n",
            "resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.935475\n",
            "resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.936120\n",
            "resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.936759\n",
            "resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.937391\n",
            "resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.938018\n",
            "resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.938637\n",
            "resetting env. episode 22.000000, reward total was -20.000000. running mean: -20.929251\n",
            "resetting env. episode 23.000000, reward total was -19.000000. running mean: -20.909959\n",
            "resetting env. episode 24.000000, reward total was -20.000000. running mean: -20.900859\n",
            "resetting env. episode 25.000000, reward total was -19.000000. running mean: -20.881850\n",
            "resetting env. episode 26.000000, reward total was -20.000000. running mean: -20.873032\n",
            "resetting env. episode 27.000000, reward total was -21.000000. running mean: -20.874302\n",
            "resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.875559\n",
            "resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.876803\n",
            "resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.878035\n",
            "resetting env. episode 31.000000, reward total was -20.000000. running mean: -20.869255\n",
            "resetting env. episode 32.000000, reward total was -20.000000. running mean: -20.860562\n",
            "resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.861956\n",
            "resetting env. episode 34.000000, reward total was -14.000000. running mean: -20.793337\n",
            "resetting env. episode 35.000000, reward total was -19.000000. running mean: -20.775403\n",
            "resetting env. episode 36.000000, reward total was -20.000000. running mean: -20.767649\n",
            "resetting env. episode 37.000000, reward total was -20.000000. running mean: -20.759973\n",
            "resetting env. episode 38.000000, reward total was -21.000000. running mean: -20.762373\n",
            "resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.764749\n",
            "resetting env. episode 40.000000, reward total was -21.000000. running mean: -20.767102\n",
            "resetting env. episode 41.000000, reward total was -21.000000. running mean: -20.769431\n",
            "resetting env. episode 42.000000, reward total was -21.000000. running mean: -20.771737\n",
            "resetting env. episode 43.000000, reward total was -18.000000. running mean: -20.744019\n",
            "resetting env. episode 44.000000, reward total was -21.000000. running mean: -20.746579\n",
            "resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.749113\n",
            "resetting env. episode 46.000000, reward total was -19.000000. running mean: -20.731622\n",
            "resetting env. episode 47.000000, reward total was -19.000000. running mean: -20.714306\n",
            "resetting env. episode 48.000000, reward total was -19.000000. running mean: -20.697163\n",
            "resetting env. episode 49.000000, reward total was -18.000000. running mean: -20.670191\n",
            "resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.673489\n",
            "resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.676754\n",
            "resetting env. episode 52.000000, reward total was -21.000000. running mean: -20.679987\n",
            "resetting env. episode 53.000000, reward total was -20.000000. running mean: -20.673187\n",
            "resetting env. episode 54.000000, reward total was -20.000000. running mean: -20.666455\n",
            "resetting env. episode 55.000000, reward total was -20.000000. running mean: -20.659791\n",
            "resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.663193\n",
            "resetting env. episode 57.000000, reward total was -20.000000. running mean: -20.656561\n",
            "resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.659995\n",
            "resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.663395\n",
            "resetting env. episode 60.000000, reward total was -20.000000. running mean: -20.656761\n",
            "resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.660194\n",
            "resetting env. episode 62.000000, reward total was -19.000000. running mean: -20.643592\n",
            "resetting env. episode 63.000000, reward total was -20.000000. running mean: -20.637156\n",
            "resetting env. episode 64.000000, reward total was -17.000000. running mean: -20.600784\n",
            "resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.604776\n",
            "resetting env. episode 66.000000, reward total was -19.000000. running mean: -20.588729\n",
            "resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.592841\n",
            "resetting env. episode 68.000000, reward total was -20.000000. running mean: -20.586913\n",
            "resetting env. episode 69.000000, reward total was -20.000000. running mean: -20.581044\n",
            "resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.585233\n",
            "resetting env. episode 71.000000, reward total was -20.000000. running mean: -20.579381\n",
            "resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.583587\n",
            "resetting env. episode 73.000000, reward total was -20.000000. running mean: -20.577751\n",
            "resetting env. episode 74.000000, reward total was -20.000000. running mean: -20.571974\n",
            "resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.576254\n",
            "resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.580492\n",
            "resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.584687\n",
            "resetting env. episode 78.000000, reward total was -19.000000. running mean: -20.568840\n",
            "resetting env. episode 79.000000, reward total was -19.000000. running mean: -20.553151\n",
            "resetting env. episode 80.000000, reward total was -21.000000. running mean: -20.557620\n",
            "resetting env. episode 81.000000, reward total was -19.000000. running mean: -20.542044\n",
            "resetting env. episode 82.000000, reward total was -19.000000. running mean: -20.526623\n",
            "resetting env. episode 83.000000, reward total was -21.000000. running mean: -20.531357\n",
            "resetting env. episode 84.000000, reward total was -20.000000. running mean: -20.526043\n",
            "resetting env. episode 85.000000, reward total was -19.000000. running mean: -20.510783\n",
            "resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.515675\n",
            "resetting env. episode 87.000000, reward total was -19.000000. running mean: -20.500518\n",
            "resetting env. episode 88.000000, reward total was -20.000000. running mean: -20.495513\n",
            "resetting env. episode 89.000000, reward total was -18.000000. running mean: -20.470558\n",
            "resetting env. episode 90.000000, reward total was -20.000000. running mean: -20.465853\n",
            "resetting env. episode 91.000000, reward total was -20.000000. running mean: -20.461194\n",
            "resetting env. episode 92.000000, reward total was -18.000000. running mean: -20.436582\n",
            "resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.442216\n",
            "resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.447794\n",
            "resetting env. episode 95.000000, reward total was -20.000000. running mean: -20.443316\n",
            "resetting env. episode 96.000000, reward total was -18.000000. running mean: -20.418883\n",
            "resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.424694\n",
            "resetting env. episode 98.000000, reward total was -20.000000. running mean: -20.420447\n",
            "resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.426243\n",
            "resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.431980\n",
            "resetting env. episode 101.000000, reward total was -21.000000. running mean: -20.437660\n",
            "resetting env. episode 102.000000, reward total was -20.000000. running mean: -20.433284\n",
            "resetting env. episode 103.000000, reward total was -19.000000. running mean: -20.418951\n",
            "resetting env. episode 104.000000, reward total was -21.000000. running mean: -20.424762\n",
            "resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.430514\n",
            "resetting env. episode 106.000000, reward total was -21.000000. running mean: -20.436209\n",
            "resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.441847\n",
            "resetting env. episode 108.000000, reward total was -21.000000. running mean: -20.447428\n",
            "resetting env. episode 109.000000, reward total was -21.000000. running mean: -20.452954\n",
            "resetting env. episode 110.000000, reward total was -20.000000. running mean: -20.448424\n",
            "resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.453940\n",
            "resetting env. episode 112.000000, reward total was -20.000000. running mean: -20.449401\n",
            "resetting env. episode 113.000000, reward total was -19.000000. running mean: -20.434907\n",
            "resetting env. episode 114.000000, reward total was -19.000000. running mean: -20.420558\n",
            "resetting env. episode 115.000000, reward total was -19.000000. running mean: -20.406352\n",
            "resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.412289\n",
            "resetting env. episode 117.000000, reward total was -19.000000. running mean: -20.398166\n",
            "resetting env. episode 118.000000, reward total was -20.000000. running mean: -20.394184\n",
            "resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.400242\n",
            "resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.406240\n",
            "resetting env. episode 121.000000, reward total was -20.000000. running mean: -20.402177\n",
            "resetting env. episode 122.000000, reward total was -20.000000. running mean: -20.398156\n",
            "resetting env. episode 123.000000, reward total was -20.000000. running mean: -20.394174\n",
            "resetting env. episode 124.000000, reward total was -21.000000. running mean: -20.400232\n",
            "resetting env. episode 125.000000, reward total was -20.000000. running mean: -20.396230\n",
            "resetting env. episode 126.000000, reward total was -20.000000. running mean: -20.392268\n",
            "resetting env. episode 127.000000, reward total was -20.000000. running mean: -20.388345\n",
            "resetting env. episode 128.000000, reward total was -20.000000. running mean: -20.384462\n",
            "resetting env. episode 129.000000, reward total was -19.000000. running mean: -20.370617\n",
            "resetting env. episode 130.000000, reward total was -21.000000. running mean: -20.376911\n",
            "resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.383142\n",
            "resetting env. episode 132.000000, reward total was -21.000000. running mean: -20.389310\n",
            "resetting env. episode 133.000000, reward total was -19.000000. running mean: -20.375417\n",
            "resetting env. episode 134.000000, reward total was -20.000000. running mean: -20.371663\n",
            "resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.377946\n",
            "resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.384167\n",
            "resetting env. episode 137.000000, reward total was -20.000000. running mean: -20.380325\n",
            "resetting env. episode 138.000000, reward total was -20.000000. running mean: -20.376522\n",
            "resetting env. episode 139.000000, reward total was -20.000000. running mean: -20.372757\n",
            "resetting env. episode 140.000000, reward total was -20.000000. running mean: -20.369029\n",
            "resetting env. episode 141.000000, reward total was -19.000000. running mean: -20.355339\n",
            "resetting env. episode 142.000000, reward total was -21.000000. running mean: -20.361785\n",
            "resetting env. episode 143.000000, reward total was -20.000000. running mean: -20.358168\n",
            "resetting env. episode 144.000000, reward total was -21.000000. running mean: -20.364586\n",
            "resetting env. episode 145.000000, reward total was -20.000000. running mean: -20.360940\n",
            "resetting env. episode 146.000000, reward total was -21.000000. running mean: -20.367331\n",
            "resetting env. episode 147.000000, reward total was -20.000000. running mean: -20.363657\n",
            "resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.370021\n",
            "resetting env. episode 149.000000, reward total was -21.000000. running mean: -20.376321\n",
            "resetting env. episode 150.000000, reward total was -21.000000. running mean: -20.382557\n",
            "resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.388732\n",
            "resetting env. episode 152.000000, reward total was -19.000000. running mean: -20.374845\n",
            "resetting env. episode 153.000000, reward total was -19.000000. running mean: -20.361096\n",
            "resetting env. episode 154.000000, reward total was -20.000000. running mean: -20.357485\n",
            "resetting env. episode 155.000000, reward total was -20.000000. running mean: -20.353910\n",
            "resetting env. episode 156.000000, reward total was -20.000000. running mean: -20.350371\n",
            "resetting env. episode 157.000000, reward total was -21.000000. running mean: -20.356867\n",
            "resetting env. episode 158.000000, reward total was -20.000000. running mean: -20.353299\n",
            "resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.359766\n",
            "resetting env. episode 160.000000, reward total was -20.000000. running mean: -20.356168\n",
            "resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.362606\n",
            "resetting env. episode 162.000000, reward total was -20.000000. running mean: -20.358980\n",
            "resetting env. episode 163.000000, reward total was -20.000000. running mean: -20.355391\n",
            "resetting env. episode 164.000000, reward total was -21.000000. running mean: -20.361837\n",
            "resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.368218\n",
            "resetting env. episode 166.000000, reward total was -20.000000. running mean: -20.364536\n",
            "resetting env. episode 167.000000, reward total was -18.000000. running mean: -20.340891\n",
            "resetting env. episode 168.000000, reward total was -20.000000. running mean: -20.337482\n",
            "resetting env. episode 169.000000, reward total was -19.000000. running mean: -20.324107\n",
            "resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.330866\n",
            "resetting env. episode 171.000000, reward total was -20.000000. running mean: -20.327557\n",
            "resetting env. episode 172.000000, reward total was -19.000000. running mean: -20.314282\n",
            "resetting env. episode 173.000000, reward total was -21.000000. running mean: -20.321139\n",
            "resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.327928\n",
            "resetting env. episode 175.000000, reward total was -19.000000. running mean: -20.314648\n",
            "resetting env. episode 176.000000, reward total was -20.000000. running mean: -20.311502\n",
            "resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.318387\n",
            "resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.325203\n",
            "resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.331951\n",
            "resetting env. episode 180.000000, reward total was -19.000000. running mean: -20.318631\n",
            "resetting env. episode 181.000000, reward total was -21.000000. running mean: -20.325445\n",
            "resetting env. episode 182.000000, reward total was -19.000000. running mean: -20.312191\n",
            "resetting env. episode 183.000000, reward total was -20.000000. running mean: -20.309069\n",
            "resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.315978\n",
            "resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.322818\n",
            "resetting env. episode 186.000000, reward total was -20.000000. running mean: -20.319590\n",
            "resetting env. episode 187.000000, reward total was -19.000000. running mean: -20.306394\n",
            "resetting env. episode 188.000000, reward total was -20.000000. running mean: -20.303330\n",
            "resetting env. episode 189.000000, reward total was -21.000000. running mean: -20.310297\n",
            "resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.317194\n",
            "resetting env. episode 191.000000, reward total was -20.000000. running mean: -20.314022\n",
            "resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.320882\n",
            "resetting env. episode 193.000000, reward total was -20.000000. running mean: -20.317673\n",
            "resetting env. episode 194.000000, reward total was -20.000000. running mean: -20.314496\n",
            "resetting env. episode 195.000000, reward total was -20.000000. running mean: -20.311351\n",
            "resetting env. episode 196.000000, reward total was -20.000000. running mean: -20.308238\n",
            "resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.315155\n",
            "resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.322004\n",
            "resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.328784\n",
            "resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.335496\n",
            "resetting env. episode 201.000000, reward total was -19.000000. running mean: -20.322141\n",
            "resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.328920\n",
            "resetting env. episode 203.000000, reward total was -21.000000. running mean: -20.335630\n",
            "resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.342274\n",
            "resetting env. episode 205.000000, reward total was -21.000000. running mean: -20.348851\n",
            "resetting env. episode 206.000000, reward total was -20.000000. running mean: -20.345363\n",
            "resetting env. episode 207.000000, reward total was -17.000000. running mean: -20.311909\n",
            "resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.318790\n",
            "resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.325602\n",
            "resetting env. episode 210.000000, reward total was -20.000000. running mean: -20.322346\n",
            "resetting env. episode 211.000000, reward total was -20.000000. running mean: -20.319123\n",
            "resetting env. episode 212.000000, reward total was -18.000000. running mean: -20.295931\n",
            "resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.302972\n",
            "resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.309942\n",
            "resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.316843\n",
            "resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.323675\n",
            "resetting env. episode 217.000000, reward total was -20.000000. running mean: -20.320438\n",
            "resetting env. episode 218.000000, reward total was -18.000000. running mean: -20.297233\n",
            "resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.304261\n",
            "resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.311219\n",
            "resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.318106\n",
            "resetting env. episode 222.000000, reward total was -18.000000. running mean: -20.294925\n",
            "resetting env. episode 223.000000, reward total was -20.000000. running mean: -20.291976\n",
            "resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.299056\n",
            "resetting env. episode 225.000000, reward total was -20.000000. running mean: -20.296066\n",
            "resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.303105\n",
            "resetting env. episode 227.000000, reward total was -19.000000. running mean: -20.290074\n",
            "resetting env. episode 228.000000, reward total was -19.000000. running mean: -20.277173\n",
            "resetting env. episode 229.000000, reward total was -20.000000. running mean: -20.274402\n",
            "resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.281657\n",
            "resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.288841\n",
            "resetting env. episode 232.000000, reward total was -20.000000. running mean: -20.285953\n",
            "resetting env. episode 233.000000, reward total was -20.000000. running mean: -20.283093\n",
            "resetting env. episode 234.000000, reward total was -18.000000. running mean: -20.260262\n",
            "resetting env. episode 235.000000, reward total was -20.000000. running mean: -20.257659\n",
            "resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.265083\n",
            "resetting env. episode 237.000000, reward total was -21.000000. running mean: -20.272432\n",
            "resetting env. episode 238.000000, reward total was -21.000000. running mean: -20.279708\n",
            "resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.286911\n",
            "resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.294042\n",
            "resetting env. episode 241.000000, reward total was -20.000000. running mean: -20.291101\n",
            "resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.298190\n",
            "resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.305208\n",
            "resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.312156\n",
            "resetting env. episode 245.000000, reward total was -18.000000. running mean: -20.289035\n",
            "resetting env. episode 246.000000, reward total was -17.000000. running mean: -20.256144\n",
            "resetting env. episode 247.000000, reward total was -19.000000. running mean: -20.243583\n",
            "resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.251147\n",
            "resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.258635\n",
            "resetting env. episode 250.000000, reward total was -20.000000. running mean: -20.256049\n",
            "resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.263489\n",
            "resetting env. episode 252.000000, reward total was -20.000000. running mean: -20.260854\n",
            "resetting env. episode 253.000000, reward total was -19.000000. running mean: -20.248245\n",
            "resetting env. episode 254.000000, reward total was -21.000000. running mean: -20.255763\n",
            "resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.263205\n",
            "resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.270573\n",
            "resetting env. episode 257.000000, reward total was -19.000000. running mean: -20.257867\n",
            "resetting env. episode 258.000000, reward total was -20.000000. running mean: -20.255289\n",
            "resetting env. episode 259.000000, reward total was -19.000000. running mean: -20.242736\n",
            "resetting env. episode 260.000000, reward total was -20.000000. running mean: -20.240308\n",
            "resetting env. episode 261.000000, reward total was -21.000000. running mean: -20.247905\n",
            "resetting env. episode 262.000000, reward total was -20.000000. running mean: -20.245426\n",
            "resetting env. episode 263.000000, reward total was -20.000000. running mean: -20.242972\n",
            "resetting env. episode 264.000000, reward total was -18.000000. running mean: -20.220542\n",
            "resetting env. episode 265.000000, reward total was -19.000000. running mean: -20.208337\n",
            "resetting env. episode 266.000000, reward total was -19.000000. running mean: -20.196253\n",
            "resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.204291\n",
            "resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.212248\n",
            "resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.220126\n",
            "resetting env. episode 270.000000, reward total was -21.000000. running mean: -20.227924\n",
            "resetting env. episode 271.000000, reward total was -19.000000. running mean: -20.215645\n",
            "resetting env. episode 272.000000, reward total was -21.000000. running mean: -20.223489\n",
            "resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.231254\n",
            "resetting env. episode 274.000000, reward total was -20.000000. running mean: -20.228941\n",
            "resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.236652\n",
            "resetting env. episode 276.000000, reward total was -19.000000. running mean: -20.224285\n",
            "resetting env. episode 277.000000, reward total was -19.000000. running mean: -20.212042\n",
            "resetting env. episode 278.000000, reward total was -20.000000. running mean: -20.209922\n",
            "resetting env. episode 279.000000, reward total was -19.000000. running mean: -20.197823\n",
            "resetting env. episode 280.000000, reward total was -20.000000. running mean: -20.195845\n",
            "resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.203886\n",
            "resetting env. episode 282.000000, reward total was -19.000000. running mean: -20.191847\n",
            "resetting env. episode 283.000000, reward total was -20.000000. running mean: -20.189929\n",
            "resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.198029\n",
            "resetting env. episode 285.000000, reward total was -19.000000. running mean: -20.186049\n",
            "resetting env. episode 286.000000, reward total was -20.000000. running mean: -20.184189\n",
            "resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.192347\n",
            "resetting env. episode 288.000000, reward total was -19.000000. running mean: -20.180423\n",
            "resetting env. episode 289.000000, reward total was -20.000000. running mean: -20.178619\n",
            "resetting env. episode 290.000000, reward total was -21.000000. running mean: -20.186833\n",
            "resetting env. episode 291.000000, reward total was -21.000000. running mean: -20.194965\n",
            "resetting env. episode 292.000000, reward total was -21.000000. running mean: -20.203015\n",
            "resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.210985\n",
            "resetting env. episode 294.000000, reward total was -20.000000. running mean: -20.208875\n",
            "resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.216786\n",
            "resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.224618\n",
            "resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.232372\n",
            "resetting env. episode 298.000000, reward total was -20.000000. running mean: -20.230048\n",
            "resetting env. episode 299.000000, reward total was -21.000000. running mean: -20.237748\n",
            "resetting env. episode 300.000000, reward total was -20.000000. running mean: -20.235370\n",
            "resetting env. episode 301.000000, reward total was -21.000000. running mean: -20.243017\n",
            "resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.250587\n",
            "resetting env. episode 303.000000, reward total was -20.000000. running mean: -20.248081\n",
            "resetting env. episode 304.000000, reward total was -19.000000. running mean: -20.235600\n",
            "resetting env. episode 305.000000, reward total was -17.000000. running mean: -20.203244\n",
            "resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.211211\n",
            "resetting env. episode 307.000000, reward total was -19.000000. running mean: -20.199099\n",
            "resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.207108\n",
            "resetting env. episode 309.000000, reward total was -19.000000. running mean: -20.195037\n",
            "resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.203087\n",
            "resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.211056\n",
            "resetting env. episode 312.000000, reward total was -19.000000. running mean: -20.198945\n",
            "resetting env. episode 313.000000, reward total was -20.000000. running mean: -20.196956\n",
            "resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.204986\n",
            "resetting env. episode 315.000000, reward total was -20.000000. running mean: -20.202937\n",
            "resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.210907\n",
            "resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.218798\n",
            "resetting env. episode 318.000000, reward total was -20.000000. running mean: -20.216610\n",
            "resetting env. episode 319.000000, reward total was -20.000000. running mean: -20.214444\n",
            "resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.222300\n",
            "resetting env. episode 321.000000, reward total was -21.000000. running mean: -20.230077\n",
            "resetting env. episode 322.000000, reward total was -20.000000. running mean: -20.227776\n",
            "resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.235498\n",
            "resetting env. episode 324.000000, reward total was -19.000000. running mean: -20.223143\n",
            "resetting env. episode 325.000000, reward total was -21.000000. running mean: -20.230912\n",
            "resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.238603\n",
            "resetting env. episode 327.000000, reward total was -20.000000. running mean: -20.236217\n",
            "resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.243854\n",
            "resetting env. episode 329.000000, reward total was -17.000000. running mean: -20.211416\n",
            "resetting env. episode 330.000000, reward total was -20.000000. running mean: -20.209302\n",
            "resetting env. episode 331.000000, reward total was -20.000000. running mean: -20.207209\n",
            "resetting env. episode 332.000000, reward total was -20.000000. running mean: -20.205137\n",
            "resetting env. episode 333.000000, reward total was -21.000000. running mean: -20.213085\n",
            "resetting env. episode 334.000000, reward total was -20.000000. running mean: -20.210954\n",
            "resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.218845\n",
            "resetting env. episode 336.000000, reward total was -20.000000. running mean: -20.216656\n",
            "resetting env. episode 337.000000, reward total was -19.000000. running mean: -20.204490\n",
            "resetting env. episode 338.000000, reward total was -20.000000. running mean: -20.202445\n",
            "resetting env. episode 339.000000, reward total was -21.000000. running mean: -20.210420\n",
            "resetting env. episode 340.000000, reward total was -20.000000. running mean: -20.208316\n",
            "resetting env. episode 341.000000, reward total was -18.000000. running mean: -20.186233\n",
            "resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.194371\n",
            "resetting env. episode 343.000000, reward total was -19.000000. running mean: -20.182427\n",
            "resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.190603\n",
            "resetting env. episode 345.000000, reward total was -19.000000. running mean: -20.178697\n",
            "resetting env. episode 346.000000, reward total was -20.000000. running mean: -20.176910\n",
            "resetting env. episode 347.000000, reward total was -21.000000. running mean: -20.185141\n",
            "resetting env. episode 348.000000, reward total was -19.000000. running mean: -20.173289\n",
            "resetting env. episode 349.000000, reward total was -20.000000. running mean: -20.171556\n",
            "resetting env. episode 350.000000, reward total was -20.000000. running mean: -20.169841\n",
            "resetting env. episode 351.000000, reward total was -20.000000. running mean: -20.168142\n",
            "resetting env. episode 352.000000, reward total was -20.000000. running mean: -20.166461\n",
            "resetting env. episode 353.000000, reward total was -20.000000. running mean: -20.164796\n",
            "resetting env. episode 354.000000, reward total was -19.000000. running mean: -20.153148\n",
            "resetting env. episode 355.000000, reward total was -20.000000. running mean: -20.151617\n",
            "resetting env. episode 356.000000, reward total was -20.000000. running mean: -20.150101\n",
            "resetting env. episode 357.000000, reward total was -19.000000. running mean: -20.138600\n",
            "resetting env. episode 358.000000, reward total was -18.000000. running mean: -20.117214\n",
            "resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.126042\n",
            "resetting env. episode 360.000000, reward total was -17.000000. running mean: -20.094781\n",
            "resetting env. episode 361.000000, reward total was -20.000000. running mean: -20.093833\n",
            "resetting env. episode 362.000000, reward total was -20.000000. running mean: -20.092895\n",
            "resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.101966\n",
            "resetting env. episode 364.000000, reward total was -21.000000. running mean: -20.110946\n",
            "resetting env. episode 365.000000, reward total was -21.000000. running mean: -20.119837\n",
            "resetting env. episode 366.000000, reward total was -20.000000. running mean: -20.118639\n",
            "resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.127452\n",
            "resetting env. episode 368.000000, reward total was -19.000000. running mean: -20.116178\n",
            "resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.125016\n",
            "resetting env. episode 370.000000, reward total was -21.000000. running mean: -20.133766\n",
            "resetting env. episode 371.000000, reward total was -20.000000. running mean: -20.132428\n",
            "resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.141104\n",
            "resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.149693\n",
            "resetting env. episode 374.000000, reward total was -18.000000. running mean: -20.128196\n",
            "resetting env. episode 375.000000, reward total was -20.000000. running mean: -20.126914\n",
            "resetting env. episode 376.000000, reward total was -20.000000. running mean: -20.125645\n",
            "resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.134388\n",
            "resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.143044\n",
            "resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.151614\n",
            "resetting env. episode 380.000000, reward total was -21.000000. running mean: -20.160098\n",
            "resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.168497\n",
            "resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.176812\n",
            "resetting env. episode 383.000000, reward total was -20.000000. running mean: -20.175044\n",
            "resetting env. episode 384.000000, reward total was -20.000000. running mean: -20.173293\n",
            "resetting env. episode 385.000000, reward total was -20.000000. running mean: -20.171560\n",
            "resetting env. episode 386.000000, reward total was -20.000000. running mean: -20.169845\n",
            "resetting env. episode 387.000000, reward total was -20.000000. running mean: -20.168146\n",
            "resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.176465\n",
            "resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.184700\n",
            "resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.192853\n",
            "resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.200925\n",
            "resetting env. episode 392.000000, reward total was -21.000000. running mean: -20.208915\n",
            "resetting env. episode 393.000000, reward total was -19.000000. running mean: -20.196826\n",
            "resetting env. episode 394.000000, reward total was -21.000000. running mean: -20.204858\n",
            "resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.212809\n",
            "resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.220681\n",
            "resetting env. episode 397.000000, reward total was -20.000000. running mean: -20.218475\n",
            "resetting env. episode 398.000000, reward total was -20.000000. running mean: -20.216290\n",
            "resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.224127\n",
            "resetting env. episode 400.000000, reward total was -20.000000. running mean: -20.221886\n",
            "resetting env. episode 401.000000, reward total was -20.000000. running mean: -20.219667\n",
            "resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.227470\n",
            "resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.235195\n",
            "resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.242843\n",
            "resetting env. episode 405.000000, reward total was -20.000000. running mean: -20.240415\n",
            "resetting env. episode 406.000000, reward total was -20.000000. running mean: -20.238011\n",
            "resetting env. episode 407.000000, reward total was -20.000000. running mean: -20.235631\n",
            "resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.243274\n",
            "resetting env. episode 409.000000, reward total was -21.000000. running mean: -20.250842\n",
            "resetting env. episode 410.000000, reward total was -20.000000. running mean: -20.248333\n",
            "resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.255850\n",
            "resetting env. episode 412.000000, reward total was -19.000000. running mean: -20.243291\n",
            "resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.250859\n",
            "resetting env. episode 414.000000, reward total was -21.000000. running mean: -20.258350\n",
            "resetting env. episode 415.000000, reward total was -21.000000. running mean: -20.265766\n",
            "resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.273109\n",
            "resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.280378\n",
            "resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.287574\n",
            "resetting env. episode 419.000000, reward total was -20.000000. running mean: -20.284698\n",
            "resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.291851\n",
            "resetting env. episode 421.000000, reward total was -20.000000. running mean: -20.288933\n",
            "resetting env. episode 422.000000, reward total was -17.000000. running mean: -20.256043\n",
            "resetting env. episode 423.000000, reward total was -19.000000. running mean: -20.243483\n",
            "resetting env. episode 424.000000, reward total was -20.000000. running mean: -20.241048\n",
            "resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.248638\n",
            "resetting env. episode 426.000000, reward total was -21.000000. running mean: -20.256151\n",
            "resetting env. episode 427.000000, reward total was -20.000000. running mean: -20.253590\n",
            "resetting env. episode 428.000000, reward total was -20.000000. running mean: -20.251054\n",
            "resetting env. episode 429.000000, reward total was -18.000000. running mean: -20.228543\n",
            "resetting env. episode 430.000000, reward total was -21.000000. running mean: -20.236258\n",
            "resetting env. episode 431.000000, reward total was -20.000000. running mean: -20.233895\n",
            "resetting env. episode 432.000000, reward total was -21.000000. running mean: -20.241556\n",
            "resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.249141\n",
            "resetting env. episode 434.000000, reward total was -19.000000. running mean: -20.236649\n",
            "resetting env. episode 435.000000, reward total was -20.000000. running mean: -20.234283\n",
            "resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.241940\n",
            "resetting env. episode 437.000000, reward total was -20.000000. running mean: -20.239521\n",
            "resetting env. episode 438.000000, reward total was -21.000000. running mean: -20.247125\n",
            "resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.254654\n",
            "resetting env. episode 440.000000, reward total was -21.000000. running mean: -20.262108\n",
            "resetting env. episode 441.000000, reward total was -19.000000. running mean: -20.249487\n",
            "resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.256992\n",
            "resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.264422\n",
            "resetting env. episode 444.000000, reward total was -19.000000. running mean: -20.251778\n",
            "resetting env. episode 445.000000, reward total was -19.000000. running mean: -20.239260\n",
            "resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.246867\n",
            "resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.254399\n",
            "resetting env. episode 448.000000, reward total was -20.000000. running mean: -20.251855\n",
            "resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.259336\n",
            "resetting env. episode 450.000000, reward total was -20.000000. running mean: -20.256743\n",
            "resetting env. episode 451.000000, reward total was -18.000000. running mean: -20.234175\n",
            "resetting env. episode 452.000000, reward total was -21.000000. running mean: -20.241833\n",
            "resetting env. episode 453.000000, reward total was -20.000000. running mean: -20.239415\n",
            "resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.247021\n",
            "resetting env. episode 455.000000, reward total was -21.000000. running mean: -20.254551\n",
            "resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.262005\n",
            "resetting env. episode 457.000000, reward total was -21.000000. running mean: -20.269385\n",
            "resetting env. episode 458.000000, reward total was -21.000000. running mean: -20.276691\n",
            "resetting env. episode 459.000000, reward total was -20.000000. running mean: -20.273924\n",
            "resetting env. episode 460.000000, reward total was -20.000000. running mean: -20.271185\n",
            "resetting env. episode 461.000000, reward total was -21.000000. running mean: -20.278473\n",
            "resetting env. episode 462.000000, reward total was -20.000000. running mean: -20.275689\n",
            "resetting env. episode 463.000000, reward total was -20.000000. running mean: -20.272932\n",
            "resetting env. episode 464.000000, reward total was -20.000000. running mean: -20.270202\n",
            "resetting env. episode 465.000000, reward total was -20.000000. running mean: -20.267500\n",
            "resetting env. episode 466.000000, reward total was -20.000000. running mean: -20.264825\n",
            "resetting env. episode 467.000000, reward total was -20.000000. running mean: -20.262177\n",
            "resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.269555\n",
            "resetting env. episode 469.000000, reward total was -18.000000. running mean: -20.246860\n",
            "resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.254391\n",
            "resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.261847\n",
            "resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.269229\n",
            "resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.276537\n",
            "resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.283771\n",
            "resetting env. episode 475.000000, reward total was -20.000000. running mean: -20.280933\n",
            "resetting env. episode 476.000000, reward total was -19.000000. running mean: -20.268124\n",
            "resetting env. episode 477.000000, reward total was -20.000000. running mean: -20.265443\n",
            "resetting env. episode 478.000000, reward total was -20.000000. running mean: -20.262788\n",
            "resetting env. episode 479.000000, reward total was -20.000000. running mean: -20.260161\n",
            "resetting env. episode 480.000000, reward total was -21.000000. running mean: -20.267559\n",
            "resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.274883\n",
            "resetting env. episode 482.000000, reward total was -20.000000. running mean: -20.272135\n",
            "resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.279413\n",
            "resetting env. episode 484.000000, reward total was -21.000000. running mean: -20.286619\n",
            "resetting env. episode 485.000000, reward total was -20.000000. running mean: -20.283753\n",
            "resetting env. episode 486.000000, reward total was -19.000000. running mean: -20.270915\n",
            "resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.278206\n",
            "resetting env. episode 488.000000, reward total was -20.000000. running mean: -20.275424\n",
            "resetting env. episode 489.000000, reward total was -20.000000. running mean: -20.272670\n",
            "resetting env. episode 490.000000, reward total was -20.000000. running mean: -20.269943\n",
            "resetting env. episode 491.000000, reward total was -20.000000. running mean: -20.267244\n",
            "resetting env. episode 492.000000, reward total was -21.000000. running mean: -20.274571\n",
            "resetting env. episode 493.000000, reward total was -20.000000. running mean: -20.271826\n",
            "resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.279107\n",
            "resetting env. episode 495.000000, reward total was -18.000000. running mean: -20.256316\n",
            "resetting env. episode 496.000000, reward total was -19.000000. running mean: -20.243753\n",
            "resetting env. episode 497.000000, reward total was -21.000000. running mean: -20.251316\n",
            "resetting env. episode 498.000000, reward total was -20.000000. running mean: -20.248802\n",
            "resetting env. episode 499.000000, reward total was -20.000000. running mean: -20.246314\n",
            "resetting env. episode 500.000000, reward total was -19.000000. running mean: -20.233851\n",
            "CPU times: user 36min 11s, sys: 11min 18s, total: 47min 29s\n",
            "Wall time: 24min 15s\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8fheN9DRlWXQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "c6e35670-ca72-4607-a121-7672c2ee8d28"
      },
      "cell_type": "code",
      "source": [
        "play_game(env, model)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9AxOcQhIsKow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcdb411c-591d-4ae2-b568-595b09c91061"
      },
      "cell_type": "code",
      "source": [
        "%time hist3 = train_model(env, model, total_episodes=1500)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resetting env. episode 1.000000, reward total was -20.000000. running mean: -20.000000\n",
            "resetting env. episode 2.000000, reward total was -20.000000. running mean: -20.000000\n",
            "resetting env. episode 3.000000, reward total was -20.000000. running mean: -20.000000\n",
            "resetting env. episode 4.000000, reward total was -21.000000. running mean: -20.010000\n",
            "resetting env. episode 5.000000, reward total was -20.000000. running mean: -20.009900\n",
            "resetting env. episode 6.000000, reward total was -20.000000. running mean: -20.009801\n",
            "resetting env. episode 7.000000, reward total was -21.000000. running mean: -20.019703\n",
            "resetting env. episode 8.000000, reward total was -19.000000. running mean: -20.009506\n",
            "resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.019411\n",
            "resetting env. episode 10.000000, reward total was -20.000000. running mean: -20.019217\n",
            "resetting env. episode 11.000000, reward total was -20.000000. running mean: -20.019025\n",
            "resetting env. episode 12.000000, reward total was -20.000000. running mean: -20.018834\n",
            "resetting env. episode 13.000000, reward total was -20.000000. running mean: -20.018646\n",
            "resetting env. episode 14.000000, reward total was -18.000000. running mean: -19.998460\n",
            "resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.008475\n",
            "resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.018390\n",
            "resetting env. episode 17.000000, reward total was -20.000000. running mean: -20.018206\n",
            "resetting env. episode 18.000000, reward total was -20.000000. running mean: -20.018024\n",
            "resetting env. episode 19.000000, reward total was -20.000000. running mean: -20.017844\n",
            "resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.027666\n",
            "resetting env. episode 21.000000, reward total was -20.000000. running mean: -20.027389\n",
            "resetting env. episode 22.000000, reward total was -19.000000. running mean: -20.017115\n",
            "resetting env. episode 23.000000, reward total was -21.000000. running mean: -20.026944\n",
            "resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.036674\n",
            "resetting env. episode 25.000000, reward total was -19.000000. running mean: -20.026308\n",
            "resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.036045\n",
            "resetting env. episode 27.000000, reward total was -21.000000. running mean: -20.045684\n",
            "resetting env. episode 28.000000, reward total was -18.000000. running mean: -20.025227\n",
            "resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.034975\n",
            "resetting env. episode 30.000000, reward total was -20.000000. running mean: -20.034625\n",
            "resetting env. episode 31.000000, reward total was -21.000000. running mean: -20.044279\n",
            "resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.053836\n",
            "resetting env. episode 33.000000, reward total was -19.000000. running mean: -20.043298\n",
            "resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.052865\n",
            "resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.062336\n",
            "resetting env. episode 36.000000, reward total was -20.000000. running mean: -20.061713\n",
            "resetting env. episode 37.000000, reward total was -19.000000. running mean: -20.051096\n",
            "resetting env. episode 38.000000, reward total was -20.000000. running mean: -20.050585\n",
            "resetting env. episode 39.000000, reward total was -20.000000. running mean: -20.050079\n",
            "resetting env. episode 40.000000, reward total was -20.000000. running mean: -20.049578\n",
            "resetting env. episode 41.000000, reward total was -20.000000. running mean: -20.049082\n",
            "resetting env. episode 42.000000, reward total was -21.000000. running mean: -20.058592\n",
            "resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.068006\n",
            "resetting env. episode 44.000000, reward total was -21.000000. running mean: -20.077326\n",
            "resetting env. episode 45.000000, reward total was -20.000000. running mean: -20.076552\n",
            "resetting env. episode 46.000000, reward total was -19.000000. running mean: -20.065787\n",
            "resetting env. episode 47.000000, reward total was -20.000000. running mean: -20.065129\n",
            "resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.074478\n",
            "resetting env. episode 49.000000, reward total was -19.000000. running mean: -20.063733\n",
            "resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.073096\n",
            "resetting env. episode 51.000000, reward total was -20.000000. running mean: -20.072365\n",
            "resetting env. episode 52.000000, reward total was -21.000000. running mean: -20.081641\n",
            "resetting env. episode 53.000000, reward total was -20.000000. running mean: -20.080825\n",
            "resetting env. episode 54.000000, reward total was -21.000000. running mean: -20.090016\n",
            "resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.099116\n",
            "resetting env. episode 56.000000, reward total was -20.000000. running mean: -20.098125\n",
            "resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.107144\n",
            "resetting env. episode 58.000000, reward total was -20.000000. running mean: -20.106072\n",
            "resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.115012\n",
            "resetting env. episode 60.000000, reward total was -17.000000. running mean: -20.083861\n",
            "resetting env. episode 61.000000, reward total was -20.000000. running mean: -20.083023\n",
            "resetting env. episode 62.000000, reward total was -20.000000. running mean: -20.082193\n",
            "resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.091371\n",
            "resetting env. episode 64.000000, reward total was -20.000000. running mean: -20.090457\n",
            "resetting env. episode 65.000000, reward total was -20.000000. running mean: -20.089552\n",
            "resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.098657\n",
            "resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.107670\n",
            "resetting env. episode 68.000000, reward total was -21.000000. running mean: -20.116594\n",
            "resetting env. episode 69.000000, reward total was -19.000000. running mean: -20.105428\n",
            "resetting env. episode 70.000000, reward total was -16.000000. running mean: -20.064373\n",
            "resetting env. episode 71.000000, reward total was -20.000000. running mean: -20.063730\n",
            "resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.073092\n",
            "resetting env. episode 73.000000, reward total was -21.000000. running mean: -20.082361\n",
            "resetting env. episode 74.000000, reward total was -19.000000. running mean: -20.071538\n",
            "resetting env. episode 75.000000, reward total was -18.000000. running mean: -20.050822\n",
            "resetting env. episode 76.000000, reward total was -19.000000. running mean: -20.040314\n",
            "resetting env. episode 77.000000, reward total was -20.000000. running mean: -20.039911\n",
            "resetting env. episode 78.000000, reward total was -20.000000. running mean: -20.039512\n",
            "resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.049117\n",
            "resetting env. episode 80.000000, reward total was -20.000000. running mean: -20.048626\n",
            "resetting env. episode 81.000000, reward total was -19.000000. running mean: -20.038139\n",
            "resetting env. episode 82.000000, reward total was -20.000000. running mean: -20.037758\n",
            "resetting env. episode 83.000000, reward total was -20.000000. running mean: -20.037380\n",
            "resetting env. episode 84.000000, reward total was -20.000000. running mean: -20.037007\n",
            "resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.046637\n",
            "resetting env. episode 86.000000, reward total was -20.000000. running mean: -20.046170\n",
            "resetting env. episode 87.000000, reward total was -21.000000. running mean: -20.055709\n",
            "resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.065151\n",
            "resetting env. episode 89.000000, reward total was -20.000000. running mean: -20.064500\n",
            "resetting env. episode 90.000000, reward total was -20.000000. running mean: -20.063855\n",
            "resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.073216\n",
            "resetting env. episode 92.000000, reward total was -20.000000. running mean: -20.072484\n",
            "resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.081759\n",
            "resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.090942\n",
            "resetting env. episode 95.000000, reward total was -20.000000. running mean: -20.090032\n",
            "resetting env. episode 96.000000, reward total was -21.000000. running mean: -20.099132\n",
            "resetting env. episode 97.000000, reward total was -19.000000. running mean: -20.088141\n",
            "resetting env. episode 98.000000, reward total was -21.000000. running mean: -20.097259\n",
            "resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.106287\n",
            "resetting env. episode 100.000000, reward total was -18.000000. running mean: -20.085224\n",
            "resetting env. episode 101.000000, reward total was -21.000000. running mean: -20.094372\n",
            "resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.103428\n",
            "resetting env. episode 103.000000, reward total was -20.000000. running mean: -20.102394\n",
            "resetting env. episode 104.000000, reward total was -20.000000. running mean: -20.101370\n",
            "resetting env. episode 105.000000, reward total was -20.000000. running mean: -20.100356\n",
            "resetting env. episode 106.000000, reward total was -20.000000. running mean: -20.099352\n",
            "resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.108359\n",
            "resetting env. episode 108.000000, reward total was -20.000000. running mean: -20.107275\n",
            "resetting env. episode 109.000000, reward total was -20.000000. running mean: -20.106203\n",
            "resetting env. episode 110.000000, reward total was -19.000000. running mean: -20.095141\n",
            "resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.104189\n",
            "resetting env. episode 112.000000, reward total was -21.000000. running mean: -20.113147\n",
            "resetting env. episode 113.000000, reward total was -19.000000. running mean: -20.102016\n",
            "resetting env. episode 114.000000, reward total was -20.000000. running mean: -20.100996\n",
            "resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.109986\n",
            "resetting env. episode 116.000000, reward total was -20.000000. running mean: -20.108886\n",
            "resetting env. episode 117.000000, reward total was -20.000000. running mean: -20.107797\n",
            "resetting env. episode 118.000000, reward total was -20.000000. running mean: -20.106719\n",
            "resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.115652\n",
            "resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.124495\n",
            "resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.133250\n",
            "resetting env. episode 122.000000, reward total was -20.000000. running mean: -20.131918\n",
            "resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.140599\n",
            "resetting env. episode 124.000000, reward total was -20.000000. running mean: -20.139193\n",
            "resetting env. episode 125.000000, reward total was -20.000000. running mean: -20.137801\n",
            "resetting env. episode 126.000000, reward total was -18.000000. running mean: -20.116423\n",
            "resetting env. episode 127.000000, reward total was -20.000000. running mean: -20.115258\n",
            "resetting env. episode 128.000000, reward total was -19.000000. running mean: -20.104106\n",
            "resetting env. episode 129.000000, reward total was -20.000000. running mean: -20.103065\n",
            "resetting env. episode 130.000000, reward total was -21.000000. running mean: -20.112034\n",
            "resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.120914\n",
            "resetting env. episode 132.000000, reward total was -18.000000. running mean: -20.099705\n",
            "resetting env. episode 133.000000, reward total was -19.000000. running mean: -20.088708\n",
            "resetting env. episode 134.000000, reward total was -19.000000. running mean: -20.077821\n",
            "resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.087042\n",
            "resetting env. episode 136.000000, reward total was -20.000000. running mean: -20.086172\n",
            "resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.095310\n",
            "resetting env. episode 138.000000, reward total was -20.000000. running mean: -20.094357\n",
            "resetting env. episode 139.000000, reward total was -18.000000. running mean: -20.073414\n",
            "resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.082679\n",
            "resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.091853\n",
            "resetting env. episode 142.000000, reward total was -18.000000. running mean: -20.070934\n",
            "resetting env. episode 143.000000, reward total was -20.000000. running mean: -20.070225\n",
            "resetting env. episode 144.000000, reward total was -19.000000. running mean: -20.059523\n",
            "resetting env. episode 145.000000, reward total was -21.000000. running mean: -20.068927\n",
            "resetting env. episode 146.000000, reward total was -21.000000. running mean: -20.078238\n",
            "resetting env. episode 147.000000, reward total was -19.000000. running mean: -20.067456\n",
            "resetting env. episode 148.000000, reward total was -20.000000. running mean: -20.066781\n",
            "resetting env. episode 149.000000, reward total was -18.000000. running mean: -20.046113\n",
            "resetting env. episode 150.000000, reward total was -20.000000. running mean: -20.045652\n",
            "resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.055196\n",
            "resetting env. episode 152.000000, reward total was -20.000000. running mean: -20.054644\n",
            "resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.064097\n",
            "resetting env. episode 154.000000, reward total was -20.000000. running mean: -20.063456\n",
            "resetting env. episode 155.000000, reward total was -20.000000. running mean: -20.062822\n",
            "resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.072193\n",
            "resetting env. episode 157.000000, reward total was -20.000000. running mean: -20.071472\n",
            "resetting env. episode 158.000000, reward total was -21.000000. running mean: -20.080757\n",
            "resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.089949\n",
            "resetting env. episode 160.000000, reward total was -21.000000. running mean: -20.099050\n",
            "resetting env. episode 161.000000, reward total was -20.000000. running mean: -20.098059\n",
            "resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.107079\n",
            "resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.116008\n",
            "resetting env. episode 164.000000, reward total was -21.000000. running mean: -20.124848\n",
            "resetting env. episode 165.000000, reward total was -20.000000. running mean: -20.123599\n",
            "resetting env. episode 166.000000, reward total was -21.000000. running mean: -20.132363\n",
            "resetting env. episode 167.000000, reward total was -21.000000. running mean: -20.141040\n",
            "resetting env. episode 168.000000, reward total was -20.000000. running mean: -20.139629\n",
            "resetting env. episode 169.000000, reward total was -18.000000. running mean: -20.118233\n",
            "resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.127051\n",
            "resetting env. episode 171.000000, reward total was -17.000000. running mean: -20.095780\n",
            "resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.104822\n",
            "resetting env. episode 173.000000, reward total was -20.000000. running mean: -20.103774\n",
            "resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.112736\n",
            "resetting env. episode 175.000000, reward total was -21.000000. running mean: -20.121609\n",
            "resetting env. episode 176.000000, reward total was -19.000000. running mean: -20.110393\n",
            "resetting env. episode 177.000000, reward total was -19.000000. running mean: -20.099289\n",
            "resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.108296\n",
            "resetting env. episode 179.000000, reward total was -20.000000. running mean: -20.107213\n",
            "resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.116141\n",
            "resetting env. episode 181.000000, reward total was -21.000000. running mean: -20.124980\n",
            "resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.133730\n",
            "resetting env. episode 183.000000, reward total was -21.000000. running mean: -20.142393\n",
            "resetting env. episode 184.000000, reward total was -20.000000. running mean: -20.140969\n",
            "resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.149559\n",
            "resetting env. episode 186.000000, reward total was -20.000000. running mean: -20.148063\n",
            "resetting env. episode 187.000000, reward total was -21.000000. running mean: -20.156583\n",
            "resetting env. episode 188.000000, reward total was -20.000000. running mean: -20.155017\n",
            "resetting env. episode 189.000000, reward total was -19.000000. running mean: -20.143467\n",
            "resetting env. episode 190.000000, reward total was -20.000000. running mean: -20.142032\n",
            "resetting env. episode 191.000000, reward total was -19.000000. running mean: -20.130612\n",
            "resetting env. episode 192.000000, reward total was -19.000000. running mean: -20.119306\n",
            "resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.128113\n",
            "resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.136831\n",
            "resetting env. episode 195.000000, reward total was -20.000000. running mean: -20.135463\n",
            "resetting env. episode 196.000000, reward total was -20.000000. running mean: -20.134108\n",
            "resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.142767\n",
            "resetting env. episode 198.000000, reward total was -20.000000. running mean: -20.141340\n",
            "resetting env. episode 199.000000, reward total was -19.000000. running mean: -20.129926\n",
            "resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.138627\n",
            "resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.147241\n",
            "resetting env. episode 202.000000, reward total was -20.000000. running mean: -20.145768\n",
            "resetting env. episode 203.000000, reward total was -21.000000. running mean: -20.154311\n",
            "resetting env. episode 204.000000, reward total was -19.000000. running mean: -20.142768\n",
            "resetting env. episode 205.000000, reward total was -21.000000. running mean: -20.151340\n",
            "resetting env. episode 206.000000, reward total was -20.000000. running mean: -20.149827\n",
            "resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.158328\n",
            "resetting env. episode 208.000000, reward total was -19.000000. running mean: -20.146745\n",
            "resetting env. episode 209.000000, reward total was -20.000000. running mean: -20.145278\n",
            "resetting env. episode 210.000000, reward total was -20.000000. running mean: -20.143825\n",
            "resetting env. episode 211.000000, reward total was -19.000000. running mean: -20.132386\n",
            "resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.141063\n",
            "resetting env. episode 213.000000, reward total was -20.000000. running mean: -20.139652\n",
            "resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.148255\n",
            "resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.156773\n",
            "resetting env. episode 216.000000, reward total was -20.000000. running mean: -20.155205\n",
            "resetting env. episode 217.000000, reward total was -20.000000. running mean: -20.153653\n",
            "resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.162117\n",
            "resetting env. episode 219.000000, reward total was -20.000000. running mean: -20.160495\n",
            "resetting env. episode 220.000000, reward total was -20.000000. running mean: -20.158890\n",
            "resetting env. episode 221.000000, reward total was -20.000000. running mean: -20.157302\n",
            "resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.165729\n",
            "resetting env. episode 223.000000, reward total was -20.000000. running mean: -20.164071\n",
            "resetting env. episode 224.000000, reward total was -20.000000. running mean: -20.162431\n",
            "resetting env. episode 225.000000, reward total was -20.000000. running mean: -20.160806\n",
            "resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.169198\n",
            "resetting env. episode 227.000000, reward total was -19.000000. running mean: -20.157506\n",
            "resetting env. episode 228.000000, reward total was -20.000000. running mean: -20.155931\n",
            "resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.164372\n",
            "resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.172728\n",
            "resetting env. episode 231.000000, reward total was -20.000000. running mean: -20.171001\n",
            "resetting env. episode 232.000000, reward total was -19.000000. running mean: -20.159291\n",
            "resetting env. episode 233.000000, reward total was -21.000000. running mean: -20.167698\n",
            "resetting env. episode 234.000000, reward total was -19.000000. running mean: -20.156021\n",
            "resetting env. episode 235.000000, reward total was -20.000000. running mean: -20.154461\n",
            "resetting env. episode 236.000000, reward total was -20.000000. running mean: -20.152916\n",
            "resetting env. episode 237.000000, reward total was -18.000000. running mean: -20.131387\n",
            "resetting env. episode 238.000000, reward total was -18.000000. running mean: -20.110073\n",
            "resetting env. episode 239.000000, reward total was -20.000000. running mean: -20.108972\n",
            "resetting env. episode 240.000000, reward total was -20.000000. running mean: -20.107883\n",
            "resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.116804\n",
            "resetting env. episode 242.000000, reward total was -19.000000. running mean: -20.105636\n",
            "resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.114579\n",
            "resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.123434\n",
            "resetting env. episode 245.000000, reward total was -21.000000. running mean: -20.132199\n",
            "resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.140877\n",
            "resetting env. episode 247.000000, reward total was -20.000000. running mean: -20.139469\n",
            "resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.148074\n",
            "resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.156593\n",
            "resetting env. episode 250.000000, reward total was -20.000000. running mean: -20.155027\n",
            "resetting env. episode 251.000000, reward total was -20.000000. running mean: -20.153477\n",
            "resetting env. episode 252.000000, reward total was -20.000000. running mean: -20.151942\n",
            "resetting env. episode 253.000000, reward total was -20.000000. running mean: -20.150423\n",
            "resetting env. episode 254.000000, reward total was -19.000000. running mean: -20.138918\n",
            "resetting env. episode 255.000000, reward total was -20.000000. running mean: -20.137529\n",
            "resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.146154\n",
            "resetting env. episode 257.000000, reward total was -20.000000. running mean: -20.144692\n",
            "resetting env. episode 258.000000, reward total was -20.000000. running mean: -20.143246\n",
            "resetting env. episode 259.000000, reward total was -19.000000. running mean: -20.131813\n",
            "resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.140495\n",
            "resetting env. episode 261.000000, reward total was -20.000000. running mean: -20.139090\n",
            "resetting env. episode 262.000000, reward total was -21.000000. running mean: -20.147699\n",
            "resetting env. episode 263.000000, reward total was -19.000000. running mean: -20.136222\n",
            "resetting env. episode 264.000000, reward total was -20.000000. running mean: -20.134860\n",
            "resetting env. episode 265.000000, reward total was -20.000000. running mean: -20.133511\n",
            "resetting env. episode 266.000000, reward total was -21.000000. running mean: -20.142176\n",
            "resetting env. episode 267.000000, reward total was -20.000000. running mean: -20.140754\n",
            "resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.149347\n",
            "resetting env. episode 269.000000, reward total was -20.000000. running mean: -20.147853\n",
            "resetting env. episode 270.000000, reward total was -19.000000. running mean: -20.136375\n",
            "resetting env. episode 271.000000, reward total was -19.000000. running mean: -20.125011\n",
            "resetting env. episode 272.000000, reward total was -21.000000. running mean: -20.133761\n",
            "resetting env. episode 273.000000, reward total was -18.000000. running mean: -20.112423\n",
            "resetting env. episode 274.000000, reward total was -17.000000. running mean: -20.081299\n",
            "resetting env. episode 275.000000, reward total was -20.000000. running mean: -20.080486\n",
            "resetting env. episode 276.000000, reward total was -18.000000. running mean: -20.059681\n",
            "resetting env. episode 277.000000, reward total was -20.000000. running mean: -20.059085\n",
            "resetting env. episode 278.000000, reward total was -20.000000. running mean: -20.058494\n",
            "resetting env. episode 279.000000, reward total was -20.000000. running mean: -20.057909\n",
            "resetting env. episode 280.000000, reward total was -18.000000. running mean: -20.037330\n",
            "resetting env. episode 281.000000, reward total was -19.000000. running mean: -20.026956\n",
            "resetting env. episode 282.000000, reward total was -20.000000. running mean: -20.026687\n",
            "resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.036420\n",
            "resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.046056\n",
            "resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.055595\n",
            "resetting env. episode 286.000000, reward total was -19.000000. running mean: -20.045039\n",
            "resetting env. episode 287.000000, reward total was -20.000000. running mean: -20.044589\n",
            "resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.054143\n",
            "resetting env. episode 289.000000, reward total was -20.000000. running mean: -20.053601\n",
            "resetting env. episode 290.000000, reward total was -20.000000. running mean: -20.053065\n",
            "resetting env. episode 291.000000, reward total was -21.000000. running mean: -20.062535\n",
            "resetting env. episode 292.000000, reward total was -20.000000. running mean: -20.061909\n",
            "resetting env. episode 293.000000, reward total was -19.000000. running mean: -20.051290\n",
            "resetting env. episode 294.000000, reward total was -20.000000. running mean: -20.050777\n",
            "resetting env. episode 295.000000, reward total was -17.000000. running mean: -20.020270\n",
            "resetting env. episode 296.000000, reward total was -19.000000. running mean: -20.010067\n",
            "resetting env. episode 297.000000, reward total was -19.000000. running mean: -19.999966\n",
            "resetting env. episode 298.000000, reward total was -18.000000. running mean: -19.979967\n",
            "resetting env. episode 299.000000, reward total was -21.000000. running mean: -19.990167\n",
            "resetting env. episode 300.000000, reward total was -21.000000. running mean: -20.000265\n",
            "resetting env. episode 301.000000, reward total was -21.000000. running mean: -20.010263\n",
            "resetting env. episode 302.000000, reward total was -19.000000. running mean: -20.000160\n",
            "resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.010158\n",
            "resetting env. episode 304.000000, reward total was -20.000000. running mean: -20.010057\n",
            "resetting env. episode 305.000000, reward total was -19.000000. running mean: -19.999956\n",
            "resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.009957\n",
            "resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.019857\n",
            "resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.029659\n",
            "resetting env. episode 309.000000, reward total was -18.000000. running mean: -20.009362\n",
            "resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.019268\n",
            "resetting env. episode 311.000000, reward total was -18.000000. running mean: -19.999076\n",
            "resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.009085\n",
            "resetting env. episode 313.000000, reward total was -18.000000. running mean: -19.988994\n",
            "resetting env. episode 314.000000, reward total was -21.000000. running mean: -19.999104\n",
            "resetting env. episode 315.000000, reward total was -18.000000. running mean: -19.979113\n",
            "resetting env. episode 316.000000, reward total was -21.000000. running mean: -19.989322\n",
            "resetting env. episode 317.000000, reward total was -20.000000. running mean: -19.989429\n",
            "resetting env. episode 318.000000, reward total was -21.000000. running mean: -19.999534\n",
            "resetting env. episode 319.000000, reward total was -20.000000. running mean: -19.999539\n",
            "resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.009544\n",
            "resetting env. episode 321.000000, reward total was -20.000000. running mean: -20.009448\n",
            "resetting env. episode 322.000000, reward total was -20.000000. running mean: -20.009354\n",
            "resetting env. episode 323.000000, reward total was -20.000000. running mean: -20.009260\n",
            "resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.019168\n",
            "resetting env. episode 325.000000, reward total was -17.000000. running mean: -19.988976\n",
            "resetting env. episode 326.000000, reward total was -20.000000. running mean: -19.989086\n",
            "resetting env. episode 327.000000, reward total was -20.000000. running mean: -19.989195\n",
            "resetting env. episode 328.000000, reward total was -21.000000. running mean: -19.999303\n",
            "resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.009310\n",
            "resetting env. episode 330.000000, reward total was -20.000000. running mean: -20.009217\n",
            "resetting env. episode 331.000000, reward total was -20.000000. running mean: -20.009125\n",
            "resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.019034\n",
            "resetting env. episode 333.000000, reward total was -19.000000. running mean: -20.008844\n",
            "resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.018755\n",
            "resetting env. episode 335.000000, reward total was -20.000000. running mean: -20.018568\n",
            "resetting env. episode 336.000000, reward total was -18.000000. running mean: -19.998382\n",
            "resetting env. episode 337.000000, reward total was -20.000000. running mean: -19.998398\n",
            "resetting env. episode 338.000000, reward total was -18.000000. running mean: -19.978414\n",
            "resetting env. episode 339.000000, reward total was -20.000000. running mean: -19.978630\n",
            "resetting env. episode 340.000000, reward total was -20.000000. running mean: -19.978844\n",
            "resetting env. episode 341.000000, reward total was -20.000000. running mean: -19.979055\n",
            "resetting env. episode 342.000000, reward total was -21.000000. running mean: -19.989265\n",
            "resetting env. episode 343.000000, reward total was -20.000000. running mean: -19.989372\n",
            "resetting env. episode 344.000000, reward total was -20.000000. running mean: -19.989478\n",
            "resetting env. episode 345.000000, reward total was -21.000000. running mean: -19.999583\n",
            "resetting env. episode 346.000000, reward total was -21.000000. running mean: -20.009588\n",
            "resetting env. episode 347.000000, reward total was -20.000000. running mean: -20.009492\n",
            "resetting env. episode 348.000000, reward total was -18.000000. running mean: -19.989397\n",
            "resetting env. episode 349.000000, reward total was -19.000000. running mean: -19.979503\n",
            "resetting env. episode 350.000000, reward total was -19.000000. running mean: -19.969708\n",
            "resetting env. episode 351.000000, reward total was -21.000000. running mean: -19.980011\n",
            "resetting env. episode 352.000000, reward total was -20.000000. running mean: -19.980211\n",
            "resetting env. episode 353.000000, reward total was -20.000000. running mean: -19.980409\n",
            "resetting env. episode 354.000000, reward total was -19.000000. running mean: -19.970604\n",
            "resetting env. episode 355.000000, reward total was -19.000000. running mean: -19.960898\n",
            "resetting env. episode 356.000000, reward total was -18.000000. running mean: -19.941289\n",
            "resetting env. episode 357.000000, reward total was -19.000000. running mean: -19.931877\n",
            "resetting env. episode 358.000000, reward total was -19.000000. running mean: -19.922558\n",
            "resetting env. episode 359.000000, reward total was -18.000000. running mean: -19.903332\n",
            "resetting env. episode 360.000000, reward total was -21.000000. running mean: -19.914299\n",
            "resetting env. episode 361.000000, reward total was -21.000000. running mean: -19.925156\n",
            "resetting env. episode 362.000000, reward total was -21.000000. running mean: -19.935904\n",
            "resetting env. episode 363.000000, reward total was -20.000000. running mean: -19.936545\n",
            "resetting env. episode 364.000000, reward total was -18.000000. running mean: -19.917180\n",
            "resetting env. episode 365.000000, reward total was -21.000000. running mean: -19.928008\n",
            "resetting env. episode 366.000000, reward total was -20.000000. running mean: -19.928728\n",
            "resetting env. episode 367.000000, reward total was -21.000000. running mean: -19.939441\n",
            "resetting env. episode 368.000000, reward total was -21.000000. running mean: -19.950046\n",
            "resetting env. episode 369.000000, reward total was -21.000000. running mean: -19.960546\n",
            "resetting env. episode 370.000000, reward total was -21.000000. running mean: -19.970940\n",
            "resetting env. episode 371.000000, reward total was -20.000000. running mean: -19.971231\n",
            "resetting env. episode 372.000000, reward total was -19.000000. running mean: -19.961519\n",
            "resetting env. episode 373.000000, reward total was -20.000000. running mean: -19.961903\n",
            "resetting env. episode 374.000000, reward total was -19.000000. running mean: -19.952284\n",
            "resetting env. episode 375.000000, reward total was -21.000000. running mean: -19.962762\n",
            "resetting env. episode 376.000000, reward total was -20.000000. running mean: -19.963134\n",
            "resetting env. episode 377.000000, reward total was -21.000000. running mean: -19.973503\n",
            "resetting env. episode 378.000000, reward total was -21.000000. running mean: -19.983768\n",
            "resetting env. episode 379.000000, reward total was -21.000000. running mean: -19.993930\n",
            "resetting env. episode 380.000000, reward total was -19.000000. running mean: -19.983991\n",
            "resetting env. episode 381.000000, reward total was -19.000000. running mean: -19.974151\n",
            "resetting env. episode 382.000000, reward total was -19.000000. running mean: -19.964409\n",
            "resetting env. episode 383.000000, reward total was -20.000000. running mean: -19.964765\n",
            "resetting env. episode 384.000000, reward total was -18.000000. running mean: -19.945117\n",
            "resetting env. episode 385.000000, reward total was -19.000000. running mean: -19.935666\n",
            "resetting env. episode 386.000000, reward total was -20.000000. running mean: -19.936310\n",
            "resetting env. episode 387.000000, reward total was -19.000000. running mean: -19.926947\n",
            "resetting env. episode 388.000000, reward total was -19.000000. running mean: -19.917677\n",
            "resetting env. episode 389.000000, reward total was -20.000000. running mean: -19.918500\n",
            "resetting env. episode 390.000000, reward total was -19.000000. running mean: -19.909315\n",
            "resetting env. episode 391.000000, reward total was -19.000000. running mean: -19.900222\n",
            "resetting env. episode 392.000000, reward total was -21.000000. running mean: -19.911220\n",
            "resetting env. episode 393.000000, reward total was -21.000000. running mean: -19.922108\n",
            "resetting env. episode 394.000000, reward total was -20.000000. running mean: -19.922887\n",
            "resetting env. episode 395.000000, reward total was -20.000000. running mean: -19.923658\n",
            "resetting env. episode 396.000000, reward total was -21.000000. running mean: -19.934421\n",
            "resetting env. episode 397.000000, reward total was -19.000000. running mean: -19.925077\n",
            "resetting env. episode 398.000000, reward total was -20.000000. running mean: -19.925826\n",
            "resetting env. episode 399.000000, reward total was -19.000000. running mean: -19.916568\n",
            "resetting env. episode 400.000000, reward total was -21.000000. running mean: -19.927402\n",
            "resetting env. episode 401.000000, reward total was -20.000000. running mean: -19.928128\n",
            "resetting env. episode 402.000000, reward total was -19.000000. running mean: -19.918847\n",
            "resetting env. episode 403.000000, reward total was -21.000000. running mean: -19.929659\n",
            "resetting env. episode 404.000000, reward total was -21.000000. running mean: -19.940362\n",
            "resetting env. episode 405.000000, reward total was -21.000000. running mean: -19.950958\n",
            "resetting env. episode 406.000000, reward total was -20.000000. running mean: -19.951449\n",
            "resetting env. episode 407.000000, reward total was -21.000000. running mean: -19.961934\n",
            "resetting env. episode 408.000000, reward total was -19.000000. running mean: -19.952315\n",
            "resetting env. episode 409.000000, reward total was -20.000000. running mean: -19.952792\n",
            "resetting env. episode 410.000000, reward total was -21.000000. running mean: -19.963264\n",
            "resetting env. episode 411.000000, reward total was -19.000000. running mean: -19.953631\n",
            "resetting env. episode 412.000000, reward total was -20.000000. running mean: -19.954095\n",
            "resetting env. episode 413.000000, reward total was -21.000000. running mean: -19.964554\n",
            "resetting env. episode 414.000000, reward total was -20.000000. running mean: -19.964908\n",
            "resetting env. episode 415.000000, reward total was -21.000000. running mean: -19.975259\n",
            "resetting env. episode 416.000000, reward total was -20.000000. running mean: -19.975507\n",
            "resetting env. episode 417.000000, reward total was -19.000000. running mean: -19.965752\n",
            "resetting env. episode 418.000000, reward total was -21.000000. running mean: -19.976094\n",
            "resetting env. episode 419.000000, reward total was -20.000000. running mean: -19.976333\n",
            "resetting env. episode 420.000000, reward total was -20.000000. running mean: -19.976570\n",
            "resetting env. episode 421.000000, reward total was -20.000000. running mean: -19.976804\n",
            "resetting env. episode 422.000000, reward total was -21.000000. running mean: -19.987036\n",
            "resetting env. episode 423.000000, reward total was -21.000000. running mean: -19.997166\n",
            "resetting env. episode 424.000000, reward total was -19.000000. running mean: -19.987194\n",
            "resetting env. episode 425.000000, reward total was -20.000000. running mean: -19.987322\n",
            "resetting env. episode 426.000000, reward total was -19.000000. running mean: -19.977449\n",
            "resetting env. episode 427.000000, reward total was -19.000000. running mean: -19.967674\n",
            "resetting env. episode 428.000000, reward total was -20.000000. running mean: -19.967998\n",
            "resetting env. episode 429.000000, reward total was -21.000000. running mean: -19.978318\n",
            "resetting env. episode 430.000000, reward total was -21.000000. running mean: -19.988535\n",
            "resetting env. episode 431.000000, reward total was -20.000000. running mean: -19.988649\n",
            "resetting env. episode 432.000000, reward total was -21.000000. running mean: -19.998763\n",
            "resetting env. episode 433.000000, reward total was -20.000000. running mean: -19.998775\n",
            "resetting env. episode 434.000000, reward total was -19.000000. running mean: -19.988787\n",
            "resetting env. episode 435.000000, reward total was -19.000000. running mean: -19.978899\n",
            "resetting env. episode 436.000000, reward total was -17.000000. running mean: -19.949110\n",
            "resetting env. episode 437.000000, reward total was -20.000000. running mean: -19.949619\n",
            "resetting env. episode 438.000000, reward total was -20.000000. running mean: -19.950123\n",
            "resetting env. episode 439.000000, reward total was -21.000000. running mean: -19.960622\n",
            "resetting env. episode 440.000000, reward total was -18.000000. running mean: -19.941016\n",
            "resetting env. episode 441.000000, reward total was -20.000000. running mean: -19.941606\n",
            "resetting env. episode 442.000000, reward total was -18.000000. running mean: -19.922189\n",
            "resetting env. episode 443.000000, reward total was -17.000000. running mean: -19.892968\n",
            "resetting env. episode 444.000000, reward total was -20.000000. running mean: -19.894038\n",
            "resetting env. episode 445.000000, reward total was -21.000000. running mean: -19.905098\n",
            "resetting env. episode 446.000000, reward total was -20.000000. running mean: -19.906047\n",
            "resetting env. episode 447.000000, reward total was -20.000000. running mean: -19.906986\n",
            "resetting env. episode 448.000000, reward total was -21.000000. running mean: -19.917916\n",
            "resetting env. episode 449.000000, reward total was -21.000000. running mean: -19.928737\n",
            "resetting env. episode 450.000000, reward total was -21.000000. running mean: -19.939450\n",
            "resetting env. episode 451.000000, reward total was -21.000000. running mean: -19.950055\n",
            "resetting env. episode 452.000000, reward total was -21.000000. running mean: -19.960555\n",
            "resetting env. episode 453.000000, reward total was -20.000000. running mean: -19.960949\n",
            "resetting env. episode 454.000000, reward total was -20.000000. running mean: -19.961340\n",
            "resetting env. episode 455.000000, reward total was -21.000000. running mean: -19.971726\n",
            "resetting env. episode 456.000000, reward total was -19.000000. running mean: -19.962009\n",
            "resetting env. episode 457.000000, reward total was -21.000000. running mean: -19.972389\n",
            "resetting env. episode 458.000000, reward total was -21.000000. running mean: -19.982665\n",
            "resetting env. episode 459.000000, reward total was -20.000000. running mean: -19.982838\n",
            "resetting env. episode 460.000000, reward total was -20.000000. running mean: -19.983010\n",
            "resetting env. episode 461.000000, reward total was -19.000000. running mean: -19.973180\n",
            "resetting env. episode 462.000000, reward total was -21.000000. running mean: -19.983448\n",
            "resetting env. episode 463.000000, reward total was -21.000000. running mean: -19.993614\n",
            "resetting env. episode 464.000000, reward total was -20.000000. running mean: -19.993677\n",
            "resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.003741\n",
            "resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.013703\n",
            "resetting env. episode 467.000000, reward total was -19.000000. running mean: -20.003566\n",
            "resetting env. episode 468.000000, reward total was -19.000000. running mean: -19.993531\n",
            "resetting env. episode 469.000000, reward total was -20.000000. running mean: -19.993595\n",
            "resetting env. episode 470.000000, reward total was -19.000000. running mean: -19.983659\n",
            "resetting env. episode 471.000000, reward total was -20.000000. running mean: -19.983823\n",
            "resetting env. episode 472.000000, reward total was -19.000000. running mean: -19.973984\n",
            "resetting env. episode 473.000000, reward total was -21.000000. running mean: -19.984245\n",
            "resetting env. episode 474.000000, reward total was -21.000000. running mean: -19.994402\n",
            "resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.004458\n",
            "resetting env. episode 476.000000, reward total was -21.000000. running mean: -20.014414\n",
            "resetting env. episode 477.000000, reward total was -18.000000. running mean: -19.994269\n",
            "resetting env. episode 478.000000, reward total was -20.000000. running mean: -19.994327\n",
            "resetting env. episode 479.000000, reward total was -20.000000. running mean: -19.994383\n",
            "resetting env. episode 480.000000, reward total was -19.000000. running mean: -19.984440\n",
            "resetting env. episode 481.000000, reward total was -21.000000. running mean: -19.994595\n",
            "resetting env. episode 482.000000, reward total was -21.000000. running mean: -20.004649\n",
            "resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.014603\n",
            "resetting env. episode 484.000000, reward total was -19.000000. running mean: -20.004457\n",
            "resetting env. episode 485.000000, reward total was -20.000000. running mean: -20.004412\n",
            "resetting env. episode 486.000000, reward total was -16.000000. running mean: -19.964368\n",
            "resetting env. episode 487.000000, reward total was -21.000000. running mean: -19.974724\n",
            "resetting env. episode 488.000000, reward total was -21.000000. running mean: -19.984977\n",
            "resetting env. episode 489.000000, reward total was -21.000000. running mean: -19.995127\n",
            "resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.005176\n",
            "resetting env. episode 491.000000, reward total was -20.000000. running mean: -20.005124\n",
            "resetting env. episode 492.000000, reward total was -19.000000. running mean: -19.995073\n",
            "resetting env. episode 493.000000, reward total was -20.000000. running mean: -19.995122\n",
            "resetting env. episode 494.000000, reward total was -19.000000. running mean: -19.985171\n",
            "resetting env. episode 495.000000, reward total was -21.000000. running mean: -19.995319\n",
            "resetting env. episode 496.000000, reward total was -21.000000. running mean: -20.005366\n",
            "resetting env. episode 497.000000, reward total was -19.000000. running mean: -19.995313\n",
            "resetting env. episode 498.000000, reward total was -20.000000. running mean: -19.995359\n",
            "resetting env. episode 499.000000, reward total was -19.000000. running mean: -19.985406\n",
            "resetting env. episode 500.000000, reward total was -20.000000. running mean: -19.985552\n",
            "resetting env. episode 501.000000, reward total was -20.000000. running mean: -19.985696\n",
            "resetting env. episode 502.000000, reward total was -18.000000. running mean: -19.965839\n",
            "resetting env. episode 503.000000, reward total was -20.000000. running mean: -19.966181\n",
            "resetting env. episode 504.000000, reward total was -17.000000. running mean: -19.936519\n",
            "resetting env. episode 505.000000, reward total was -21.000000. running mean: -19.947154\n",
            "resetting env. episode 506.000000, reward total was -18.000000. running mean: -19.927682\n",
            "resetting env. episode 507.000000, reward total was -21.000000. running mean: -19.938406\n",
            "resetting env. episode 508.000000, reward total was -21.000000. running mean: -19.949022\n",
            "resetting env. episode 509.000000, reward total was -21.000000. running mean: -19.959531\n",
            "resetting env. episode 510.000000, reward total was -20.000000. running mean: -19.959936\n",
            "resetting env. episode 511.000000, reward total was -18.000000. running mean: -19.940337\n",
            "resetting env. episode 512.000000, reward total was -18.000000. running mean: -19.920933\n",
            "resetting env. episode 513.000000, reward total was -20.000000. running mean: -19.921724\n",
            "resetting env. episode 514.000000, reward total was -19.000000. running mean: -19.912507\n",
            "resetting env. episode 515.000000, reward total was -21.000000. running mean: -19.923382\n",
            "resetting env. episode 516.000000, reward total was -18.000000. running mean: -19.904148\n",
            "resetting env. episode 517.000000, reward total was -20.000000. running mean: -19.905106\n",
            "resetting env. episode 518.000000, reward total was -19.000000. running mean: -19.896055\n",
            "resetting env. episode 519.000000, reward total was -20.000000. running mean: -19.897095\n",
            "resetting env. episode 520.000000, reward total was -20.000000. running mean: -19.898124\n",
            "resetting env. episode 521.000000, reward total was -19.000000. running mean: -19.889143\n",
            "resetting env. episode 522.000000, reward total was -19.000000. running mean: -19.880251\n",
            "resetting env. episode 523.000000, reward total was -20.000000. running mean: -19.881449\n",
            "resetting env. episode 524.000000, reward total was -18.000000. running mean: -19.862634\n",
            "resetting env. episode 525.000000, reward total was -17.000000. running mean: -19.834008\n",
            "resetting env. episode 526.000000, reward total was -19.000000. running mean: -19.825668\n",
            "resetting env. episode 527.000000, reward total was -20.000000. running mean: -19.827411\n",
            "resetting env. episode 528.000000, reward total was -21.000000. running mean: -19.839137\n",
            "resetting env. episode 529.000000, reward total was -21.000000. running mean: -19.850746\n",
            "resetting env. episode 530.000000, reward total was -20.000000. running mean: -19.852238\n",
            "resetting env. episode 531.000000, reward total was -20.000000. running mean: -19.853716\n",
            "resetting env. episode 532.000000, reward total was -21.000000. running mean: -19.865179\n",
            "resetting env. episode 533.000000, reward total was -20.000000. running mean: -19.866527\n",
            "resetting env. episode 534.000000, reward total was -20.000000. running mean: -19.867861\n",
            "resetting env. episode 535.000000, reward total was -21.000000. running mean: -19.879183\n",
            "resetting env. episode 536.000000, reward total was -21.000000. running mean: -19.890391\n",
            "resetting env. episode 537.000000, reward total was -21.000000. running mean: -19.901487\n",
            "resetting env. episode 538.000000, reward total was -19.000000. running mean: -19.892472\n",
            "resetting env. episode 539.000000, reward total was -18.000000. running mean: -19.873548\n",
            "resetting env. episode 540.000000, reward total was -17.000000. running mean: -19.844812\n",
            "resetting env. episode 541.000000, reward total was -18.000000. running mean: -19.826364\n",
            "resetting env. episode 542.000000, reward total was -21.000000. running mean: -19.838100\n",
            "resetting env. episode 543.000000, reward total was -20.000000. running mean: -19.839719\n",
            "resetting env. episode 544.000000, reward total was -20.000000. running mean: -19.841322\n",
            "resetting env. episode 545.000000, reward total was -19.000000. running mean: -19.832909\n",
            "resetting env. episode 546.000000, reward total was -19.000000. running mean: -19.824580\n",
            "resetting env. episode 547.000000, reward total was -19.000000. running mean: -19.816334\n",
            "resetting env. episode 548.000000, reward total was -21.000000. running mean: -19.828171\n",
            "resetting env. episode 549.000000, reward total was -21.000000. running mean: -19.839889\n",
            "resetting env. episode 550.000000, reward total was -20.000000. running mean: -19.841490\n",
            "resetting env. episode 551.000000, reward total was -20.000000. running mean: -19.843075\n",
            "resetting env. episode 552.000000, reward total was -20.000000. running mean: -19.844644\n",
            "resetting env. episode 553.000000, reward total was -21.000000. running mean: -19.856198\n",
            "resetting env. episode 554.000000, reward total was -18.000000. running mean: -19.837636\n",
            "resetting env. episode 555.000000, reward total was -19.000000. running mean: -19.829260\n",
            "resetting env. episode 556.000000, reward total was -21.000000. running mean: -19.840967\n",
            "resetting env. episode 557.000000, reward total was -18.000000. running mean: -19.822557\n",
            "resetting env. episode 558.000000, reward total was -20.000000. running mean: -19.824332\n",
            "resetting env. episode 559.000000, reward total was -21.000000. running mean: -19.836088\n",
            "resetting env. episode 560.000000, reward total was -20.000000. running mean: -19.837728\n",
            "resetting env. episode 561.000000, reward total was -21.000000. running mean: -19.849350\n",
            "resetting env. episode 562.000000, reward total was -18.000000. running mean: -19.830857\n",
            "resetting env. episode 563.000000, reward total was -21.000000. running mean: -19.842548\n",
            "resetting env. episode 564.000000, reward total was -21.000000. running mean: -19.854123\n",
            "resetting env. episode 565.000000, reward total was -21.000000. running mean: -19.865582\n",
            "resetting env. episode 566.000000, reward total was -19.000000. running mean: -19.856926\n",
            "resetting env. episode 567.000000, reward total was -20.000000. running mean: -19.858356\n",
            "resetting env. episode 568.000000, reward total was -20.000000. running mean: -19.859773\n",
            "resetting env. episode 569.000000, reward total was -21.000000. running mean: -19.871175\n",
            "resetting env. episode 570.000000, reward total was -21.000000. running mean: -19.882463\n",
            "resetting env. episode 571.000000, reward total was -21.000000. running mean: -19.893639\n",
            "resetting env. episode 572.000000, reward total was -20.000000. running mean: -19.894702\n",
            "resetting env. episode 573.000000, reward total was -21.000000. running mean: -19.905755\n",
            "resetting env. episode 574.000000, reward total was -19.000000. running mean: -19.896698\n",
            "resetting env. episode 575.000000, reward total was -19.000000. running mean: -19.887731\n",
            "resetting env. episode 576.000000, reward total was -19.000000. running mean: -19.878854\n",
            "resetting env. episode 577.000000, reward total was -21.000000. running mean: -19.890065\n",
            "resetting env. episode 578.000000, reward total was -21.000000. running mean: -19.901164\n",
            "resetting env. episode 579.000000, reward total was -20.000000. running mean: -19.902153\n",
            "resetting env. episode 580.000000, reward total was -19.000000. running mean: -19.893131\n",
            "resetting env. episode 581.000000, reward total was -19.000000. running mean: -19.884200\n",
            "resetting env. episode 582.000000, reward total was -19.000000. running mean: -19.875358\n",
            "resetting env. episode 583.000000, reward total was -18.000000. running mean: -19.856604\n",
            "resetting env. episode 584.000000, reward total was -20.000000. running mean: -19.858038\n",
            "resetting env. episode 585.000000, reward total was -20.000000. running mean: -19.859458\n",
            "resetting env. episode 586.000000, reward total was -21.000000. running mean: -19.870863\n",
            "resetting env. episode 587.000000, reward total was -21.000000. running mean: -19.882155\n",
            "resetting env. episode 588.000000, reward total was -19.000000. running mean: -19.873333\n",
            "resetting env. episode 589.000000, reward total was -20.000000. running mean: -19.874600\n",
            "resetting env. episode 590.000000, reward total was -20.000000. running mean: -19.875854\n",
            "resetting env. episode 591.000000, reward total was -20.000000. running mean: -19.877095\n",
            "resetting env. episode 592.000000, reward total was -19.000000. running mean: -19.868324\n",
            "resetting env. episode 593.000000, reward total was -20.000000. running mean: -19.869641\n",
            "resetting env. episode 594.000000, reward total was -18.000000. running mean: -19.850945\n",
            "resetting env. episode 595.000000, reward total was -18.000000. running mean: -19.832435\n",
            "resetting env. episode 596.000000, reward total was -20.000000. running mean: -19.834111\n",
            "resetting env. episode 597.000000, reward total was -21.000000. running mean: -19.845770\n",
            "resetting env. episode 598.000000, reward total was -21.000000. running mean: -19.857312\n",
            "resetting env. episode 599.000000, reward total was -21.000000. running mean: -19.868739\n",
            "resetting env. episode 600.000000, reward total was -18.000000. running mean: -19.850052\n",
            "resetting env. episode 601.000000, reward total was -17.000000. running mean: -19.821551\n",
            "resetting env. episode 602.000000, reward total was -20.000000. running mean: -19.823335\n",
            "resetting env. episode 603.000000, reward total was -21.000000. running mean: -19.835102\n",
            "resetting env. episode 604.000000, reward total was -21.000000. running mean: -19.846751\n",
            "resetting env. episode 605.000000, reward total was -21.000000. running mean: -19.858284\n",
            "resetting env. episode 606.000000, reward total was -21.000000. running mean: -19.869701\n",
            "resetting env. episode 607.000000, reward total was -19.000000. running mean: -19.861004\n",
            "resetting env. episode 608.000000, reward total was -21.000000. running mean: -19.872394\n",
            "resetting env. episode 609.000000, reward total was -21.000000. running mean: -19.883670\n",
            "resetting env. episode 610.000000, reward total was -18.000000. running mean: -19.864833\n",
            "resetting env. episode 611.000000, reward total was -21.000000. running mean: -19.876185\n",
            "resetting env. episode 612.000000, reward total was -20.000000. running mean: -19.877423\n",
            "resetting env. episode 613.000000, reward total was -19.000000. running mean: -19.868649\n",
            "resetting env. episode 614.000000, reward total was -18.000000. running mean: -19.849962\n",
            "resetting env. episode 615.000000, reward total was -19.000000. running mean: -19.841463\n",
            "resetting env. episode 616.000000, reward total was -19.000000. running mean: -19.833048\n",
            "resetting env. episode 617.000000, reward total was -18.000000. running mean: -19.814717\n",
            "resetting env. episode 618.000000, reward total was -19.000000. running mean: -19.806570\n",
            "resetting env. episode 619.000000, reward total was -20.000000. running mean: -19.808505\n",
            "resetting env. episode 620.000000, reward total was -20.000000. running mean: -19.810420\n",
            "resetting env. episode 621.000000, reward total was -21.000000. running mean: -19.822315\n",
            "resetting env. episode 622.000000, reward total was -21.000000. running mean: -19.834092\n",
            "resetting env. episode 623.000000, reward total was -21.000000. running mean: -19.845751\n",
            "resetting env. episode 624.000000, reward total was -20.000000. running mean: -19.847294\n",
            "resetting env. episode 625.000000, reward total was -17.000000. running mean: -19.818821\n",
            "resetting env. episode 626.000000, reward total was -21.000000. running mean: -19.830633\n",
            "resetting env. episode 627.000000, reward total was -21.000000. running mean: -19.842326\n",
            "resetting env. episode 628.000000, reward total was -21.000000. running mean: -19.853903\n",
            "resetting env. episode 629.000000, reward total was -21.000000. running mean: -19.865364\n",
            "resetting env. episode 630.000000, reward total was -19.000000. running mean: -19.856710\n",
            "resetting env. episode 631.000000, reward total was -19.000000. running mean: -19.848143\n",
            "resetting env. episode 632.000000, reward total was -19.000000. running mean: -19.839662\n",
            "resetting env. episode 633.000000, reward total was -20.000000. running mean: -19.841265\n",
            "resetting env. episode 634.000000, reward total was -21.000000. running mean: -19.852853\n",
            "resetting env. episode 635.000000, reward total was -19.000000. running mean: -19.844324\n",
            "resetting env. episode 636.000000, reward total was -18.000000. running mean: -19.825881\n",
            "resetting env. episode 637.000000, reward total was -21.000000. running mean: -19.837622\n",
            "resetting env. episode 638.000000, reward total was -21.000000. running mean: -19.849246\n",
            "resetting env. episode 639.000000, reward total was -20.000000. running mean: -19.850753\n",
            "resetting env. episode 640.000000, reward total was -21.000000. running mean: -19.862246\n",
            "resetting env. episode 641.000000, reward total was -20.000000. running mean: -19.863623\n",
            "resetting env. episode 642.000000, reward total was -19.000000. running mean: -19.854987\n",
            "resetting env. episode 643.000000, reward total was -19.000000. running mean: -19.846437\n",
            "resetting env. episode 644.000000, reward total was -20.000000. running mean: -19.847973\n",
            "resetting env. episode 645.000000, reward total was -18.000000. running mean: -19.829493\n",
            "resetting env. episode 646.000000, reward total was -20.000000. running mean: -19.831198\n",
            "resetting env. episode 647.000000, reward total was -18.000000. running mean: -19.812886\n",
            "resetting env. episode 648.000000, reward total was -20.000000. running mean: -19.814757\n",
            "resetting env. episode 649.000000, reward total was -20.000000. running mean: -19.816610\n",
            "resetting env. episode 650.000000, reward total was -20.000000. running mean: -19.818444\n",
            "resetting env. episode 651.000000, reward total was -19.000000. running mean: -19.810259\n",
            "resetting env. episode 652.000000, reward total was -20.000000. running mean: -19.812157\n",
            "resetting env. episode 653.000000, reward total was -21.000000. running mean: -19.824035\n",
            "resetting env. episode 654.000000, reward total was -19.000000. running mean: -19.815795\n",
            "resetting env. episode 655.000000, reward total was -20.000000. running mean: -19.817637\n",
            "resetting env. episode 656.000000, reward total was -21.000000. running mean: -19.829460\n",
            "resetting env. episode 657.000000, reward total was -20.000000. running mean: -19.831166\n",
            "resetting env. episode 658.000000, reward total was -20.000000. running mean: -19.832854\n",
            "resetting env. episode 659.000000, reward total was -21.000000. running mean: -19.844526\n",
            "resetting env. episode 660.000000, reward total was -19.000000. running mean: -19.836080\n",
            "resetting env. episode 661.000000, reward total was -18.000000. running mean: -19.817720\n",
            "resetting env. episode 662.000000, reward total was -19.000000. running mean: -19.809542\n",
            "resetting env. episode 663.000000, reward total was -21.000000. running mean: -19.821447\n",
            "resetting env. episode 664.000000, reward total was -21.000000. running mean: -19.833232\n",
            "resetting env. episode 665.000000, reward total was -19.000000. running mean: -19.824900\n",
            "resetting env. episode 666.000000, reward total was -20.000000. running mean: -19.826651\n",
            "resetting env. episode 667.000000, reward total was -19.000000. running mean: -19.818385\n",
            "resetting env. episode 668.000000, reward total was -20.000000. running mean: -19.820201\n",
            "resetting env. episode 669.000000, reward total was -21.000000. running mean: -19.831999\n",
            "resetting env. episode 670.000000, reward total was -21.000000. running mean: -19.843679\n",
            "resetting env. episode 671.000000, reward total was -20.000000. running mean: -19.845242\n",
            "resetting env. episode 672.000000, reward total was -19.000000. running mean: -19.836790\n",
            "resetting env. episode 673.000000, reward total was -19.000000. running mean: -19.828422\n",
            "resetting env. episode 674.000000, reward total was -20.000000. running mean: -19.830137\n",
            "resetting env. episode 675.000000, reward total was -20.000000. running mean: -19.831836\n",
            "resetting env. episode 676.000000, reward total was -21.000000. running mean: -19.843518\n",
            "resetting env. episode 677.000000, reward total was -21.000000. running mean: -19.855083\n",
            "resetting env. episode 678.000000, reward total was -20.000000. running mean: -19.856532\n",
            "resetting env. episode 679.000000, reward total was -20.000000. running mean: -19.857966\n",
            "resetting env. episode 680.000000, reward total was -20.000000. running mean: -19.859387\n",
            "resetting env. episode 681.000000, reward total was -21.000000. running mean: -19.870793\n",
            "resetting env. episode 682.000000, reward total was -20.000000. running mean: -19.872085\n",
            "resetting env. episode 683.000000, reward total was -19.000000. running mean: -19.863364\n",
            "resetting env. episode 684.000000, reward total was -19.000000. running mean: -19.854730\n",
            "resetting env. episode 685.000000, reward total was -21.000000. running mean: -19.866183\n",
            "resetting env. episode 686.000000, reward total was -19.000000. running mean: -19.857521\n",
            "resetting env. episode 687.000000, reward total was -21.000000. running mean: -19.868946\n",
            "resetting env. episode 688.000000, reward total was -21.000000. running mean: -19.880257\n",
            "resetting env. episode 689.000000, reward total was -21.000000. running mean: -19.891454\n",
            "resetting env. episode 690.000000, reward total was -21.000000. running mean: -19.902540\n",
            "resetting env. episode 691.000000, reward total was -19.000000. running mean: -19.893514\n",
            "resetting env. episode 692.000000, reward total was -20.000000. running mean: -19.894579\n",
            "resetting env. episode 693.000000, reward total was -20.000000. running mean: -19.895633\n",
            "resetting env. episode 694.000000, reward total was -20.000000. running mean: -19.896677\n",
            "resetting env. episode 695.000000, reward total was -20.000000. running mean: -19.897710\n",
            "resetting env. episode 696.000000, reward total was -20.000000. running mean: -19.898733\n",
            "resetting env. episode 697.000000, reward total was -19.000000. running mean: -19.889746\n",
            "resetting env. episode 698.000000, reward total was -19.000000. running mean: -19.880848\n",
            "resetting env. episode 699.000000, reward total was -19.000000. running mean: -19.872040\n",
            "resetting env. episode 700.000000, reward total was -18.000000. running mean: -19.853319\n",
            "resetting env. episode 701.000000, reward total was -21.000000. running mean: -19.864786\n",
            "resetting env. episode 702.000000, reward total was -20.000000. running mean: -19.866138\n",
            "resetting env. episode 703.000000, reward total was -21.000000. running mean: -19.877477\n",
            "resetting env. episode 704.000000, reward total was -21.000000. running mean: -19.888702\n",
            "resetting env. episode 705.000000, reward total was -21.000000. running mean: -19.899815\n",
            "resetting env. episode 706.000000, reward total was -18.000000. running mean: -19.880817\n",
            "resetting env. episode 707.000000, reward total was -20.000000. running mean: -19.882009\n",
            "resetting env. episode 708.000000, reward total was -20.000000. running mean: -19.883189\n",
            "resetting env. episode 709.000000, reward total was -18.000000. running mean: -19.864357\n",
            "resetting env. episode 710.000000, reward total was -21.000000. running mean: -19.875713\n",
            "resetting env. episode 711.000000, reward total was -21.000000. running mean: -19.886956\n",
            "resetting env. episode 712.000000, reward total was -20.000000. running mean: -19.888087\n",
            "resetting env. episode 713.000000, reward total was -20.000000. running mean: -19.889206\n",
            "resetting env. episode 714.000000, reward total was -20.000000. running mean: -19.890314\n",
            "resetting env. episode 715.000000, reward total was -18.000000. running mean: -19.871410\n",
            "resetting env. episode 716.000000, reward total was -18.000000. running mean: -19.852696\n",
            "resetting env. episode 717.000000, reward total was -21.000000. running mean: -19.864169\n",
            "resetting env. episode 718.000000, reward total was -17.000000. running mean: -19.835528\n",
            "resetting env. episode 719.000000, reward total was -20.000000. running mean: -19.837172\n",
            "resetting env. episode 720.000000, reward total was -18.000000. running mean: -19.818801\n",
            "resetting env. episode 721.000000, reward total was -20.000000. running mean: -19.820613\n",
            "resetting env. episode 722.000000, reward total was -21.000000. running mean: -19.832407\n",
            "resetting env. episode 723.000000, reward total was -19.000000. running mean: -19.824083\n",
            "resetting env. episode 724.000000, reward total was -19.000000. running mean: -19.815842\n",
            "resetting env. episode 725.000000, reward total was -21.000000. running mean: -19.827683\n",
            "resetting env. episode 726.000000, reward total was -20.000000. running mean: -19.829406\n",
            "resetting env. episode 727.000000, reward total was -20.000000. running mean: -19.831112\n",
            "resetting env. episode 728.000000, reward total was -20.000000. running mean: -19.832801\n",
            "resetting env. episode 729.000000, reward total was -20.000000. running mean: -19.834473\n",
            "resetting env. episode 730.000000, reward total was -18.000000. running mean: -19.816129\n",
            "resetting env. episode 731.000000, reward total was -20.000000. running mean: -19.817967\n",
            "resetting env. episode 732.000000, reward total was -20.000000. running mean: -19.819788\n",
            "resetting env. episode 733.000000, reward total was -17.000000. running mean: -19.791590\n",
            "resetting env. episode 734.000000, reward total was -21.000000. running mean: -19.803674\n",
            "resetting env. episode 735.000000, reward total was -20.000000. running mean: -19.805637\n",
            "resetting env. episode 736.000000, reward total was -20.000000. running mean: -19.807581\n",
            "resetting env. episode 737.000000, reward total was -18.000000. running mean: -19.789505\n",
            "resetting env. episode 738.000000, reward total was -21.000000. running mean: -19.801610\n",
            "resetting env. episode 739.000000, reward total was -18.000000. running mean: -19.783594\n",
            "resetting env. episode 740.000000, reward total was -20.000000. running mean: -19.785758\n",
            "resetting env. episode 741.000000, reward total was -17.000000. running mean: -19.757900\n",
            "resetting env. episode 742.000000, reward total was -21.000000. running mean: -19.770321\n",
            "resetting env. episode 743.000000, reward total was -19.000000. running mean: -19.762618\n",
            "resetting env. episode 744.000000, reward total was -21.000000. running mean: -19.774992\n",
            "resetting env. episode 745.000000, reward total was -19.000000. running mean: -19.767242\n",
            "resetting env. episode 746.000000, reward total was -20.000000. running mean: -19.769569\n",
            "resetting env. episode 747.000000, reward total was -20.000000. running mean: -19.771874\n",
            "resetting env. episode 748.000000, reward total was -21.000000. running mean: -19.784155\n",
            "resetting env. episode 749.000000, reward total was -19.000000. running mean: -19.776313\n",
            "resetting env. episode 750.000000, reward total was -21.000000. running mean: -19.788550\n",
            "resetting env. episode 751.000000, reward total was -19.000000. running mean: -19.780665\n",
            "resetting env. episode 752.000000, reward total was -21.000000. running mean: -19.792858\n",
            "resetting env. episode 753.000000, reward total was -19.000000. running mean: -19.784930\n",
            "resetting env. episode 754.000000, reward total was -21.000000. running mean: -19.797080\n",
            "resetting env. episode 755.000000, reward total was -19.000000. running mean: -19.789110\n",
            "resetting env. episode 756.000000, reward total was -18.000000. running mean: -19.771218\n",
            "resetting env. episode 757.000000, reward total was -21.000000. running mean: -19.783506\n",
            "resetting env. episode 758.000000, reward total was -20.000000. running mean: -19.785671\n",
            "resetting env. episode 759.000000, reward total was -19.000000. running mean: -19.777814\n",
            "resetting env. episode 760.000000, reward total was -20.000000. running mean: -19.780036\n",
            "resetting env. episode 761.000000, reward total was -19.000000. running mean: -19.772236\n",
            "resetting env. episode 762.000000, reward total was -18.000000. running mean: -19.754514\n",
            "resetting env. episode 763.000000, reward total was -16.000000. running mean: -19.716968\n",
            "resetting env. episode 764.000000, reward total was -19.000000. running mean: -19.709799\n",
            "resetting env. episode 765.000000, reward total was -18.000000. running mean: -19.692701\n",
            "resetting env. episode 766.000000, reward total was -21.000000. running mean: -19.705774\n",
            "resetting env. episode 767.000000, reward total was -20.000000. running mean: -19.708716\n",
            "resetting env. episode 768.000000, reward total was -19.000000. running mean: -19.701629\n",
            "resetting env. episode 769.000000, reward total was -19.000000. running mean: -19.694613\n",
            "resetting env. episode 770.000000, reward total was -18.000000. running mean: -19.677666\n",
            "resetting env. episode 771.000000, reward total was -16.000000. running mean: -19.640890\n",
            "resetting env. episode 772.000000, reward total was -21.000000. running mean: -19.654481\n",
            "resetting env. episode 773.000000, reward total was -21.000000. running mean: -19.667936\n",
            "resetting env. episode 774.000000, reward total was -21.000000. running mean: -19.681257\n",
            "resetting env. episode 775.000000, reward total was -21.000000. running mean: -19.694444\n",
            "resetting env. episode 776.000000, reward total was -19.000000. running mean: -19.687500\n",
            "resetting env. episode 777.000000, reward total was -20.000000. running mean: -19.690625\n",
            "resetting env. episode 778.000000, reward total was -19.000000. running mean: -19.683718\n",
            "resetting env. episode 779.000000, reward total was -18.000000. running mean: -19.666881\n",
            "resetting env. episode 780.000000, reward total was -21.000000. running mean: -19.680212\n",
            "resetting env. episode 781.000000, reward total was -20.000000. running mean: -19.683410\n",
            "resetting env. episode 782.000000, reward total was -18.000000. running mean: -19.666576\n",
            "resetting env. episode 783.000000, reward total was -20.000000. running mean: -19.669910\n",
            "resetting env. episode 784.000000, reward total was -21.000000. running mean: -19.683211\n",
            "resetting env. episode 785.000000, reward total was -21.000000. running mean: -19.696379\n",
            "resetting env. episode 786.000000, reward total was -21.000000. running mean: -19.709415\n",
            "resetting env. episode 787.000000, reward total was -20.000000. running mean: -19.712321\n",
            "resetting env. episode 788.000000, reward total was -21.000000. running mean: -19.725198\n",
            "resetting env. episode 789.000000, reward total was -20.000000. running mean: -19.727946\n",
            "resetting env. episode 790.000000, reward total was -20.000000. running mean: -19.730667\n",
            "resetting env. episode 791.000000, reward total was -20.000000. running mean: -19.733360\n",
            "resetting env. episode 792.000000, reward total was -21.000000. running mean: -19.746026\n",
            "resetting env. episode 793.000000, reward total was -19.000000. running mean: -19.738566\n",
            "resetting env. episode 794.000000, reward total was -20.000000. running mean: -19.741180\n",
            "resetting env. episode 795.000000, reward total was -19.000000. running mean: -19.733769\n",
            "resetting env. episode 796.000000, reward total was -20.000000. running mean: -19.736431\n",
            "resetting env. episode 797.000000, reward total was -21.000000. running mean: -19.749067\n",
            "resetting env. episode 798.000000, reward total was -20.000000. running mean: -19.751576\n",
            "resetting env. episode 799.000000, reward total was -17.000000. running mean: -19.724060\n",
            "resetting env. episode 800.000000, reward total was -21.000000. running mean: -19.736820\n",
            "resetting env. episode 801.000000, reward total was -19.000000. running mean: -19.729451\n",
            "resetting env. episode 802.000000, reward total was -21.000000. running mean: -19.742157\n",
            "resetting env. episode 803.000000, reward total was -21.000000. running mean: -19.754735\n",
            "resetting env. episode 804.000000, reward total was -21.000000. running mean: -19.767188\n",
            "resetting env. episode 805.000000, reward total was -20.000000. running mean: -19.769516\n",
            "resetting env. episode 806.000000, reward total was -21.000000. running mean: -19.781821\n",
            "resetting env. episode 807.000000, reward total was -21.000000. running mean: -19.794003\n",
            "resetting env. episode 808.000000, reward total was -19.000000. running mean: -19.786063\n",
            "resetting env. episode 809.000000, reward total was -18.000000. running mean: -19.768202\n",
            "resetting env. episode 810.000000, reward total was -20.000000. running mean: -19.770520\n",
            "resetting env. episode 811.000000, reward total was -21.000000. running mean: -19.782815\n",
            "resetting env. episode 812.000000, reward total was -21.000000. running mean: -19.794987\n",
            "resetting env. episode 813.000000, reward total was -19.000000. running mean: -19.787037\n",
            "resetting env. episode 814.000000, reward total was -19.000000. running mean: -19.779167\n",
            "resetting env. episode 815.000000, reward total was -21.000000. running mean: -19.791375\n",
            "resetting env. episode 816.000000, reward total was -19.000000. running mean: -19.783461\n",
            "resetting env. episode 817.000000, reward total was -15.000000. running mean: -19.735626\n",
            "resetting env. episode 818.000000, reward total was -20.000000. running mean: -19.738270\n",
            "resetting env. episode 819.000000, reward total was -19.000000. running mean: -19.730888\n",
            "resetting env. episode 820.000000, reward total was -21.000000. running mean: -19.743579\n",
            "resetting env. episode 821.000000, reward total was -21.000000. running mean: -19.756143\n",
            "resetting env. episode 822.000000, reward total was -17.000000. running mean: -19.728581\n",
            "resetting env. episode 823.000000, reward total was -20.000000. running mean: -19.731296\n",
            "resetting env. episode 824.000000, reward total was -20.000000. running mean: -19.733983\n",
            "resetting env. episode 825.000000, reward total was -21.000000. running mean: -19.746643\n",
            "resetting env. episode 826.000000, reward total was -19.000000. running mean: -19.739176\n",
            "resetting env. episode 827.000000, reward total was -20.000000. running mean: -19.741785\n",
            "resetting env. episode 828.000000, reward total was -20.000000. running mean: -19.744367\n",
            "resetting env. episode 829.000000, reward total was -20.000000. running mean: -19.746923\n",
            "resetting env. episode 830.000000, reward total was -19.000000. running mean: -19.739454\n",
            "resetting env. episode 831.000000, reward total was -19.000000. running mean: -19.732059\n",
            "resetting env. episode 832.000000, reward total was -18.000000. running mean: -19.714739\n",
            "resetting env. episode 833.000000, reward total was -21.000000. running mean: -19.727591\n",
            "resetting env. episode 834.000000, reward total was -20.000000. running mean: -19.730315\n",
            "resetting env. episode 835.000000, reward total was -21.000000. running mean: -19.743012\n",
            "resetting env. episode 836.000000, reward total was -21.000000. running mean: -19.755582\n",
            "resetting env. episode 837.000000, reward total was -19.000000. running mean: -19.748026\n",
            "resetting env. episode 838.000000, reward total was -18.000000. running mean: -19.730546\n",
            "resetting env. episode 839.000000, reward total was -16.000000. running mean: -19.693241\n",
            "resetting env. episode 840.000000, reward total was -19.000000. running mean: -19.686308\n",
            "resetting env. episode 841.000000, reward total was -18.000000. running mean: -19.669445\n",
            "resetting env. episode 842.000000, reward total was -21.000000. running mean: -19.682751\n",
            "resetting env. episode 843.000000, reward total was -20.000000. running mean: -19.685923\n",
            "resetting env. episode 844.000000, reward total was -18.000000. running mean: -19.669064\n",
            "resetting env. episode 845.000000, reward total was -21.000000. running mean: -19.682373\n",
            "resetting env. episode 846.000000, reward total was -19.000000. running mean: -19.675550\n",
            "resetting env. episode 847.000000, reward total was -21.000000. running mean: -19.688794\n",
            "resetting env. episode 848.000000, reward total was -19.000000. running mean: -19.681906\n",
            "resetting env. episode 849.000000, reward total was -21.000000. running mean: -19.695087\n",
            "resetting env. episode 850.000000, reward total was -21.000000. running mean: -19.708136\n",
            "resetting env. episode 851.000000, reward total was -19.000000. running mean: -19.701055\n",
            "resetting env. episode 852.000000, reward total was -21.000000. running mean: -19.714044\n",
            "resetting env. episode 853.000000, reward total was -21.000000. running mean: -19.726904\n",
            "resetting env. episode 854.000000, reward total was -20.000000. running mean: -19.729635\n",
            "resetting env. episode 855.000000, reward total was -20.000000. running mean: -19.732338\n",
            "resetting env. episode 856.000000, reward total was -18.000000. running mean: -19.715015\n",
            "resetting env. episode 857.000000, reward total was -21.000000. running mean: -19.727865\n",
            "resetting env. episode 858.000000, reward total was -21.000000. running mean: -19.740586\n",
            "resetting env. episode 859.000000, reward total was -20.000000. running mean: -19.743180\n",
            "resetting env. episode 860.000000, reward total was -21.000000. running mean: -19.755749\n",
            "resetting env. episode 861.000000, reward total was -21.000000. running mean: -19.768191\n",
            "resetting env. episode 862.000000, reward total was -19.000000. running mean: -19.760509\n",
            "resetting env. episode 863.000000, reward total was -18.000000. running mean: -19.742904\n",
            "resetting env. episode 864.000000, reward total was -20.000000. running mean: -19.745475\n",
            "resetting env. episode 865.000000, reward total was -21.000000. running mean: -19.758020\n",
            "resetting env. episode 866.000000, reward total was -20.000000. running mean: -19.760440\n",
            "resetting env. episode 867.000000, reward total was -20.000000. running mean: -19.762836\n",
            "resetting env. episode 868.000000, reward total was -21.000000. running mean: -19.775207\n",
            "resetting env. episode 869.000000, reward total was -19.000000. running mean: -19.767455\n",
            "resetting env. episode 870.000000, reward total was -20.000000. running mean: -19.769781\n",
            "resetting env. episode 871.000000, reward total was -19.000000. running mean: -19.762083\n",
            "resetting env. episode 872.000000, reward total was -18.000000. running mean: -19.744462\n",
            "resetting env. episode 873.000000, reward total was -18.000000. running mean: -19.727017\n",
            "resetting env. episode 874.000000, reward total was -19.000000. running mean: -19.719747\n",
            "resetting env. episode 875.000000, reward total was -16.000000. running mean: -19.682550\n",
            "resetting env. episode 876.000000, reward total was -20.000000. running mean: -19.685724\n",
            "resetting env. episode 877.000000, reward total was -20.000000. running mean: -19.688867\n",
            "resetting env. episode 878.000000, reward total was -20.000000. running mean: -19.691978\n",
            "resetting env. episode 879.000000, reward total was -21.000000. running mean: -19.705059\n",
            "resetting env. episode 880.000000, reward total was -17.000000. running mean: -19.678008\n",
            "resetting env. episode 881.000000, reward total was -21.000000. running mean: -19.691228\n",
            "resetting env. episode 882.000000, reward total was -19.000000. running mean: -19.684316\n",
            "resetting env. episode 883.000000, reward total was -19.000000. running mean: -19.677473\n",
            "resetting env. episode 884.000000, reward total was -20.000000. running mean: -19.680698\n",
            "resetting env. episode 885.000000, reward total was -20.000000. running mean: -19.683891\n",
            "resetting env. episode 886.000000, reward total was -20.000000. running mean: -19.687052\n",
            "resetting env. episode 887.000000, reward total was -19.000000. running mean: -19.680181\n",
            "resetting env. episode 888.000000, reward total was -19.000000. running mean: -19.673380\n",
            "resetting env. episode 889.000000, reward total was -17.000000. running mean: -19.646646\n",
            "resetting env. episode 890.000000, reward total was -19.000000. running mean: -19.640179\n",
            "resetting env. episode 891.000000, reward total was -19.000000. running mean: -19.633778\n",
            "resetting env. episode 892.000000, reward total was -21.000000. running mean: -19.647440\n",
            "resetting env. episode 893.000000, reward total was -21.000000. running mean: -19.660965\n",
            "resetting env. episode 894.000000, reward total was -18.000000. running mean: -19.644356\n",
            "resetting env. episode 895.000000, reward total was -19.000000. running mean: -19.637912\n",
            "resetting env. episode 896.000000, reward total was -21.000000. running mean: -19.651533\n",
            "resetting env. episode 897.000000, reward total was -19.000000. running mean: -19.645018\n",
            "resetting env. episode 898.000000, reward total was -20.000000. running mean: -19.648568\n",
            "resetting env. episode 899.000000, reward total was -21.000000. running mean: -19.662082\n",
            "resetting env. episode 900.000000, reward total was -19.000000. running mean: -19.655461\n",
            "resetting env. episode 901.000000, reward total was -21.000000. running mean: -19.668906\n",
            "resetting env. episode 902.000000, reward total was -20.000000. running mean: -19.672217\n",
            "resetting env. episode 903.000000, reward total was -18.000000. running mean: -19.655495\n",
            "resetting env. episode 904.000000, reward total was -20.000000. running mean: -19.658940\n",
            "resetting env. episode 905.000000, reward total was -20.000000. running mean: -19.662351\n",
            "resetting env. episode 906.000000, reward total was -19.000000. running mean: -19.655727\n",
            "resetting env. episode 907.000000, reward total was -20.000000. running mean: -19.659170\n",
            "resetting env. episode 908.000000, reward total was -21.000000. running mean: -19.672578\n",
            "resetting env. episode 909.000000, reward total was -20.000000. running mean: -19.675853\n",
            "resetting env. episode 910.000000, reward total was -21.000000. running mean: -19.689094\n",
            "resetting env. episode 911.000000, reward total was -21.000000. running mean: -19.702203\n",
            "resetting env. episode 912.000000, reward total was -20.000000. running mean: -19.705181\n",
            "resetting env. episode 913.000000, reward total was -20.000000. running mean: -19.708129\n",
            "resetting env. episode 914.000000, reward total was -21.000000. running mean: -19.721048\n",
            "resetting env. episode 915.000000, reward total was -20.000000. running mean: -19.723837\n",
            "resetting env. episode 916.000000, reward total was -20.000000. running mean: -19.726599\n",
            "resetting env. episode 917.000000, reward total was -19.000000. running mean: -19.719333\n",
            "resetting env. episode 918.000000, reward total was -21.000000. running mean: -19.732140\n",
            "resetting env. episode 919.000000, reward total was -20.000000. running mean: -19.734818\n",
            "resetting env. episode 920.000000, reward total was -20.000000. running mean: -19.737470\n",
            "resetting env. episode 921.000000, reward total was -20.000000. running mean: -19.740096\n",
            "resetting env. episode 922.000000, reward total was -20.000000. running mean: -19.742695\n",
            "resetting env. episode 923.000000, reward total was -18.000000. running mean: -19.725268\n",
            "resetting env. episode 924.000000, reward total was -20.000000. running mean: -19.728015\n",
            "resetting env. episode 925.000000, reward total was -21.000000. running mean: -19.740735\n",
            "resetting env. episode 926.000000, reward total was -20.000000. running mean: -19.743327\n",
            "resetting env. episode 927.000000, reward total was -19.000000. running mean: -19.735894\n",
            "resetting env. episode 928.000000, reward total was -16.000000. running mean: -19.698535\n",
            "resetting env. episode 929.000000, reward total was -20.000000. running mean: -19.701550\n",
            "resetting env. episode 930.000000, reward total was -20.000000. running mean: -19.704534\n",
            "resetting env. episode 931.000000, reward total was -21.000000. running mean: -19.717489\n",
            "resetting env. episode 932.000000, reward total was -21.000000. running mean: -19.730314\n",
            "resetting env. episode 933.000000, reward total was -21.000000. running mean: -19.743011\n",
            "resetting env. episode 934.000000, reward total was -21.000000. running mean: -19.755581\n",
            "resetting env. episode 935.000000, reward total was -20.000000. running mean: -19.758025\n",
            "resetting env. episode 936.000000, reward total was -20.000000. running mean: -19.760445\n",
            "resetting env. episode 937.000000, reward total was -21.000000. running mean: -19.772840\n",
            "resetting env. episode 938.000000, reward total was -16.000000. running mean: -19.735112\n",
            "resetting env. episode 939.000000, reward total was -20.000000. running mean: -19.737761\n",
            "resetting env. episode 940.000000, reward total was -19.000000. running mean: -19.730383\n",
            "resetting env. episode 941.000000, reward total was -17.000000. running mean: -19.703079\n",
            "resetting env. episode 942.000000, reward total was -19.000000. running mean: -19.696049\n",
            "resetting env. episode 943.000000, reward total was -20.000000. running mean: -19.699088\n",
            "resetting env. episode 944.000000, reward total was -20.000000. running mean: -19.702097\n",
            "resetting env. episode 945.000000, reward total was -17.000000. running mean: -19.675076\n",
            "resetting env. episode 946.000000, reward total was -19.000000. running mean: -19.668326\n",
            "resetting env. episode 947.000000, reward total was -20.000000. running mean: -19.671642\n",
            "resetting env. episode 948.000000, reward total was -21.000000. running mean: -19.684926\n",
            "resetting env. episode 949.000000, reward total was -19.000000. running mean: -19.678077\n",
            "resetting env. episode 950.000000, reward total was -21.000000. running mean: -19.691296\n",
            "resetting env. episode 951.000000, reward total was -17.000000. running mean: -19.664383\n",
            "resetting env. episode 952.000000, reward total was -20.000000. running mean: -19.667739\n",
            "resetting env. episode 953.000000, reward total was -19.000000. running mean: -19.661062\n",
            "resetting env. episode 954.000000, reward total was -19.000000. running mean: -19.654451\n",
            "resetting env. episode 955.000000, reward total was -20.000000. running mean: -19.657907\n",
            "resetting env. episode 956.000000, reward total was -20.000000. running mean: -19.661327\n",
            "resetting env. episode 957.000000, reward total was -18.000000. running mean: -19.644714\n",
            "resetting env. episode 958.000000, reward total was -21.000000. running mean: -19.658267\n",
            "resetting env. episode 959.000000, reward total was -19.000000. running mean: -19.651684\n",
            "resetting env. episode 960.000000, reward total was -21.000000. running mean: -19.665168\n",
            "resetting env. episode 961.000000, reward total was -20.000000. running mean: -19.668516\n",
            "resetting env. episode 962.000000, reward total was -21.000000. running mean: -19.681831\n",
            "resetting env. episode 963.000000, reward total was -21.000000. running mean: -19.695012\n",
            "resetting env. episode 964.000000, reward total was -20.000000. running mean: -19.698062\n",
            "resetting env. episode 965.000000, reward total was -21.000000. running mean: -19.711082\n",
            "resetting env. episode 966.000000, reward total was -18.000000. running mean: -19.693971\n",
            "resetting env. episode 967.000000, reward total was -21.000000. running mean: -19.707031\n",
            "resetting env. episode 968.000000, reward total was -19.000000. running mean: -19.699961\n",
            "resetting env. episode 969.000000, reward total was -20.000000. running mean: -19.702961\n",
            "resetting env. episode 970.000000, reward total was -18.000000. running mean: -19.685932\n",
            "resetting env. episode 971.000000, reward total was -19.000000. running mean: -19.679072\n",
            "resetting env. episode 972.000000, reward total was -20.000000. running mean: -19.682282\n",
            "resetting env. episode 973.000000, reward total was -21.000000. running mean: -19.695459\n",
            "resetting env. episode 974.000000, reward total was -20.000000. running mean: -19.698504\n",
            "resetting env. episode 975.000000, reward total was -20.000000. running mean: -19.701519\n",
            "resetting env. episode 976.000000, reward total was -18.000000. running mean: -19.684504\n",
            "resetting env. episode 977.000000, reward total was -21.000000. running mean: -19.697659\n",
            "resetting env. episode 978.000000, reward total was -19.000000. running mean: -19.690682\n",
            "resetting env. episode 979.000000, reward total was -21.000000. running mean: -19.703775\n",
            "resetting env. episode 980.000000, reward total was -20.000000. running mean: -19.706738\n",
            "resetting env. episode 981.000000, reward total was -21.000000. running mean: -19.719670\n",
            "resetting env. episode 982.000000, reward total was -19.000000. running mean: -19.712474\n",
            "resetting env. episode 983.000000, reward total was -18.000000. running mean: -19.695349\n",
            "resetting env. episode 984.000000, reward total was -17.000000. running mean: -19.668395\n",
            "resetting env. episode 985.000000, reward total was -19.000000. running mean: -19.661711\n",
            "resetting env. episode 986.000000, reward total was -20.000000. running mean: -19.665094\n",
            "resetting env. episode 987.000000, reward total was -18.000000. running mean: -19.648443\n",
            "resetting env. episode 988.000000, reward total was -19.000000. running mean: -19.641959\n",
            "resetting env. episode 989.000000, reward total was -20.000000. running mean: -19.645539\n",
            "resetting env. episode 990.000000, reward total was -20.000000. running mean: -19.649084\n",
            "resetting env. episode 991.000000, reward total was -20.000000. running mean: -19.652593\n",
            "resetting env. episode 992.000000, reward total was -17.000000. running mean: -19.626067\n",
            "resetting env. episode 993.000000, reward total was -20.000000. running mean: -19.629807\n",
            "resetting env. episode 994.000000, reward total was -21.000000. running mean: -19.643508\n",
            "resetting env. episode 995.000000, reward total was -14.000000. running mean: -19.587073\n",
            "resetting env. episode 996.000000, reward total was -20.000000. running mean: -19.591203\n",
            "resetting env. episode 997.000000, reward total was -20.000000. running mean: -19.595291\n",
            "resetting env. episode 998.000000, reward total was -21.000000. running mean: -19.609338\n",
            "resetting env. episode 999.000000, reward total was -19.000000. running mean: -19.603244\n",
            "resetting env. episode 1000.000000, reward total was -20.000000. running mean: -19.607212\n",
            "resetting env. episode 1001.000000, reward total was -18.000000. running mean: -19.591140\n",
            "resetting env. episode 1002.000000, reward total was -20.000000. running mean: -19.595228\n",
            "resetting env. episode 1003.000000, reward total was -19.000000. running mean: -19.589276\n",
            "resetting env. episode 1004.000000, reward total was -20.000000. running mean: -19.593383\n",
            "resetting env. episode 1005.000000, reward total was -20.000000. running mean: -19.597449\n",
            "resetting env. episode 1006.000000, reward total was -20.000000. running mean: -19.601475\n",
            "resetting env. episode 1007.000000, reward total was -20.000000. running mean: -19.605460\n",
            "resetting env. episode 1008.000000, reward total was -20.000000. running mean: -19.609406\n",
            "resetting env. episode 1009.000000, reward total was -19.000000. running mean: -19.603312\n",
            "resetting env. episode 1010.000000, reward total was -20.000000. running mean: -19.607278\n",
            "resetting env. episode 1011.000000, reward total was -19.000000. running mean: -19.601206\n",
            "resetting env. episode 1012.000000, reward total was -20.000000. running mean: -19.605194\n",
            "resetting env. episode 1013.000000, reward total was -21.000000. running mean: -19.619142\n",
            "resetting env. episode 1014.000000, reward total was -21.000000. running mean: -19.632950\n",
            "resetting env. episode 1015.000000, reward total was -21.000000. running mean: -19.646621\n",
            "resetting env. episode 1016.000000, reward total was -20.000000. running mean: -19.650155\n",
            "resetting env. episode 1017.000000, reward total was -21.000000. running mean: -19.663653\n",
            "resetting env. episode 1018.000000, reward total was -18.000000. running mean: -19.647016\n",
            "resetting env. episode 1019.000000, reward total was -18.000000. running mean: -19.630546\n",
            "resetting env. episode 1020.000000, reward total was -21.000000. running mean: -19.644241\n",
            "resetting env. episode 1021.000000, reward total was -20.000000. running mean: -19.647798\n",
            "resetting env. episode 1022.000000, reward total was -19.000000. running mean: -19.641320\n",
            "resetting env. episode 1023.000000, reward total was -19.000000. running mean: -19.634907\n",
            "resetting env. episode 1024.000000, reward total was -20.000000. running mean: -19.638558\n",
            "resetting env. episode 1025.000000, reward total was -21.000000. running mean: -19.652173\n",
            "resetting env. episode 1026.000000, reward total was -20.000000. running mean: -19.655651\n",
            "resetting env. episode 1027.000000, reward total was -21.000000. running mean: -19.669094\n",
            "resetting env. episode 1028.000000, reward total was -20.000000. running mean: -19.672403\n",
            "resetting env. episode 1029.000000, reward total was -19.000000. running mean: -19.665679\n",
            "resetting env. episode 1030.000000, reward total was -19.000000. running mean: -19.659023\n",
            "resetting env. episode 1031.000000, reward total was -19.000000. running mean: -19.652432\n",
            "resetting env. episode 1032.000000, reward total was -18.000000. running mean: -19.635908\n",
            "resetting env. episode 1033.000000, reward total was -18.000000. running mean: -19.619549\n",
            "resetting env. episode 1034.000000, reward total was -20.000000. running mean: -19.623353\n",
            "resetting env. episode 1035.000000, reward total was -19.000000. running mean: -19.617120\n",
            "resetting env. episode 1036.000000, reward total was -21.000000. running mean: -19.630949\n",
            "resetting env. episode 1037.000000, reward total was -21.000000. running mean: -19.644639\n",
            "resetting env. episode 1038.000000, reward total was -18.000000. running mean: -19.628193\n",
            "resetting env. episode 1039.000000, reward total was -19.000000. running mean: -19.621911\n",
            "resetting env. episode 1040.000000, reward total was -21.000000. running mean: -19.635692\n",
            "resetting env. episode 1041.000000, reward total was -18.000000. running mean: -19.619335\n",
            "resetting env. episode 1042.000000, reward total was -19.000000. running mean: -19.613142\n",
            "resetting env. episode 1043.000000, reward total was -20.000000. running mean: -19.617010\n",
            "resetting env. episode 1044.000000, reward total was -19.000000. running mean: -19.610840\n",
            "resetting env. episode 1045.000000, reward total was -20.000000. running mean: -19.614732\n",
            "resetting env. episode 1046.000000, reward total was -21.000000. running mean: -19.628584\n",
            "resetting env. episode 1047.000000, reward total was -19.000000. running mean: -19.622298\n",
            "resetting env. episode 1048.000000, reward total was -21.000000. running mean: -19.636075\n",
            "resetting env. episode 1049.000000, reward total was -18.000000. running mean: -19.619715\n",
            "resetting env. episode 1050.000000, reward total was -17.000000. running mean: -19.593518\n",
            "resetting env. episode 1051.000000, reward total was -21.000000. running mean: -19.607582\n",
            "resetting env. episode 1052.000000, reward total was -17.000000. running mean: -19.581507\n",
            "resetting env. episode 1053.000000, reward total was -20.000000. running mean: -19.585692\n",
            "resetting env. episode 1054.000000, reward total was -21.000000. running mean: -19.599835\n",
            "resetting env. episode 1055.000000, reward total was -19.000000. running mean: -19.593836\n",
            "resetting env. episode 1056.000000, reward total was -21.000000. running mean: -19.607898\n",
            "resetting env. episode 1057.000000, reward total was -19.000000. running mean: -19.601819\n",
            "resetting env. episode 1058.000000, reward total was -18.000000. running mean: -19.585801\n",
            "resetting env. episode 1059.000000, reward total was -20.000000. running mean: -19.589943\n",
            "resetting env. episode 1060.000000, reward total was -21.000000. running mean: -19.604043\n",
            "resetting env. episode 1061.000000, reward total was -20.000000. running mean: -19.608003\n",
            "resetting env. episode 1062.000000, reward total was -20.000000. running mean: -19.611923\n",
            "resetting env. episode 1063.000000, reward total was -21.000000. running mean: -19.625804\n",
            "resetting env. episode 1064.000000, reward total was -21.000000. running mean: -19.639546\n",
            "resetting env. episode 1065.000000, reward total was -18.000000. running mean: -19.623150\n",
            "resetting env. episode 1066.000000, reward total was -21.000000. running mean: -19.636919\n",
            "resetting env. episode 1067.000000, reward total was -19.000000. running mean: -19.630549\n",
            "resetting env. episode 1068.000000, reward total was -21.000000. running mean: -19.644244\n",
            "resetting env. episode 1069.000000, reward total was -20.000000. running mean: -19.647802\n",
            "resetting env. episode 1070.000000, reward total was -16.000000. running mean: -19.611323\n",
            "resetting env. episode 1071.000000, reward total was -19.000000. running mean: -19.605210\n",
            "resetting env. episode 1072.000000, reward total was -20.000000. running mean: -19.609158\n",
            "resetting env. episode 1073.000000, reward total was -20.000000. running mean: -19.613067\n",
            "resetting env. episode 1074.000000, reward total was -19.000000. running mean: -19.606936\n",
            "resetting env. episode 1075.000000, reward total was -20.000000. running mean: -19.610867\n",
            "resetting env. episode 1076.000000, reward total was -19.000000. running mean: -19.604758\n",
            "resetting env. episode 1077.000000, reward total was -18.000000. running mean: -19.588710\n",
            "resetting env. episode 1078.000000, reward total was -19.000000. running mean: -19.582823\n",
            "resetting env. episode 1079.000000, reward total was -20.000000. running mean: -19.586995\n",
            "resetting env. episode 1080.000000, reward total was -20.000000. running mean: -19.591125\n",
            "resetting env. episode 1081.000000, reward total was -19.000000. running mean: -19.585214\n",
            "resetting env. episode 1082.000000, reward total was -20.000000. running mean: -19.589362\n",
            "resetting env. episode 1083.000000, reward total was -18.000000. running mean: -19.573468\n",
            "resetting env. episode 1084.000000, reward total was -20.000000. running mean: -19.577733\n",
            "resetting env. episode 1085.000000, reward total was -21.000000. running mean: -19.591956\n",
            "resetting env. episode 1086.000000, reward total was -20.000000. running mean: -19.596036\n",
            "resetting env. episode 1087.000000, reward total was -20.000000. running mean: -19.600076\n",
            "resetting env. episode 1088.000000, reward total was -21.000000. running mean: -19.614075\n",
            "resetting env. episode 1089.000000, reward total was -17.000000. running mean: -19.587935\n",
            "resetting env. episode 1090.000000, reward total was -21.000000. running mean: -19.602055\n",
            "resetting env. episode 1091.000000, reward total was -21.000000. running mean: -19.616035\n",
            "resetting env. episode 1092.000000, reward total was -17.000000. running mean: -19.589874\n",
            "resetting env. episode 1093.000000, reward total was -21.000000. running mean: -19.603976\n",
            "resetting env. episode 1094.000000, reward total was -19.000000. running mean: -19.597936\n",
            "resetting env. episode 1095.000000, reward total was -21.000000. running mean: -19.611956\n",
            "resetting env. episode 1096.000000, reward total was -19.000000. running mean: -19.605837\n",
            "resetting env. episode 1097.000000, reward total was -18.000000. running mean: -19.589779\n",
            "resetting env. episode 1098.000000, reward total was -19.000000. running mean: -19.583881\n",
            "resetting env. episode 1099.000000, reward total was -19.000000. running mean: -19.578042\n",
            "resetting env. episode 1100.000000, reward total was -20.000000. running mean: -19.582262\n",
            "resetting env. episode 1101.000000, reward total was -18.000000. running mean: -19.566439\n",
            "resetting env. episode 1102.000000, reward total was -20.000000. running mean: -19.570775\n",
            "resetting env. episode 1103.000000, reward total was -21.000000. running mean: -19.585067\n",
            "resetting env. episode 1104.000000, reward total was -17.000000. running mean: -19.559216\n",
            "resetting env. episode 1105.000000, reward total was -21.000000. running mean: -19.573624\n",
            "resetting env. episode 1106.000000, reward total was -21.000000. running mean: -19.587888\n",
            "resetting env. episode 1107.000000, reward total was -19.000000. running mean: -19.582009\n",
            "resetting env. episode 1108.000000, reward total was -20.000000. running mean: -19.586189\n",
            "resetting env. episode 1109.000000, reward total was -21.000000. running mean: -19.600327\n",
            "resetting env. episode 1110.000000, reward total was -21.000000. running mean: -19.614324\n",
            "resetting env. episode 1111.000000, reward total was -20.000000. running mean: -19.618180\n",
            "resetting env. episode 1112.000000, reward total was -15.000000. running mean: -19.571999\n",
            "resetting env. episode 1113.000000, reward total was -20.000000. running mean: -19.576279\n",
            "resetting env. episode 1114.000000, reward total was -21.000000. running mean: -19.590516\n",
            "resetting env. episode 1115.000000, reward total was -16.000000. running mean: -19.554611\n",
            "resetting env. episode 1116.000000, reward total was -20.000000. running mean: -19.559064\n",
            "resetting env. episode 1117.000000, reward total was -21.000000. running mean: -19.573474\n",
            "resetting env. episode 1118.000000, reward total was -21.000000. running mean: -19.587739\n",
            "resetting env. episode 1119.000000, reward total was -21.000000. running mean: -19.601862\n",
            "resetting env. episode 1120.000000, reward total was -20.000000. running mean: -19.605843\n",
            "resetting env. episode 1121.000000, reward total was -17.000000. running mean: -19.579785\n",
            "resetting env. episode 1122.000000, reward total was -20.000000. running mean: -19.583987\n",
            "resetting env. episode 1123.000000, reward total was -19.000000. running mean: -19.578147\n",
            "resetting env. episode 1124.000000, reward total was -20.000000. running mean: -19.582365\n",
            "resetting env. episode 1125.000000, reward total was -20.000000. running mean: -19.586542\n",
            "resetting env. episode 1126.000000, reward total was -20.000000. running mean: -19.590676\n",
            "resetting env. episode 1127.000000, reward total was -21.000000. running mean: -19.604770\n",
            "resetting env. episode 1128.000000, reward total was -21.000000. running mean: -19.618722\n",
            "resetting env. episode 1129.000000, reward total was -20.000000. running mean: -19.622535\n",
            "resetting env. episode 1130.000000, reward total was -21.000000. running mean: -19.636309\n",
            "resetting env. episode 1131.000000, reward total was -19.000000. running mean: -19.629946\n",
            "resetting env. episode 1132.000000, reward total was -18.000000. running mean: -19.613647\n",
            "resetting env. episode 1133.000000, reward total was -19.000000. running mean: -19.607510\n",
            "resetting env. episode 1134.000000, reward total was -18.000000. running mean: -19.591435\n",
            "resetting env. episode 1135.000000, reward total was -21.000000. running mean: -19.605521\n",
            "resetting env. episode 1136.000000, reward total was -19.000000. running mean: -19.599466\n",
            "resetting env. episode 1137.000000, reward total was -19.000000. running mean: -19.593471\n",
            "resetting env. episode 1138.000000, reward total was -15.000000. running mean: -19.547536\n",
            "resetting env. episode 1139.000000, reward total was -21.000000. running mean: -19.562061\n",
            "resetting env. episode 1140.000000, reward total was -19.000000. running mean: -19.556440\n",
            "resetting env. episode 1141.000000, reward total was -16.000000. running mean: -19.520876\n",
            "resetting env. episode 1142.000000, reward total was -19.000000. running mean: -19.515667\n",
            "resetting env. episode 1143.000000, reward total was -19.000000. running mean: -19.510511\n",
            "resetting env. episode 1144.000000, reward total was -18.000000. running mean: -19.495405\n",
            "resetting env. episode 1145.000000, reward total was -16.000000. running mean: -19.460451\n",
            "resetting env. episode 1146.000000, reward total was -20.000000. running mean: -19.465847\n",
            "resetting env. episode 1147.000000, reward total was -20.000000. running mean: -19.471188\n",
            "resetting env. episode 1148.000000, reward total was -21.000000. running mean: -19.486476\n",
            "resetting env. episode 1149.000000, reward total was -19.000000. running mean: -19.481612\n",
            "resetting env. episode 1150.000000, reward total was -20.000000. running mean: -19.486796\n",
            "resetting env. episode 1151.000000, reward total was -19.000000. running mean: -19.481928\n",
            "resetting env. episode 1152.000000, reward total was -18.000000. running mean: -19.467108\n",
            "resetting env. episode 1153.000000, reward total was -19.000000. running mean: -19.462437\n",
            "resetting env. episode 1154.000000, reward total was -16.000000. running mean: -19.427813\n",
            "resetting env. episode 1155.000000, reward total was -20.000000. running mean: -19.433535\n",
            "resetting env. episode 1156.000000, reward total was -20.000000. running mean: -19.439199\n",
            "resetting env. episode 1157.000000, reward total was -20.000000. running mean: -19.444807\n",
            "resetting env. episode 1158.000000, reward total was -18.000000. running mean: -19.430359\n",
            "resetting env. episode 1159.000000, reward total was -17.000000. running mean: -19.406056\n",
            "resetting env. episode 1160.000000, reward total was -18.000000. running mean: -19.391995\n",
            "resetting env. episode 1161.000000, reward total was -19.000000. running mean: -19.388075\n",
            "resetting env. episode 1162.000000, reward total was -20.000000. running mean: -19.394195\n",
            "resetting env. episode 1163.000000, reward total was -20.000000. running mean: -19.400253\n",
            "resetting env. episode 1164.000000, reward total was -20.000000. running mean: -19.406250\n",
            "resetting env. episode 1165.000000, reward total was -18.000000. running mean: -19.392188\n",
            "resetting env. episode 1166.000000, reward total was -19.000000. running mean: -19.388266\n",
            "resetting env. episode 1167.000000, reward total was -21.000000. running mean: -19.404383\n",
            "resetting env. episode 1168.000000, reward total was -20.000000. running mean: -19.410339\n",
            "resetting env. episode 1169.000000, reward total was -20.000000. running mean: -19.416236\n",
            "resetting env. episode 1170.000000, reward total was -17.000000. running mean: -19.392073\n",
            "resetting env. episode 1171.000000, reward total was -20.000000. running mean: -19.398153\n",
            "resetting env. episode 1172.000000, reward total was -21.000000. running mean: -19.414171\n",
            "resetting env. episode 1173.000000, reward total was -19.000000. running mean: -19.410029\n",
            "resetting env. episode 1174.000000, reward total was -19.000000. running mean: -19.405929\n",
            "resetting env. episode 1175.000000, reward total was -18.000000. running mean: -19.391870\n",
            "resetting env. episode 1176.000000, reward total was -18.000000. running mean: -19.377951\n",
            "resetting env. episode 1177.000000, reward total was -19.000000. running mean: -19.374172\n",
            "resetting env. episode 1178.000000, reward total was -20.000000. running mean: -19.380430\n",
            "resetting env. episode 1179.000000, reward total was -21.000000. running mean: -19.396626\n",
            "resetting env. episode 1180.000000, reward total was -20.000000. running mean: -19.402659\n",
            "resetting env. episode 1181.000000, reward total was -21.000000. running mean: -19.418633\n",
            "resetting env. episode 1182.000000, reward total was -19.000000. running mean: -19.414446\n",
            "resetting env. episode 1183.000000, reward total was -21.000000. running mean: -19.430302\n",
            "resetting env. episode 1184.000000, reward total was -19.000000. running mean: -19.425999\n",
            "resetting env. episode 1185.000000, reward total was -21.000000. running mean: -19.441739\n",
            "resetting env. episode 1186.000000, reward total was -18.000000. running mean: -19.427322\n",
            "resetting env. episode 1187.000000, reward total was -21.000000. running mean: -19.443048\n",
            "resetting env. episode 1188.000000, reward total was -18.000000. running mean: -19.428618\n",
            "resetting env. episode 1189.000000, reward total was -19.000000. running mean: -19.424332\n",
            "resetting env. episode 1190.000000, reward total was -19.000000. running mean: -19.420088\n",
            "resetting env. episode 1191.000000, reward total was -19.000000. running mean: -19.415888\n",
            "resetting env. episode 1192.000000, reward total was -19.000000. running mean: -19.411729\n",
            "resetting env. episode 1193.000000, reward total was -19.000000. running mean: -19.407611\n",
            "resetting env. episode 1194.000000, reward total was -19.000000. running mean: -19.403535\n",
            "resetting env. episode 1195.000000, reward total was -20.000000. running mean: -19.409500\n",
            "resetting env. episode 1196.000000, reward total was -19.000000. running mean: -19.405405\n",
            "resetting env. episode 1197.000000, reward total was -19.000000. running mean: -19.401351\n",
            "resetting env. episode 1198.000000, reward total was -19.000000. running mean: -19.397337\n",
            "resetting env. episode 1199.000000, reward total was -20.000000. running mean: -19.403364\n",
            "resetting env. episode 1200.000000, reward total was -21.000000. running mean: -19.419330\n",
            "resetting env. episode 1201.000000, reward total was -21.000000. running mean: -19.435137\n",
            "resetting env. episode 1202.000000, reward total was -21.000000. running mean: -19.450786\n",
            "resetting env. episode 1203.000000, reward total was -21.000000. running mean: -19.466278\n",
            "resetting env. episode 1204.000000, reward total was -20.000000. running mean: -19.471615\n",
            "resetting env. episode 1205.000000, reward total was -19.000000. running mean: -19.466899\n",
            "resetting env. episode 1206.000000, reward total was -21.000000. running mean: -19.482230\n",
            "resetting env. episode 1207.000000, reward total was -18.000000. running mean: -19.467408\n",
            "resetting env. episode 1208.000000, reward total was -20.000000. running mean: -19.472734\n",
            "resetting env. episode 1209.000000, reward total was -19.000000. running mean: -19.468006\n",
            "resetting env. episode 1210.000000, reward total was -20.000000. running mean: -19.473326\n",
            "resetting env. episode 1211.000000, reward total was -20.000000. running mean: -19.478593\n",
            "resetting env. episode 1212.000000, reward total was -17.000000. running mean: -19.453807\n",
            "resetting env. episode 1213.000000, reward total was -19.000000. running mean: -19.449269\n",
            "resetting env. episode 1214.000000, reward total was -20.000000. running mean: -19.454776\n",
            "resetting env. episode 1215.000000, reward total was -21.000000. running mean: -19.470228\n",
            "resetting env. episode 1216.000000, reward total was -20.000000. running mean: -19.475526\n",
            "resetting env. episode 1217.000000, reward total was -19.000000. running mean: -19.470771\n",
            "resetting env. episode 1218.000000, reward total was -19.000000. running mean: -19.466063\n",
            "resetting env. episode 1219.000000, reward total was -21.000000. running mean: -19.481403\n",
            "resetting env. episode 1220.000000, reward total was -19.000000. running mean: -19.476588\n",
            "resetting env. episode 1221.000000, reward total was -19.000000. running mean: -19.471823\n",
            "resetting env. episode 1222.000000, reward total was -20.000000. running mean: -19.477104\n",
            "resetting env. episode 1223.000000, reward total was -19.000000. running mean: -19.472333\n",
            "resetting env. episode 1224.000000, reward total was -21.000000. running mean: -19.487610\n",
            "resetting env. episode 1225.000000, reward total was -17.000000. running mean: -19.462734\n",
            "resetting env. episode 1226.000000, reward total was -19.000000. running mean: -19.458107\n",
            "resetting env. episode 1227.000000, reward total was -20.000000. running mean: -19.463526\n",
            "resetting env. episode 1228.000000, reward total was -21.000000. running mean: -19.478890\n",
            "resetting env. episode 1229.000000, reward total was -20.000000. running mean: -19.484101\n",
            "resetting env. episode 1230.000000, reward total was -17.000000. running mean: -19.459260\n",
            "resetting env. episode 1231.000000, reward total was -20.000000. running mean: -19.464668\n",
            "resetting env. episode 1232.000000, reward total was -19.000000. running mean: -19.460021\n",
            "resetting env. episode 1233.000000, reward total was -21.000000. running mean: -19.475421\n",
            "resetting env. episode 1234.000000, reward total was -20.000000. running mean: -19.480667\n",
            "resetting env. episode 1235.000000, reward total was -17.000000. running mean: -19.455860\n",
            "resetting env. episode 1236.000000, reward total was -19.000000. running mean: -19.451301\n",
            "resetting env. episode 1237.000000, reward total was -19.000000. running mean: -19.446788\n",
            "resetting env. episode 1238.000000, reward total was -19.000000. running mean: -19.442320\n",
            "resetting env. episode 1239.000000, reward total was -19.000000. running mean: -19.437897\n",
            "resetting env. episode 1240.000000, reward total was -20.000000. running mean: -19.443518\n",
            "resetting env. episode 1241.000000, reward total was -21.000000. running mean: -19.459083\n",
            "resetting env. episode 1242.000000, reward total was -20.000000. running mean: -19.464492\n",
            "resetting env. episode 1243.000000, reward total was -17.000000. running mean: -19.439847\n",
            "resetting env. episode 1244.000000, reward total was -20.000000. running mean: -19.445449\n",
            "resetting env. episode 1245.000000, reward total was -18.000000. running mean: -19.430994\n",
            "resetting env. episode 1246.000000, reward total was -19.000000. running mean: -19.426684\n",
            "resetting env. episode 1247.000000, reward total was -21.000000. running mean: -19.442418\n",
            "resetting env. episode 1248.000000, reward total was -19.000000. running mean: -19.437993\n",
            "resetting env. episode 1249.000000, reward total was -21.000000. running mean: -19.453613\n",
            "resetting env. episode 1250.000000, reward total was -21.000000. running mean: -19.469077\n",
            "resetting env. episode 1251.000000, reward total was -19.000000. running mean: -19.464387\n",
            "resetting env. episode 1252.000000, reward total was -20.000000. running mean: -19.469743\n",
            "resetting env. episode 1253.000000, reward total was -18.000000. running mean: -19.455045\n",
            "resetting env. episode 1254.000000, reward total was -18.000000. running mean: -19.440495\n",
            "resetting env. episode 1255.000000, reward total was -19.000000. running mean: -19.436090\n",
            "resetting env. episode 1256.000000, reward total was -21.000000. running mean: -19.451729\n",
            "resetting env. episode 1257.000000, reward total was -20.000000. running mean: -19.457212\n",
            "resetting env. episode 1258.000000, reward total was -17.000000. running mean: -19.432640\n",
            "resetting env. episode 1259.000000, reward total was -18.000000. running mean: -19.418313\n",
            "resetting env. episode 1260.000000, reward total was -17.000000. running mean: -19.394130\n",
            "resetting env. episode 1261.000000, reward total was -18.000000. running mean: -19.380189\n",
            "resetting env. episode 1262.000000, reward total was -18.000000. running mean: -19.366387\n",
            "resetting env. episode 1263.000000, reward total was -18.000000. running mean: -19.352723\n",
            "resetting env. episode 1264.000000, reward total was -20.000000. running mean: -19.359196\n",
            "resetting env. episode 1265.000000, reward total was -21.000000. running mean: -19.375604\n",
            "resetting env. episode 1266.000000, reward total was -18.000000. running mean: -19.361848\n",
            "resetting env. episode 1267.000000, reward total was -21.000000. running mean: -19.378229\n",
            "resetting env. episode 1268.000000, reward total was -21.000000. running mean: -19.394447\n",
            "resetting env. episode 1269.000000, reward total was -15.000000. running mean: -19.350503\n",
            "resetting env. episode 1270.000000, reward total was -18.000000. running mean: -19.336998\n",
            "resetting env. episode 1271.000000, reward total was -20.000000. running mean: -19.343628\n",
            "resetting env. episode 1272.000000, reward total was -18.000000. running mean: -19.330191\n",
            "resetting env. episode 1273.000000, reward total was -20.000000. running mean: -19.336889\n",
            "resetting env. episode 1274.000000, reward total was -19.000000. running mean: -19.333520\n",
            "resetting env. episode 1275.000000, reward total was -21.000000. running mean: -19.350185\n",
            "resetting env. episode 1276.000000, reward total was -21.000000. running mean: -19.366683\n",
            "resetting env. episode 1277.000000, reward total was -20.000000. running mean: -19.373017\n",
            "resetting env. episode 1278.000000, reward total was -21.000000. running mean: -19.389286\n",
            "resetting env. episode 1279.000000, reward total was -21.000000. running mean: -19.405394\n",
            "resetting env. episode 1280.000000, reward total was -20.000000. running mean: -19.411340\n",
            "resetting env. episode 1281.000000, reward total was -20.000000. running mean: -19.417226\n",
            "resetting env. episode 1282.000000, reward total was -18.000000. running mean: -19.403054\n",
            "resetting env. episode 1283.000000, reward total was -18.000000. running mean: -19.389023\n",
            "resetting env. episode 1284.000000, reward total was -18.000000. running mean: -19.375133\n",
            "resetting env. episode 1285.000000, reward total was -21.000000. running mean: -19.391382\n",
            "resetting env. episode 1286.000000, reward total was -21.000000. running mean: -19.407468\n",
            "resetting env. episode 1287.000000, reward total was -20.000000. running mean: -19.413393\n",
            "resetting env. episode 1288.000000, reward total was -19.000000. running mean: -19.409259\n",
            "resetting env. episode 1289.000000, reward total was -19.000000. running mean: -19.405167\n",
            "resetting env. episode 1290.000000, reward total was -20.000000. running mean: -19.411115\n",
            "resetting env. episode 1291.000000, reward total was -16.000000. running mean: -19.377004\n",
            "resetting env. episode 1292.000000, reward total was -21.000000. running mean: -19.393234\n",
            "resetting env. episode 1293.000000, reward total was -19.000000. running mean: -19.389302\n",
            "resetting env. episode 1294.000000, reward total was -16.000000. running mean: -19.355409\n",
            "resetting env. episode 1295.000000, reward total was -20.000000. running mean: -19.361855\n",
            "resetting env. episode 1296.000000, reward total was -19.000000. running mean: -19.358236\n",
            "resetting env. episode 1297.000000, reward total was -19.000000. running mean: -19.354654\n",
            "resetting env. episode 1298.000000, reward total was -21.000000. running mean: -19.371107\n",
            "resetting env. episode 1299.000000, reward total was -20.000000. running mean: -19.377396\n",
            "resetting env. episode 1300.000000, reward total was -20.000000. running mean: -19.383622\n",
            "resetting env. episode 1301.000000, reward total was -18.000000. running mean: -19.369786\n",
            "resetting env. episode 1302.000000, reward total was -20.000000. running mean: -19.376088\n",
            "resetting env. episode 1303.000000, reward total was -21.000000. running mean: -19.392327\n",
            "resetting env. episode 1304.000000, reward total was -20.000000. running mean: -19.398404\n",
            "resetting env. episode 1305.000000, reward total was -17.000000. running mean: -19.374420\n",
            "resetting env. episode 1306.000000, reward total was -21.000000. running mean: -19.390676\n",
            "resetting env. episode 1307.000000, reward total was -19.000000. running mean: -19.386769\n",
            "resetting env. episode 1308.000000, reward total was -19.000000. running mean: -19.382901\n",
            "resetting env. episode 1309.000000, reward total was -19.000000. running mean: -19.379072\n",
            "resetting env. episode 1310.000000, reward total was -20.000000. running mean: -19.385281\n",
            "resetting env. episode 1311.000000, reward total was -21.000000. running mean: -19.401429\n",
            "resetting env. episode 1312.000000, reward total was -21.000000. running mean: -19.417414\n",
            "resetting env. episode 1313.000000, reward total was -19.000000. running mean: -19.413240\n",
            "resetting env. episode 1314.000000, reward total was -19.000000. running mean: -19.409108\n",
            "resetting env. episode 1315.000000, reward total was -20.000000. running mean: -19.415017\n",
            "resetting env. episode 1316.000000, reward total was -20.000000. running mean: -19.420867\n",
            "resetting env. episode 1317.000000, reward total was -21.000000. running mean: -19.436658\n",
            "resetting env. episode 1318.000000, reward total was -21.000000. running mean: -19.452291\n",
            "resetting env. episode 1319.000000, reward total was -19.000000. running mean: -19.447768\n",
            "resetting env. episode 1320.000000, reward total was -21.000000. running mean: -19.463291\n",
            "resetting env. episode 1321.000000, reward total was -20.000000. running mean: -19.468658\n",
            "resetting env. episode 1322.000000, reward total was -19.000000. running mean: -19.463971\n",
            "resetting env. episode 1323.000000, reward total was -19.000000. running mean: -19.459331\n",
            "resetting env. episode 1324.000000, reward total was -17.000000. running mean: -19.434738\n",
            "resetting env. episode 1325.000000, reward total was -17.000000. running mean: -19.410391\n",
            "resetting env. episode 1326.000000, reward total was -20.000000. running mean: -19.416287\n",
            "resetting env. episode 1327.000000, reward total was -21.000000. running mean: -19.432124\n",
            "resetting env. episode 1328.000000, reward total was -19.000000. running mean: -19.427803\n",
            "resetting env. episode 1329.000000, reward total was -19.000000. running mean: -19.423525\n",
            "resetting env. episode 1330.000000, reward total was -21.000000. running mean: -19.439289\n",
            "resetting env. episode 1331.000000, reward total was -20.000000. running mean: -19.444897\n",
            "resetting env. episode 1332.000000, reward total was -19.000000. running mean: -19.440448\n",
            "resetting env. episode 1333.000000, reward total was -17.000000. running mean: -19.416043\n",
            "resetting env. episode 1334.000000, reward total was -20.000000. running mean: -19.421883\n",
            "resetting env. episode 1335.000000, reward total was -19.000000. running mean: -19.417664\n",
            "resetting env. episode 1336.000000, reward total was -21.000000. running mean: -19.433487\n",
            "resetting env. episode 1337.000000, reward total was -20.000000. running mean: -19.439152\n",
            "resetting env. episode 1338.000000, reward total was -18.000000. running mean: -19.424761\n",
            "resetting env. episode 1339.000000, reward total was -16.000000. running mean: -19.390513\n",
            "resetting env. episode 1340.000000, reward total was -21.000000. running mean: -19.406608\n",
            "resetting env. episode 1341.000000, reward total was -19.000000. running mean: -19.402542\n",
            "resetting env. episode 1342.000000, reward total was -18.000000. running mean: -19.388517\n",
            "resetting env. episode 1343.000000, reward total was -20.000000. running mean: -19.394631\n",
            "resetting env. episode 1344.000000, reward total was -20.000000. running mean: -19.400685\n",
            "resetting env. episode 1345.000000, reward total was -20.000000. running mean: -19.406678\n",
            "resetting env. episode 1346.000000, reward total was -17.000000. running mean: -19.382611\n",
            "resetting env. episode 1347.000000, reward total was -19.000000. running mean: -19.378785\n",
            "resetting env. episode 1348.000000, reward total was -19.000000. running mean: -19.374998\n",
            "resetting env. episode 1349.000000, reward total was -21.000000. running mean: -19.391248\n",
            "resetting env. episode 1350.000000, reward total was -18.000000. running mean: -19.377335\n",
            "resetting env. episode 1351.000000, reward total was -19.000000. running mean: -19.373562\n",
            "resetting env. episode 1352.000000, reward total was -18.000000. running mean: -19.359826\n",
            "resetting env. episode 1353.000000, reward total was -20.000000. running mean: -19.366228\n",
            "resetting env. episode 1354.000000, reward total was -19.000000. running mean: -19.362566\n",
            "resetting env. episode 1355.000000, reward total was -17.000000. running mean: -19.338940\n",
            "resetting env. episode 1356.000000, reward total was -19.000000. running mean: -19.335551\n",
            "resetting env. episode 1357.000000, reward total was -19.000000. running mean: -19.332195\n",
            "resetting env. episode 1358.000000, reward total was -21.000000. running mean: -19.348873\n",
            "resetting env. episode 1359.000000, reward total was -17.000000. running mean: -19.325384\n",
            "resetting env. episode 1360.000000, reward total was -20.000000. running mean: -19.332130\n",
            "resetting env. episode 1361.000000, reward total was -19.000000. running mean: -19.328809\n",
            "resetting env. episode 1362.000000, reward total was -20.000000. running mean: -19.335521\n",
            "resetting env. episode 1363.000000, reward total was -21.000000. running mean: -19.352166\n",
            "resetting env. episode 1364.000000, reward total was -20.000000. running mean: -19.358644\n",
            "resetting env. episode 1365.000000, reward total was -18.000000. running mean: -19.345058\n",
            "resetting env. episode 1366.000000, reward total was -20.000000. running mean: -19.351607\n",
            "resetting env. episode 1367.000000, reward total was -20.000000. running mean: -19.358091\n",
            "resetting env. episode 1368.000000, reward total was -17.000000. running mean: -19.334510\n",
            "resetting env. episode 1369.000000, reward total was -19.000000. running mean: -19.331165\n",
            "resetting env. episode 1370.000000, reward total was -21.000000. running mean: -19.347853\n",
            "resetting env. episode 1371.000000, reward total was -20.000000. running mean: -19.354375\n",
            "resetting env. episode 1372.000000, reward total was -19.000000. running mean: -19.350831\n",
            "resetting env. episode 1373.000000, reward total was -20.000000. running mean: -19.357323\n",
            "resetting env. episode 1374.000000, reward total was -21.000000. running mean: -19.373750\n",
            "resetting env. episode 1375.000000, reward total was -19.000000. running mean: -19.370012\n",
            "resetting env. episode 1376.000000, reward total was -18.000000. running mean: -19.356312\n",
            "resetting env. episode 1377.000000, reward total was -19.000000. running mean: -19.352749\n",
            "resetting env. episode 1378.000000, reward total was -19.000000. running mean: -19.349221\n",
            "resetting env. episode 1379.000000, reward total was -21.000000. running mean: -19.365729\n",
            "resetting env. episode 1380.000000, reward total was -21.000000. running mean: -19.382072\n",
            "resetting env. episode 1381.000000, reward total was -20.000000. running mean: -19.388251\n",
            "resetting env. episode 1382.000000, reward total was -19.000000. running mean: -19.384369\n",
            "resetting env. episode 1383.000000, reward total was -20.000000. running mean: -19.390525\n",
            "resetting env. episode 1384.000000, reward total was -19.000000. running mean: -19.386620\n",
            "resetting env. episode 1385.000000, reward total was -19.000000. running mean: -19.382754\n",
            "resetting env. episode 1386.000000, reward total was -21.000000. running mean: -19.398926\n",
            "resetting env. episode 1387.000000, reward total was -17.000000. running mean: -19.374937\n",
            "resetting env. episode 1388.000000, reward total was -18.000000. running mean: -19.361187\n",
            "resetting env. episode 1389.000000, reward total was -18.000000. running mean: -19.347576\n",
            "resetting env. episode 1390.000000, reward total was -19.000000. running mean: -19.344100\n",
            "resetting env. episode 1391.000000, reward total was -21.000000. running mean: -19.360659\n",
            "resetting env. episode 1392.000000, reward total was -19.000000. running mean: -19.357052\n",
            "resetting env. episode 1393.000000, reward total was -18.000000. running mean: -19.343482\n",
            "resetting env. episode 1394.000000, reward total was -20.000000. running mean: -19.350047\n",
            "resetting env. episode 1395.000000, reward total was -17.000000. running mean: -19.326546\n",
            "resetting env. episode 1396.000000, reward total was -21.000000. running mean: -19.343281\n",
            "resetting env. episode 1397.000000, reward total was -19.000000. running mean: -19.339848\n",
            "resetting env. episode 1398.000000, reward total was -20.000000. running mean: -19.346450\n",
            "resetting env. episode 1399.000000, reward total was -18.000000. running mean: -19.332985\n",
            "resetting env. episode 1400.000000, reward total was -18.000000. running mean: -19.319655\n",
            "resetting env. episode 1401.000000, reward total was -21.000000. running mean: -19.336459\n",
            "resetting env. episode 1402.000000, reward total was -21.000000. running mean: -19.353094\n",
            "resetting env. episode 1403.000000, reward total was -19.000000. running mean: -19.349563\n",
            "resetting env. episode 1404.000000, reward total was -20.000000. running mean: -19.356068\n",
            "resetting env. episode 1405.000000, reward total was -17.000000. running mean: -19.332507\n",
            "resetting env. episode 1406.000000, reward total was -21.000000. running mean: -19.349182\n",
            "resetting env. episode 1407.000000, reward total was -20.000000. running mean: -19.355690\n",
            "resetting env. episode 1408.000000, reward total was -18.000000. running mean: -19.342133\n",
            "resetting env. episode 1409.000000, reward total was -15.000000. running mean: -19.298712\n",
            "resetting env. episode 1410.000000, reward total was -16.000000. running mean: -19.265725\n",
            "resetting env. episode 1411.000000, reward total was -18.000000. running mean: -19.253067\n",
            "resetting env. episode 1412.000000, reward total was -18.000000. running mean: -19.240537\n",
            "resetting env. episode 1413.000000, reward total was -18.000000. running mean: -19.228131\n",
            "resetting env. episode 1414.000000, reward total was -21.000000. running mean: -19.245850\n",
            "resetting env. episode 1415.000000, reward total was -16.000000. running mean: -19.213392\n",
            "resetting env. episode 1416.000000, reward total was -19.000000. running mean: -19.211258\n",
            "resetting env. episode 1417.000000, reward total was -21.000000. running mean: -19.229145\n",
            "resetting env. episode 1418.000000, reward total was -21.000000. running mean: -19.246854\n",
            "resetting env. episode 1419.000000, reward total was -19.000000. running mean: -19.244385\n",
            "resetting env. episode 1420.000000, reward total was -19.000000. running mean: -19.241941\n",
            "resetting env. episode 1421.000000, reward total was -18.000000. running mean: -19.229522\n",
            "resetting env. episode 1422.000000, reward total was -18.000000. running mean: -19.217227\n",
            "resetting env. episode 1423.000000, reward total was -21.000000. running mean: -19.235054\n",
            "resetting env. episode 1424.000000, reward total was -20.000000. running mean: -19.242704\n",
            "resetting env. episode 1425.000000, reward total was -19.000000. running mean: -19.240277\n",
            "resetting env. episode 1426.000000, reward total was -19.000000. running mean: -19.237874\n",
            "resetting env. episode 1427.000000, reward total was -20.000000. running mean: -19.245495\n",
            "resetting env. episode 1428.000000, reward total was -18.000000. running mean: -19.233040\n",
            "resetting env. episode 1429.000000, reward total was -19.000000. running mean: -19.230710\n",
            "resetting env. episode 1430.000000, reward total was -20.000000. running mean: -19.238403\n",
            "resetting env. episode 1431.000000, reward total was -19.000000. running mean: -19.236019\n",
            "resetting env. episode 1432.000000, reward total was -20.000000. running mean: -19.243659\n",
            "resetting env. episode 1433.000000, reward total was -20.000000. running mean: -19.251222\n",
            "resetting env. episode 1434.000000, reward total was -20.000000. running mean: -19.258710\n",
            "resetting env. episode 1435.000000, reward total was -21.000000. running mean: -19.276123\n",
            "resetting env. episode 1436.000000, reward total was -19.000000. running mean: -19.273361\n",
            "resetting env. episode 1437.000000, reward total was -20.000000. running mean: -19.280628\n",
            "resetting env. episode 1438.000000, reward total was -20.000000. running mean: -19.287822\n",
            "resetting env. episode 1439.000000, reward total was -21.000000. running mean: -19.304943\n",
            "resetting env. episode 1440.000000, reward total was -19.000000. running mean: -19.301894\n",
            "resetting env. episode 1441.000000, reward total was -19.000000. running mean: -19.298875\n",
            "resetting env. episode 1442.000000, reward total was -18.000000. running mean: -19.285886\n",
            "resetting env. episode 1443.000000, reward total was -19.000000. running mean: -19.283027\n",
            "resetting env. episode 1444.000000, reward total was -18.000000. running mean: -19.270197\n",
            "resetting env. episode 1445.000000, reward total was -19.000000. running mean: -19.267495\n",
            "resetting env. episode 1446.000000, reward total was -19.000000. running mean: -19.264820\n",
            "resetting env. episode 1447.000000, reward total was -19.000000. running mean: -19.262172\n",
            "resetting env. episode 1448.000000, reward total was -16.000000. running mean: -19.229550\n",
            "resetting env. episode 1449.000000, reward total was -17.000000. running mean: -19.207255\n",
            "resetting env. episode 1450.000000, reward total was -21.000000. running mean: -19.225182\n",
            "resetting env. episode 1451.000000, reward total was -19.000000. running mean: -19.222930\n",
            "resetting env. episode 1452.000000, reward total was -21.000000. running mean: -19.240701\n",
            "resetting env. episode 1453.000000, reward total was -19.000000. running mean: -19.238294\n",
            "resetting env. episode 1454.000000, reward total was -19.000000. running mean: -19.235911\n",
            "resetting env. episode 1455.000000, reward total was -19.000000. running mean: -19.233552\n",
            "resetting env. episode 1456.000000, reward total was -19.000000. running mean: -19.231216\n",
            "resetting env. episode 1457.000000, reward total was -16.000000. running mean: -19.198904\n",
            "resetting env. episode 1458.000000, reward total was -19.000000. running mean: -19.196915\n",
            "resetting env. episode 1459.000000, reward total was -20.000000. running mean: -19.204946\n",
            "resetting env. episode 1460.000000, reward total was -20.000000. running mean: -19.212897\n",
            "resetting env. episode 1461.000000, reward total was -20.000000. running mean: -19.220768\n",
            "resetting env. episode 1462.000000, reward total was -20.000000. running mean: -19.228560\n",
            "resetting env. episode 1463.000000, reward total was -19.000000. running mean: -19.226274\n",
            "resetting env. episode 1464.000000, reward total was -19.000000. running mean: -19.224012\n",
            "resetting env. episode 1465.000000, reward total was -21.000000. running mean: -19.241772\n",
            "resetting env. episode 1466.000000, reward total was -18.000000. running mean: -19.229354\n",
            "resetting env. episode 1467.000000, reward total was -19.000000. running mean: -19.227060\n",
            "resetting env. episode 1468.000000, reward total was -20.000000. running mean: -19.234790\n",
            "resetting env. episode 1469.000000, reward total was -21.000000. running mean: -19.252442\n",
            "resetting env. episode 1470.000000, reward total was -19.000000. running mean: -19.249917\n",
            "resetting env. episode 1471.000000, reward total was -19.000000. running mean: -19.247418\n",
            "resetting env. episode 1472.000000, reward total was -20.000000. running mean: -19.254944\n",
            "resetting env. episode 1473.000000, reward total was -19.000000. running mean: -19.252395\n",
            "resetting env. episode 1474.000000, reward total was -19.000000. running mean: -19.249871\n",
            "resetting env. episode 1475.000000, reward total was -21.000000. running mean: -19.267372\n",
            "resetting env. episode 1476.000000, reward total was -18.000000. running mean: -19.254698\n",
            "resetting env. episode 1477.000000, reward total was -19.000000. running mean: -19.252151\n",
            "resetting env. episode 1478.000000, reward total was -20.000000. running mean: -19.259630\n",
            "resetting env. episode 1479.000000, reward total was -18.000000. running mean: -19.247033\n",
            "resetting env. episode 1480.000000, reward total was -21.000000. running mean: -19.264563\n",
            "resetting env. episode 1481.000000, reward total was -20.000000. running mean: -19.271917\n",
            "resetting env. episode 1482.000000, reward total was -20.000000. running mean: -19.279198\n",
            "resetting env. episode 1483.000000, reward total was -17.000000. running mean: -19.256406\n",
            "resetting env. episode 1484.000000, reward total was -19.000000. running mean: -19.253842\n",
            "resetting env. episode 1485.000000, reward total was -19.000000. running mean: -19.251304\n",
            "resetting env. episode 1486.000000, reward total was -20.000000. running mean: -19.258791\n",
            "resetting env. episode 1487.000000, reward total was -19.000000. running mean: -19.256203\n",
            "resetting env. episode 1488.000000, reward total was -18.000000. running mean: -19.243641\n",
            "resetting env. episode 1489.000000, reward total was -16.000000. running mean: -19.211204\n",
            "resetting env. episode 1490.000000, reward total was -21.000000. running mean: -19.229092\n",
            "resetting env. episode 1491.000000, reward total was -21.000000. running mean: -19.246801\n",
            "resetting env. episode 1492.000000, reward total was -19.000000. running mean: -19.244333\n",
            "resetting env. episode 1493.000000, reward total was -19.000000. running mean: -19.241890\n",
            "resetting env. episode 1494.000000, reward total was -21.000000. running mean: -19.259471\n",
            "resetting env. episode 1495.000000, reward total was -20.000000. running mean: -19.266876\n",
            "resetting env. episode 1496.000000, reward total was -19.000000. running mean: -19.264208\n",
            "resetting env. episode 1497.000000, reward total was -20.000000. running mean: -19.271566\n",
            "resetting env. episode 1498.000000, reward total was -19.000000. running mean: -19.268850\n",
            "resetting env. episode 1499.000000, reward total was -18.000000. running mean: -19.256161\n",
            "resetting env. episode 1500.000000, reward total was -21.000000. running mean: -19.273600\n",
            "CPU times: user 2h 7min 5s, sys: 39min 29s, total: 2h 46min 34s\n",
            "Wall time: 1h 24min 56s\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "w2NblmwDsL3y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "95e21a0d-51ad-45ae-cbbb-1738e8dacb49"
      },
      "cell_type": "code",
      "source": [
        "play_game(env, model)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time hist4 = train_model(env, model, total_episodes=1500)"
      ],
      "metadata": {
        "id": "txYQV0szVGX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51702a5b-8ee9-4328-a007-1c7efaadbd9c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resetting env. episode 1.000000, reward total was -19.000000. running mean: -19.000000\n",
            "resetting env. episode 2.000000, reward total was -19.000000. running mean: -19.000000\n",
            "resetting env. episode 3.000000, reward total was -20.000000. running mean: -19.010000\n",
            "resetting env. episode 4.000000, reward total was -20.000000. running mean: -19.019900\n",
            "resetting env. episode 5.000000, reward total was -20.000000. running mean: -19.029701\n",
            "resetting env. episode 6.000000, reward total was -19.000000. running mean: -19.029404\n",
            "resetting env. episode 7.000000, reward total was -21.000000. running mean: -19.049110\n",
            "resetting env. episode 8.000000, reward total was -20.000000. running mean: -19.058619\n",
            "resetting env. episode 9.000000, reward total was -18.000000. running mean: -19.048033\n",
            "resetting env. episode 10.000000, reward total was -18.000000. running mean: -19.037552\n",
            "resetting env. episode 11.000000, reward total was -19.000000. running mean: -19.037177\n",
            "resetting env. episode 12.000000, reward total was -16.000000. running mean: -19.006805\n",
            "resetting env. episode 13.000000, reward total was -21.000000. running mean: -19.026737\n",
            "resetting env. episode 14.000000, reward total was -19.000000. running mean: -19.026470\n",
            "resetting env. episode 15.000000, reward total was -20.000000. running mean: -19.036205\n",
            "resetting env. episode 16.000000, reward total was -19.000000. running mean: -19.035843\n",
            "resetting env. episode 17.000000, reward total was -19.000000. running mean: -19.035484\n",
            "resetting env. episode 18.000000, reward total was -20.000000. running mean: -19.045130\n",
            "resetting env. episode 19.000000, reward total was -21.000000. running mean: -19.064678\n",
            "resetting env. episode 20.000000, reward total was -18.000000. running mean: -19.054032\n",
            "resetting env. episode 21.000000, reward total was -19.000000. running mean: -19.053491\n",
            "resetting env. episode 22.000000, reward total was -20.000000. running mean: -19.062956\n",
            "resetting env. episode 23.000000, reward total was -21.000000. running mean: -19.082327\n",
            "resetting env. episode 24.000000, reward total was -21.000000. running mean: -19.101503\n",
            "resetting env. episode 25.000000, reward total was -21.000000. running mean: -19.120488\n",
            "resetting env. episode 26.000000, reward total was -20.000000. running mean: -19.129284\n",
            "resetting env. episode 27.000000, reward total was -20.000000. running mean: -19.137991\n",
            "resetting env. episode 28.000000, reward total was -20.000000. running mean: -19.146611\n",
            "resetting env. episode 29.000000, reward total was -20.000000. running mean: -19.155145\n",
            "resetting env. episode 30.000000, reward total was -19.000000. running mean: -19.153593\n",
            "resetting env. episode 31.000000, reward total was -17.000000. running mean: -19.132057\n",
            "resetting env. episode 32.000000, reward total was -21.000000. running mean: -19.150737\n",
            "resetting env. episode 33.000000, reward total was -16.000000. running mean: -19.119229\n",
            "resetting env. episode 34.000000, reward total was -18.000000. running mean: -19.108037\n",
            "resetting env. episode 35.000000, reward total was -21.000000. running mean: -19.126957\n",
            "resetting env. episode 36.000000, reward total was -19.000000. running mean: -19.125687\n",
            "resetting env. episode 37.000000, reward total was -21.000000. running mean: -19.144430\n",
            "resetting env. episode 38.000000, reward total was -21.000000. running mean: -19.162986\n",
            "resetting env. episode 39.000000, reward total was -17.000000. running mean: -19.141356\n",
            "resetting env. episode 40.000000, reward total was -21.000000. running mean: -19.159943\n",
            "resetting env. episode 41.000000, reward total was -21.000000. running mean: -19.178343\n",
            "resetting env. episode 42.000000, reward total was -18.000000. running mean: -19.166560\n",
            "resetting env. episode 43.000000, reward total was -21.000000. running mean: -19.184894\n",
            "resetting env. episode 44.000000, reward total was -19.000000. running mean: -19.183045\n",
            "resetting env. episode 45.000000, reward total was -19.000000. running mean: -19.181215\n",
            "resetting env. episode 46.000000, reward total was -20.000000. running mean: -19.189403\n",
            "resetting env. episode 47.000000, reward total was -19.000000. running mean: -19.187509\n",
            "resetting env. episode 48.000000, reward total was -20.000000. running mean: -19.195633\n",
            "resetting env. episode 49.000000, reward total was -18.000000. running mean: -19.183677\n",
            "resetting env. episode 50.000000, reward total was -19.000000. running mean: -19.181840\n",
            "resetting env. episode 51.000000, reward total was -19.000000. running mean: -19.180022\n",
            "resetting env. episode 52.000000, reward total was -21.000000. running mean: -19.198222\n",
            "resetting env. episode 53.000000, reward total was -21.000000. running mean: -19.216240\n",
            "resetting env. episode 54.000000, reward total was -20.000000. running mean: -19.224077\n",
            "resetting env. episode 55.000000, reward total was -21.000000. running mean: -19.241836\n",
            "resetting env. episode 56.000000, reward total was -20.000000. running mean: -19.249418\n",
            "resetting env. episode 57.000000, reward total was -21.000000. running mean: -19.266924\n",
            "resetting env. episode 58.000000, reward total was -21.000000. running mean: -19.284255\n",
            "resetting env. episode 59.000000, reward total was -21.000000. running mean: -19.301412\n",
            "resetting env. episode 60.000000, reward total was -17.000000. running mean: -19.278398\n",
            "resetting env. episode 61.000000, reward total was -18.000000. running mean: -19.265614\n",
            "resetting env. episode 62.000000, reward total was -20.000000. running mean: -19.272958\n",
            "resetting env. episode 63.000000, reward total was -18.000000. running mean: -19.260228\n",
            "resetting env. episode 64.000000, reward total was -20.000000. running mean: -19.267626\n",
            "resetting env. episode 65.000000, reward total was -18.000000. running mean: -19.254950\n",
            "resetting env. episode 66.000000, reward total was -21.000000. running mean: -19.272400\n",
            "resetting env. episode 67.000000, reward total was -20.000000. running mean: -19.279676\n",
            "resetting env. episode 68.000000, reward total was -20.000000. running mean: -19.286879\n",
            "resetting env. episode 69.000000, reward total was -17.000000. running mean: -19.264011\n",
            "resetting env. episode 70.000000, reward total was -20.000000. running mean: -19.271370\n",
            "resetting env. episode 71.000000, reward total was -19.000000. running mean: -19.268657\n",
            "resetting env. episode 72.000000, reward total was -21.000000. running mean: -19.285970\n",
            "resetting env. episode 73.000000, reward total was -21.000000. running mean: -19.303111\n",
            "resetting env. episode 74.000000, reward total was -20.000000. running mean: -19.310079\n",
            "resetting env. episode 75.000000, reward total was -19.000000. running mean: -19.306979\n",
            "resetting env. episode 76.000000, reward total was -20.000000. running mean: -19.313909\n",
            "resetting env. episode 77.000000, reward total was -19.000000. running mean: -19.310770\n",
            "resetting env. episode 78.000000, reward total was -18.000000. running mean: -19.297662\n",
            "resetting env. episode 79.000000, reward total was -16.000000. running mean: -19.264685\n",
            "resetting env. episode 80.000000, reward total was -20.000000. running mean: -19.272039\n",
            "resetting env. episode 81.000000, reward total was -20.000000. running mean: -19.279318\n",
            "resetting env. episode 82.000000, reward total was -19.000000. running mean: -19.276525\n",
            "resetting env. episode 83.000000, reward total was -20.000000. running mean: -19.283760\n",
            "resetting env. episode 84.000000, reward total was -19.000000. running mean: -19.280922\n",
            "resetting env. episode 85.000000, reward total was -21.000000. running mean: -19.298113\n",
            "resetting env. episode 86.000000, reward total was -21.000000. running mean: -19.315132\n",
            "resetting env. episode 87.000000, reward total was -20.000000. running mean: -19.321980\n",
            "resetting env. episode 88.000000, reward total was -20.000000. running mean: -19.328761\n",
            "resetting env. episode 89.000000, reward total was -15.000000. running mean: -19.285473\n",
            "resetting env. episode 90.000000, reward total was -20.000000. running mean: -19.292618\n",
            "resetting env. episode 91.000000, reward total was -20.000000. running mean: -19.299692\n",
            "resetting env. episode 92.000000, reward total was -17.000000. running mean: -19.276695\n",
            "resetting env. episode 93.000000, reward total was -19.000000. running mean: -19.273928\n",
            "resetting env. episode 94.000000, reward total was -18.000000. running mean: -19.261189\n",
            "resetting env. episode 95.000000, reward total was -17.000000. running mean: -19.238577\n",
            "resetting env. episode 96.000000, reward total was -20.000000. running mean: -19.246191\n",
            "resetting env. episode 97.000000, reward total was -18.000000. running mean: -19.233729\n",
            "resetting env. episode 98.000000, reward total was -21.000000. running mean: -19.251392\n",
            "resetting env. episode 99.000000, reward total was -20.000000. running mean: -19.258878\n",
            "resetting env. episode 100.000000, reward total was -19.000000. running mean: -19.256289\n",
            "resetting env. episode 101.000000, reward total was -18.000000. running mean: -19.243727\n",
            "resetting env. episode 102.000000, reward total was -16.000000. running mean: -19.211289\n",
            "resetting env. episode 103.000000, reward total was -21.000000. running mean: -19.229176\n",
            "resetting env. episode 104.000000, reward total was -21.000000. running mean: -19.246885\n",
            "resetting env. episode 105.000000, reward total was -19.000000. running mean: -19.244416\n",
            "resetting env. episode 106.000000, reward total was -21.000000. running mean: -19.261972\n",
            "resetting env. episode 107.000000, reward total was -21.000000. running mean: -19.279352\n",
            "resetting env. episode 108.000000, reward total was -19.000000. running mean: -19.276558\n",
            "resetting env. episode 109.000000, reward total was -17.000000. running mean: -19.253793\n",
            "resetting env. episode 110.000000, reward total was -19.000000. running mean: -19.251255\n",
            "resetting env. episode 111.000000, reward total was -18.000000. running mean: -19.238742\n",
            "resetting env. episode 112.000000, reward total was -20.000000. running mean: -19.246355\n",
            "resetting env. episode 113.000000, reward total was -20.000000. running mean: -19.253891\n",
            "resetting env. episode 114.000000, reward total was -18.000000. running mean: -19.241352\n",
            "resetting env. episode 115.000000, reward total was -16.000000. running mean: -19.208939\n",
            "resetting env. episode 116.000000, reward total was -19.000000. running mean: -19.206850\n",
            "resetting env. episode 117.000000, reward total was -20.000000. running mean: -19.214781\n",
            "resetting env. episode 118.000000, reward total was -19.000000. running mean: -19.212633\n",
            "resetting env. episode 119.000000, reward total was -18.000000. running mean: -19.200507\n",
            "resetting env. episode 120.000000, reward total was -19.000000. running mean: -19.198502\n",
            "resetting env. episode 121.000000, reward total was -19.000000. running mean: -19.196517\n",
            "resetting env. episode 122.000000, reward total was -21.000000. running mean: -19.214552\n",
            "resetting env. episode 123.000000, reward total was -20.000000. running mean: -19.222406\n",
            "resetting env. episode 124.000000, reward total was -20.000000. running mean: -19.230182\n",
            "resetting env. episode 125.000000, reward total was -20.000000. running mean: -19.237880\n",
            "resetting env. episode 126.000000, reward total was -21.000000. running mean: -19.255501\n",
            "resetting env. episode 127.000000, reward total was -18.000000. running mean: -19.242946\n",
            "resetting env. episode 128.000000, reward total was -21.000000. running mean: -19.260517\n",
            "resetting env. episode 129.000000, reward total was -21.000000. running mean: -19.277912\n",
            "resetting env. episode 130.000000, reward total was -18.000000. running mean: -19.265133\n",
            "resetting env. episode 131.000000, reward total was -20.000000. running mean: -19.272481\n",
            "resetting env. episode 132.000000, reward total was -19.000000. running mean: -19.269757\n",
            "resetting env. episode 133.000000, reward total was -19.000000. running mean: -19.267059\n",
            "resetting env. episode 134.000000, reward total was -19.000000. running mean: -19.264388\n",
            "resetting env. episode 135.000000, reward total was -20.000000. running mean: -19.271744\n",
            "resetting env. episode 136.000000, reward total was -19.000000. running mean: -19.269027\n",
            "resetting env. episode 137.000000, reward total was -20.000000. running mean: -19.276337\n",
            "resetting env. episode 138.000000, reward total was -21.000000. running mean: -19.293573\n",
            "resetting env. episode 139.000000, reward total was -21.000000. running mean: -19.310638\n",
            "resetting env. episode 140.000000, reward total was -19.000000. running mean: -19.307531\n",
            "resetting env. episode 141.000000, reward total was -18.000000. running mean: -19.294456\n",
            "resetting env. episode 142.000000, reward total was -19.000000. running mean: -19.291511\n",
            "resetting env. episode 143.000000, reward total was -20.000000. running mean: -19.298596\n",
            "resetting env. episode 144.000000, reward total was -20.000000. running mean: -19.305610\n",
            "resetting env. episode 145.000000, reward total was -20.000000. running mean: -19.312554\n",
            "resetting env. episode 146.000000, reward total was -19.000000. running mean: -19.309429\n",
            "resetting env. episode 147.000000, reward total was -18.000000. running mean: -19.296334\n",
            "resetting env. episode 148.000000, reward total was -19.000000. running mean: -19.293371\n",
            "resetting env. episode 149.000000, reward total was -21.000000. running mean: -19.310437\n",
            "resetting env. episode 150.000000, reward total was -18.000000. running mean: -19.297333\n",
            "resetting env. episode 151.000000, reward total was -17.000000. running mean: -19.274360\n",
            "resetting env. episode 152.000000, reward total was -17.000000. running mean: -19.251616\n",
            "resetting env. episode 153.000000, reward total was -19.000000. running mean: -19.249100\n",
            "resetting env. episode 154.000000, reward total was -20.000000. running mean: -19.256609\n",
            "resetting env. episode 155.000000, reward total was -20.000000. running mean: -19.264043\n",
            "resetting env. episode 156.000000, reward total was -19.000000. running mean: -19.261402\n",
            "resetting env. episode 157.000000, reward total was -18.000000. running mean: -19.248788\n",
            "resetting env. episode 158.000000, reward total was -19.000000. running mean: -19.246300\n",
            "resetting env. episode 159.000000, reward total was -18.000000. running mean: -19.233837\n",
            "resetting env. episode 160.000000, reward total was -21.000000. running mean: -19.251499\n",
            "resetting env. episode 161.000000, reward total was -19.000000. running mean: -19.248984\n",
            "resetting env. episode 162.000000, reward total was -20.000000. running mean: -19.256494\n",
            "resetting env. episode 163.000000, reward total was -21.000000. running mean: -19.273929\n",
            "resetting env. episode 164.000000, reward total was -17.000000. running mean: -19.251190\n",
            "resetting env. episode 165.000000, reward total was -16.000000. running mean: -19.218678\n",
            "resetting env. episode 166.000000, reward total was -19.000000. running mean: -19.216491\n",
            "resetting env. episode 167.000000, reward total was -20.000000. running mean: -19.224326\n",
            "resetting env. episode 168.000000, reward total was -20.000000. running mean: -19.232083\n",
            "resetting env. episode 169.000000, reward total was -20.000000. running mean: -19.239762\n",
            "resetting env. episode 170.000000, reward total was -21.000000. running mean: -19.257365\n",
            "resetting env. episode 171.000000, reward total was -19.000000. running mean: -19.254791\n",
            "resetting env. episode 172.000000, reward total was -21.000000. running mean: -19.272243\n",
            "resetting env. episode 173.000000, reward total was -19.000000. running mean: -19.269521\n",
            "resetting env. episode 174.000000, reward total was -18.000000. running mean: -19.256826\n",
            "resetting env. episode 175.000000, reward total was -19.000000. running mean: -19.254257\n",
            "resetting env. episode 176.000000, reward total was -19.000000. running mean: -19.251715\n",
            "resetting env. episode 177.000000, reward total was -20.000000. running mean: -19.259198\n",
            "resetting env. episode 178.000000, reward total was -21.000000. running mean: -19.276606\n",
            "resetting env. episode 179.000000, reward total was -19.000000. running mean: -19.273840\n",
            "resetting env. episode 180.000000, reward total was -19.000000. running mean: -19.271101\n",
            "resetting env. episode 181.000000, reward total was -21.000000. running mean: -19.288390\n",
            "resetting env. episode 182.000000, reward total was -20.000000. running mean: -19.295506\n",
            "resetting env. episode 183.000000, reward total was -20.000000. running mean: -19.302551\n",
            "resetting env. episode 184.000000, reward total was -18.000000. running mean: -19.289526\n",
            "resetting env. episode 185.000000, reward total was -20.000000. running mean: -19.296630\n",
            "resetting env. episode 186.000000, reward total was -20.000000. running mean: -19.303664\n",
            "resetting env. episode 187.000000, reward total was -21.000000. running mean: -19.320627\n",
            "resetting env. episode 188.000000, reward total was -16.000000. running mean: -19.287421\n",
            "resetting env. episode 189.000000, reward total was -16.000000. running mean: -19.254547\n",
            "resetting env. episode 190.000000, reward total was -17.000000. running mean: -19.232001\n",
            "resetting env. episode 191.000000, reward total was -17.000000. running mean: -19.209681\n",
            "resetting env. episode 192.000000, reward total was -20.000000. running mean: -19.217585\n",
            "resetting env. episode 193.000000, reward total was -21.000000. running mean: -19.235409\n",
            "resetting env. episode 194.000000, reward total was -21.000000. running mean: -19.253055\n",
            "resetting env. episode 195.000000, reward total was -21.000000. running mean: -19.270524\n",
            "resetting env. episode 196.000000, reward total was -21.000000. running mean: -19.287819\n",
            "resetting env. episode 197.000000, reward total was -19.000000. running mean: -19.284941\n",
            "resetting env. episode 198.000000, reward total was -18.000000. running mean: -19.272091\n",
            "resetting env. episode 199.000000, reward total was -21.000000. running mean: -19.289370\n",
            "resetting env. episode 200.000000, reward total was -19.000000. running mean: -19.286477\n",
            "resetting env. episode 201.000000, reward total was -19.000000. running mean: -19.283612\n",
            "resetting env. episode 202.000000, reward total was -21.000000. running mean: -19.300776\n",
            "resetting env. episode 203.000000, reward total was -21.000000. running mean: -19.317768\n",
            "resetting env. episode 204.000000, reward total was -19.000000. running mean: -19.314590\n",
            "resetting env. episode 205.000000, reward total was -20.000000. running mean: -19.321444\n",
            "resetting env. episode 206.000000, reward total was -21.000000. running mean: -19.338230\n",
            "resetting env. episode 207.000000, reward total was -20.000000. running mean: -19.344848\n",
            "resetting env. episode 208.000000, reward total was -21.000000. running mean: -19.361399\n",
            "resetting env. episode 209.000000, reward total was -18.000000. running mean: -19.347785\n",
            "resetting env. episode 210.000000, reward total was -17.000000. running mean: -19.324307\n",
            "resetting env. episode 211.000000, reward total was -20.000000. running mean: -19.331064\n",
            "resetting env. episode 212.000000, reward total was -19.000000. running mean: -19.327754\n",
            "resetting env. episode 213.000000, reward total was -19.000000. running mean: -19.324476\n",
            "resetting env. episode 214.000000, reward total was -21.000000. running mean: -19.341231\n",
            "resetting env. episode 215.000000, reward total was -21.000000. running mean: -19.357819\n",
            "resetting env. episode 216.000000, reward total was -20.000000. running mean: -19.364241\n",
            "resetting env. episode 217.000000, reward total was -19.000000. running mean: -19.360598\n",
            "resetting env. episode 218.000000, reward total was -20.000000. running mean: -19.366992\n",
            "resetting env. episode 219.000000, reward total was -21.000000. running mean: -19.383323\n",
            "resetting env. episode 220.000000, reward total was -19.000000. running mean: -19.379489\n",
            "resetting env. episode 221.000000, reward total was -20.000000. running mean: -19.385694\n",
            "resetting env. episode 222.000000, reward total was -17.000000. running mean: -19.361838\n",
            "resetting env. episode 223.000000, reward total was -20.000000. running mean: -19.368219\n",
            "resetting env. episode 224.000000, reward total was -19.000000. running mean: -19.364537\n",
            "resetting env. episode 225.000000, reward total was -19.000000. running mean: -19.360892\n",
            "resetting env. episode 226.000000, reward total was -20.000000. running mean: -19.367283\n",
            "resetting env. episode 227.000000, reward total was -18.000000. running mean: -19.353610\n",
            "resetting env. episode 228.000000, reward total was -20.000000. running mean: -19.360074\n",
            "resetting env. episode 229.000000, reward total was -21.000000. running mean: -19.376473\n",
            "resetting env. episode 230.000000, reward total was -21.000000. running mean: -19.392708\n",
            "resetting env. episode 231.000000, reward total was -21.000000. running mean: -19.408781\n",
            "resetting env. episode 232.000000, reward total was -18.000000. running mean: -19.394693\n",
            "resetting env. episode 233.000000, reward total was -17.000000. running mean: -19.370746\n",
            "resetting env. episode 234.000000, reward total was -20.000000. running mean: -19.377039\n",
            "resetting env. episode 235.000000, reward total was -21.000000. running mean: -19.393269\n",
            "resetting env. episode 236.000000, reward total was -21.000000. running mean: -19.409336\n",
            "resetting env. episode 237.000000, reward total was -19.000000. running mean: -19.405243\n",
            "resetting env. episode 238.000000, reward total was -20.000000. running mean: -19.411190\n",
            "resetting env. episode 239.000000, reward total was -19.000000. running mean: -19.407078\n",
            "resetting env. episode 240.000000, reward total was -20.000000. running mean: -19.413007\n",
            "resetting env. episode 241.000000, reward total was -21.000000. running mean: -19.428877\n",
            "resetting env. episode 242.000000, reward total was -21.000000. running mean: -19.444589\n",
            "resetting env. episode 243.000000, reward total was -21.000000. running mean: -19.460143\n",
            "resetting env. episode 244.000000, reward total was -18.000000. running mean: -19.445541\n",
            "resetting env. episode 245.000000, reward total was -20.000000. running mean: -19.451086\n",
            "resetting env. episode 246.000000, reward total was -19.000000. running mean: -19.446575\n",
            "resetting env. episode 247.000000, reward total was -19.000000. running mean: -19.442109\n",
            "resetting env. episode 248.000000, reward total was -15.000000. running mean: -19.397688\n",
            "resetting env. episode 249.000000, reward total was -16.000000. running mean: -19.363711\n",
            "resetting env. episode 250.000000, reward total was -21.000000. running mean: -19.380074\n",
            "resetting env. episode 251.000000, reward total was -19.000000. running mean: -19.376273\n",
            "resetting env. episode 252.000000, reward total was -20.000000. running mean: -19.382511\n",
            "resetting env. episode 253.000000, reward total was -17.000000. running mean: -19.358686\n",
            "resetting env. episode 254.000000, reward total was -19.000000. running mean: -19.355099\n",
            "resetting env. episode 255.000000, reward total was -21.000000. running mean: -19.371548\n",
            "resetting env. episode 256.000000, reward total was -21.000000. running mean: -19.387832\n",
            "resetting env. episode 257.000000, reward total was -21.000000. running mean: -19.403954\n",
            "resetting env. episode 258.000000, reward total was -21.000000. running mean: -19.419914\n",
            "resetting env. episode 259.000000, reward total was -21.000000. running mean: -19.435715\n",
            "resetting env. episode 260.000000, reward total was -20.000000. running mean: -19.441358\n",
            "resetting env. episode 261.000000, reward total was -19.000000. running mean: -19.436945\n",
            "resetting env. episode 262.000000, reward total was -18.000000. running mean: -19.422575\n",
            "resetting env. episode 263.000000, reward total was -19.000000. running mean: -19.418349\n",
            "resetting env. episode 264.000000, reward total was -17.000000. running mean: -19.394166\n",
            "resetting env. episode 265.000000, reward total was -20.000000. running mean: -19.400224\n",
            "resetting env. episode 266.000000, reward total was -20.000000. running mean: -19.406222\n",
            "resetting env. episode 267.000000, reward total was -20.000000. running mean: -19.412160\n",
            "resetting env. episode 268.000000, reward total was -21.000000. running mean: -19.428038\n",
            "resetting env. episode 269.000000, reward total was -18.000000. running mean: -19.413758\n",
            "resetting env. episode 270.000000, reward total was -19.000000. running mean: -19.409620\n",
            "resetting env. episode 271.000000, reward total was -19.000000. running mean: -19.405524\n",
            "resetting env. episode 272.000000, reward total was -20.000000. running mean: -19.411469\n",
            "resetting env. episode 273.000000, reward total was -21.000000. running mean: -19.427354\n",
            "resetting env. episode 274.000000, reward total was -20.000000. running mean: -19.433080\n",
            "resetting env. episode 275.000000, reward total was -19.000000. running mean: -19.428750\n",
            "resetting env. episode 276.000000, reward total was -21.000000. running mean: -19.444462\n",
            "resetting env. episode 277.000000, reward total was -18.000000. running mean: -19.430018\n",
            "resetting env. episode 278.000000, reward total was -18.000000. running mean: -19.415717\n",
            "resetting env. episode 279.000000, reward total was -19.000000. running mean: -19.411560\n",
            "resetting env. episode 280.000000, reward total was -21.000000. running mean: -19.427445\n",
            "resetting env. episode 281.000000, reward total was -15.000000. running mean: -19.383170\n",
            "resetting env. episode 282.000000, reward total was -18.000000. running mean: -19.369338\n",
            "resetting env. episode 283.000000, reward total was -18.000000. running mean: -19.355645\n",
            "resetting env. episode 284.000000, reward total was -19.000000. running mean: -19.352089\n",
            "resetting env. episode 285.000000, reward total was -17.000000. running mean: -19.328568\n",
            "resetting env. episode 286.000000, reward total was -20.000000. running mean: -19.335282\n",
            "resetting env. episode 287.000000, reward total was -18.000000. running mean: -19.321929\n",
            "resetting env. episode 288.000000, reward total was -18.000000. running mean: -19.308710\n",
            "resetting env. episode 289.000000, reward total was -19.000000. running mean: -19.305623\n",
            "resetting env. episode 290.000000, reward total was -16.000000. running mean: -19.272567\n",
            "resetting env. episode 291.000000, reward total was -19.000000. running mean: -19.269841\n",
            "resetting env. episode 292.000000, reward total was -18.000000. running mean: -19.257143\n",
            "resetting env. episode 293.000000, reward total was -18.000000. running mean: -19.244571\n",
            "resetting env. episode 294.000000, reward total was -18.000000. running mean: -19.232125\n",
            "resetting env. episode 295.000000, reward total was -19.000000. running mean: -19.229804\n",
            "resetting env. episode 296.000000, reward total was -20.000000. running mean: -19.237506\n",
            "resetting env. episode 297.000000, reward total was -20.000000. running mean: -19.245131\n",
            "resetting env. episode 298.000000, reward total was -19.000000. running mean: -19.242680\n",
            "resetting env. episode 299.000000, reward total was -18.000000. running mean: -19.230253\n",
            "resetting env. episode 300.000000, reward total was -20.000000. running mean: -19.237950\n",
            "resetting env. episode 301.000000, reward total was -18.000000. running mean: -19.225571\n",
            "resetting env. episode 302.000000, reward total was -19.000000. running mean: -19.223315\n",
            "resetting env. episode 303.000000, reward total was -19.000000. running mean: -19.221082\n",
            "resetting env. episode 304.000000, reward total was -21.000000. running mean: -19.238871\n",
            "resetting env. episode 305.000000, reward total was -19.000000. running mean: -19.236483\n",
            "resetting env. episode 306.000000, reward total was -20.000000. running mean: -19.244118\n",
            "resetting env. episode 307.000000, reward total was -19.000000. running mean: -19.241677\n",
            "resetting env. episode 308.000000, reward total was -20.000000. running mean: -19.249260\n",
            "resetting env. episode 309.000000, reward total was -17.000000. running mean: -19.226767\n",
            "resetting env. episode 310.000000, reward total was -19.000000. running mean: -19.224499\n",
            "resetting env. episode 311.000000, reward total was -17.000000. running mean: -19.202254\n",
            "resetting env. episode 312.000000, reward total was -20.000000. running mean: -19.210232\n",
            "resetting env. episode 313.000000, reward total was -20.000000. running mean: -19.218130\n",
            "resetting env. episode 314.000000, reward total was -21.000000. running mean: -19.235948\n",
            "resetting env. episode 315.000000, reward total was -18.000000. running mean: -19.223589\n",
            "resetting env. episode 316.000000, reward total was -18.000000. running mean: -19.211353\n",
            "resetting env. episode 317.000000, reward total was -17.000000. running mean: -19.189239\n",
            "resetting env. episode 318.000000, reward total was -20.000000. running mean: -19.197347\n",
            "resetting env. episode 319.000000, reward total was -18.000000. running mean: -19.185374\n",
            "resetting env. episode 320.000000, reward total was -19.000000. running mean: -19.183520\n",
            "resetting env. episode 321.000000, reward total was -17.000000. running mean: -19.161685\n",
            "resetting env. episode 322.000000, reward total was -19.000000. running mean: -19.160068\n",
            "resetting env. episode 323.000000, reward total was -20.000000. running mean: -19.168467\n",
            "resetting env. episode 324.000000, reward total was -18.000000. running mean: -19.156782\n",
            "resetting env. episode 325.000000, reward total was -21.000000. running mean: -19.175215\n",
            "resetting env. episode 326.000000, reward total was -19.000000. running mean: -19.173462\n",
            "resetting env. episode 327.000000, reward total was -19.000000. running mean: -19.171728\n",
            "resetting env. episode 328.000000, reward total was -21.000000. running mean: -19.190011\n",
            "resetting env. episode 329.000000, reward total was -16.000000. running mean: -19.158110\n",
            "resetting env. episode 330.000000, reward total was -19.000000. running mean: -19.156529\n",
            "resetting env. episode 331.000000, reward total was -19.000000. running mean: -19.154964\n",
            "resetting env. episode 332.000000, reward total was -18.000000. running mean: -19.143414\n",
            "resetting env. episode 333.000000, reward total was -21.000000. running mean: -19.161980\n",
            "resetting env. episode 334.000000, reward total was -21.000000. running mean: -19.180360\n",
            "resetting env. episode 335.000000, reward total was -19.000000. running mean: -19.178557\n",
            "resetting env. episode 336.000000, reward total was -19.000000. running mean: -19.176771\n",
            "resetting env. episode 337.000000, reward total was -18.000000. running mean: -19.165004\n",
            "resetting env. episode 338.000000, reward total was -21.000000. running mean: -19.183354\n",
            "resetting env. episode 339.000000, reward total was -17.000000. running mean: -19.161520\n",
            "resetting env. episode 340.000000, reward total was -19.000000. running mean: -19.159905\n",
            "resetting env. episode 341.000000, reward total was -20.000000. running mean: -19.168306\n",
            "resetting env. episode 342.000000, reward total was -21.000000. running mean: -19.186623\n",
            "resetting env. episode 343.000000, reward total was -20.000000. running mean: -19.194756\n",
            "resetting env. episode 344.000000, reward total was -17.000000. running mean: -19.172809\n",
            "resetting env. episode 345.000000, reward total was -19.000000. running mean: -19.171081\n",
            "resetting env. episode 346.000000, reward total was -18.000000. running mean: -19.159370\n",
            "resetting env. episode 347.000000, reward total was -17.000000. running mean: -19.137776\n",
            "resetting env. episode 348.000000, reward total was -19.000000. running mean: -19.136399\n",
            "resetting env. episode 349.000000, reward total was -20.000000. running mean: -19.145035\n",
            "resetting env. episode 350.000000, reward total was -20.000000. running mean: -19.153584\n",
            "resetting env. episode 351.000000, reward total was -20.000000. running mean: -19.162048\n",
            "resetting env. episode 352.000000, reward total was -16.000000. running mean: -19.130428\n",
            "resetting env. episode 353.000000, reward total was -18.000000. running mean: -19.119124\n",
            "resetting env. episode 354.000000, reward total was -21.000000. running mean: -19.137932\n",
            "resetting env. episode 355.000000, reward total was -21.000000. running mean: -19.156553\n",
            "resetting env. episode 356.000000, reward total was -19.000000. running mean: -19.154988\n",
            "resetting env. episode 357.000000, reward total was -20.000000. running mean: -19.163438\n",
            "resetting env. episode 358.000000, reward total was -19.000000. running mean: -19.161803\n",
            "resetting env. episode 359.000000, reward total was -17.000000. running mean: -19.140185\n",
            "resetting env. episode 360.000000, reward total was -17.000000. running mean: -19.118783\n",
            "resetting env. episode 361.000000, reward total was -18.000000. running mean: -19.107596\n",
            "resetting env. episode 362.000000, reward total was -20.000000. running mean: -19.116520\n",
            "resetting env. episode 363.000000, reward total was -21.000000. running mean: -19.135354\n",
            "resetting env. episode 364.000000, reward total was -19.000000. running mean: -19.134001\n",
            "resetting env. episode 365.000000, reward total was -18.000000. running mean: -19.122661\n",
            "resetting env. episode 366.000000, reward total was -19.000000. running mean: -19.121434\n",
            "resetting env. episode 367.000000, reward total was -20.000000. running mean: -19.130220\n",
            "resetting env. episode 368.000000, reward total was -20.000000. running mean: -19.138918\n",
            "resetting env. episode 369.000000, reward total was -19.000000. running mean: -19.137529\n",
            "resetting env. episode 370.000000, reward total was -18.000000. running mean: -19.126153\n",
            "resetting env. episode 371.000000, reward total was -19.000000. running mean: -19.124892\n",
            "resetting env. episode 372.000000, reward total was -19.000000. running mean: -19.123643\n",
            "resetting env. episode 373.000000, reward total was -19.000000. running mean: -19.122406\n",
            "resetting env. episode 374.000000, reward total was -21.000000. running mean: -19.141182\n",
            "resetting env. episode 375.000000, reward total was -18.000000. running mean: -19.129770\n",
            "resetting env. episode 376.000000, reward total was -19.000000. running mean: -19.128473\n",
            "resetting env. episode 377.000000, reward total was -21.000000. running mean: -19.147188\n",
            "resetting env. episode 378.000000, reward total was -21.000000. running mean: -19.165716\n",
            "resetting env. episode 379.000000, reward total was -21.000000. running mean: -19.184059\n",
            "resetting env. episode 380.000000, reward total was -16.000000. running mean: -19.152218\n",
            "resetting env. episode 381.000000, reward total was -16.000000. running mean: -19.120696\n",
            "resetting env. episode 382.000000, reward total was -20.000000. running mean: -19.129489\n",
            "resetting env. episode 383.000000, reward total was -21.000000. running mean: -19.148194\n",
            "resetting env. episode 384.000000, reward total was -20.000000. running mean: -19.156712\n",
            "resetting env. episode 385.000000, reward total was -18.000000. running mean: -19.145145\n",
            "resetting env. episode 386.000000, reward total was -17.000000. running mean: -19.123694\n",
            "resetting env. episode 387.000000, reward total was -20.000000. running mean: -19.132457\n",
            "resetting env. episode 388.000000, reward total was -18.000000. running mean: -19.121132\n",
            "resetting env. episode 389.000000, reward total was -20.000000. running mean: -19.129921\n",
            "resetting env. episode 390.000000, reward total was -19.000000. running mean: -19.128622\n",
            "resetting env. episode 391.000000, reward total was -19.000000. running mean: -19.127336\n",
            "resetting env. episode 392.000000, reward total was -19.000000. running mean: -19.126062\n",
            "resetting env. episode 393.000000, reward total was -21.000000. running mean: -19.144802\n",
            "resetting env. episode 394.000000, reward total was -20.000000. running mean: -19.153354\n",
            "resetting env. episode 395.000000, reward total was -21.000000. running mean: -19.171820\n",
            "resetting env. episode 396.000000, reward total was -20.000000. running mean: -19.180102\n",
            "resetting env. episode 397.000000, reward total was -19.000000. running mean: -19.178301\n",
            "resetting env. episode 398.000000, reward total was -19.000000. running mean: -19.176518\n",
            "resetting env. episode 399.000000, reward total was -20.000000. running mean: -19.184753\n",
            "resetting env. episode 400.000000, reward total was -17.000000. running mean: -19.162905\n",
            "resetting env. episode 401.000000, reward total was -19.000000. running mean: -19.161276\n",
            "resetting env. episode 402.000000, reward total was -18.000000. running mean: -19.149663\n",
            "resetting env. episode 403.000000, reward total was -19.000000. running mean: -19.148167\n",
            "resetting env. episode 404.000000, reward total was -19.000000. running mean: -19.146685\n",
            "resetting env. episode 405.000000, reward total was -16.000000. running mean: -19.115218\n",
            "resetting env. episode 406.000000, reward total was -19.000000. running mean: -19.114066\n",
            "resetting env. episode 407.000000, reward total was -19.000000. running mean: -19.112925\n",
            "resetting env. episode 408.000000, reward total was -20.000000. running mean: -19.121796\n",
            "resetting env. episode 409.000000, reward total was -20.000000. running mean: -19.130578\n",
            "resetting env. episode 410.000000, reward total was -19.000000. running mean: -19.129272\n",
            "resetting env. episode 411.000000, reward total was -19.000000. running mean: -19.127980\n",
            "resetting env. episode 412.000000, reward total was -19.000000. running mean: -19.126700\n",
            "resetting env. episode 413.000000, reward total was -19.000000. running mean: -19.125433\n",
            "resetting env. episode 414.000000, reward total was -19.000000. running mean: -19.124178\n",
            "resetting env. episode 415.000000, reward total was -16.000000. running mean: -19.092937\n",
            "resetting env. episode 416.000000, reward total was -20.000000. running mean: -19.102007\n",
            "resetting env. episode 417.000000, reward total was -19.000000. running mean: -19.100987\n",
            "resetting env. episode 418.000000, reward total was -19.000000. running mean: -19.099977\n",
            "resetting env. episode 419.000000, reward total was -17.000000. running mean: -19.078978\n",
            "resetting env. episode 420.000000, reward total was -17.000000. running mean: -19.058188\n",
            "resetting env. episode 421.000000, reward total was -21.000000. running mean: -19.077606\n",
            "resetting env. episode 422.000000, reward total was -15.000000. running mean: -19.036830\n",
            "resetting env. episode 423.000000, reward total was -21.000000. running mean: -19.056462\n",
            "resetting env. episode 424.000000, reward total was -19.000000. running mean: -19.055897\n",
            "resetting env. episode 425.000000, reward total was -19.000000. running mean: -19.055338\n",
            "resetting env. episode 426.000000, reward total was -20.000000. running mean: -19.064785\n",
            "resetting env. episode 427.000000, reward total was -21.000000. running mean: -19.084137\n",
            "resetting env. episode 428.000000, reward total was -19.000000. running mean: -19.083295\n",
            "resetting env. episode 429.000000, reward total was -20.000000. running mean: -19.092462\n",
            "resetting env. episode 430.000000, reward total was -20.000000. running mean: -19.101538\n",
            "resetting env. episode 431.000000, reward total was -20.000000. running mean: -19.110522\n",
            "resetting env. episode 432.000000, reward total was -18.000000. running mean: -19.099417\n",
            "resetting env. episode 433.000000, reward total was -21.000000. running mean: -19.118423\n",
            "resetting env. episode 434.000000, reward total was -21.000000. running mean: -19.137239\n",
            "resetting env. episode 435.000000, reward total was -20.000000. running mean: -19.145866\n",
            "resetting env. episode 436.000000, reward total was -20.000000. running mean: -19.154408\n",
            "resetting env. episode 437.000000, reward total was -20.000000. running mean: -19.162864\n",
            "resetting env. episode 438.000000, reward total was -17.000000. running mean: -19.141235\n",
            "resetting env. episode 439.000000, reward total was -19.000000. running mean: -19.139823\n",
            "resetting env. episode 440.000000, reward total was -16.000000. running mean: -19.108424\n",
            "resetting env. episode 441.000000, reward total was -18.000000. running mean: -19.097340\n",
            "resetting env. episode 442.000000, reward total was -20.000000. running mean: -19.106367\n",
            "resetting env. episode 443.000000, reward total was -21.000000. running mean: -19.125303\n",
            "resetting env. episode 444.000000, reward total was -19.000000. running mean: -19.124050\n",
            "resetting env. episode 445.000000, reward total was -19.000000. running mean: -19.122810\n",
            "resetting env. episode 446.000000, reward total was -20.000000. running mean: -19.131582\n",
            "resetting env. episode 447.000000, reward total was -20.000000. running mean: -19.140266\n",
            "resetting env. episode 448.000000, reward total was -19.000000. running mean: -19.138863\n",
            "resetting env. episode 449.000000, reward total was -21.000000. running mean: -19.157474\n",
            "resetting env. episode 450.000000, reward total was -21.000000. running mean: -19.175900\n",
            "resetting env. episode 451.000000, reward total was -20.000000. running mean: -19.184141\n",
            "resetting env. episode 452.000000, reward total was -21.000000. running mean: -19.202299\n",
            "resetting env. episode 453.000000, reward total was -17.000000. running mean: -19.180276\n",
            "resetting env. episode 454.000000, reward total was -18.000000. running mean: -19.168474\n",
            "resetting env. episode 455.000000, reward total was -21.000000. running mean: -19.186789\n",
            "resetting env. episode 456.000000, reward total was -20.000000. running mean: -19.194921\n",
            "resetting env. episode 457.000000, reward total was -17.000000. running mean: -19.172972\n",
            "resetting env. episode 458.000000, reward total was -19.000000. running mean: -19.171242\n",
            "resetting env. episode 459.000000, reward total was -17.000000. running mean: -19.149530\n",
            "resetting env. episode 460.000000, reward total was -21.000000. running mean: -19.168034\n",
            "resetting env. episode 461.000000, reward total was -21.000000. running mean: -19.186354\n",
            "resetting env. episode 462.000000, reward total was -18.000000. running mean: -19.174490\n",
            "resetting env. episode 463.000000, reward total was -16.000000. running mean: -19.142745\n",
            "resetting env. episode 464.000000, reward total was -21.000000. running mean: -19.161318\n",
            "resetting env. episode 465.000000, reward total was -20.000000. running mean: -19.169705\n",
            "resetting env. episode 466.000000, reward total was -17.000000. running mean: -19.148008\n",
            "resetting env. episode 467.000000, reward total was -18.000000. running mean: -19.136528\n",
            "resetting env. episode 468.000000, reward total was -18.000000. running mean: -19.125162\n",
            "resetting env. episode 469.000000, reward total was -19.000000. running mean: -19.123911\n",
            "resetting env. episode 470.000000, reward total was -19.000000. running mean: -19.122672\n",
            "resetting env. episode 471.000000, reward total was -20.000000. running mean: -19.131445\n",
            "resetting env. episode 472.000000, reward total was -17.000000. running mean: -19.110131\n",
            "resetting env. episode 473.000000, reward total was -17.000000. running mean: -19.089029\n",
            "resetting env. episode 474.000000, reward total was -14.000000. running mean: -19.038139\n",
            "resetting env. episode 475.000000, reward total was -19.000000. running mean: -19.037758\n",
            "resetting env. episode 476.000000, reward total was -19.000000. running mean: -19.037380\n",
            "resetting env. episode 477.000000, reward total was -19.000000. running mean: -19.037006\n",
            "resetting env. episode 478.000000, reward total was -18.000000. running mean: -19.026636\n",
            "resetting env. episode 479.000000, reward total was -19.000000. running mean: -19.026370\n",
            "resetting env. episode 480.000000, reward total was -21.000000. running mean: -19.046106\n",
            "resetting env. episode 481.000000, reward total was -19.000000. running mean: -19.045645\n",
            "resetting env. episode 482.000000, reward total was -19.000000. running mean: -19.045189\n",
            "resetting env. episode 483.000000, reward total was -20.000000. running mean: -19.054737\n",
            "resetting env. episode 484.000000, reward total was -19.000000. running mean: -19.054189\n",
            "resetting env. episode 485.000000, reward total was -14.000000. running mean: -19.003647\n",
            "resetting env. episode 486.000000, reward total was -19.000000. running mean: -19.003611\n",
            "resetting env. episode 487.000000, reward total was -21.000000. running mean: -19.023575\n",
            "resetting env. episode 488.000000, reward total was -17.000000. running mean: -19.003339\n",
            "resetting env. episode 489.000000, reward total was -21.000000. running mean: -19.023306\n",
            "resetting env. episode 490.000000, reward total was -19.000000. running mean: -19.023073\n",
            "resetting env. episode 491.000000, reward total was -20.000000. running mean: -19.032842\n",
            "resetting env. episode 492.000000, reward total was -20.000000. running mean: -19.042513\n",
            "resetting env. episode 493.000000, reward total was -17.000000. running mean: -19.022088\n",
            "resetting env. episode 494.000000, reward total was -20.000000. running mean: -19.031867\n",
            "resetting env. episode 495.000000, reward total was -19.000000. running mean: -19.031549\n",
            "resetting env. episode 496.000000, reward total was -17.000000. running mean: -19.011233\n",
            "resetting env. episode 497.000000, reward total was -19.000000. running mean: -19.011121\n",
            "resetting env. episode 498.000000, reward total was -19.000000. running mean: -19.011010\n",
            "resetting env. episode 499.000000, reward total was -17.000000. running mean: -18.990900\n",
            "resetting env. episode 500.000000, reward total was -19.000000. running mean: -18.990991\n",
            "resetting env. episode 501.000000, reward total was -21.000000. running mean: -19.011081\n",
            "resetting env. episode 502.000000, reward total was -20.000000. running mean: -19.020970\n",
            "resetting env. episode 503.000000, reward total was -19.000000. running mean: -19.020760\n",
            "resetting env. episode 504.000000, reward total was -19.000000. running mean: -19.020553\n",
            "resetting env. episode 505.000000, reward total was -18.000000. running mean: -19.010347\n",
            "resetting env. episode 506.000000, reward total was -21.000000. running mean: -19.030244\n",
            "resetting env. episode 507.000000, reward total was -18.000000. running mean: -19.019941\n",
            "resetting env. episode 508.000000, reward total was -18.000000. running mean: -19.009742\n",
            "resetting env. episode 509.000000, reward total was -19.000000. running mean: -19.009644\n",
            "resetting env. episode 510.000000, reward total was -20.000000. running mean: -19.019548\n",
            "resetting env. episode 511.000000, reward total was -19.000000. running mean: -19.019352\n",
            "resetting env. episode 512.000000, reward total was -20.000000. running mean: -19.029159\n",
            "resetting env. episode 513.000000, reward total was -18.000000. running mean: -19.018867\n",
            "resetting env. episode 514.000000, reward total was -21.000000. running mean: -19.038679\n",
            "resetting env. episode 515.000000, reward total was -20.000000. running mean: -19.048292\n",
            "resetting env. episode 516.000000, reward total was -21.000000. running mean: -19.067809\n",
            "resetting env. episode 517.000000, reward total was -19.000000. running mean: -19.067131\n",
            "resetting env. episode 518.000000, reward total was -18.000000. running mean: -19.056460\n",
            "resetting env. episode 519.000000, reward total was -21.000000. running mean: -19.075895\n",
            "resetting env. episode 520.000000, reward total was -19.000000. running mean: -19.075136\n",
            "resetting env. episode 521.000000, reward total was -21.000000. running mean: -19.094385\n",
            "resetting env. episode 522.000000, reward total was -18.000000. running mean: -19.083441\n",
            "resetting env. episode 523.000000, reward total was -18.000000. running mean: -19.072606\n",
            "resetting env. episode 524.000000, reward total was -19.000000. running mean: -19.071880\n",
            "resetting env. episode 525.000000, reward total was -20.000000. running mean: -19.081162\n",
            "resetting env. episode 526.000000, reward total was -18.000000. running mean: -19.070350\n",
            "resetting env. episode 527.000000, reward total was -21.000000. running mean: -19.089646\n",
            "resetting env. episode 528.000000, reward total was -20.000000. running mean: -19.098750\n",
            "resetting env. episode 529.000000, reward total was -16.000000. running mean: -19.067762\n",
            "resetting env. episode 530.000000, reward total was -21.000000. running mean: -19.087085\n",
            "resetting env. episode 531.000000, reward total was -21.000000. running mean: -19.106214\n",
            "resetting env. episode 532.000000, reward total was -19.000000. running mean: -19.105152\n",
            "resetting env. episode 533.000000, reward total was -19.000000. running mean: -19.104100\n",
            "resetting env. episode 534.000000, reward total was -20.000000. running mean: -19.113059\n",
            "resetting env. episode 535.000000, reward total was -18.000000. running mean: -19.101929\n",
            "resetting env. episode 536.000000, reward total was -18.000000. running mean: -19.090909\n",
            "resetting env. episode 537.000000, reward total was -20.000000. running mean: -19.100000\n",
            "resetting env. episode 538.000000, reward total was -17.000000. running mean: -19.079000\n",
            "resetting env. episode 539.000000, reward total was -18.000000. running mean: -19.068210\n",
            "resetting env. episode 540.000000, reward total was -20.000000. running mean: -19.077528\n",
            "resetting env. episode 541.000000, reward total was -21.000000. running mean: -19.096753\n",
            "resetting env. episode 542.000000, reward total was -17.000000. running mean: -19.075785\n",
            "resetting env. episode 543.000000, reward total was -20.000000. running mean: -19.085028\n",
            "resetting env. episode 544.000000, reward total was -19.000000. running mean: -19.084177\n",
            "resetting env. episode 545.000000, reward total was -21.000000. running mean: -19.103336\n",
            "resetting env. episode 546.000000, reward total was -19.000000. running mean: -19.102302\n",
            "resetting env. episode 547.000000, reward total was -18.000000. running mean: -19.091279\n",
            "resetting env. episode 548.000000, reward total was -20.000000. running mean: -19.100366\n",
            "resetting env. episode 549.000000, reward total was -20.000000. running mean: -19.109363\n",
            "resetting env. episode 550.000000, reward total was -18.000000. running mean: -19.098269\n",
            "resetting env. episode 551.000000, reward total was -20.000000. running mean: -19.107286\n",
            "resetting env. episode 552.000000, reward total was -21.000000. running mean: -19.126214\n",
            "resetting env. episode 553.000000, reward total was -19.000000. running mean: -19.124951\n",
            "resetting env. episode 554.000000, reward total was -21.000000. running mean: -19.143702\n",
            "resetting env. episode 555.000000, reward total was -19.000000. running mean: -19.142265\n",
            "resetting env. episode 556.000000, reward total was -20.000000. running mean: -19.150842\n",
            "resetting env. episode 557.000000, reward total was -20.000000. running mean: -19.159334\n",
            "resetting env. episode 558.000000, reward total was -19.000000. running mean: -19.157740\n",
            "resetting env. episode 559.000000, reward total was -21.000000. running mean: -19.176163\n",
            "resetting env. episode 560.000000, reward total was -20.000000. running mean: -19.184401\n",
            "resetting env. episode 561.000000, reward total was -15.000000. running mean: -19.142557\n",
            "resetting env. episode 562.000000, reward total was -21.000000. running mean: -19.161132\n",
            "resetting env. episode 563.000000, reward total was -21.000000. running mean: -19.179520\n",
            "resetting env. episode 564.000000, reward total was -18.000000. running mean: -19.167725\n",
            "resetting env. episode 565.000000, reward total was -19.000000. running mean: -19.166048\n",
            "resetting env. episode 566.000000, reward total was -18.000000. running mean: -19.154388\n",
            "resetting env. episode 567.000000, reward total was -17.000000. running mean: -19.132844\n",
            "resetting env. episode 568.000000, reward total was -20.000000. running mean: -19.141515\n",
            "resetting env. episode 569.000000, reward total was -21.000000. running mean: -19.160100\n",
            "resetting env. episode 570.000000, reward total was -21.000000. running mean: -19.178499\n",
            "resetting env. episode 571.000000, reward total was -21.000000. running mean: -19.196714\n",
            "resetting env. episode 572.000000, reward total was -19.000000. running mean: -19.194747\n",
            "resetting env. episode 573.000000, reward total was -20.000000. running mean: -19.202799\n",
            "resetting env. episode 574.000000, reward total was -18.000000. running mean: -19.190771\n",
            "resetting env. episode 575.000000, reward total was -17.000000. running mean: -19.168864\n",
            "resetting env. episode 576.000000, reward total was -20.000000. running mean: -19.177175\n",
            "resetting env. episode 577.000000, reward total was -15.000000. running mean: -19.135403\n",
            "resetting env. episode 578.000000, reward total was -17.000000. running mean: -19.114049\n",
            "resetting env. episode 579.000000, reward total was -21.000000. running mean: -19.132909\n",
            "resetting env. episode 580.000000, reward total was -21.000000. running mean: -19.151580\n",
            "resetting env. episode 581.000000, reward total was -21.000000. running mean: -19.170064\n",
            "resetting env. episode 582.000000, reward total was -19.000000. running mean: -19.168363\n",
            "resetting env. episode 583.000000, reward total was -20.000000. running mean: -19.176680\n",
            "resetting env. episode 584.000000, reward total was -18.000000. running mean: -19.164913\n",
            "resetting env. episode 585.000000, reward total was -17.000000. running mean: -19.143264\n",
            "resetting env. episode 586.000000, reward total was -20.000000. running mean: -19.151831\n",
            "resetting env. episode 587.000000, reward total was -18.000000. running mean: -19.140313\n",
            "resetting env. episode 588.000000, reward total was -19.000000. running mean: -19.138910\n",
            "resetting env. episode 589.000000, reward total was -21.000000. running mean: -19.157521\n",
            "resetting env. episode 590.000000, reward total was -21.000000. running mean: -19.175945\n",
            "resetting env. episode 591.000000, reward total was -19.000000. running mean: -19.174186\n",
            "resetting env. episode 592.000000, reward total was -19.000000. running mean: -19.172444\n",
            "resetting env. episode 593.000000, reward total was -21.000000. running mean: -19.190720\n",
            "resetting env. episode 594.000000, reward total was -21.000000. running mean: -19.208812\n",
            "resetting env. episode 595.000000, reward total was -18.000000. running mean: -19.196724\n",
            "resetting env. episode 596.000000, reward total was -19.000000. running mean: -19.194757\n",
            "resetting env. episode 597.000000, reward total was -13.000000. running mean: -19.132810\n",
            "resetting env. episode 598.000000, reward total was -20.000000. running mean: -19.141481\n",
            "resetting env. episode 599.000000, reward total was -17.000000. running mean: -19.120067\n",
            "resetting env. episode 600.000000, reward total was -19.000000. running mean: -19.118866\n",
            "resetting env. episode 601.000000, reward total was -17.000000. running mean: -19.097677\n",
            "resetting env. episode 602.000000, reward total was -19.000000. running mean: -19.096701\n",
            "resetting env. episode 603.000000, reward total was -18.000000. running mean: -19.085733\n",
            "resetting env. episode 604.000000, reward total was -18.000000. running mean: -19.074876\n",
            "resetting env. episode 605.000000, reward total was -19.000000. running mean: -19.074127\n",
            "resetting env. episode 606.000000, reward total was -19.000000. running mean: -19.073386\n",
            "resetting env. episode 607.000000, reward total was -19.000000. running mean: -19.072652\n",
            "resetting env. episode 608.000000, reward total was -20.000000. running mean: -19.081926\n",
            "resetting env. episode 609.000000, reward total was -20.000000. running mean: -19.091106\n",
            "resetting env. episode 610.000000, reward total was -17.000000. running mean: -19.070195\n",
            "resetting env. episode 611.000000, reward total was -19.000000. running mean: -19.069493\n",
            "resetting env. episode 612.000000, reward total was -18.000000. running mean: -19.058799\n",
            "resetting env. episode 613.000000, reward total was -20.000000. running mean: -19.068211\n",
            "resetting env. episode 614.000000, reward total was -19.000000. running mean: -19.067528\n",
            "resetting env. episode 615.000000, reward total was -17.000000. running mean: -19.046853\n",
            "resetting env. episode 616.000000, reward total was -18.000000. running mean: -19.036385\n",
            "resetting env. episode 617.000000, reward total was -20.000000. running mean: -19.046021\n",
            "resetting env. episode 618.000000, reward total was -18.000000. running mean: -19.035561\n",
            "resetting env. episode 619.000000, reward total was -21.000000. running mean: -19.055205\n",
            "resetting env. episode 620.000000, reward total was -21.000000. running mean: -19.074653\n",
            "resetting env. episode 621.000000, reward total was -19.000000. running mean: -19.073906\n",
            "resetting env. episode 622.000000, reward total was -18.000000. running mean: -19.063167\n",
            "resetting env. episode 623.000000, reward total was -16.000000. running mean: -19.032536\n",
            "resetting env. episode 624.000000, reward total was -21.000000. running mean: -19.052210\n",
            "resetting env. episode 625.000000, reward total was -18.000000. running mean: -19.041688\n",
            "resetting env. episode 626.000000, reward total was -21.000000. running mean: -19.061271\n",
            "resetting env. episode 627.000000, reward total was -16.000000. running mean: -19.030659\n",
            "resetting env. episode 628.000000, reward total was -19.000000. running mean: -19.030352\n",
            "resetting env. episode 629.000000, reward total was -20.000000. running mean: -19.040048\n",
            "resetting env. episode 630.000000, reward total was -19.000000. running mean: -19.039648\n",
            "resetting env. episode 631.000000, reward total was -19.000000. running mean: -19.039252\n",
            "resetting env. episode 632.000000, reward total was -19.000000. running mean: -19.038859\n",
            "resetting env. episode 633.000000, reward total was -20.000000. running mean: -19.048470\n",
            "resetting env. episode 634.000000, reward total was -19.000000. running mean: -19.047986\n",
            "resetting env. episode 635.000000, reward total was -18.000000. running mean: -19.037506\n",
            "resetting env. episode 636.000000, reward total was -16.000000. running mean: -19.007131\n",
            "resetting env. episode 637.000000, reward total was -18.000000. running mean: -18.997059\n",
            "resetting env. episode 638.000000, reward total was -21.000000. running mean: -19.017089\n",
            "resetting env. episode 639.000000, reward total was -21.000000. running mean: -19.036918\n",
            "resetting env. episode 640.000000, reward total was -17.000000. running mean: -19.016549\n",
            "resetting env. episode 641.000000, reward total was -18.000000. running mean: -19.006383\n",
            "resetting env. episode 642.000000, reward total was -20.000000. running mean: -19.016320\n",
            "resetting env. episode 643.000000, reward total was -19.000000. running mean: -19.016156\n",
            "resetting env. episode 644.000000, reward total was -19.000000. running mean: -19.015995\n",
            "resetting env. episode 645.000000, reward total was -20.000000. running mean: -19.025835\n",
            "resetting env. episode 646.000000, reward total was -19.000000. running mean: -19.025576\n",
            "resetting env. episode 647.000000, reward total was -18.000000. running mean: -19.015321\n",
            "resetting env. episode 648.000000, reward total was -20.000000. running mean: -19.025167\n",
            "resetting env. episode 649.000000, reward total was -20.000000. running mean: -19.034916\n",
            "resetting env. episode 650.000000, reward total was -20.000000. running mean: -19.044567\n",
            "resetting env. episode 651.000000, reward total was -21.000000. running mean: -19.064121\n",
            "resetting env. episode 652.000000, reward total was -21.000000. running mean: -19.083480\n",
            "resetting env. episode 653.000000, reward total was -18.000000. running mean: -19.072645\n",
            "resetting env. episode 654.000000, reward total was -19.000000. running mean: -19.071919\n",
            "resetting env. episode 655.000000, reward total was -18.000000. running mean: -19.061199\n",
            "resetting env. episode 656.000000, reward total was -19.000000. running mean: -19.060587\n",
            "resetting env. episode 657.000000, reward total was -20.000000. running mean: -19.069981\n",
            "resetting env. episode 658.000000, reward total was -20.000000. running mean: -19.079282\n",
            "resetting env. episode 659.000000, reward total was -20.000000. running mean: -19.088489\n",
            "resetting env. episode 660.000000, reward total was -18.000000. running mean: -19.077604\n",
            "resetting env. episode 661.000000, reward total was -21.000000. running mean: -19.096828\n",
            "resetting env. episode 662.000000, reward total was -16.000000. running mean: -19.065860\n",
            "resetting env. episode 663.000000, reward total was -16.000000. running mean: -19.035201\n",
            "resetting env. episode 664.000000, reward total was -19.000000. running mean: -19.034849\n",
            "resetting env. episode 665.000000, reward total was -18.000000. running mean: -19.024501\n",
            "resetting env. episode 666.000000, reward total was -20.000000. running mean: -19.034256\n",
            "resetting env. episode 667.000000, reward total was -19.000000. running mean: -19.033913\n",
            "resetting env. episode 668.000000, reward total was -15.000000. running mean: -18.993574\n",
            "resetting env. episode 669.000000, reward total was -20.000000. running mean: -19.003638\n",
            "resetting env. episode 670.000000, reward total was -21.000000. running mean: -19.023602\n",
            "resetting env. episode 671.000000, reward total was -20.000000. running mean: -19.033366\n",
            "resetting env. episode 672.000000, reward total was -18.000000. running mean: -19.023032\n",
            "resetting env. episode 673.000000, reward total was -15.000000. running mean: -18.982802\n",
            "resetting env. episode 674.000000, reward total was -20.000000. running mean: -18.992974\n",
            "resetting env. episode 675.000000, reward total was -19.000000. running mean: -18.993044\n",
            "resetting env. episode 676.000000, reward total was -19.000000. running mean: -18.993114\n",
            "resetting env. episode 677.000000, reward total was -21.000000. running mean: -19.013182\n",
            "resetting env. episode 678.000000, reward total was -21.000000. running mean: -19.033051\n",
            "resetting env. episode 679.000000, reward total was -20.000000. running mean: -19.042720\n",
            "resetting env. episode 680.000000, reward total was -20.000000. running mean: -19.052293\n",
            "resetting env. episode 681.000000, reward total was -17.000000. running mean: -19.031770\n",
            "resetting env. episode 682.000000, reward total was -17.000000. running mean: -19.011452\n",
            "resetting env. episode 683.000000, reward total was -19.000000. running mean: -19.011338\n",
            "resetting env. episode 684.000000, reward total was -19.000000. running mean: -19.011224\n",
            "resetting env. episode 685.000000, reward total was -19.000000. running mean: -19.011112\n",
            "resetting env. episode 686.000000, reward total was -20.000000. running mean: -19.021001\n",
            "resetting env. episode 687.000000, reward total was -19.000000. running mean: -19.020791\n",
            "resetting env. episode 688.000000, reward total was -20.000000. running mean: -19.030583\n",
            "resetting env. episode 689.000000, reward total was -21.000000. running mean: -19.050277\n",
            "resetting env. episode 690.000000, reward total was -21.000000. running mean: -19.069774\n",
            "resetting env. episode 691.000000, reward total was -17.000000. running mean: -19.049077\n",
            "resetting env. episode 692.000000, reward total was -14.000000. running mean: -18.998586\n",
            "resetting env. episode 693.000000, reward total was -19.000000. running mean: -18.998600\n",
            "resetting env. episode 694.000000, reward total was -21.000000. running mean: -19.018614\n",
            "resetting env. episode 695.000000, reward total was -17.000000. running mean: -18.998428\n",
            "resetting env. episode 696.000000, reward total was -19.000000. running mean: -18.998444\n",
            "resetting env. episode 697.000000, reward total was -17.000000. running mean: -18.978459\n",
            "resetting env. episode 698.000000, reward total was -21.000000. running mean: -18.998675\n",
            "resetting env. episode 699.000000, reward total was -21.000000. running mean: -19.018688\n",
            "resetting env. episode 700.000000, reward total was -20.000000. running mean: -19.028501\n",
            "resetting env. episode 701.000000, reward total was -21.000000. running mean: -19.048216\n",
            "resetting env. episode 702.000000, reward total was -20.000000. running mean: -19.057734\n",
            "resetting env. episode 703.000000, reward total was -17.000000. running mean: -19.037157\n",
            "resetting env. episode 704.000000, reward total was -19.000000. running mean: -19.036785\n",
            "resetting env. episode 705.000000, reward total was -19.000000. running mean: -19.036417\n",
            "resetting env. episode 706.000000, reward total was -19.000000. running mean: -19.036053\n",
            "resetting env. episode 707.000000, reward total was -19.000000. running mean: -19.035692\n",
            "resetting env. episode 708.000000, reward total was -18.000000. running mean: -19.025335\n",
            "resetting env. episode 709.000000, reward total was -19.000000. running mean: -19.025082\n",
            "resetting env. episode 710.000000, reward total was -16.000000. running mean: -18.994831\n",
            "resetting env. episode 711.000000, reward total was -20.000000. running mean: -19.004883\n",
            "resetting env. episode 712.000000, reward total was -20.000000. running mean: -19.014834\n",
            "resetting env. episode 713.000000, reward total was -21.000000. running mean: -19.034686\n",
            "resetting env. episode 714.000000, reward total was -19.000000. running mean: -19.034339\n",
            "resetting env. episode 715.000000, reward total was -16.000000. running mean: -19.003996\n",
            "resetting env. episode 716.000000, reward total was -19.000000. running mean: -19.003956\n",
            "resetting env. episode 717.000000, reward total was -20.000000. running mean: -19.013916\n",
            "resetting env. episode 718.000000, reward total was -20.000000. running mean: -19.023777\n",
            "resetting env. episode 719.000000, reward total was -15.000000. running mean: -18.983539\n",
            "resetting env. episode 720.000000, reward total was -17.000000. running mean: -18.963704\n",
            "resetting env. episode 721.000000, reward total was -21.000000. running mean: -18.984067\n",
            "resetting env. episode 722.000000, reward total was -19.000000. running mean: -18.984226\n",
            "resetting env. episode 723.000000, reward total was -20.000000. running mean: -18.994384\n",
            "resetting env. episode 724.000000, reward total was -15.000000. running mean: -18.954440\n",
            "resetting env. episode 725.000000, reward total was -19.000000. running mean: -18.954896\n",
            "resetting env. episode 726.000000, reward total was -17.000000. running mean: -18.935347\n",
            "resetting env. episode 727.000000, reward total was -19.000000. running mean: -18.935993\n",
            "resetting env. episode 728.000000, reward total was -19.000000. running mean: -18.936633\n",
            "resetting env. episode 729.000000, reward total was -20.000000. running mean: -18.947267\n",
            "resetting env. episode 730.000000, reward total was -21.000000. running mean: -18.967794\n",
            "resetting env. episode 731.000000, reward total was -16.000000. running mean: -18.938116\n",
            "resetting env. episode 732.000000, reward total was -14.000000. running mean: -18.888735\n",
            "resetting env. episode 733.000000, reward total was -21.000000. running mean: -18.909848\n",
            "resetting env. episode 734.000000, reward total was -21.000000. running mean: -18.930749\n",
            "resetting env. episode 735.000000, reward total was -19.000000. running mean: -18.931442\n",
            "resetting env. episode 736.000000, reward total was -20.000000. running mean: -18.942127\n",
            "resetting env. episode 737.000000, reward total was -17.000000. running mean: -18.922706\n",
            "resetting env. episode 738.000000, reward total was -21.000000. running mean: -18.943479\n",
            "resetting env. episode 739.000000, reward total was -17.000000. running mean: -18.924044\n",
            "resetting env. episode 740.000000, reward total was -19.000000. running mean: -18.924804\n",
            "resetting env. episode 741.000000, reward total was -20.000000. running mean: -18.935556\n",
            "resetting env. episode 742.000000, reward total was -21.000000. running mean: -18.956200\n",
            "resetting env. episode 743.000000, reward total was -17.000000. running mean: -18.936638\n",
            "resetting env. episode 744.000000, reward total was -16.000000. running mean: -18.907272\n",
            "resetting env. episode 745.000000, reward total was -20.000000. running mean: -18.918199\n",
            "resetting env. episode 746.000000, reward total was -18.000000. running mean: -18.909017\n",
            "resetting env. episode 747.000000, reward total was -17.000000. running mean: -18.889927\n",
            "resetting env. episode 748.000000, reward total was -19.000000. running mean: -18.891028\n",
            "resetting env. episode 749.000000, reward total was -17.000000. running mean: -18.872117\n",
            "resetting env. episode 750.000000, reward total was -19.000000. running mean: -18.873396\n",
            "resetting env. episode 751.000000, reward total was -17.000000. running mean: -18.854662\n",
            "resetting env. episode 752.000000, reward total was -18.000000. running mean: -18.846116\n",
            "resetting env. episode 753.000000, reward total was -18.000000. running mean: -18.837654\n",
            "resetting env. episode 754.000000, reward total was -19.000000. running mean: -18.839278\n",
            "resetting env. episode 755.000000, reward total was -15.000000. running mean: -18.800885\n",
            "resetting env. episode 756.000000, reward total was -20.000000. running mean: -18.812876\n",
            "resetting env. episode 757.000000, reward total was -19.000000. running mean: -18.814748\n",
            "resetting env. episode 758.000000, reward total was -20.000000. running mean: -18.826600\n",
            "resetting env. episode 759.000000, reward total was -20.000000. running mean: -18.838334\n",
            "resetting env. episode 760.000000, reward total was -19.000000. running mean: -18.839951\n",
            "resetting env. episode 761.000000, reward total was -19.000000. running mean: -18.841551\n",
            "resetting env. episode 762.000000, reward total was -19.000000. running mean: -18.843136\n",
            "resetting env. episode 763.000000, reward total was -19.000000. running mean: -18.844704\n",
            "resetting env. episode 764.000000, reward total was -16.000000. running mean: -18.816257\n",
            "resetting env. episode 765.000000, reward total was -19.000000. running mean: -18.818095\n",
            "resetting env. episode 766.000000, reward total was -19.000000. running mean: -18.819914\n",
            "resetting env. episode 767.000000, reward total was -19.000000. running mean: -18.821715\n",
            "resetting env. episode 768.000000, reward total was -14.000000. running mean: -18.773497\n",
            "resetting env. episode 769.000000, reward total was -16.000000. running mean: -18.745762\n",
            "resetting env. episode 770.000000, reward total was -19.000000. running mean: -18.748305\n",
            "resetting env. episode 771.000000, reward total was -16.000000. running mean: -18.720822\n",
            "resetting env. episode 772.000000, reward total was -21.000000. running mean: -18.743614\n",
            "resetting env. episode 773.000000, reward total was -21.000000. running mean: -18.766177\n",
            "resetting env. episode 774.000000, reward total was -17.000000. running mean: -18.748516\n",
            "resetting env. episode 775.000000, reward total was -19.000000. running mean: -18.751031\n",
            "resetting env. episode 776.000000, reward total was -16.000000. running mean: -18.723520\n",
            "resetting env. episode 777.000000, reward total was -19.000000. running mean: -18.726285\n",
            "resetting env. episode 778.000000, reward total was -19.000000. running mean: -18.729022\n",
            "resetting env. episode 779.000000, reward total was -20.000000. running mean: -18.741732\n",
            "resetting env. episode 780.000000, reward total was -19.000000. running mean: -18.744315\n",
            "resetting env. episode 781.000000, reward total was -20.000000. running mean: -18.756871\n",
            "resetting env. episode 782.000000, reward total was -18.000000. running mean: -18.749303\n",
            "resetting env. episode 783.000000, reward total was -16.000000. running mean: -18.721810\n",
            "resetting env. episode 784.000000, reward total was -21.000000. running mean: -18.744592\n",
            "resetting env. episode 785.000000, reward total was -17.000000. running mean: -18.727146\n",
            "resetting env. episode 786.000000, reward total was -18.000000. running mean: -18.719874\n",
            "resetting env. episode 787.000000, reward total was -20.000000. running mean: -18.732676\n",
            "resetting env. episode 788.000000, reward total was -17.000000. running mean: -18.715349\n",
            "resetting env. episode 789.000000, reward total was -20.000000. running mean: -18.728195\n",
            "resetting env. episode 790.000000, reward total was -19.000000. running mean: -18.730913\n",
            "resetting env. episode 791.000000, reward total was -18.000000. running mean: -18.723604\n",
            "resetting env. episode 792.000000, reward total was -17.000000. running mean: -18.706368\n",
            "resetting env. episode 793.000000, reward total was -17.000000. running mean: -18.689304\n",
            "resetting env. episode 794.000000, reward total was -20.000000. running mean: -18.702411\n",
            "resetting env. episode 795.000000, reward total was -19.000000. running mean: -18.705387\n",
            "resetting env. episode 796.000000, reward total was -21.000000. running mean: -18.728333\n",
            "resetting env. episode 797.000000, reward total was -21.000000. running mean: -18.751050\n",
            "resetting env. episode 798.000000, reward total was -20.000000. running mean: -18.763540\n",
            "resetting env. episode 799.000000, reward total was -20.000000. running mean: -18.775904\n",
            "resetting env. episode 800.000000, reward total was -17.000000. running mean: -18.758145\n",
            "resetting env. episode 801.000000, reward total was -18.000000. running mean: -18.750564\n",
            "resetting env. episode 802.000000, reward total was -20.000000. running mean: -18.763058\n",
            "resetting env. episode 803.000000, reward total was -19.000000. running mean: -18.765428\n",
            "resetting env. episode 804.000000, reward total was -20.000000. running mean: -18.777773\n",
            "resetting env. episode 805.000000, reward total was -19.000000. running mean: -18.779995\n",
            "resetting env. episode 806.000000, reward total was -17.000000. running mean: -18.762196\n",
            "resetting env. episode 807.000000, reward total was -18.000000. running mean: -18.754574\n",
            "resetting env. episode 808.000000, reward total was -19.000000. running mean: -18.757028\n",
            "resetting env. episode 809.000000, reward total was -19.000000. running mean: -18.759458\n",
            "resetting env. episode 810.000000, reward total was -21.000000. running mean: -18.781863\n",
            "resetting env. episode 811.000000, reward total was -18.000000. running mean: -18.774044\n",
            "resetting env. episode 812.000000, reward total was -20.000000. running mean: -18.786304\n",
            "resetting env. episode 813.000000, reward total was -19.000000. running mean: -18.788441\n",
            "resetting env. episode 814.000000, reward total was -20.000000. running mean: -18.800556\n",
            "resetting env. episode 815.000000, reward total was -17.000000. running mean: -18.782551\n",
            "resetting env. episode 816.000000, reward total was -17.000000. running mean: -18.764725\n",
            "resetting env. episode 817.000000, reward total was -20.000000. running mean: -18.777078\n",
            "resetting env. episode 818.000000, reward total was -20.000000. running mean: -18.789307\n",
            "resetting env. episode 819.000000, reward total was -21.000000. running mean: -18.811414\n",
            "resetting env. episode 820.000000, reward total was -16.000000. running mean: -18.783300\n",
            "resetting env. episode 821.000000, reward total was -18.000000. running mean: -18.775467\n",
            "resetting env. episode 822.000000, reward total was -18.000000. running mean: -18.767712\n",
            "resetting env. episode 823.000000, reward total was -19.000000. running mean: -18.770035\n",
            "resetting env. episode 824.000000, reward total was -17.000000. running mean: -18.752335\n",
            "resetting env. episode 825.000000, reward total was -17.000000. running mean: -18.734812\n",
            "resetting env. episode 826.000000, reward total was -19.000000. running mean: -18.737464\n",
            "resetting env. episode 827.000000, reward total was -19.000000. running mean: -18.740089\n",
            "resetting env. episode 828.000000, reward total was -16.000000. running mean: -18.712688\n",
            "resetting env. episode 829.000000, reward total was -18.000000. running mean: -18.705561\n",
            "resetting env. episode 830.000000, reward total was -17.000000. running mean: -18.688506\n",
            "resetting env. episode 831.000000, reward total was -17.000000. running mean: -18.671620\n",
            "resetting env. episode 832.000000, reward total was -19.000000. running mean: -18.674904\n",
            "resetting env. episode 833.000000, reward total was -19.000000. running mean: -18.678155\n",
            "resetting env. episode 834.000000, reward total was -21.000000. running mean: -18.701374\n",
            "resetting env. episode 835.000000, reward total was -18.000000. running mean: -18.694360\n",
            "resetting env. episode 836.000000, reward total was -18.000000. running mean: -18.687416\n",
            "resetting env. episode 837.000000, reward total was -20.000000. running mean: -18.700542\n",
            "resetting env. episode 838.000000, reward total was -18.000000. running mean: -18.693537\n",
            "resetting env. episode 839.000000, reward total was -19.000000. running mean: -18.696601\n",
            "resetting env. episode 840.000000, reward total was -18.000000. running mean: -18.689635\n",
            "resetting env. episode 841.000000, reward total was -19.000000. running mean: -18.692739\n",
            "resetting env. episode 842.000000, reward total was -18.000000. running mean: -18.685812\n",
            "resetting env. episode 843.000000, reward total was -19.000000. running mean: -18.688954\n",
            "resetting env. episode 844.000000, reward total was -20.000000. running mean: -18.702064\n",
            "resetting env. episode 845.000000, reward total was -17.000000. running mean: -18.685043\n",
            "resetting env. episode 846.000000, reward total was -19.000000. running mean: -18.688193\n",
            "resetting env. episode 847.000000, reward total was -21.000000. running mean: -18.711311\n",
            "resetting env. episode 848.000000, reward total was -20.000000. running mean: -18.724198\n",
            "resetting env. episode 849.000000, reward total was -20.000000. running mean: -18.736956\n",
            "resetting env. episode 850.000000, reward total was -19.000000. running mean: -18.739586\n",
            "resetting env. episode 851.000000, reward total was -17.000000. running mean: -18.722190\n",
            "resetting env. episode 852.000000, reward total was -19.000000. running mean: -18.724969\n",
            "resetting env. episode 853.000000, reward total was -19.000000. running mean: -18.727719\n",
            "resetting env. episode 854.000000, reward total was -18.000000. running mean: -18.720442\n",
            "resetting env. episode 855.000000, reward total was -20.000000. running mean: -18.733237\n",
            "resetting env. episode 856.000000, reward total was -19.000000. running mean: -18.735905\n",
            "resetting env. episode 857.000000, reward total was -20.000000. running mean: -18.748546\n",
            "resetting env. episode 858.000000, reward total was -18.000000. running mean: -18.741060\n",
            "resetting env. episode 859.000000, reward total was -19.000000. running mean: -18.743650\n",
            "resetting env. episode 860.000000, reward total was -15.000000. running mean: -18.706213\n",
            "resetting env. episode 861.000000, reward total was -19.000000. running mean: -18.709151\n",
            "resetting env. episode 862.000000, reward total was -18.000000. running mean: -18.702060\n",
            "resetting env. episode 863.000000, reward total was -20.000000. running mean: -18.715039\n",
            "resetting env. episode 864.000000, reward total was -20.000000. running mean: -18.727889\n",
            "resetting env. episode 865.000000, reward total was -20.000000. running mean: -18.740610\n",
            "resetting env. episode 866.000000, reward total was -19.000000. running mean: -18.743204\n",
            "resetting env. episode 867.000000, reward total was -17.000000. running mean: -18.725772\n",
            "resetting env. episode 868.000000, reward total was -15.000000. running mean: -18.688514\n",
            "resetting env. episode 869.000000, reward total was -18.000000. running mean: -18.681629\n",
            "resetting env. episode 870.000000, reward total was -16.000000. running mean: -18.654812\n",
            "resetting env. episode 871.000000, reward total was -18.000000. running mean: -18.648264\n",
            "resetting env. episode 872.000000, reward total was -21.000000. running mean: -18.671782\n",
            "resetting env. episode 873.000000, reward total was -19.000000. running mean: -18.675064\n",
            "resetting env. episode 874.000000, reward total was -21.000000. running mean: -18.698313\n",
            "resetting env. episode 875.000000, reward total was -17.000000. running mean: -18.681330\n",
            "resetting env. episode 876.000000, reward total was -20.000000. running mean: -18.694517\n",
            "resetting env. episode 877.000000, reward total was -15.000000. running mean: -18.657572\n",
            "resetting env. episode 878.000000, reward total was -19.000000. running mean: -18.660996\n",
            "resetting env. episode 879.000000, reward total was -18.000000. running mean: -18.654386\n",
            "resetting env. episode 880.000000, reward total was -20.000000. running mean: -18.667842\n",
            "resetting env. episode 881.000000, reward total was -19.000000. running mean: -18.671164\n",
            "resetting env. episode 882.000000, reward total was -17.000000. running mean: -18.654452\n",
            "resetting env. episode 883.000000, reward total was -17.000000. running mean: -18.637908\n",
            "resetting env. episode 884.000000, reward total was -20.000000. running mean: -18.651528\n",
            "resetting env. episode 885.000000, reward total was -18.000000. running mean: -18.645013\n",
            "resetting env. episode 886.000000, reward total was -19.000000. running mean: -18.648563\n",
            "resetting env. episode 887.000000, reward total was -17.000000. running mean: -18.632077\n",
            "resetting env. episode 888.000000, reward total was -19.000000. running mean: -18.635757\n",
            "resetting env. episode 889.000000, reward total was -21.000000. running mean: -18.659399\n",
            "resetting env. episode 890.000000, reward total was -20.000000. running mean: -18.672805\n",
            "resetting env. episode 891.000000, reward total was -17.000000. running mean: -18.656077\n",
            "resetting env. episode 892.000000, reward total was -17.000000. running mean: -18.639516\n",
            "resetting env. episode 893.000000, reward total was -20.000000. running mean: -18.653121\n",
            "resetting env. episode 894.000000, reward total was -17.000000. running mean: -18.636590\n",
            "resetting env. episode 895.000000, reward total was -15.000000. running mean: -18.600224\n",
            "resetting env. episode 896.000000, reward total was -21.000000. running mean: -18.624222\n",
            "resetting env. episode 897.000000, reward total was -19.000000. running mean: -18.627980\n",
            "resetting env. episode 898.000000, reward total was -19.000000. running mean: -18.631700\n",
            "resetting env. episode 899.000000, reward total was -15.000000. running mean: -18.595383\n",
            "resetting env. episode 900.000000, reward total was -19.000000. running mean: -18.599429\n",
            "resetting env. episode 901.000000, reward total was -19.000000. running mean: -18.603435\n",
            "resetting env. episode 902.000000, reward total was -19.000000. running mean: -18.607400\n",
            "resetting env. episode 903.000000, reward total was -21.000000. running mean: -18.631326\n",
            "resetting env. episode 904.000000, reward total was -17.000000. running mean: -18.615013\n",
            "resetting env. episode 905.000000, reward total was -21.000000. running mean: -18.638863\n",
            "resetting env. episode 906.000000, reward total was -17.000000. running mean: -18.622474\n",
            "resetting env. episode 907.000000, reward total was -17.000000. running mean: -18.606250\n",
            "resetting env. episode 908.000000, reward total was -20.000000. running mean: -18.620187\n",
            "resetting env. episode 909.000000, reward total was -20.000000. running mean: -18.633985\n",
            "resetting env. episode 910.000000, reward total was -16.000000. running mean: -18.607645\n",
            "resetting env. episode 911.000000, reward total was -17.000000. running mean: -18.591569\n",
            "resetting env. episode 912.000000, reward total was -13.000000. running mean: -18.535653\n",
            "resetting env. episode 913.000000, reward total was -17.000000. running mean: -18.520297\n",
            "resetting env. episode 914.000000, reward total was -20.000000. running mean: -18.535094\n",
            "resetting env. episode 915.000000, reward total was -21.000000. running mean: -18.559743\n",
            "resetting env. episode 916.000000, reward total was -21.000000. running mean: -18.584145\n",
            "resetting env. episode 917.000000, reward total was -20.000000. running mean: -18.598304\n",
            "resetting env. episode 918.000000, reward total was -20.000000. running mean: -18.612321\n",
            "resetting env. episode 919.000000, reward total was -17.000000. running mean: -18.596198\n",
            "resetting env. episode 920.000000, reward total was -21.000000. running mean: -18.620236\n",
            "resetting env. episode 921.000000, reward total was -19.000000. running mean: -18.624033\n",
            "resetting env. episode 922.000000, reward total was -17.000000. running mean: -18.607793\n",
            "resetting env. episode 923.000000, reward total was -18.000000. running mean: -18.601715\n",
            "resetting env. episode 924.000000, reward total was -17.000000. running mean: -18.585698\n",
            "resetting env. episode 925.000000, reward total was -20.000000. running mean: -18.599841\n",
            "resetting env. episode 926.000000, reward total was -14.000000. running mean: -18.553842\n",
            "resetting env. episode 927.000000, reward total was -20.000000. running mean: -18.568304\n",
            "resetting env. episode 928.000000, reward total was -19.000000. running mean: -18.572621\n",
            "resetting env. episode 929.000000, reward total was -18.000000. running mean: -18.566895\n",
            "resetting env. episode 930.000000, reward total was -19.000000. running mean: -18.571226\n",
            "resetting env. episode 931.000000, reward total was -15.000000. running mean: -18.535514\n",
            "resetting env. episode 932.000000, reward total was -19.000000. running mean: -18.540158\n",
            "resetting env. episode 933.000000, reward total was -19.000000. running mean: -18.544757\n",
            "resetting env. episode 934.000000, reward total was -20.000000. running mean: -18.559309\n",
            "resetting env. episode 935.000000, reward total was -17.000000. running mean: -18.543716\n",
            "resetting env. episode 936.000000, reward total was -16.000000. running mean: -18.518279\n",
            "resetting env. episode 937.000000, reward total was -17.000000. running mean: -18.503096\n",
            "resetting env. episode 938.000000, reward total was -19.000000. running mean: -18.508065\n",
            "resetting env. episode 939.000000, reward total was -19.000000. running mean: -18.512985\n",
            "resetting env. episode 940.000000, reward total was -19.000000. running mean: -18.517855\n",
            "resetting env. episode 941.000000, reward total was -19.000000. running mean: -18.522676\n",
            "resetting env. episode 942.000000, reward total was -17.000000. running mean: -18.507449\n",
            "resetting env. episode 943.000000, reward total was -18.000000. running mean: -18.502375\n",
            "resetting env. episode 944.000000, reward total was -16.000000. running mean: -18.477351\n",
            "resetting env. episode 945.000000, reward total was -20.000000. running mean: -18.492578\n",
            "resetting env. episode 946.000000, reward total was -20.000000. running mean: -18.507652\n",
            "resetting env. episode 947.000000, reward total was -18.000000. running mean: -18.502575\n",
            "resetting env. episode 948.000000, reward total was -18.000000. running mean: -18.497550\n",
            "resetting env. episode 949.000000, reward total was -16.000000. running mean: -18.472574\n",
            "resetting env. episode 950.000000, reward total was -19.000000. running mean: -18.477848\n",
            "resetting env. episode 951.000000, reward total was -18.000000. running mean: -18.473070\n",
            "resetting env. episode 952.000000, reward total was -18.000000. running mean: -18.468339\n",
            "resetting env. episode 953.000000, reward total was -16.000000. running mean: -18.443656\n",
            "resetting env. episode 954.000000, reward total was -20.000000. running mean: -18.459219\n",
            "resetting env. episode 955.000000, reward total was -20.000000. running mean: -18.474627\n",
            "resetting env. episode 956.000000, reward total was -15.000000. running mean: -18.439881\n",
            "resetting env. episode 957.000000, reward total was -21.000000. running mean: -18.465482\n",
            "resetting env. episode 958.000000, reward total was -21.000000. running mean: -18.490827\n",
            "resetting env. episode 959.000000, reward total was -19.000000. running mean: -18.495919\n",
            "resetting env. episode 960.000000, reward total was -17.000000. running mean: -18.480960\n",
            "resetting env. episode 961.000000, reward total was -18.000000. running mean: -18.476150\n",
            "resetting env. episode 962.000000, reward total was -21.000000. running mean: -18.501389\n",
            "resetting env. episode 963.000000, reward total was -19.000000. running mean: -18.506375\n",
            "resetting env. episode 964.000000, reward total was -17.000000. running mean: -18.491311\n",
            "resetting env. episode 965.000000, reward total was -17.000000. running mean: -18.476398\n",
            "resetting env. episode 966.000000, reward total was -17.000000. running mean: -18.461634\n",
            "resetting env. episode 967.000000, reward total was -16.000000. running mean: -18.437018\n",
            "resetting env. episode 968.000000, reward total was -21.000000. running mean: -18.462647\n",
            "resetting env. episode 969.000000, reward total was -19.000000. running mean: -18.468021\n",
            "resetting env. episode 970.000000, reward total was -21.000000. running mean: -18.493341\n",
            "resetting env. episode 971.000000, reward total was -21.000000. running mean: -18.518407\n",
            "resetting env. episode 972.000000, reward total was -18.000000. running mean: -18.513223\n",
            "resetting env. episode 973.000000, reward total was -18.000000. running mean: -18.508091\n",
            "resetting env. episode 974.000000, reward total was -18.000000. running mean: -18.503010\n",
            "resetting env. episode 975.000000, reward total was -19.000000. running mean: -18.507980\n",
            "resetting env. episode 976.000000, reward total was -17.000000. running mean: -18.492900\n",
            "resetting env. episode 977.000000, reward total was -20.000000. running mean: -18.507971\n",
            "resetting env. episode 978.000000, reward total was -19.000000. running mean: -18.512891\n",
            "resetting env. episode 979.000000, reward total was -17.000000. running mean: -18.497763\n",
            "resetting env. episode 980.000000, reward total was -16.000000. running mean: -18.472785\n",
            "resetting env. episode 981.000000, reward total was -20.000000. running mean: -18.488057\n",
            "resetting env. episode 982.000000, reward total was -20.000000. running mean: -18.503177\n",
            "resetting env. episode 983.000000, reward total was -19.000000. running mean: -18.508145\n",
            "resetting env. episode 984.000000, reward total was -21.000000. running mean: -18.533063\n",
            "resetting env. episode 985.000000, reward total was -20.000000. running mean: -18.547733\n",
            "resetting env. episode 986.000000, reward total was -20.000000. running mean: -18.562255\n",
            "resetting env. episode 987.000000, reward total was -20.000000. running mean: -18.576633\n",
            "resetting env. episode 988.000000, reward total was -15.000000. running mean: -18.540866\n",
            "resetting env. episode 989.000000, reward total was -19.000000. running mean: -18.545458\n",
            "resetting env. episode 990.000000, reward total was -20.000000. running mean: -18.560003\n",
            "resetting env. episode 991.000000, reward total was -18.000000. running mean: -18.554403\n",
            "resetting env. episode 992.000000, reward total was -20.000000. running mean: -18.568859\n",
            "resetting env. episode 993.000000, reward total was -21.000000. running mean: -18.593171\n",
            "resetting env. episode 994.000000, reward total was -18.000000. running mean: -18.587239\n",
            "resetting env. episode 995.000000, reward total was -19.000000. running mean: -18.591366\n",
            "resetting env. episode 996.000000, reward total was -21.000000. running mean: -18.615453\n",
            "resetting env. episode 997.000000, reward total was -19.000000. running mean: -18.619298\n",
            "resetting env. episode 998.000000, reward total was -21.000000. running mean: -18.643105\n",
            "resetting env. episode 999.000000, reward total was -16.000000. running mean: -18.616674\n",
            "resetting env. episode 1000.000000, reward total was -21.000000. running mean: -18.640508\n",
            "resetting env. episode 1001.000000, reward total was -15.000000. running mean: -18.604102\n",
            "resetting env. episode 1002.000000, reward total was -21.000000. running mean: -18.628061\n",
            "resetting env. episode 1003.000000, reward total was -21.000000. running mean: -18.651781\n",
            "resetting env. episode 1004.000000, reward total was -16.000000. running mean: -18.625263\n",
            "resetting env. episode 1005.000000, reward total was -17.000000. running mean: -18.609010\n",
            "resetting env. episode 1006.000000, reward total was -19.000000. running mean: -18.612920\n",
            "resetting env. episode 1007.000000, reward total was -18.000000. running mean: -18.606791\n",
            "resetting env. episode 1008.000000, reward total was -18.000000. running mean: -18.600723\n",
            "resetting env. episode 1009.000000, reward total was -17.000000. running mean: -18.584716\n",
            "resetting env. episode 1010.000000, reward total was -18.000000. running mean: -18.578869\n",
            "resetting env. episode 1011.000000, reward total was -19.000000. running mean: -18.583080\n",
            "resetting env. episode 1012.000000, reward total was -17.000000. running mean: -18.567249\n",
            "resetting env. episode 1013.000000, reward total was -17.000000. running mean: -18.551577\n",
            "resetting env. episode 1014.000000, reward total was -19.000000. running mean: -18.556061\n",
            "resetting env. episode 1015.000000, reward total was -20.000000. running mean: -18.570500\n",
            "resetting env. episode 1016.000000, reward total was -18.000000. running mean: -18.564795\n",
            "resetting env. episode 1017.000000, reward total was -18.000000. running mean: -18.559147\n",
            "resetting env. episode 1018.000000, reward total was -17.000000. running mean: -18.543556\n",
            "resetting env. episode 1019.000000, reward total was -19.000000. running mean: -18.548120\n",
            "resetting env. episode 1020.000000, reward total was -20.000000. running mean: -18.562639\n",
            "resetting env. episode 1021.000000, reward total was -20.000000. running mean: -18.577013\n",
            "resetting env. episode 1022.000000, reward total was -19.000000. running mean: -18.581243\n",
            "resetting env. episode 1023.000000, reward total was -19.000000. running mean: -18.585430\n",
            "resetting env. episode 1024.000000, reward total was -17.000000. running mean: -18.569576\n",
            "resetting env. episode 1025.000000, reward total was -21.000000. running mean: -18.593880\n",
            "resetting env. episode 1026.000000, reward total was -19.000000. running mean: -18.597941\n",
            "resetting env. episode 1027.000000, reward total was -16.000000. running mean: -18.571962\n",
            "resetting env. episode 1028.000000, reward total was -21.000000. running mean: -18.596242\n",
            "resetting env. episode 1029.000000, reward total was -17.000000. running mean: -18.580280\n",
            "resetting env. episode 1030.000000, reward total was -19.000000. running mean: -18.584477\n",
            "resetting env. episode 1031.000000, reward total was -16.000000. running mean: -18.558632\n",
            "resetting env. episode 1032.000000, reward total was -19.000000. running mean: -18.563046\n",
            "resetting env. episode 1033.000000, reward total was -19.000000. running mean: -18.567416\n",
            "resetting env. episode 1034.000000, reward total was -21.000000. running mean: -18.591741\n",
            "resetting env. episode 1035.000000, reward total was -19.000000. running mean: -18.595824\n",
            "resetting env. episode 1036.000000, reward total was -19.000000. running mean: -18.599866\n",
            "resetting env. episode 1037.000000, reward total was -18.000000. running mean: -18.593867\n",
            "resetting env. episode 1038.000000, reward total was -16.000000. running mean: -18.567928\n",
            "resetting env. episode 1039.000000, reward total was -20.000000. running mean: -18.582249\n",
            "resetting env. episode 1040.000000, reward total was -19.000000. running mean: -18.586427\n",
            "resetting env. episode 1041.000000, reward total was -17.000000. running mean: -18.570562\n",
            "resetting env. episode 1042.000000, reward total was -19.000000. running mean: -18.574857\n",
            "resetting env. episode 1043.000000, reward total was -16.000000. running mean: -18.549108\n",
            "resetting env. episode 1044.000000, reward total was -20.000000. running mean: -18.563617\n",
            "resetting env. episode 1045.000000, reward total was -18.000000. running mean: -18.557981\n",
            "resetting env. episode 1046.000000, reward total was -17.000000. running mean: -18.542401\n",
            "resetting env. episode 1047.000000, reward total was -19.000000. running mean: -18.546977\n",
            "resetting env. episode 1048.000000, reward total was -18.000000. running mean: -18.541507\n",
            "resetting env. episode 1049.000000, reward total was -19.000000. running mean: -18.546092\n",
            "resetting env. episode 1050.000000, reward total was -19.000000. running mean: -18.550631\n",
            "resetting env. episode 1051.000000, reward total was -16.000000. running mean: -18.525125\n",
            "resetting env. episode 1052.000000, reward total was -13.000000. running mean: -18.469874\n",
            "resetting env. episode 1053.000000, reward total was -19.000000. running mean: -18.475175\n",
            "resetting env. episode 1054.000000, reward total was -19.000000. running mean: -18.480423\n",
            "resetting env. episode 1055.000000, reward total was -19.000000. running mean: -18.485619\n",
            "resetting env. episode 1056.000000, reward total was -19.000000. running mean: -18.490763\n",
            "resetting env. episode 1057.000000, reward total was -20.000000. running mean: -18.505855\n",
            "resetting env. episode 1058.000000, reward total was -21.000000. running mean: -18.530797\n",
            "resetting env. episode 1059.000000, reward total was -19.000000. running mean: -18.535489\n",
            "resetting env. episode 1060.000000, reward total was -17.000000. running mean: -18.520134\n",
            "resetting env. episode 1061.000000, reward total was -18.000000. running mean: -18.514933\n",
            "resetting env. episode 1062.000000, reward total was -18.000000. running mean: -18.509783\n",
            "resetting env. episode 1063.000000, reward total was -15.000000. running mean: -18.474685\n",
            "resetting env. episode 1064.000000, reward total was -18.000000. running mean: -18.469938\n",
            "resetting env. episode 1065.000000, reward total was -19.000000. running mean: -18.475239\n",
            "resetting env. episode 1066.000000, reward total was -18.000000. running mean: -18.470487\n",
            "resetting env. episode 1067.000000, reward total was -15.000000. running mean: -18.435782\n",
            "resetting env. episode 1068.000000, reward total was -19.000000. running mean: -18.441424\n",
            "resetting env. episode 1069.000000, reward total was -19.000000. running mean: -18.447010\n",
            "resetting env. episode 1070.000000, reward total was -16.000000. running mean: -18.422540\n",
            "resetting env. episode 1071.000000, reward total was -19.000000. running mean: -18.428314\n",
            "resetting env. episode 1072.000000, reward total was -17.000000. running mean: -18.414031\n",
            "resetting env. episode 1073.000000, reward total was -14.000000. running mean: -18.369891\n",
            "resetting env. episode 1074.000000, reward total was -18.000000. running mean: -18.366192\n",
            "resetting env. episode 1075.000000, reward total was -17.000000. running mean: -18.352530\n",
            "resetting env. episode 1076.000000, reward total was -16.000000. running mean: -18.329005\n",
            "resetting env. episode 1077.000000, reward total was -17.000000. running mean: -18.315715\n",
            "resetting env. episode 1078.000000, reward total was -14.000000. running mean: -18.272558\n",
            "resetting env. episode 1079.000000, reward total was -20.000000. running mean: -18.289832\n",
            "resetting env. episode 1080.000000, reward total was -19.000000. running mean: -18.296934\n",
            "resetting env. episode 1081.000000, reward total was -21.000000. running mean: -18.323964\n",
            "resetting env. episode 1082.000000, reward total was -17.000000. running mean: -18.310725\n",
            "resetting env. episode 1083.000000, reward total was -16.000000. running mean: -18.287617\n",
            "resetting env. episode 1084.000000, reward total was -19.000000. running mean: -18.294741\n",
            "resetting env. episode 1085.000000, reward total was -16.000000. running mean: -18.271794\n",
            "resetting env. episode 1086.000000, reward total was -15.000000. running mean: -18.239076\n",
            "resetting env. episode 1087.000000, reward total was -18.000000. running mean: -18.236685\n",
            "resetting env. episode 1088.000000, reward total was -18.000000. running mean: -18.234318\n",
            "resetting env. episode 1089.000000, reward total was -19.000000. running mean: -18.241975\n",
            "resetting env. episode 1090.000000, reward total was -21.000000. running mean: -18.269555\n",
            "resetting env. episode 1091.000000, reward total was -16.000000. running mean: -18.246860\n",
            "resetting env. episode 1092.000000, reward total was -19.000000. running mean: -18.254391\n",
            "resetting env. episode 1093.000000, reward total was -21.000000. running mean: -18.281847\n",
            "resetting env. episode 1094.000000, reward total was -18.000000. running mean: -18.279029\n",
            "resetting env. episode 1095.000000, reward total was -19.000000. running mean: -18.286239\n",
            "resetting env. episode 1096.000000, reward total was -20.000000. running mean: -18.303376\n",
            "resetting env. episode 1097.000000, reward total was -19.000000. running mean: -18.310342\n",
            "resetting env. episode 1098.000000, reward total was -17.000000. running mean: -18.297239\n",
            "resetting env. episode 1099.000000, reward total was -16.000000. running mean: -18.274267\n",
            "resetting env. episode 1100.000000, reward total was -19.000000. running mean: -18.281524\n",
            "resetting env. episode 1101.000000, reward total was -21.000000. running mean: -18.308709\n",
            "resetting env. episode 1102.000000, reward total was -16.000000. running mean: -18.285622\n",
            "resetting env. episode 1103.000000, reward total was -21.000000. running mean: -18.312765\n",
            "resetting env. episode 1104.000000, reward total was -15.000000. running mean: -18.279638\n",
            "resetting env. episode 1105.000000, reward total was -19.000000. running mean: -18.286841\n",
            "resetting env. episode 1106.000000, reward total was -21.000000. running mean: -18.313973\n",
            "resetting env. episode 1107.000000, reward total was -17.000000. running mean: -18.300833\n",
            "resetting env. episode 1108.000000, reward total was -17.000000. running mean: -18.287825\n",
            "resetting env. episode 1109.000000, reward total was -17.000000. running mean: -18.274947\n",
            "resetting env. episode 1110.000000, reward total was -21.000000. running mean: -18.302197\n",
            "resetting env. episode 1111.000000, reward total was -18.000000. running mean: -18.299175\n",
            "resetting env. episode 1112.000000, reward total was -18.000000. running mean: -18.296183\n",
            "resetting env. episode 1113.000000, reward total was -17.000000. running mean: -18.283222\n",
            "resetting env. episode 1114.000000, reward total was -17.000000. running mean: -18.270389\n",
            "resetting env. episode 1115.000000, reward total was -18.000000. running mean: -18.267685\n",
            "resetting env. episode 1116.000000, reward total was -19.000000. running mean: -18.275009\n",
            "resetting env. episode 1117.000000, reward total was -17.000000. running mean: -18.262259\n",
            "resetting env. episode 1118.000000, reward total was -19.000000. running mean: -18.269636\n",
            "resetting env. episode 1119.000000, reward total was -14.000000. running mean: -18.226940\n",
            "resetting env. episode 1120.000000, reward total was -19.000000. running mean: -18.234670\n",
            "resetting env. episode 1121.000000, reward total was -16.000000. running mean: -18.212323\n",
            "resetting env. episode 1122.000000, reward total was -18.000000. running mean: -18.210200\n",
            "resetting env. episode 1123.000000, reward total was -17.000000. running mean: -18.198098\n",
            "resetting env. episode 1124.000000, reward total was -14.000000. running mean: -18.156117\n",
            "resetting env. episode 1125.000000, reward total was -19.000000. running mean: -18.164556\n",
            "resetting env. episode 1126.000000, reward total was -19.000000. running mean: -18.172911\n",
            "resetting env. episode 1127.000000, reward total was -21.000000. running mean: -18.201181\n",
            "resetting env. episode 1128.000000, reward total was -20.000000. running mean: -18.219170\n",
            "resetting env. episode 1129.000000, reward total was -16.000000. running mean: -18.196978\n",
            "resetting env. episode 1130.000000, reward total was -18.000000. running mean: -18.195008\n",
            "resetting env. episode 1131.000000, reward total was -19.000000. running mean: -18.203058\n",
            "resetting env. episode 1132.000000, reward total was -21.000000. running mean: -18.231027\n",
            "resetting env. episode 1133.000000, reward total was -18.000000. running mean: -18.228717\n",
            "resetting env. episode 1134.000000, reward total was -16.000000. running mean: -18.206430\n",
            "resetting env. episode 1135.000000, reward total was -19.000000. running mean: -18.214366\n",
            "resetting env. episode 1136.000000, reward total was -16.000000. running mean: -18.192222\n",
            "resetting env. episode 1137.000000, reward total was -21.000000. running mean: -18.220300\n",
            "resetting env. episode 1138.000000, reward total was -19.000000. running mean: -18.228097\n",
            "resetting env. episode 1139.000000, reward total was -18.000000. running mean: -18.225816\n",
            "resetting env. episode 1140.000000, reward total was -19.000000. running mean: -18.233558\n",
            "resetting env. episode 1141.000000, reward total was -17.000000. running mean: -18.221222\n",
            "resetting env. episode 1142.000000, reward total was -19.000000. running mean: -18.229010\n",
            "resetting env. episode 1143.000000, reward total was -19.000000. running mean: -18.236720\n",
            "resetting env. episode 1144.000000, reward total was -16.000000. running mean: -18.214353\n",
            "resetting env. episode 1145.000000, reward total was -19.000000. running mean: -18.222209\n",
            "resetting env. episode 1146.000000, reward total was -20.000000. running mean: -18.239987\n",
            "resetting env. episode 1147.000000, reward total was -20.000000. running mean: -18.257587\n",
            "resetting env. episode 1148.000000, reward total was -20.000000. running mean: -18.275011\n",
            "resetting env. episode 1149.000000, reward total was -14.000000. running mean: -18.232261\n",
            "resetting env. episode 1150.000000, reward total was -14.000000. running mean: -18.189939\n",
            "resetting env. episode 1151.000000, reward total was -20.000000. running mean: -18.208039\n",
            "resetting env. episode 1152.000000, reward total was -17.000000. running mean: -18.195959\n",
            "resetting env. episode 1153.000000, reward total was -21.000000. running mean: -18.223999\n",
            "resetting env. episode 1154.000000, reward total was -16.000000. running mean: -18.201759\n",
            "resetting env. episode 1155.000000, reward total was -20.000000. running mean: -18.219742\n",
            "resetting env. episode 1156.000000, reward total was -19.000000. running mean: -18.227544\n",
            "resetting env. episode 1157.000000, reward total was -19.000000. running mean: -18.235269\n",
            "resetting env. episode 1158.000000, reward total was -18.000000. running mean: -18.232916\n",
            "resetting env. episode 1159.000000, reward total was -21.000000. running mean: -18.260587\n",
            "resetting env. episode 1160.000000, reward total was -19.000000. running mean: -18.267981\n",
            "resetting env. episode 1161.000000, reward total was -21.000000. running mean: -18.295301\n",
            "resetting env. episode 1162.000000, reward total was -19.000000. running mean: -18.302348\n",
            "resetting env. episode 1163.000000, reward total was -18.000000. running mean: -18.299325\n",
            "resetting env. episode 1164.000000, reward total was -20.000000. running mean: -18.316331\n",
            "resetting env. episode 1165.000000, reward total was -19.000000. running mean: -18.323168\n",
            "resetting env. episode 1166.000000, reward total was -17.000000. running mean: -18.309936\n",
            "resetting env. episode 1167.000000, reward total was -17.000000. running mean: -18.296837\n",
            "resetting env. episode 1168.000000, reward total was -18.000000. running mean: -18.293869\n",
            "resetting env. episode 1169.000000, reward total was -19.000000. running mean: -18.300930\n",
            "resetting env. episode 1170.000000, reward total was -13.000000. running mean: -18.247921\n",
            "resetting env. episode 1171.000000, reward total was -19.000000. running mean: -18.255442\n",
            "resetting env. episode 1172.000000, reward total was -19.000000. running mean: -18.262887\n",
            "resetting env. episode 1173.000000, reward total was -19.000000. running mean: -18.270258\n",
            "resetting env. episode 1174.000000, reward total was -18.000000. running mean: -18.267556\n",
            "resetting env. episode 1175.000000, reward total was -20.000000. running mean: -18.284880\n",
            "resetting env. episode 1176.000000, reward total was -15.000000. running mean: -18.252031\n",
            "resetting env. episode 1177.000000, reward total was -15.000000. running mean: -18.219511\n",
            "resetting env. episode 1178.000000, reward total was -20.000000. running mean: -18.237316\n",
            "resetting env. episode 1179.000000, reward total was -19.000000. running mean: -18.244943\n",
            "resetting env. episode 1180.000000, reward total was -21.000000. running mean: -18.272493\n",
            "resetting env. episode 1181.000000, reward total was -20.000000. running mean: -18.289768\n",
            "resetting env. episode 1182.000000, reward total was -18.000000. running mean: -18.286871\n",
            "resetting env. episode 1183.000000, reward total was -17.000000. running mean: -18.274002\n",
            "resetting env. episode 1184.000000, reward total was -14.000000. running mean: -18.231262\n",
            "resetting env. episode 1185.000000, reward total was -19.000000. running mean: -18.238949\n",
            "resetting env. episode 1186.000000, reward total was -19.000000. running mean: -18.246560\n",
            "resetting env. episode 1187.000000, reward total was -15.000000. running mean: -18.214094\n",
            "resetting env. episode 1188.000000, reward total was -19.000000. running mean: -18.221953\n",
            "resetting env. episode 1189.000000, reward total was -17.000000. running mean: -18.209734\n",
            "resetting env. episode 1190.000000, reward total was -20.000000. running mean: -18.227636\n",
            "resetting env. episode 1191.000000, reward total was -17.000000. running mean: -18.215360\n",
            "resetting env. episode 1192.000000, reward total was -17.000000. running mean: -18.203206\n",
            "resetting env. episode 1193.000000, reward total was -17.000000. running mean: -18.191174\n",
            "resetting env. episode 1194.000000, reward total was -15.000000. running mean: -18.159263\n",
            "resetting env. episode 1195.000000, reward total was -18.000000. running mean: -18.157670\n",
            "resetting env. episode 1196.000000, reward total was -18.000000. running mean: -18.156093\n",
            "resetting env. episode 1197.000000, reward total was -21.000000. running mean: -18.184532\n",
            "resetting env. episode 1198.000000, reward total was -19.000000. running mean: -18.192687\n",
            "resetting env. episode 1199.000000, reward total was -16.000000. running mean: -18.170760\n",
            "resetting env. episode 1200.000000, reward total was -19.000000. running mean: -18.179053\n",
            "resetting env. episode 1201.000000, reward total was -16.000000. running mean: -18.157262\n",
            "resetting env. episode 1202.000000, reward total was -17.000000. running mean: -18.145689\n",
            "resetting env. episode 1203.000000, reward total was -17.000000. running mean: -18.134233\n",
            "resetting env. episode 1204.000000, reward total was -17.000000. running mean: -18.122890\n",
            "resetting env. episode 1205.000000, reward total was -19.000000. running mean: -18.131661\n",
            "resetting env. episode 1206.000000, reward total was -19.000000. running mean: -18.140345\n",
            "resetting env. episode 1207.000000, reward total was -20.000000. running mean: -18.158941\n",
            "resetting env. episode 1208.000000, reward total was -19.000000. running mean: -18.167352\n",
            "resetting env. episode 1209.000000, reward total was -15.000000. running mean: -18.135678\n",
            "resetting env. episode 1210.000000, reward total was -13.000000. running mean: -18.084322\n",
            "resetting env. episode 1211.000000, reward total was -18.000000. running mean: -18.083478\n",
            "resetting env. episode 1212.000000, reward total was -17.000000. running mean: -18.072644\n",
            "resetting env. episode 1213.000000, reward total was -19.000000. running mean: -18.081917\n",
            "resetting env. episode 1214.000000, reward total was -19.000000. running mean: -18.091098\n",
            "resetting env. episode 1215.000000, reward total was -19.000000. running mean: -18.100187\n",
            "resetting env. episode 1216.000000, reward total was -20.000000. running mean: -18.119185\n",
            "resetting env. episode 1217.000000, reward total was -21.000000. running mean: -18.147993\n",
            "resetting env. episode 1218.000000, reward total was -18.000000. running mean: -18.146513\n",
            "resetting env. episode 1219.000000, reward total was -19.000000. running mean: -18.155048\n",
            "resetting env. episode 1220.000000, reward total was -19.000000. running mean: -18.163498\n",
            "resetting env. episode 1221.000000, reward total was -20.000000. running mean: -18.181863\n",
            "resetting env. episode 1222.000000, reward total was -20.000000. running mean: -18.200044\n",
            "resetting env. episode 1223.000000, reward total was -15.000000. running mean: -18.168044\n",
            "resetting env. episode 1224.000000, reward total was -19.000000. running mean: -18.176363\n",
            "resetting env. episode 1225.000000, reward total was -17.000000. running mean: -18.164600\n",
            "resetting env. episode 1226.000000, reward total was -19.000000. running mean: -18.172954\n",
            "resetting env. episode 1227.000000, reward total was -20.000000. running mean: -18.191224\n",
            "resetting env. episode 1228.000000, reward total was -19.000000. running mean: -18.199312\n",
            "resetting env. episode 1229.000000, reward total was -18.000000. running mean: -18.197319\n",
            "resetting env. episode 1230.000000, reward total was -20.000000. running mean: -18.215346\n",
            "resetting env. episode 1231.000000, reward total was -19.000000. running mean: -18.223192\n",
            "resetting env. episode 1232.000000, reward total was -19.000000. running mean: -18.230960\n",
            "resetting env. episode 1233.000000, reward total was -17.000000. running mean: -18.218651\n",
            "resetting env. episode 1234.000000, reward total was -20.000000. running mean: -18.236464\n",
            "resetting env. episode 1235.000000, reward total was -18.000000. running mean: -18.234099\n",
            "resetting env. episode 1236.000000, reward total was -19.000000. running mean: -18.241758\n",
            "resetting env. episode 1237.000000, reward total was -19.000000. running mean: -18.249341\n",
            "resetting env. episode 1238.000000, reward total was -21.000000. running mean: -18.276847\n",
            "resetting env. episode 1239.000000, reward total was -20.000000. running mean: -18.294079\n",
            "resetting env. episode 1240.000000, reward total was -19.000000. running mean: -18.301138\n",
            "resetting env. episode 1241.000000, reward total was -17.000000. running mean: -18.288127\n",
            "resetting env. episode 1242.000000, reward total was -19.000000. running mean: -18.295245\n",
            "resetting env. episode 1243.000000, reward total was -20.000000. running mean: -18.312293\n",
            "resetting env. episode 1244.000000, reward total was -19.000000. running mean: -18.319170\n",
            "resetting env. episode 1245.000000, reward total was -21.000000. running mean: -18.345978\n",
            "resetting env. episode 1246.000000, reward total was -17.000000. running mean: -18.332519\n",
            "resetting env. episode 1247.000000, reward total was -17.000000. running mean: -18.319193\n",
            "resetting env. episode 1248.000000, reward total was -19.000000. running mean: -18.326002\n",
            "resetting env. episode 1249.000000, reward total was -19.000000. running mean: -18.332741\n",
            "resetting env. episode 1250.000000, reward total was -20.000000. running mean: -18.349414\n",
            "resetting env. episode 1251.000000, reward total was -20.000000. running mean: -18.365920\n",
            "resetting env. episode 1252.000000, reward total was -16.000000. running mean: -18.342261\n",
            "resetting env. episode 1253.000000, reward total was -19.000000. running mean: -18.348838\n",
            "resetting env. episode 1254.000000, reward total was -16.000000. running mean: -18.325350\n",
            "resetting env. episode 1255.000000, reward total was -18.000000. running mean: -18.322096\n",
            "resetting env. episode 1256.000000, reward total was -16.000000. running mean: -18.298875\n",
            "resetting env. episode 1257.000000, reward total was -19.000000. running mean: -18.305887\n",
            "resetting env. episode 1258.000000, reward total was -21.000000. running mean: -18.332828\n",
            "resetting env. episode 1259.000000, reward total was -19.000000. running mean: -18.339499\n",
            "resetting env. episode 1260.000000, reward total was -20.000000. running mean: -18.356104\n",
            "resetting env. episode 1261.000000, reward total was -17.000000. running mean: -18.342543\n",
            "resetting env. episode 1262.000000, reward total was -18.000000. running mean: -18.339118\n",
            "resetting env. episode 1263.000000, reward total was -18.000000. running mean: -18.335727\n",
            "resetting env. episode 1264.000000, reward total was -19.000000. running mean: -18.342369\n",
            "resetting env. episode 1265.000000, reward total was -18.000000. running mean: -18.338946\n",
            "resetting env. episode 1266.000000, reward total was -20.000000. running mean: -18.355556\n",
            "resetting env. episode 1267.000000, reward total was -17.000000. running mean: -18.342001\n",
            "resetting env. episode 1268.000000, reward total was -21.000000. running mean: -18.368581\n",
            "resetting env. episode 1269.000000, reward total was -15.000000. running mean: -18.334895\n",
            "resetting env. episode 1270.000000, reward total was -17.000000. running mean: -18.321546\n",
            "resetting env. episode 1271.000000, reward total was -15.000000. running mean: -18.288331\n",
            "resetting env. episode 1272.000000, reward total was -19.000000. running mean: -18.295447\n",
            "resetting env. episode 1273.000000, reward total was -20.000000. running mean: -18.312493\n",
            "resetting env. episode 1274.000000, reward total was -18.000000. running mean: -18.309368\n",
            "resetting env. episode 1275.000000, reward total was -18.000000. running mean: -18.306274\n",
            "resetting env. episode 1276.000000, reward total was -16.000000. running mean: -18.283211\n",
            "resetting env. episode 1277.000000, reward total was -17.000000. running mean: -18.270379\n",
            "resetting env. episode 1278.000000, reward total was -19.000000. running mean: -18.277675\n",
            "resetting env. episode 1279.000000, reward total was -20.000000. running mean: -18.294899\n",
            "resetting env. episode 1280.000000, reward total was -17.000000. running mean: -18.281950\n",
            "resetting env. episode 1281.000000, reward total was -17.000000. running mean: -18.269130\n",
            "resetting env. episode 1282.000000, reward total was -15.000000. running mean: -18.236439\n",
            "resetting env. episode 1283.000000, reward total was -19.000000. running mean: -18.244075\n",
            "resetting env. episode 1284.000000, reward total was -19.000000. running mean: -18.251634\n",
            "resetting env. episode 1285.000000, reward total was -13.000000. running mean: -18.199117\n",
            "resetting env. episode 1286.000000, reward total was -18.000000. running mean: -18.197126\n",
            "resetting env. episode 1287.000000, reward total was -21.000000. running mean: -18.225155\n",
            "resetting env. episode 1288.000000, reward total was -16.000000. running mean: -18.202903\n",
            "resetting env. episode 1289.000000, reward total was -19.000000. running mean: -18.210874\n",
            "resetting env. episode 1290.000000, reward total was -20.000000. running mean: -18.228766\n",
            "resetting env. episode 1291.000000, reward total was -17.000000. running mean: -18.216478\n",
            "resetting env. episode 1292.000000, reward total was -21.000000. running mean: -18.244313\n",
            "resetting env. episode 1293.000000, reward total was -19.000000. running mean: -18.251870\n",
            "resetting env. episode 1294.000000, reward total was -19.000000. running mean: -18.259351\n",
            "resetting env. episode 1295.000000, reward total was -17.000000. running mean: -18.246758\n",
            "resetting env. episode 1296.000000, reward total was -17.000000. running mean: -18.234290\n",
            "resetting env. episode 1297.000000, reward total was -18.000000. running mean: -18.231947\n",
            "resetting env. episode 1298.000000, reward total was -18.000000. running mean: -18.229628\n",
            "resetting env. episode 1299.000000, reward total was -21.000000. running mean: -18.257332\n",
            "resetting env. episode 1300.000000, reward total was -16.000000. running mean: -18.234758\n",
            "resetting env. episode 1301.000000, reward total was -21.000000. running mean: -18.262411\n",
            "resetting env. episode 1302.000000, reward total was -15.000000. running mean: -18.229787\n",
            "resetting env. episode 1303.000000, reward total was -19.000000. running mean: -18.237489\n",
            "resetting env. episode 1304.000000, reward total was -18.000000. running mean: -18.235114\n",
            "resetting env. episode 1305.000000, reward total was -19.000000. running mean: -18.242763\n",
            "resetting env. episode 1306.000000, reward total was -17.000000. running mean: -18.230335\n",
            "resetting env. episode 1307.000000, reward total was -18.000000. running mean: -18.228032\n",
            "resetting env. episode 1308.000000, reward total was -21.000000. running mean: -18.255751\n",
            "resetting env. episode 1309.000000, reward total was -20.000000. running mean: -18.273194\n",
            "resetting env. episode 1310.000000, reward total was -16.000000. running mean: -18.250462\n",
            "resetting env. episode 1311.000000, reward total was -12.000000. running mean: -18.187957\n",
            "resetting env. episode 1312.000000, reward total was -13.000000. running mean: -18.136078\n",
            "resetting env. episode 1313.000000, reward total was -19.000000. running mean: -18.144717\n",
            "resetting env. episode 1314.000000, reward total was -17.000000. running mean: -18.133270\n",
            "resetting env. episode 1315.000000, reward total was -18.000000. running mean: -18.131937\n",
            "resetting env. episode 1316.000000, reward total was -18.000000. running mean: -18.130618\n",
            "resetting env. episode 1317.000000, reward total was -17.000000. running mean: -18.119312\n",
            "resetting env. episode 1318.000000, reward total was -19.000000. running mean: -18.128119\n",
            "resetting env. episode 1319.000000, reward total was -21.000000. running mean: -18.156837\n",
            "resetting env. episode 1320.000000, reward total was -19.000000. running mean: -18.165269\n",
            "resetting env. episode 1321.000000, reward total was -17.000000. running mean: -18.153616\n",
            "resetting env. episode 1322.000000, reward total was -17.000000. running mean: -18.142080\n",
            "resetting env. episode 1323.000000, reward total was -19.000000. running mean: -18.150659\n",
            "resetting env. episode 1324.000000, reward total was -17.000000. running mean: -18.139153\n",
            "resetting env. episode 1325.000000, reward total was -19.000000. running mean: -18.147761\n",
            "resetting env. episode 1326.000000, reward total was -17.000000. running mean: -18.136284\n",
            "resetting env. episode 1327.000000, reward total was -17.000000. running mean: -18.124921\n",
            "resetting env. episode 1328.000000, reward total was -19.000000. running mean: -18.133672\n",
            "resetting env. episode 1329.000000, reward total was -17.000000. running mean: -18.122335\n",
            "resetting env. episode 1330.000000, reward total was -18.000000. running mean: -18.121111\n",
            "resetting env. episode 1331.000000, reward total was -16.000000. running mean: -18.099900\n",
            "resetting env. episode 1332.000000, reward total was -17.000000. running mean: -18.088901\n",
            "resetting env. episode 1333.000000, reward total was -19.000000. running mean: -18.098012\n",
            "resetting env. episode 1334.000000, reward total was -19.000000. running mean: -18.107032\n",
            "resetting env. episode 1335.000000, reward total was -17.000000. running mean: -18.095962\n",
            "resetting env. episode 1336.000000, reward total was -17.000000. running mean: -18.085002\n",
            "resetting env. episode 1337.000000, reward total was -18.000000. running mean: -18.084152\n",
            "resetting env. episode 1338.000000, reward total was -18.000000. running mean: -18.083311\n",
            "resetting env. episode 1339.000000, reward total was -20.000000. running mean: -18.102478\n",
            "resetting env. episode 1340.000000, reward total was -19.000000. running mean: -18.111453\n",
            "resetting env. episode 1341.000000, reward total was -21.000000. running mean: -18.140338\n",
            "resetting env. episode 1342.000000, reward total was -19.000000. running mean: -18.148935\n",
            "resetting env. episode 1343.000000, reward total was -17.000000. running mean: -18.137446\n",
            "resetting env. episode 1344.000000, reward total was -16.000000. running mean: -18.116071\n",
            "resetting env. episode 1345.000000, reward total was -17.000000. running mean: -18.104910\n",
            "resetting env. episode 1346.000000, reward total was -17.000000. running mean: -18.093861\n",
            "resetting env. episode 1347.000000, reward total was -19.000000. running mean: -18.102923\n",
            "resetting env. episode 1348.000000, reward total was -20.000000. running mean: -18.121893\n",
            "resetting env. episode 1349.000000, reward total was -16.000000. running mean: -18.100675\n",
            "resetting env. episode 1350.000000, reward total was -19.000000. running mean: -18.109668\n",
            "resetting env. episode 1351.000000, reward total was -21.000000. running mean: -18.138571\n",
            "resetting env. episode 1352.000000, reward total was -17.000000. running mean: -18.127185\n",
            "resetting env. episode 1353.000000, reward total was -17.000000. running mean: -18.115914\n",
            "resetting env. episode 1354.000000, reward total was -17.000000. running mean: -18.104754\n",
            "resetting env. episode 1355.000000, reward total was -17.000000. running mean: -18.093707\n",
            "resetting env. episode 1356.000000, reward total was -18.000000. running mean: -18.092770\n",
            "resetting env. episode 1357.000000, reward total was -15.000000. running mean: -18.061842\n",
            "resetting env. episode 1358.000000, reward total was -20.000000. running mean: -18.081224\n",
            "resetting env. episode 1359.000000, reward total was -19.000000. running mean: -18.090411\n",
            "resetting env. episode 1360.000000, reward total was -13.000000. running mean: -18.039507\n",
            "resetting env. episode 1361.000000, reward total was -20.000000. running mean: -18.059112\n",
            "resetting env. episode 1362.000000, reward total was -18.000000. running mean: -18.058521\n",
            "resetting env. episode 1363.000000, reward total was -19.000000. running mean: -18.067936\n",
            "resetting env. episode 1364.000000, reward total was -18.000000. running mean: -18.067257\n",
            "resetting env. episode 1365.000000, reward total was -18.000000. running mean: -18.066584\n",
            "resetting env. episode 1366.000000, reward total was -19.000000. running mean: -18.075918\n",
            "resetting env. episode 1367.000000, reward total was -17.000000. running mean: -18.065159\n",
            "resetting env. episode 1368.000000, reward total was -19.000000. running mean: -18.074507\n",
            "resetting env. episode 1369.000000, reward total was -15.000000. running mean: -18.043762\n",
            "resetting env. episode 1370.000000, reward total was -17.000000. running mean: -18.033325\n",
            "resetting env. episode 1371.000000, reward total was -17.000000. running mean: -18.022991\n",
            "resetting env. episode 1372.000000, reward total was -21.000000. running mean: -18.052762\n",
            "resetting env. episode 1373.000000, reward total was -17.000000. running mean: -18.042234\n",
            "resetting env. episode 1374.000000, reward total was -19.000000. running mean: -18.051812\n",
            "resetting env. episode 1375.000000, reward total was -18.000000. running mean: -18.051293\n",
            "resetting env. episode 1376.000000, reward total was -21.000000. running mean: -18.080781\n",
            "resetting env. episode 1377.000000, reward total was -19.000000. running mean: -18.089973\n",
            "resetting env. episode 1378.000000, reward total was -18.000000. running mean: -18.089073\n",
            "resetting env. episode 1379.000000, reward total was -16.000000. running mean: -18.068182\n",
            "resetting env. episode 1380.000000, reward total was -16.000000. running mean: -18.047500\n",
            "resetting env. episode 1381.000000, reward total was -19.000000. running mean: -18.057025\n",
            "resetting env. episode 1382.000000, reward total was -18.000000. running mean: -18.056455\n",
            "resetting env. episode 1383.000000, reward total was -18.000000. running mean: -18.055891\n",
            "resetting env. episode 1384.000000, reward total was -21.000000. running mean: -18.085332\n",
            "resetting env. episode 1385.000000, reward total was -17.000000. running mean: -18.074478\n",
            "resetting env. episode 1386.000000, reward total was -19.000000. running mean: -18.083734\n",
            "resetting env. episode 1387.000000, reward total was -17.000000. running mean: -18.072896\n",
            "resetting env. episode 1388.000000, reward total was -18.000000. running mean: -18.072167\n",
            "resetting env. episode 1389.000000, reward total was -18.000000. running mean: -18.071446\n",
            "resetting env. episode 1390.000000, reward total was -18.000000. running mean: -18.070731\n",
            "resetting env. episode 1391.000000, reward total was -16.000000. running mean: -18.050024\n",
            "resetting env. episode 1392.000000, reward total was -17.000000. running mean: -18.039524\n",
            "resetting env. episode 1393.000000, reward total was -19.000000. running mean: -18.049128\n",
            "resetting env. episode 1394.000000, reward total was -19.000000. running mean: -18.058637\n",
            "resetting env. episode 1395.000000, reward total was -19.000000. running mean: -18.068051\n",
            "resetting env. episode 1396.000000, reward total was -19.000000. running mean: -18.077370\n",
            "resetting env. episode 1397.000000, reward total was -21.000000. running mean: -18.106597\n",
            "resetting env. episode 1398.000000, reward total was -21.000000. running mean: -18.135531\n",
            "resetting env. episode 1399.000000, reward total was -20.000000. running mean: -18.154175\n",
            "resetting env. episode 1400.000000, reward total was -17.000000. running mean: -18.142634\n",
            "resetting env. episode 1401.000000, reward total was -17.000000. running mean: -18.131207\n",
            "resetting env. episode 1402.000000, reward total was -21.000000. running mean: -18.159895\n",
            "resetting env. episode 1403.000000, reward total was -14.000000. running mean: -18.118296\n",
            "resetting env. episode 1404.000000, reward total was -21.000000. running mean: -18.147113\n",
            "resetting env. episode 1405.000000, reward total was -15.000000. running mean: -18.115642\n",
            "resetting env. episode 1406.000000, reward total was -18.000000. running mean: -18.114486\n",
            "resetting env. episode 1407.000000, reward total was -21.000000. running mean: -18.143341\n",
            "resetting env. episode 1408.000000, reward total was -21.000000. running mean: -18.171907\n",
            "resetting env. episode 1409.000000, reward total was -20.000000. running mean: -18.190188\n",
            "resetting env. episode 1410.000000, reward total was -15.000000. running mean: -18.158286\n",
            "resetting env. episode 1411.000000, reward total was -19.000000. running mean: -18.166704\n",
            "resetting env. episode 1412.000000, reward total was -17.000000. running mean: -18.155037\n",
            "resetting env. episode 1413.000000, reward total was -18.000000. running mean: -18.153486\n",
            "resetting env. episode 1414.000000, reward total was -19.000000. running mean: -18.161951\n",
            "resetting env. episode 1415.000000, reward total was -19.000000. running mean: -18.170332\n",
            "resetting env. episode 1416.000000, reward total was -19.000000. running mean: -18.178628\n",
            "resetting env. episode 1417.000000, reward total was -16.000000. running mean: -18.156842\n",
            "resetting env. episode 1418.000000, reward total was -19.000000. running mean: -18.165274\n",
            "resetting env. episode 1419.000000, reward total was -19.000000. running mean: -18.173621\n",
            "resetting env. episode 1420.000000, reward total was -17.000000. running mean: -18.161885\n",
            "resetting env. episode 1421.000000, reward total was -16.000000. running mean: -18.140266\n",
            "resetting env. episode 1422.000000, reward total was -17.000000. running mean: -18.128863\n",
            "resetting env. episode 1423.000000, reward total was -21.000000. running mean: -18.157575\n",
            "resetting env. episode 1424.000000, reward total was -18.000000. running mean: -18.155999\n",
            "resetting env. episode 1425.000000, reward total was -17.000000. running mean: -18.144439\n",
            "resetting env. episode 1426.000000, reward total was -17.000000. running mean: -18.132995\n",
            "resetting env. episode 1427.000000, reward total was -19.000000. running mean: -18.141665\n",
            "resetting env. episode 1428.000000, reward total was -17.000000. running mean: -18.130248\n",
            "resetting env. episode 1429.000000, reward total was -20.000000. running mean: -18.148945\n",
            "resetting env. episode 1430.000000, reward total was -21.000000. running mean: -18.177456\n",
            "resetting env. episode 1431.000000, reward total was -17.000000. running mean: -18.165681\n",
            "resetting env. episode 1432.000000, reward total was -15.000000. running mean: -18.134025\n",
            "resetting env. episode 1433.000000, reward total was -21.000000. running mean: -18.162684\n",
            "resetting env. episode 1434.000000, reward total was -17.000000. running mean: -18.151058\n",
            "resetting env. episode 1435.000000, reward total was -13.000000. running mean: -18.099547\n",
            "resetting env. episode 1436.000000, reward total was -18.000000. running mean: -18.098552\n",
            "resetting env. episode 1437.000000, reward total was -15.000000. running mean: -18.067566\n",
            "resetting env. episode 1438.000000, reward total was -19.000000. running mean: -18.076890\n",
            "resetting env. episode 1439.000000, reward total was -21.000000. running mean: -18.106121\n",
            "resetting env. episode 1440.000000, reward total was -18.000000. running mean: -18.105060\n",
            "resetting env. episode 1441.000000, reward total was -19.000000. running mean: -18.114010\n",
            "resetting env. episode 1442.000000, reward total was -18.000000. running mean: -18.112870\n",
            "resetting env. episode 1443.000000, reward total was -20.000000. running mean: -18.131741\n",
            "resetting env. episode 1444.000000, reward total was -19.000000. running mean: -18.140423\n",
            "resetting env. episode 1445.000000, reward total was -14.000000. running mean: -18.099019\n",
            "resetting env. episode 1446.000000, reward total was -16.000000. running mean: -18.078029\n",
            "resetting env. episode 1447.000000, reward total was -19.000000. running mean: -18.087249\n",
            "resetting env. episode 1448.000000, reward total was -19.000000. running mean: -18.096376\n",
            "resetting env. episode 1449.000000, reward total was -18.000000. running mean: -18.095412\n",
            "resetting env. episode 1450.000000, reward total was -17.000000. running mean: -18.084458\n",
            "resetting env. episode 1451.000000, reward total was -20.000000. running mean: -18.103614\n",
            "resetting env. episode 1452.000000, reward total was -17.000000. running mean: -18.092578\n",
            "resetting env. episode 1453.000000, reward total was -14.000000. running mean: -18.051652\n",
            "resetting env. episode 1454.000000, reward total was -17.000000. running mean: -18.041135\n",
            "resetting env. episode 1455.000000, reward total was -20.000000. running mean: -18.060724\n",
            "resetting env. episode 1456.000000, reward total was -20.000000. running mean: -18.080117\n",
            "resetting env. episode 1457.000000, reward total was -18.000000. running mean: -18.079316\n",
            "resetting env. episode 1458.000000, reward total was -19.000000. running mean: -18.088522\n",
            "resetting env. episode 1459.000000, reward total was -19.000000. running mean: -18.097637\n",
            "resetting env. episode 1460.000000, reward total was -20.000000. running mean: -18.116661\n",
            "resetting env. episode 1461.000000, reward total was -17.000000. running mean: -18.105494\n",
            "resetting env. episode 1462.000000, reward total was -17.000000. running mean: -18.094439\n",
            "resetting env. episode 1463.000000, reward total was -15.000000. running mean: -18.063495\n",
            "resetting env. episode 1464.000000, reward total was -19.000000. running mean: -18.072860\n",
            "resetting env. episode 1465.000000, reward total was -15.000000. running mean: -18.042131\n",
            "resetting env. episode 1466.000000, reward total was -21.000000. running mean: -18.071710\n",
            "resetting env. episode 1467.000000, reward total was -20.000000. running mean: -18.090993\n",
            "resetting env. episode 1468.000000, reward total was -17.000000. running mean: -18.080083\n",
            "resetting env. episode 1469.000000, reward total was -16.000000. running mean: -18.059282\n",
            "resetting env. episode 1470.000000, reward total was -19.000000. running mean: -18.068689\n",
            "resetting env. episode 1471.000000, reward total was -20.000000. running mean: -18.088002\n",
            "resetting env. episode 1472.000000, reward total was -20.000000. running mean: -18.107122\n",
            "resetting env. episode 1473.000000, reward total was -19.000000. running mean: -18.116051\n",
            "resetting env. episode 1474.000000, reward total was -18.000000. running mean: -18.114891\n",
            "resetting env. episode 1475.000000, reward total was -17.000000. running mean: -18.103742\n",
            "resetting env. episode 1476.000000, reward total was -19.000000. running mean: -18.112704\n",
            "resetting env. episode 1477.000000, reward total was -15.000000. running mean: -18.081577\n",
            "resetting env. episode 1478.000000, reward total was -21.000000. running mean: -18.110762\n",
            "resetting env. episode 1479.000000, reward total was -16.000000. running mean: -18.089654\n",
            "resetting env. episode 1480.000000, reward total was -18.000000. running mean: -18.088757\n",
            "resetting env. episode 1481.000000, reward total was -20.000000. running mean: -18.107870\n",
            "resetting env. episode 1482.000000, reward total was -17.000000. running mean: -18.096791\n",
            "resetting env. episode 1483.000000, reward total was -13.000000. running mean: -18.045823\n",
            "resetting env. episode 1484.000000, reward total was -17.000000. running mean: -18.035365\n",
            "resetting env. episode 1485.000000, reward total was -19.000000. running mean: -18.045011\n",
            "resetting env. episode 1486.000000, reward total was -19.000000. running mean: -18.054561\n",
            "resetting env. episode 1487.000000, reward total was -17.000000. running mean: -18.044016\n",
            "resetting env. episode 1488.000000, reward total was -19.000000. running mean: -18.053575\n",
            "resetting env. episode 1489.000000, reward total was -19.000000. running mean: -18.063040\n",
            "resetting env. episode 1490.000000, reward total was -18.000000. running mean: -18.062409\n",
            "resetting env. episode 1491.000000, reward total was -17.000000. running mean: -18.051785\n",
            "resetting env. episode 1492.000000, reward total was -19.000000. running mean: -18.061267\n",
            "resetting env. episode 1493.000000, reward total was -17.000000. running mean: -18.050655\n",
            "resetting env. episode 1494.000000, reward total was -21.000000. running mean: -18.080148\n",
            "resetting env. episode 1495.000000, reward total was -19.000000. running mean: -18.089347\n",
            "resetting env. episode 1496.000000, reward total was -17.000000. running mean: -18.078453\n",
            "resetting env. episode 1497.000000, reward total was -19.000000. running mean: -18.087669\n",
            "resetting env. episode 1498.000000, reward total was -17.000000. running mean: -18.076792\n",
            "resetting env. episode 1499.000000, reward total was -18.000000. running mean: -18.076024\n",
            "resetting env. episode 1500.000000, reward total was -18.000000. running mean: -18.075264\n",
            "CPU times: user 2h 43min 33s, sys: 50min 37s, total: 3h 34min 10s\n",
            "Wall time: 1h 49min 9s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "play_game(env, model)"
      ],
      "metadata": {
        "id": "CteN7XKMVGqg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "76bb5112-19e8-4196-fb00-6e64126d63ce"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_yNATrbN0W3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZYA0HgMoO77a"
      },
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# pickle.dump(model, open('model.pkl', 'wb'))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Vu9PonFR5NA"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}